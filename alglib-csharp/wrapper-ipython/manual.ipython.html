<html>
<head>
<style type="text/css">
h1              { background-color: #808080; padding: 0.2em; }
h2              { background-color: #B0B0B0; padding: 0.2em; }
h3              { background-color: #E0E0E0; padding: 0.2em; }
sheader         { }
.inlineheader   { background-color: #E8E8E8; padding: 0.1em; font-weight:bold; }
.pagecontent    { font-family: Verdana, Arial, sans-serif; font-size: 1.0em; width: 50em; text-align: justify; }
.pageheader     { width: 50em; }
.source         { font-family: "Courier New"; font-size: 1.0em; }

code            { font-family: monospace; font-size: 1.0em; }


.p_example      { margin-left: 4em; }
.p_note         { margin-left: 50px; margin-right: 50px; font-size: 80%; }
.p_att          { margin-left: 50px; margin-right: 50px; color: red; font-weight: bold; }
.p_code_head    { margin-left: 50px; margin-top: 50px; margin-bottom:    0; padding: 5px; width: 720px; font-family: "Courier New", monospace; background-color: navy; font-weight: bold; color: white;}
.p_code_body    { margin-left: 50px; margin-top:    0; margin-bottom: 50px; padding: 5px; width: 720px; font-family: "Courier New", monospace; background-color: #F0F0F0; }
.p_code         { margin-left: 50px; margin-top: 50px; margin-bottom: 50px; padding: 5px; width: 720px; font-family: "Courier New", monospace; background-color: #F0F0F0; }
.s_code         { font-family: "Courier New"; background-color: #F0F0F0; }
.s_str          { font-family: "Courier New"; color: blue; font-weight: bold; }
.s_comment      { color: navy; font-style: italic; }
.s_preprocessor { color: green; }

a               { color:#000077; text-decoration: underline; }
a:visited       { color:#000077; text-decoration: underline;}
a:hover         { color:#000077; text-decoration: underline; }

a.toc           { color:#000077; text-decoration: none; }
a.toc:visited   { color:#000077; text-decoration: none;}
a.toc:hover     { color:#000077; text-decoration: underline; }

a.nav           { color:#000077; font-weight:bold; text-decoration: none; }
a.nav:visited   { color:#000077; font-weight:bold; text-decoration: none;}
a.nav:hover     { color:#000077; font-weight:bold; text-decoration: underline; }

.cond           { color:blue; }
.const          { color:#222222; }
.func           { color:#111111; }
</style>
</head>
<body>
<pre>
<a href='#int_main'>1 Introduction</a>
    <a href='#int_whatisalglib'>1.1 What is ALGLIB</a>
    <a href='#int_license'>1.2 ALGLIB license</a>
    <a href='#int_doc_license'>1.3 Documentation license</a>
    <a href='#gs_guide'>1.4 Reference Manual and User Guide</a>
    <a href='#int_ack'>1.5 Acknowledgements</a>
<a href='#gs_main'>2 Getting started with ALGLIB</a>
    <a href='#gs_about'>2.1 About ALGLIB for IronPython</a>
    <a href='#gs_compatibility'>2.2 Compatibility</a>
        <a href='#gs_compatibility_interpreter'>2.2.1 Python interpreter</a>
        <a href='#gs_compatibility_compiler'>2.2.2 Other</a>
    <a href='#gs_installing'>2.3 Installing ALGLIB</a>
    <a href='#gs_using_noinst'>2.4 Using ALGLIB without installation</a>
    <a href='#gs_recompiling'>2.5 Recompiling computational core</a>
    <a href='#gs_working_with'>2.6 Working with ALGLIB</a>
        <a href='#gs_datatypes'>2.6.1 Datatypes</a>
        <a href='#gs_functions'>2.6.2 Calling ALGLIB functions</a>
        <a href='#gs_errors'>2.6.3 Handling errors</a>
<a href='#alglib_main'>3 ALGLIB packages and subpackages</a>
    <a href='#pck_AlglibMisc'>3.1 <code>AlglibMisc</code> package</a>
    <a href='#pck_DataAnalysis'>3.2 <code>DataAnalysis</code> package</a>
    <a href='#pck_DiffEquations'>3.3 <code>DiffEquations</code> package</a>
    <a href='#pck_FastTransforms'>3.4 <code>FastTransforms</code> package</a>
    <a href='#pck_Integration'>3.5 <code>Integration</code> package</a>
    <a href='#pck_Interpolation'>3.6 <code>Interpolation</code> package</a>
    <a href='#pck_LinAlg'>3.7 <code>LinAlg</code> package</a>
    <a href='#pck_Optimization'>3.8 <code>Optimization</code> package</a>
    <a href='#pck_Solvers'>3.9 <code>Solvers</code> package</a>
    <a href='#pck_SpecialFunctions'>3.10 <code>SpecialFunctions</code> package</a>
    <a href='#pck_Statistics'>3.11 <code>Statistics</code> package</a>

</pre>
<div class=pagecontent>
<a name='int_main' class='sheader'></a><h1>1 Introduction</h1>

<a name='int_whatisalglib' class='sheader'></a><h2>1.1 What is ALGLIB</h2>

<p align=justify>
ALGLIB is a cross-platform numerical analysis and data mining library.
It supports several programming languages (C++, C#, Java, Delphi, VB.NET, Python) and several operating systems (Windows, *nix family).
</p>

<p align=justify>
ALGLIB features include: 
</p>

<ul>
<li>Data analysis (classification/regression, including neural networks)</li>
<li>Optimization and nonlinear solvers</li>
<li>Interpolation and linear/nonlinear least-squares fitting</li>
<li>Linear algebra (direct algorithms, EVD/SVD), direct and iterative linear solvers, Fast Fourier Transform and many other algorithms (numerical integration, ODEs, statistics, special functions)</li>
</ul>

<p align=justify>
ALGLIB Project (the company behind ALGLIB) delivers to you several editions of ALGLIB:
</p>

<ul>
<li><i>ALGLIB Free Edition</i> - full functionality but limited performance and license</li>
<li><i>ALGLIB Commercial Edition</i> - high-performance version of ALGLIB with business-friendly license</li>
</ul>

<p align=justify>
Free Edition is a serial version without multithreading support and with a limited set of SIMD optimizations.
Commercial Edition is a heavily optimized version of ALGLIB.
It supports multithreading, it is extensively optimized, and (on Intel platforms) -
our commercial users may enjoy a precompiled version of ALGLIB which internally calls Intel MKL to accelerate low-level tasks.
We obtained a license from Intel corp., which allows us to integrate Intel MKL into ALGLIB, so you don't have to get a separate license from Intel.
</p>

<a name='int_license' class='sheader'></a><h2>1.2 ALGLIB license</h2>

<p align=justify>
<b>ALGLIB Free Edition</b> is distributed under license which favors non-commercial usage,
but is not well suited for commercial applications:
</p>

<ul>
<li>
<b>ALGLIB for C++</b> and <b>ALGLIB for C#</b> are distributed under GPL 2+, GPL license version 2 or at your option any later version.
A copy of the GNU General Public License is available at <a href='http://www.fsf.org/licensing/licenses'>http://www.fsf.org/licensing/licenses</a>
</li>
<li>
<b>ALGLIB for Delphi</b> and <b>ALGLIB for CPython</b> are distributed under <a href='http://www.alglib.net/download.php'>ALGLIB Personal and Academic Use License Agreement</a>.
</li>
</ul>

<p align=justify>
<b>ALGLIB Commercial Edition</b> is distributed under license which is friendly to commercial users.
A copy of the commercial license can be found at <a href='http://www.alglib.net/commercial.php'>http://www.alglib.net/commercial.php</a>.
</p>

<a name='int_doc_license' class='sheader'></a><h2>1.3 Documentation license</h2>

<div style='width: 640px;'>
<p>
<U>This reference manual is licensed under BSD-like documentation license</U>:
</p>

<p>
Copyright 1994-2017 Sergey Bochkanov, ALGLIB Project. All rights reserved.
</p>

<p>
Redistribution and use of this document (ALGLIB Reference Manual) with or without modification,
are permitted provided that such redistributions will retain the above copyright notice,
this condition and the following disclaimer as the first (or last) lines of this file.
</p>

<p>
THIS DOCUMENTATION IS PROVIDED BY THE ALGLIB PROJECT "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE ALGLIB PROJECT BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS DOCUMENTATION, EVEN IF ADVISED
OF THE POSSIBILITY OF SUCH DAMAGE.
</p>
</div>

<a name='gs_guide' class='sheader'></a><h2>1.4 Reference Manual and User Guide</h2>

<p>
ALGLIB Project provides two sources of information: ALGLIB Reference Manual (this document) and <a href="http://www.alglib.net/#book">ALGLIB User Guide</a>.
</p>

<p>
ALGLIB Reference Manual contains full description of all publicly accessible ALGLIB units accompanied with examples.
Reference Manual is focused on the source code: it documents units, functions, structures and so on.
If you want to know what unit <code>YYY</code> can do or what subroutines unit <code>ZZZ</code> contains, the Reference Manual is a place to go.
Free software needs free documentation - that's why the ALGLIB Reference Manual is licensed under BSD-like documentation license.
</p>

<p>
Additionally to the Reference Manual we provide you <a href="http://www.alglib.net/#book">User Guide</a>.
User Guide is focused on more general questions: how fast ALGLIB is? how reliable is it? what are the strong and weak sides of the algorithms used?
We aim to make ALGLIB User Guide an important source of information both about ALGLIB and numerical analysis algorithms in general.
We want it to be a book about algorithms, not just software documentation.
And we want it to be unique - that's why the ALGLIB User Guide is distributed under a less-permissive <a href="http://alglib.net.localhost/#guide_license">personal-use-only license</a>.
</p>

<a name='int_ack' class='sheader'></a><h2>1.5 Acknowledgements</h2>

<p>
ALGLIB was not possible without contribution of the following open source projects:
</p>

<ul>
<li><a href="http://www.netlib.org/lapack/">LAPACK</a></li>
<li><a href="http://www.moshier.net/">Cephes</a></li>
<li><a href="http://gmplib.org/">GNU MP</a></li>
<li><a href="http://www.mpfr.org/">MPFR</a></li>
</ul>

<p>
We also want to thank developers of the Intel's evelopment center for their help during MKL integration.
</p>




<a name='gs_main' class='sheader'></a><h1>2 Getting started with ALGLIB</h1>



<a name='gs_about' class='sheader'></a><h2>2.1 About ALGLIB for IronPython</h2>

<p>
ALGLIB for IronPython is an interface to the computational core written in C#.
It includes wrapper module <code>xalglib.py</code> which connects to the ALGLIB assembly.
It is 100% .NET library with 100% safe (using .NET terminology) code.
</p>

<p>
Current version of IronPython wrapper for ALGLIB does not support access to native computational core;
only 100% managed version of ALGLIB can be used with this wrapper.
High performance native ALGLIB can be accessed from C#, but not from IronPython.
</p>

<p>
As non-pure Python library, ALGLIB requires compilation by C# compiler.
However, computational core is distributed in the precompiled form, so you have to compile it only when you change something.
And (that's .NET!) you can use this precompiled core on <i>any</i> platform .NET supports without recompilation.
</p>

<a name='gs_compatibility' class='sheader'></a><h2>2.2 Compatibility</h2>

<a name='gs_compatibility_interpreter' class='sheader'></a><h3>2.2.1 Python interpreter</h3>

<p>
ALGLIB for IronPython is compatible with any IronPython version since 2.6
</p>

<a name='gs_compatibility_compiler' class='sheader'></a><h3>2.2.2 Other</h3>

<p>
Being non-pure Python library, ALGLIB needs C# compiler if you want to recompile computational core.
ALGLIB computational core is compatible with:
</p>

<ul>
<li>any kind of optimization settings</li>
<li>any CPU which supports .NET</li>
<li>both Microsoft-provided implementation of .NET framework (2.0 or higher) and open source implementation of .NET (Mono).</li>
<li>any C# compiler which support C# 2.0 or later (MS C# compiler or Mono C# compiler)</li>
<li>any OS where .NET framework exists</li>
</ul>

<a name='gs_installing' class='sheader'></a><h2>2.3 Installing ALGLIB</h2>

<p>
IronPython doesn't support distutils installation, so you have to install ALGLIB manually:
</p>

<ul>
<li>copy <code>xalglib.py</code> to the site-packages directory</li>
<li>copy <code>alglibnet2.dll</code> (.NET assembly) to the Python root
</ul>

<p>
These steps are same for any platform which supports NET.
You don't have to build computational core on your platform or to do some platform-specific setup - just copy these files.
</p>

<a name='gs_using_noinst' class='sheader'></a><h2>2.4 Using ALGLIB without installation</h2>

<p>
Sometimes you may need to use ALGLIB without installation. For example, you may want to create self-contained Python library or simply don't have root access to your system.
If you want to do so:
</p>

<ul>
<li>
copy <code>xalglib.py</code> to the directory of your choice
</li>
<li>
copy precompiled computational core <code>alglib.dll</code> to the directory where you've copied <code>xalglib.py</code>
</li>
<li>
import <code>xalglib.py</code> from your Python program - it will detect presense of <code>alglib.dll</code> in the same directory and load it.
</li>
</ul>

<a name='gs_recompiling' class='sheader'></a><h2>2.5 Recompiling computational core</h2>

<p>
ALGLIB computational core is just a C# version of ALGLIB which is distributed in the precompiled form.
This precompiled assembly may be used with any version of NET framework, so it doesn't need recompilation when you port ALGLIB to another platform.
</p>

<p>
Source code of computational core is located in the <code>core</code> subdirectory of ALGLIB distribution.
If for some reason you want to recompile it, it is really simple to do: 
</p>

<ul>
<li>
<code>cd</code> into <code>core</code> directory
</li>
<li>
execute <span class='s_code'>csc.exe /t:library /out:alglibnet2.dll /optimize+ *.cs</span> (or invoke Mono compiler with similar arguments)
</li>
<li>
copy <code>alglibnet2.dll</code> to the main directory of ALGLIB distribution
</li>
</ul>


<a name='gs_working_with' class='sheader'></a><h2>2.6 Working with ALGLIB</h2>

<a name='gs_datatypes' class='sheader'></a><h3>2.6.1 Datatypes</h3>

<p>
Following datatypes can be used with ALGLIB functions:
</p>

<ul>
<li>scalar types - boolean, integer, real, complex</li>
<li>lists (interpreted as vectors)</li>
<li>lists of lists (interpreted as matrices)</li>
<li>1D and 2D ndarray's (including 1D and 2D slices of multidimensional arrays)</li>
<li>classes</li>
</ul>

<p>
ALGLIB functions use Python lists and ndarrays to <i>accept</i> and <i>return</i> vectors.
A vector can be boolean, integer, real or complex.
If ALGLIB function expects integer vector, you can't pass a list with real elements (an exception will be thrown in such cases).
Contrary, function which expects real vector can process list whose elements are integers (i.e. <span class='s_code'>[1.0, 2.0]</span> and <span class='s_code'>[1,2]</span> are considered same).
</p>

<p>
Lists of lists and two-dimensional ndarrays are used to accept and return matrices.
Just like vectors, matrices can be boolean, integer, real or complex.
List of lists is a valid matrix if it has a rectangular form.
</p>

<pre class='p_example'>
<span style='color: darkcyan;'># valid matrices</span>
v0 = [[]]
v1 = [[1],[2]]
v2 = [[1,2]]
v3 = [[1,2],[3,4]]

<span style='color: darkcyan;'># invalid matrices</span>
i0 = [[1],[1,2]]
i1 = ["string"]
</pre>

<p>
ALGLIB package contains many classes that can be divided into two distinct groups: "transparent" classes, i.e. classes whose fields are publicly accessible,
and "handle" classes, which do not have publicly accessible fields at all.
</p>

<p>
"Transparent" classes are mostly used to report algorithm results.
One common idiom is for algorithm to return both solution and structure which contains additional information (iterations count, stopping criterion met, etc.).
"Transparent" classes are 100% transparent - there is no private fields and no pointers to "external" objects (i.e. objects which are not part of Python data model).
</p>

<p>
"Handle" classes represent another programming idiom - opaque pointer.
Contrary to "transparent" classes, they have no public fields and you should use ALGLIB functions to work with them.
"Handle" classes are used to work with complex structures managed by ALGLIB environment - optimizers, solvers, neural networks.
Instance of "handle" class stores only a pointer to the external object (in CPython it is native object accesed through <code>ctypes</code>, and IronPython it is C# object).
Instances of "handle" class are created by calling corresponding ALGLIB functions and are automatically freed when there are no references to them.
They are "pointer-like", i.e. multiple copies of Python wrapper object actually point to the same ALGLIB object.
</p>

<a name='gs_functions' class='sheader'></a><h3>2.6.2 Calling ALGLIB functions</h3>

<p>
All ALGLIB functionality can be accessed through a single module, <code>xalglib.py</code>, which should be imported before you start using ALGLIB.
</p>

<p>
ALGLIB follows consistent conventions regarding function parameters and their handling.
Parameters can be divided into the following types:
</p>

<ul>
<li>
<b>Input parameters</b> include basic types (booleans, integers, floats and complex numbers) and read-only instances of vectors and matrices.
The latter includes both lists (list of lists) and 1D/2D instances of ndarrays.
</li>
<li>
<b>In-place input/output parameters</b> are parameters that have an initial value modified by ALGLIB without allocating a new instance of an object.
This includes vectors (lists and 1D ndarrays), matrices (lists of lists, 2D ndarrays), transparent classes, and handle (opaque pointer-like) classes.
For example, the <code>xalglib.rmatrixinverse</code> function replaces the original matrix with its inverse of the same size.
Another example are ALGLIB functions which modify the internal state of an ALGLIB object, e.g., pass constraints to an optimizer.
Finally, this also includes situations where the initial value of a vector/matrix/object is simply a preallocated buffer to store the output.
An example is <code>sparsecopybuf</code> which copies a sparse matrix, rewriting and reusing previously allocated storage in the target variable.
</li>
<li>
<b>Output parameters</b>, i.e. parameters with no initial value.
This includes basic types, vectors/matrices, transparent and handle classes.
Due to Python's syntax, such parameters are not included in the formal parameters list.
As of ALGLIB 4.03, vectors and matrices are always returned as lists (lists of lists).
</li>
<li>
<b>Out-of-place input/output parameters</b> are parameters with an initial value that is modified by ALGLIB,
with the modified value being returned separately instead of rewriting the reference passed to a function.
This includes basic types (due to Python limitations it is impossible to modify them in-place)
and vectors/matrices (when resized by the callee).
As of ALGLIB 4.03, vectors/matrices can be accepted as either lists or ndarrays, but are always returned as lists (lists of lists).
</li>
</ul>

<p>
Depending on the number of non-inplace values returned, ALGLIB functions can be divided into three categories:
</p>

<ul>
<li>
<b>Functions with no return value</b>, including functions with in-place input/output parameters.
This includes most linear algebra functions or functions that are used to change an internal state of an ALGLIB object.
</li>
<li><b>Functions that return only one out-of-place value</b>,
including functions with multiple in-place input/output parameters which have one and only one output (or out-of-place input/output) parameter.
The output parameter is returned as usual.
</li>
<li><b>Functions that return multiple values</b>. These functions return multiple values packed into a tuple.
</li>
</ul>

<p>
An example:
</p>

<pre class='p_example'>
import xalglib

def function1_grad(x, grad, param):
    func = 100*(x[0]+3)**4 + (x[1]-3)**4
    grad[0] = 400*(x[0]+3)**3
    grad[1] = 4*(x[1]-3)**3
    return func

<span style='color: darkcyan;'># L-BFGS optimizer with m=2 is created, one result is returned</span>
s = xalglib.minlbfgscreate(2,[0,0,0])

<span style='color: darkcyan;'># function with no output values is called</span>
xalglib.minlbfgssetcond(state, 0, 0, 0, 10)

<span style='color: darkcyan;'># some optimization code here </span>
xalglib.minlbfgsoptimize_g(state, function1_grad)

<span style='color: darkcyan;'># and, finally, call to function with multiple outputs </span>
x, rep = xalglib.minlbfgsresults(state)
</pre>

<p>
Most ALGLIB functions provide two interfaces: 'expert' and 'friendly'.
What is the difference between two?
When you use 'friendly' interface, ALGLIB:
</p>

<ul>
<li>tries to automatically determine size of input arguments</li>
<li>throws an exception when arguments have inconsistent size (for example, square matrix is expected, but non-square is passed;
another example - two parameters must have same size, but have different size)</li>
</ul>

<p>
When you use 'expert' interface, ALGLIB requires caller to explicitly specify size of input arguments.
If vector/matrix is larger than size being specified (say, N), only N leading elements are used.
</p>

<p>
Here are several examples of 'friendly' and 'expert' interfaces:
</p>

<pre class='p_example'>
import xalglib

x  = [0,1,2,3]
y  = [1,5,3,9]
y2 = [1,5,3,9,0]


s = xalglib.spline1dbuildlinear(x, y, 4) <span style='color: darkcyan;'># 'expert' interface is used, we passed the number of points</span>
s = alglib.spline1dbuildlinear(x, y)     <span style='color: darkcyan;'># 'friendly' interface - input size is</span>
                                         <span style='color: darkcyan;'># automatically determined</span>

s = alglib.spline1dbuildlinear(x, y2, 4) <span style='color: darkcyan;'># y2.length() is 5 (larger then len(x)), but it will work</span>

s = alglib.spline1dbuildlinear(x, y2)    <span style='color: darkcyan;'># it won't work because sizes of x and y2</span>
                                         <span style='color: darkcyan;'># are inconsistent</span>
</pre>

<a name='gs_errors' class='sheader'></a><h3>2.6.3 Handling errors</h3>

<p>
ALGLIB uses two error handling strategies:
</p>

<ul>
<li>returning error code</li>
<li>throwing exception</li>
</ul>

<p>
What is actually done depends on function being used and error being reported:
</p>

<ol>
<li>if function returns some error code <b>and</b> has corresponding value for this kind of error, ALLGIB returns error code</li>
<li>if function does not return error code (or returns error code, but there is no code for error being reported), ALGLIB throws <code>RuntimeError</code> exception.</li>
<li>if it is some very basis error in the inputs, like expecting to get matrix and getting scalar instead, <code>ValueError</code> will be thrown.</li>
</ol>

<p>
To make things clear we consider several examples of error handling.
</p>

<p>
<u>Example 1</u>. <a href="#sub_mincgcreate">mincgreate</a> function creates nonlinear CG optimizer. It accepts problem size <code>N</code> and initial point <code>X</code>.
Several things can go wrong - you may pass array which is too short, filled by NAN's, or otherwise pass incorrect data.
However, this function returns no error code - so it throws an exception in case something goes wrong.
There is no other way to tell caller that something went wrong.
</p>

<p>
<u>Example 2</u>. <a href="#sub_rmatrixinverse">rmatrixinverse</a> function calculates inverse matrix.
It returns error code, which is set to <code>+1</code> when problem is solved and is set to <code>-3</code> if singular matrix was passed to the function.
However, there is no error code for matrix which is non-square or contains infinities.
Well, we could have created corresponding error codes - but we didn't.
So if you pass singular matrix to <code>rmatrixinverse</code>, you will get completion code <code>-3</code>.
But if you pass matrix which contains INF in one of its elements, <code>alglib.ap_error</code> will be thrown.
</p>

<p>
First error handling strategy (error codes) is used to report "frequent" errors, which can occur during normal execution of user program.
Second error handling strategy (exceptions) is used to report "rare" errors which are result of serious flaws in your program (or ALGLIB) - 
infinities/NAN's in the inputs, inconsistent inputs, etc.
</p>


</div>
<a name='alglib_main' class='sheader'></a><h1>3 ALGLIB packages and subpackages</h1>
<table border=0 cellspacing=0>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8>
<a name='pck_AlglibMisc' class='sheader'></a><h2>3.1 <code>AlglibMisc</code> package</h2>
</td></tr>
<tr align=left valign=top><td><a href='#unit_hqrnd' class=toc>hqrnd</a></td><td width=15>&nbsp;</td><td>High quality random numbers generator</td></tr>
<tr align=left valign=top><td><a href='#unit_nearestneighbor' class=toc>nearestneighbor</a></td><td width=15>&nbsp;</td><td>Nearest neighbor search: approximate and exact</td></tr>
<tr align=left valign=top><td><a href='#unit_xdebug' class=toc>xdebug</a></td><td width=15>&nbsp;</td><td>Debug functions to test ALGLIB interface generator </td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8>
<a name='pck_DataAnalysis' class='sheader'></a><h2>3.2 <code>DataAnalysis</code> package</h2>
</td></tr>
<tr align=left valign=top><td><a href='#unit_bdss' class=toc>bdss</a></td><td width=15>&nbsp;</td><td>Basic dataset functions</td></tr>
<tr align=left valign=top><td><a href='#unit_clustering' class=toc>clustering</a></td><td width=15>&nbsp;</td><td>Clustering functions (hierarchical, k-means, k-means++)</td></tr>
<tr align=left valign=top><td><a href='#unit_datacomp' class=toc>datacomp</a></td><td width=15>&nbsp;</td><td>Backward compatibility functions</td></tr>
<tr align=left valign=top><td><a href='#unit_dforest' class=toc>dforest</a></td><td width=15>&nbsp;</td><td>Decision forest classifier (regression model)</td></tr>
<tr align=left valign=top><td><a href='#unit_filters' class=toc>filters</a></td><td width=15>&nbsp;</td><td>Different filters used in data analysis</td></tr>
<tr align=left valign=top><td><a href='#unit_knn' class=toc>knn</a></td><td width=15>&nbsp;</td><td>K Nearest Neighbors classification/regression</td></tr>
<tr align=left valign=top><td><a href='#unit_lda' class=toc>lda</a></td><td width=15>&nbsp;</td><td>Linear discriminant analysis</td></tr>
<tr align=left valign=top><td><a href='#unit_linreg' class=toc>linreg</a></td><td width=15>&nbsp;</td><td>Linear models</td></tr>
<tr align=left valign=top><td><a href='#unit_logit' class=toc>logit</a></td><td width=15>&nbsp;</td><td>Logit models</td></tr>
<tr align=left valign=top><td><a href='#unit_mcpd' class=toc>mcpd</a></td><td width=15>&nbsp;</td><td>Markov Chains for Population/proportional Data</td></tr>
<tr align=left valign=top><td><a href='#unit_mlpbase' class=toc>mlpbase</a></td><td width=15>&nbsp;</td><td>Basic functions for neural networks</td></tr>
<tr align=left valign=top><td><a href='#unit_mlpe' class=toc>mlpe</a></td><td width=15>&nbsp;</td><td>Basic functions for neural ensemble models</td></tr>
<tr align=left valign=top><td><a href='#unit_mlptrain' class=toc>mlptrain</a></td><td width=15>&nbsp;</td><td>Neural network training</td></tr>
<tr align=left valign=top><td><a href='#unit_pca' class=toc>pca</a></td><td width=15>&nbsp;</td><td>Principal component analysis</td></tr>
<tr align=left valign=top><td><a href='#unit_ssa' class=toc>ssa</a></td><td width=15>&nbsp;</td><td>Singular Spectrum Analysis</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8>
<a name='pck_DiffEquations' class='sheader'></a><h2>3.3 <code>DiffEquations</code> package</h2>
</td></tr>
<tr align=left valign=top><td><a href='#unit_odesolver' class=toc>odesolver</a></td><td width=15>&nbsp;</td><td>Ordinary differential equation solver</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8>
<a name='pck_FastTransforms' class='sheader'></a><h2>3.4 <code>FastTransforms</code> package</h2>
</td></tr>
<tr align=left valign=top><td><a href='#unit_conv' class=toc>conv</a></td><td width=15>&nbsp;</td><td>Fast real/complex convolution</td></tr>
<tr align=left valign=top><td><a href='#unit_corr' class=toc>corr</a></td><td width=15>&nbsp;</td><td>Fast real/complex cross-correlation</td></tr>
<tr align=left valign=top><td><a href='#unit_fft' class=toc>fft</a></td><td width=15>&nbsp;</td><td>Real/complex FFT</td></tr>
<tr align=left valign=top><td><a href='#unit_fht' class=toc>fht</a></td><td width=15>&nbsp;</td><td>Real Fast Hartley Transform</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8>
<a name='pck_Integration' class='sheader'></a><h2>3.5 <code>Integration</code> package</h2>
</td></tr>
<tr align=left valign=top><td><a href='#unit_autogk' class=toc>autogk</a></td><td width=15>&nbsp;</td><td>Adaptive 1-dimensional integration</td></tr>
<tr align=left valign=top><td><a href='#unit_gkq' class=toc>gkq</a></td><td width=15>&nbsp;</td><td>Gauss-Kronrod quadrature generator</td></tr>
<tr align=left valign=top><td><a href='#unit_gq' class=toc>gq</a></td><td width=15>&nbsp;</td><td>Gaussian quadrature generator</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8>
<a name='pck_Interpolation' class='sheader'></a><h2>3.6 <code>Interpolation</code> package</h2>
</td></tr>
<tr align=left valign=top><td><a href='#unit_fitsphere' class=toc>fitsphere</a></td><td width=15>&nbsp;</td><td>Fitting circle/sphere to data (least squares, minimum circumscribed, maximum inscribed, minimum zone)</td></tr>
<tr align=left valign=top><td><a href='#unit_idw' class=toc>idw</a></td><td width=15>&nbsp;</td><td>Inverse distance weighting: interpolation/fitting with improved Shepard-like algorithm</td></tr>
<tr align=left valign=top><td><a href='#unit_intcomp' class=toc>intcomp</a></td><td width=15>&nbsp;</td><td>Backward compatibility functions</td></tr>
<tr align=left valign=top><td><a href='#unit_lsfit' class=toc>lsfit</a></td><td width=15>&nbsp;</td><td>Fitting with least squates target function (linear and nonlinear least-squares)</td></tr>
<tr align=left valign=top><td><a href='#unit_parametric' class=toc>parametric</a></td><td width=15>&nbsp;</td><td>Parametric curves</td></tr>
<tr align=left valign=top><td><a href='#unit_polint' class=toc>polint</a></td><td width=15>&nbsp;</td><td>Polynomial interpolation/fitting</td></tr>
<tr align=left valign=top><td><a href='#unit_ratint' class=toc>ratint</a></td><td width=15>&nbsp;</td><td>Rational interpolation/fitting</td></tr>
<tr align=left valign=top><td><a href='#unit_rbf' class=toc>rbf</a></td><td width=15>&nbsp;</td><td>Scattered N-dimensional interpolation with RBF models</td></tr>
<tr align=left valign=top><td><a href='#unit_spline1d' class=toc>spline1d</a></td><td width=15>&nbsp;</td><td>1D spline interpolation/fitting</td></tr>
<tr align=left valign=top><td><a href='#unit_spline2d' class=toc>spline2d</a></td><td width=15>&nbsp;</td><td>2D spline interpolation and fitting</td></tr>
<tr align=left valign=top><td><a href='#unit_spline3d' class=toc>spline3d</a></td><td width=15>&nbsp;</td><td>3D spline interpolation</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8>
<a name='pck_LinAlg' class='sheader'></a><h2>3.7 <code>LinAlg</code> package</h2>
</td></tr>
<tr align=left valign=top><td><a href='#unit_ablas' class=toc>ablas</a></td><td width=15>&nbsp;</td><td>Level 2 and Level 3 BLAS operations</td></tr>
<tr align=left valign=top><td><a href='#unit_bdsvd' class=toc>bdsvd</a></td><td width=15>&nbsp;</td><td>Bidiagonal SVD</td></tr>
<tr align=left valign=top><td><a href='#unit_evd' class=toc>evd</a></td><td width=15>&nbsp;</td><td>Direct and iterative eigensolvers</td></tr>
<tr align=left valign=top><td><a href='#unit_inverseupdate' class=toc>inverseupdate</a></td><td width=15>&nbsp;</td><td>Sherman-Morrison update of the inverse matrix</td></tr>
<tr align=left valign=top><td><a href='#unit_matdet' class=toc>matdet</a></td><td width=15>&nbsp;</td><td>Determinant calculation</td></tr>
<tr align=left valign=top><td><a href='#unit_matgen' class=toc>matgen</a></td><td width=15>&nbsp;</td><td>Random matrix generation</td></tr>
<tr align=left valign=top><td><a href='#unit_matinv' class=toc>matinv</a></td><td width=15>&nbsp;</td><td>Matrix inverse</td></tr>
<tr align=left valign=top><td><a href='#unit_normestimator' class=toc>normestimator</a></td><td width=15>&nbsp;</td><td>Estimates norm of the sparse matrix (from below)</td></tr>
<tr align=left valign=top><td><a href='#unit_ortfac' class=toc>ortfac</a></td><td width=15>&nbsp;</td><td>Real/complex QR/LQ, bi(tri)diagonal, Hessenberg decompositions</td></tr>
<tr align=left valign=top><td><a href='#unit_rcond' class=toc>rcond</a></td><td width=15>&nbsp;</td><td>Condition number estimates</td></tr>
<tr align=left valign=top><td><a href='#unit_schur' class=toc>schur</a></td><td width=15>&nbsp;</td><td>Schur decomposition</td></tr>
<tr align=left valign=top><td><a href='#unit_sparse' class=toc>sparse</a></td><td width=15>&nbsp;</td><td>Sparse matrices</td></tr>
<tr align=left valign=top><td><a href='#unit_spdgevd' class=toc>spdgevd</a></td><td width=15>&nbsp;</td><td>Generalized symmetric eigensolver</td></tr>
<tr align=left valign=top><td><a href='#unit_svd' class=toc>svd</a></td><td width=15>&nbsp;</td><td>Singular value decomposition</td></tr>
<tr align=left valign=top><td><a href='#unit_trfac' class=toc>trfac</a></td><td width=15>&nbsp;</td><td>LU and Cholesky decompositions (dense and sparse)</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8>
<a name='pck_Optimization' class='sheader'></a><h2>3.8 <code>Optimization</code> package</h2>
</td></tr>
<tr align=left valign=top><td><a href='#unit_minbc' class=toc>minbc</a></td><td width=15>&nbsp;</td><td>Box constrained optimizer with fast activation of multiple constraints per step</td></tr>
<tr align=left valign=top><td><a href='#unit_minbleic' class=toc>minbleic</a></td><td width=15>&nbsp;</td><td>Bound constrained optimizer with additional linear equality/inequality constraints </td></tr>
<tr align=left valign=top><td><a href='#unit_mincg' class=toc>mincg</a></td><td width=15>&nbsp;</td><td>Conjugate gradient optimizer</td></tr>
<tr align=left valign=top><td><a href='#unit_mincomp' class=toc>mincomp</a></td><td width=15>&nbsp;</td><td>Backward compatibility functions</td></tr>
<tr align=left valign=top><td><a href='#unit_mindf' class=toc>mindf</a></td><td width=15>&nbsp;</td><td>Derivative-free and global optimization </td></tr>
<tr align=left valign=top><td><a href='#unit_minlbfgs' class=toc>minlbfgs</a></td><td width=15>&nbsp;</td><td>Limited memory BFGS optimizer</td></tr>
<tr align=left valign=top><td><a href='#unit_minlm' class=toc>minlm</a></td><td width=15>&nbsp;</td><td>Improved Levenberg-Marquardt optimizer</td></tr>
<tr align=left valign=top><td><a href='#unit_minlp' class=toc>minlp</a></td><td width=15>&nbsp;</td><td>Linear programming suite </td></tr>
<tr align=left valign=top><td><a href='#unit_minmo' class=toc>minmo</a></td><td width=15>&nbsp;</td><td>Multi-objective optimizer</td></tr>
<tr align=left valign=top><td><a href='#unit_minnlc' class=toc>minnlc</a></td><td width=15>&nbsp;</td><td>Nonlinear programming solver (analytic gradient, numdiff, model-based DFO)</td></tr>
<tr align=left valign=top><td><a href='#unit_minns' class=toc>minns</a></td><td width=15>&nbsp;</td><td>Nonsmooth constrained optimizer </td></tr>
<tr align=left valign=top><td><a href='#unit_minqp' class=toc>minqp</a></td><td width=15>&nbsp;</td><td>Quadratic optimization with linear, quadratic and conic constraints </td></tr>
<tr align=left valign=top><td><a href='#unit_nls' class=toc>nls</a></td><td width=15>&nbsp;</td><td>Nonlinear least squares (derivative-free)</td></tr>
<tr align=left valign=top><td><a href='#unit_optguardapi' class=toc>optguardapi</a></td><td width=15>&nbsp;</td><td>OptGuard integrity checking for nonlinear models </td></tr>
<tr align=left valign=top><td><a href='#unit_opts' class=toc>opts</a></td><td width=15>&nbsp;</td><td>Internal service functions </td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8>
<a name='pck_Solvers' class='sheader'></a><h2>3.9 <code>Solvers</code> package</h2>
</td></tr>
<tr align=left valign=top><td><a href='#unit_directdensesolvers' class=toc>directdensesolvers</a></td><td width=15>&nbsp;</td><td>Direct dense linear solvers</td></tr>
<tr align=left valign=top><td><a href='#unit_directsparsesolvers' class=toc>directsparsesolvers</a></td><td width=15>&nbsp;</td><td>Direct sparse linear solvers</td></tr>
<tr align=left valign=top><td><a href='#unit_iterativesparse' class=toc>iterativesparse</a></td><td width=15>&nbsp;</td><td>Sparse linear iterative solvers (GMRES)</td></tr>
<tr align=left valign=top><td><a href='#unit_lincg' class=toc>lincg</a></td><td width=15>&nbsp;</td><td>Sparse linear CG solver</td></tr>
<tr align=left valign=top><td><a href='#unit_linlsqr' class=toc>linlsqr</a></td><td width=15>&nbsp;</td><td>Sparse linear LSQR solver</td></tr>
<tr align=left valign=top><td><a href='#unit_nleq' class=toc>nleq</a></td><td width=15>&nbsp;</td><td>Solvers for nonlinear equations</td></tr>
<tr align=left valign=top><td><a href='#unit_polynomialsolver' class=toc>polynomialsolver</a></td><td width=15>&nbsp;</td><td>Polynomial solver</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8>
<a name='pck_SpecialFunctions' class='sheader'></a><h2>3.10 <code>SpecialFunctions</code> package</h2>
</td></tr>
<tr align=left valign=top><td><a href='#unit_airyf' class=toc>airyf</a></td><td width=15>&nbsp;</td><td>Airy functions</td></tr>
<tr align=left valign=top><td><a href='#unit_bessel' class=toc>bessel</a></td><td width=15>&nbsp;</td><td>Bessel functions</td></tr>
<tr align=left valign=top><td><a href='#unit_betaf' class=toc>betaf</a></td><td width=15>&nbsp;</td><td>Beta function</td></tr>
<tr align=left valign=top><td><a href='#unit_binomialdistr' class=toc>binomialdistr</a></td><td width=15>&nbsp;</td><td>Binomial distribution</td></tr>
<tr align=left valign=top><td><a href='#unit_chebyshev' class=toc>chebyshev</a></td><td width=15>&nbsp;</td><td>Chebyshev polynomials</td></tr>
<tr align=left valign=top><td><a href='#unit_chisquaredistr' class=toc>chisquaredistr</a></td><td width=15>&nbsp;</td><td>Chi-Square distribution</td></tr>
<tr align=left valign=top><td><a href='#unit_dawson' class=toc>dawson</a></td><td width=15>&nbsp;</td><td>Dawson integral</td></tr>
<tr align=left valign=top><td><a href='#unit_elliptic' class=toc>elliptic</a></td><td width=15>&nbsp;</td><td>Elliptic integrals</td></tr>
<tr align=left valign=top><td><a href='#unit_expintegrals' class=toc>expintegrals</a></td><td width=15>&nbsp;</td><td>Exponential integrals</td></tr>
<tr align=left valign=top><td><a href='#unit_fdistr' class=toc>fdistr</a></td><td width=15>&nbsp;</td><td>F-distribution</td></tr>
<tr align=left valign=top><td><a href='#unit_fresnel' class=toc>fresnel</a></td><td width=15>&nbsp;</td><td>Fresnel integrals</td></tr>
<tr align=left valign=top><td><a href='#unit_gammafunc' class=toc>gammafunc</a></td><td width=15>&nbsp;</td><td>Gamma function</td></tr>
<tr align=left valign=top><td><a href='#unit_hermite' class=toc>hermite</a></td><td width=15>&nbsp;</td><td>Hermite polynomials</td></tr>
<tr align=left valign=top><td><a href='#unit_ibetaf' class=toc>ibetaf</a></td><td width=15>&nbsp;</td><td>Incomplete beta function</td></tr>
<tr align=left valign=top><td><a href='#unit_igammaf' class=toc>igammaf</a></td><td width=15>&nbsp;</td><td>Incomplete gamma function</td></tr>
<tr align=left valign=top><td><a href='#unit_jacobianelliptic' class=toc>jacobianelliptic</a></td><td width=15>&nbsp;</td><td>Jacobian elliptic functions</td></tr>
<tr align=left valign=top><td><a href='#unit_laguerre' class=toc>laguerre</a></td><td width=15>&nbsp;</td><td>Laguerre polynomials</td></tr>
<tr align=left valign=top><td><a href='#unit_legendre' class=toc>legendre</a></td><td width=15>&nbsp;</td><td>Legendre polynomials</td></tr>
<tr align=left valign=top><td><a href='#unit_normaldistr' class=toc>normaldistr</a></td><td width=15>&nbsp;</td><td>Univarite and bivariate normal distribution PDF and CDF</td></tr>
<tr align=left valign=top><td><a href='#unit_poissondistr' class=toc>poissondistr</a></td><td width=15>&nbsp;</td><td>Poisson distribution</td></tr>
<tr align=left valign=top><td><a href='#unit_psif' class=toc>psif</a></td><td width=15>&nbsp;</td><td>Psi function</td></tr>
<tr align=left valign=top><td><a href='#unit_studenttdistr' class=toc>studenttdistr</a></td><td width=15>&nbsp;</td><td>Student's t-distribution</td></tr>
<tr align=left valign=top><td><a href='#unit_trigintegrals' class=toc>trigintegrals</a></td><td width=15>&nbsp;</td><td>Trigonometric integrals</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8>
<a name='pck_Statistics' class='sheader'></a><h2>3.11 <code>Statistics</code> package</h2>
</td></tr>
<tr align=left valign=top><td><a href='#unit_basestat' class=toc>basestat</a></td><td width=15>&nbsp;</td><td>Mean, variance, covariance, correlation, etc.</td></tr>
<tr align=left valign=top><td><a href='#unit_correlationtests' class=toc>correlationtests</a></td><td width=15>&nbsp;</td><td>Hypothesis testing: correlation tests</td></tr>
<tr align=left valign=top><td><a href='#unit_jarquebera' class=toc>jarquebera</a></td><td width=15>&nbsp;</td><td>Hypothesis testing: Jarque-Bera test</td></tr>
<tr align=left valign=top><td><a href='#unit_mannwhitneyu' class=toc>mannwhitneyu</a></td><td width=15>&nbsp;</td><td>Hypothesis testing: Mann-Whitney-U test</td></tr>
<tr align=left valign=top><td><a href='#unit_stest' class=toc>stest</a></td><td width=15>&nbsp;</td><td>Hypothesis testing: sign test</td></tr>
<tr align=left valign=top><td><a href='#unit_studentttests' class=toc>studentttests</a></td><td width=15>&nbsp;</td><td>Hypothesis testing: Student's t-test</td></tr>
<tr align=left valign=top><td><a href='#unit_variancetests' class=toc>variancetests</a></td><td width=15>&nbsp;</td><td>Hypothesis testing: F-test and one-sample variance test</td></tr>
<tr align=left valign=top><td><a href='#unit_wsr' class=toc>wsr</a></td><td width=15>&nbsp;</td><td>Hypothesis testing: Wilcoxon signed rank test</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
</table>
<a name=unit_ablas></a><h2 class=pageheader><code>ablas</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cmatrixcopy' class=toc>cmatrixcopy</a><br>
<a href='#sub_cmatrixgemm' class=toc>cmatrixgemm</a><br>
<a href='#sub_cmatrixherk' class=toc>cmatrixherk</a><br>
<a href='#sub_cmatrixlefttrsm' class=toc>cmatrixlefttrsm</a><br>
<a href='#sub_cmatrixmv' class=toc>cmatrixmv</a><br>
<a href='#sub_cmatrixrank1' class=toc>cmatrixrank1</a><br>
<a href='#sub_cmatrixrighttrsm' class=toc>cmatrixrighttrsm</a><br>
<a href='#sub_cmatrixsyrk' class=toc>cmatrixsyrk</a><br>
<a href='#sub_cmatrixtranspose' class=toc>cmatrixtranspose</a><br>
<a href='#sub_rmatrixcopy' class=toc>rmatrixcopy</a><br>
<a href='#sub_rmatrixenforcesymmetricity' class=toc>rmatrixenforcesymmetricity</a><br>
<a href='#sub_rmatrixgemm' class=toc>rmatrixgemm</a><br>
<a href='#sub_rmatrixgemv' class=toc>rmatrixgemv</a><br>
<a href='#sub_rmatrixgencopy' class=toc>rmatrixgencopy</a><br>
<a href='#sub_rmatrixger' class=toc>rmatrixger</a><br>
<a href='#sub_rmatrixlefttrsm' class=toc>rmatrixlefttrsm</a><br>
<a href='#sub_rmatrixmv' class=toc>rmatrixmv</a><br>
<a href='#sub_rmatrixrank1' class=toc>rmatrixrank1</a><br>
<a href='#sub_rmatrixrighttrsm' class=toc>rmatrixrighttrsm</a><br>
<a href='#sub_rmatrixsymv' class=toc>rmatrixsymv</a><br>
<a href='#sub_rmatrixsyrk' class=toc>rmatrixsyrk</a><br>
<a href='#sub_rmatrixsyvmv' class=toc>rmatrixsyvmv</a><br>
<a href='#sub_rmatrixtranspose' class=toc>rmatrixtranspose</a><br>
<a href='#sub_rmatrixtrsv' class=toc>rmatrixtrsv</a><br>
<a href='#sub_rvectorcopy' class=toc>rvectorcopy</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_cmatrixcopy'></a><h3 class=pageheader><code>cmatrixcopy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Copy
# 
# Input parameters:
#     M   -   number of rows
#     N   -   number of columns
#     A   -   source matrix, MxN submatrix is copied
#     IA  -   submatrix offset (row index)
#     JA  -   submatrix offset (column index)
#     B   -   destination matrix, must be large enough to store result
#     IB  -   submatrix offset (row index)
#     JB  -   submatrix offset (column index)
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.cmatrixcopy(m, n, a, ia, ja, b, ib, jb)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          a:          2D array/list of complex
          ia:         int
          ja:         int
          b:          2D array/list of complex
          ib:         int
          jb:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_cmatrixgemm'></a><h3 class=pageheader><code>cmatrixgemm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates C = alpha*op1(A)*op2(B) +beta*C where:
# * C is MxN general matrix
# * op1(A) is MxK matrix
# * op2(B) is KxN matrix
# * &quot;op&quot; may be identity transformation, transposition, conjugate transposition
# 
# Additional info:
# * cache-oblivious algorithm is used.
# * multiplication result replaces C. If Beta=0, C elements are not used in
#   calculations (not multiplied by zero - just not referenced)
# * if Alpha=0, A is not used (not multiplied by zero - just not referenced)
# * if both Beta and Alpha are zero, C is filled by zeros.
# 
# IMPORTANT:
# 
# This function does NOT preallocate output matrix C, it MUST be preallocated
# by caller prior to calling this function. In case C does not have  enough
# space to store result, exception will be generated.
# 
# INPUT PARAMETERS
#     M       -   matrix size, M&gt;0
#     N       -   matrix size, N&gt;0
#     K       -   matrix size, K&gt;0
#     Alpha   -   coefficient
#     A       -   matrix
#     IA      -   submatrix offset
#     JA      -   submatrix offset
#     OpTypeA -   transformation type:
#                 * 0 - no transformation
#                 * 1 - transposition
#                 * 2 - conjugate transposition
#     B       -   matrix
#     IB      -   submatrix offset
#     JB      -   submatrix offset
#     OpTypeB -   transformation type:
#                 * 0 - no transformation
#                 * 1 - transposition
#                 * 2 - conjugate transposition
#     Beta    -   coefficient
#     C       -   matrix (PREALLOCATED, large enough to store result)
#     IC      -   submatrix offset
#     JC      -   submatrix offset
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      2009-2019
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.cmatrixgemm(m, n, k, alpha, a, ia, ja, optypea, b, ib, jb, optypeb, beta, c, ic, jc)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          k:          int
          alpha:      complex
          a:          2D array/list of complex
          ia:         int
          ja:         int
          optypea:    int
          b:          2D array/list of complex
          ib:         int
          jb:         int
          optypeb:    int
          beta:       complex
          c:          2D array/list of complex
          ic:         int
          jc:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_cmatrixherk'></a><h3 class=pageheader><code>cmatrixherk</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates  C=alpha*A*A^H+beta*C  or  C=alpha*A^H*A+beta*C
# where:
# * C is NxN Hermitian matrix given by its upper/lower triangle
# * A is NxK matrix when A*A^H is calculated, KxN matrix otherwise
# 
# Additional info:
# * multiplication result replaces C. If Beta=0, C elements are not used in
#   calculations (not multiplied by zero - just not referenced)
# * if Alpha=0, A is not used (not multiplied by zero - just not referenced)
# * if both Beta and Alpha are zero, C is filled by zeros.
# 
# INPUT PARAMETERS
#     N       -   matrix size, N&gt;=0
#     K       -   matrix size, K&gt;=0
#     Alpha   -   coefficient
#     A       -   matrix
#     IA      -   submatrix offset (row index)
#     JA      -   submatrix offset (column index)
#     OpTypeA -   multiplication type:
#                 * 0 - A*A^H is calculated
#                 * 2 - A^H*A is calculated
#     Beta    -   coefficient
#     C       -   preallocated input/output matrix
#     IC      -   submatrix offset (row index)
#     JC      -   submatrix offset (column index)
#     IsUpper -   whether upper or lower triangle of C is updated;
#                 this function updates only one half of C, leaving
#                 other half unchanged (not referenced at all).
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      16.12.2009-22.01.2018
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.cmatrixherk(n, k, alpha, a, ia, ja, optypea, beta, c, ic, jc, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          k:          int
          alpha:      float
          a:          2D array/list of complex
          ia:         int
          ja:         int
          optypea:    int
          beta:       float
          c:          2D array/list of complex
          ic:         int
          jc:         int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_cmatrixlefttrsm'></a><h3 class=pageheader><code>cmatrixlefttrsm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates op(A^-1)*X where:
# * X is MxN general matrix
# * A is MxM upper/lower triangular/unitriangular matrix
# * &quot;op&quot; may be identity transformation, transposition, conjugate transposition
# Multiplication result replaces X.
# 
# INPUT PARAMETERS
#     N   -   matrix size, N&gt;=0
#     M   -   matrix size, N&gt;=0
#     A       -   matrix, actial matrix is stored in A[I1:I1+M-1,J1:J1+M-1]
#     I1      -   submatrix offset
#     J1      -   submatrix offset
#     IsUpper -   whether matrix is upper triangular
#     IsUnit  -   whether matrix is unitriangular
#     OpType  -   transformation type:
#                 * 0 - no transformation
#                 * 1 - transposition
#                 * 2 - conjugate transposition
#     X   -   matrix, actial matrix is stored in X[I2:I2+M-1,J2:J2+N-1]
#     I2  -   submatrix offset
#     J2  -   submatrix offset
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      15.12.2009-22.01.2018
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.cmatrixlefttrsm(m, n, a, i1, j1, isupper, isunit, optype, x, i2, j2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          a:          2D array/list of complex
          i1:         int
          j1:         int
          isupper:    bool
          isunit:     bool
          optype:     int
          x:          2D array/list of complex
          i2:         int
          j2:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> x
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_cmatrixmv'></a><h3 class=pageheader><code>cmatrixmv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Matrix-vector product: y := op(A)*x
# 
# INPUT PARAMETERS:
#     M   -   number of rows of op(A)
#             M&gt;=0
#     N   -   number of columns of op(A)
#             N&gt;=0
#     A   -   target matrix
#     IA  -   submatrix offset (row index)
#     JA  -   submatrix offset (column index)
#     OpA -   operation type:
#             * OpA=0     =&gt;  op(A) = A
#             * OpA=1     =&gt;  op(A) = A^T
#             * OpA=2     =&gt;  op(A) = A^H
#     X   -   input vector
#     IX  -   subvector offset
#     IY  -   subvector offset
#     Y   -   preallocated matrix, must be large enough to store result
# 
# OUTPUT PARAMETERS:
#     Y   -   vector which stores result
# 
# if M=0, then subroutine does nothing.
# if N=0, Y is filled by zeros.
# 
# 
#   -- ALGLIB routine --
# 
#      28.01.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.cmatrixmv(m, n, a, ia, ja, opa, x, ix, y, iy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          a:          2D array/list of complex
          ia:         int
          ja:         int
          opa:        int
          x:          1D array/list of complex
          ix:         int
          y:          1D array/list of complex
          iy:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> y
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_cmatrixrank1'></a><h3 class=pageheader><code>cmatrixrank1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Rank-1 correction: A := A + u*v'
# 
# INPUT PARAMETERS:
#     M   -   number of rows
#     N   -   number of columns
#     A   -   target matrix, MxN submatrix is updated
#     IA  -   submatrix offset (row index)
#     JA  -   submatrix offset (column index)
#     U   -   vector #1
#     IU  -   subvector offset
#     V   -   vector #2
#     IV  -   subvector offset
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.cmatrixrank1(m, n, a, ia, ja, u, iu, v, iv)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          a:          2D array/list of complex
          ia:         int
          ja:         int
          u:          1D array/list of complex
          iu:         int
          v:          1D array/list of complex
          iv:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_cmatrixrighttrsm'></a><h3 class=pageheader><code>cmatrixrighttrsm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates X*op(A^-1) where:
# * X is MxN general matrix
# * A is NxN upper/lower triangular/unitriangular matrix
# * &quot;op&quot; may be identity transformation, transposition, conjugate transposition
# Multiplication result replaces X.
# 
# INPUT PARAMETERS
#     N   -   matrix size, N&gt;=0
#     M   -   matrix size, N&gt;=0
#     A       -   matrix, actial matrix is stored in A[I1:I1+N-1,J1:J1+N-1]
#     I1      -   submatrix offset
#     J1      -   submatrix offset
#     IsUpper -   whether matrix is upper triangular
#     IsUnit  -   whether matrix is unitriangular
#     OpType  -   transformation type:
#                 * 0 - no transformation
#                 * 1 - transposition
#                 * 2 - conjugate transposition
#     X   -   matrix, actial matrix is stored in X[I2:I2+M-1,J2:J2+N-1]
#     I2  -   submatrix offset
#     J2  -   submatrix offset
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      20.01.2018
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.cmatrixrighttrsm(m, n, a, i1, j1, isupper, isunit, optype, x, i2, j2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          a:          2D array/list of complex
          i1:         int
          j1:         int
          isupper:    bool
          isunit:     bool
          optype:     int
          x:          2D array/list of complex
          i2:         int
          j2:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> x
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_cmatrixsyrk'></a><h3 class=pageheader><code>cmatrixsyrk</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine is an older version of CMatrixHERK(), one with wrong  name
# (it is HErmitian update, not SYmmetric). It  is  left  here  for  backward
# compatibility.
# 
#   -- ALGLIB routine --
#      16.12.2009
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.cmatrixsyrk(n, k, alpha, a, ia, ja, optypea, beta, c, ic, jc, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          k:          int
          alpha:      float
          a:          2D array/list of complex
          ia:         int
          ja:         int
          optypea:    int
          beta:       float
          c:          2D array/list of complex
          ic:         int
          jc:         int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_cmatrixtranspose'></a><h3 class=pageheader><code>cmatrixtranspose</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Cache-oblivous complex &quot;copy-and-transpose&quot;
# 
# Input parameters:
#     M   -   number of rows
#     N   -   number of columns
#     A   -   source matrix, MxN submatrix is copied and transposed
#     IA  -   submatrix offset (row index)
#     JA  -   submatrix offset (column index)
#     B   -   destination matrix, must be large enough to store result
#     IB  -   submatrix offset (row index)
#     JB  -   submatrix offset (column index)
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.cmatrixtranspose(m, n, a, ia, ja, b, ib, jb)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          a:          2D array/list of complex
          ia:         int
          ja:         int
          b:          2D array/list of complex
          ib:         int
          jb:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixcopy'></a><h3 class=pageheader><code>rmatrixcopy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Copy
# 
# Input parameters:
#     M   -   number of rows
#     N   -   number of columns
#     A   -   source matrix, MxN submatrix is copied
#     IA  -   submatrix offset (row index)
#     JA  -   submatrix offset (column index)
#     B   -   destination matrix, must be large enough to store result
#     IB  -   submatrix offset (row index)
#     JB  -   submatrix offset (column index)
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixcopy(m, n, a, ia, ja, b, ib, jb)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          a:          2D array/list of float
          ia:         int
          ja:         int
          b:          2D array/list of float
          ib:         int
          jb:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixenforcesymmetricity'></a><h3 class=pageheader><code>rmatrixenforcesymmetricity</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This code enforces symmetricy of the matrix by copying Upper part to lower
# one (or vice versa).
# 
# INPUT PARAMETERS:
#     A   -   matrix
#     N   -   number of rows/columns
#     IsUpper - whether we want to copy upper triangle to lower one (True)
#             or vice versa (False).
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixenforcesymmetricity(a, n, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixgemm'></a><h3 class=pageheader><code>rmatrixgemm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates C = alpha*op1(A)*op2(B) +beta*C where:
# * C is MxN general matrix
# * op1(A) is MxK matrix
# * op2(B) is KxN matrix
# * &quot;op&quot; may be identity transformation, transposition
# 
# Additional info:
# * cache-oblivious algorithm is used.
# * multiplication result replaces C. If Beta=0, C elements are not used in
#   calculations (not multiplied by zero - just not referenced)
# * if Alpha=0, A is not used (not multiplied by zero - just not referenced)
# * if both Beta and Alpha are zero, C is filled by zeros.
# 
# IMPORTANT:
# 
# This function does NOT preallocate output matrix C, it MUST be preallocated
# by caller prior to calling this function. In case C does not have  enough
# space to store result, exception will be generated.
# 
# INPUT PARAMETERS
#     M       -   matrix size, M&gt;0
#     N       -   matrix size, N&gt;0
#     K       -   matrix size, K&gt;0
#     Alpha   -   coefficient
#     A       -   matrix
#     IA      -   submatrix offset
#     JA      -   submatrix offset
#     OpTypeA -   transformation type:
#                 * 0 - no transformation
#                 * 1 - transposition
#     B       -   matrix
#     IB      -   submatrix offset
#     JB      -   submatrix offset
#     OpTypeB -   transformation type:
#                 * 0 - no transformation
#                 * 1 - transposition
#     Beta    -   coefficient
#     C       -   PREALLOCATED output matrix, large enough to store result
#     IC      -   submatrix offset
#     JC      -   submatrix offset
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      2009-2019
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixgemm(m, n, k, alpha, a, ia, ja, optypea, b, ib, jb, optypeb, beta, c, ic, jc)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          k:          int
          alpha:      float
          a:          2D array/list of float
          ia:         int
          ja:         int
          optypea:    int
          b:          2D array/list of float
          ib:         int
          jb:         int
          optypeb:    int
          beta:       float
          c:          2D array/list of float
          ic:         int
          jc:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixgemv'></a><h3 class=pageheader><code>rmatrixgemv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixgemv(m, n, alpha, a, ia, ja, opa, x, ix, beta, y, iy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          alpha:      float
          a:          2D array/list of float
          ia:         int
          ja:         int
          opa:        int
          x:          1D array/list of float
          ix:         int
          beta:       float
          y:          1D array/list of float
          iy:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> y
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixgencopy'></a><h3 class=pageheader><code>rmatrixgencopy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Performs generalized copy: B := Beta*B + Alpha*A.
# 
# If Beta=0, then previous contents of B is simply ignored. If Alpha=0, then
# A is ignored and not referenced. If both Alpha and Beta  are  zero,  B  is
# filled by zeros.
# 
# Input parameters:
#     M   -   number of rows
#     N   -   number of columns
#     Alpha-  coefficient
#     A   -   source matrix, MxN submatrix is copied
#     IA  -   submatrix offset (row index)
#     JA  -   submatrix offset (column index)
#     Beta-   coefficient
#     B   -   destination matrix, must be large enough to store result
#     IB  -   submatrix offset (row index)
#     JB  -   submatrix offset (column index)
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixgencopy(m, n, alpha, a, ia, ja, beta, b, ib, jb)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          alpha:      float
          a:          2D array/list of float
          ia:         int
          ja:         int
          beta:       float
          b:          2D array/list of float
          ib:         int
          jb:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixger'></a><h3 class=pageheader><code>rmatrixger</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Rank-1 correction: A := A + alpha*u*v'
# 
# NOTE: this  function  expects  A  to  be  large enough to store result. No
#       automatic preallocation happens for  smaller  arrays.  No  integrity
#       checks is performed for sizes of A, u, v.
# 
# INPUT PARAMETERS:
#     M   -   number of rows
#     N   -   number of columns
#     A   -   target matrix, MxN submatrix is updated
#     IA  -   submatrix offset (row index)
#     JA  -   submatrix offset (column index)
#     Alpha-  coefficient
#     U   -   vector #1
#     IU  -   subvector offset
#     V   -   vector #2
#     IV  -   subvector offset
# 
# 
#   -- ALGLIB routine --
# 
#      16.10.2017
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixger(m, n, a, ia, ja, alpha, u, iu, v, iv)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          a:          2D array/list of float
          ia:         int
          ja:         int
          alpha:      float
          u:          1D array/list of float
          iu:         int
          v:          1D array/list of float
          iv:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixlefttrsm'></a><h3 class=pageheader><code>rmatrixlefttrsm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates op(A^-1)*X where:
# * X is MxN general matrix
# * A is MxM upper/lower triangular/unitriangular matrix
# * &quot;op&quot; may be identity transformation, transposition
# Multiplication result replaces X.
# 
# INPUT PARAMETERS
#     N   -   matrix size, N&gt;=0
#     M   -   matrix size, N&gt;=0
#     A       -   matrix, actial matrix is stored in A[I1:I1+M-1,J1:J1+M-1]
#     I1      -   submatrix offset
#     J1      -   submatrix offset
#     IsUpper -   whether matrix is upper triangular
#     IsUnit  -   whether matrix is unitriangular
#     OpType  -   transformation type:
#                 * 0 - no transformation
#                 * 1 - transposition
#     X   -   matrix, actial matrix is stored in X[I2:I2+M-1,J2:J2+N-1]
#     I2  -   submatrix offset
#     J2  -   submatrix offset
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      15.12.2009-22.01.2018
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixlefttrsm(m, n, a, i1, j1, isupper, isunit, optype, x, i2, j2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          a:          2D array/list of float
          i1:         int
          j1:         int
          isupper:    bool
          isunit:     bool
          optype:     int
          x:          2D array/list of float
          i2:         int
          j2:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> x
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixmv'></a><h3 class=pageheader><code>rmatrixmv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# IMPORTANT: this function is deprecated since ALGLIB 3.13. Use RMatrixGEMV()
#            which is more generic version of this function.
# 
# Matrix-vector product: y := op(A)*x
# 
# INPUT PARAMETERS:
#     M   -   number of rows of op(A)
#     N   -   number of columns of op(A)
#     A   -   target matrix
#     IA  -   submatrix offset (row index)
#     JA  -   submatrix offset (column index)
#     OpA -   operation type:
#             * OpA=0     =&gt;  op(A) = A
#             * OpA=1     =&gt;  op(A) = A^T
#     X   -   input vector
#     IX  -   subvector offset
#     IY  -   subvector offset
#     Y   -   preallocated matrix, must be large enough to store result
# 
# OUTPUT PARAMETERS:
#     Y   -   vector which stores result
# 
# if M=0, then subroutine does nothing.
# if N=0, Y is filled by zeros.
# 
# 
#   -- ALGLIB routine --
# 
#      28.01.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixmv(m, n, a, ia, ja, opa, x, ix, y, iy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          a:          2D array/list of float
          ia:         int
          ja:         int
          opa:        int
          x:          1D array/list of float
          ix:         int
          y:          1D array/list of float
          iy:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> y
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixrank1'></a><h3 class=pageheader><code>rmatrixrank1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# IMPORTANT: this function is deprecated since ALGLIB 3.13. Use RMatrixGER()
#            which is more generic version of this function.
# 
# Rank-1 correction: A := A + u*v'
# 
# INPUT PARAMETERS:
#     M   -   number of rows
#     N   -   number of columns
#     A   -   target matrix, MxN submatrix is updated
#     IA  -   submatrix offset (row index)
#     JA  -   submatrix offset (column index)
#     U   -   vector #1
#     IU  -   subvector offset
#     V   -   vector #2
#     IV  -   subvector offset
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixrank1(m, n, a, ia, ja, u, iu, v, iv)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          a:          2D array/list of float
          ia:         int
          ja:         int
          u:          1D array/list of float
          iu:         int
          v:          1D array/list of float
          iv:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixrighttrsm'></a><h3 class=pageheader><code>rmatrixrighttrsm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates X*op(A^-1) where:
# * X is MxN general matrix
# * A is NxN upper/lower triangular/unitriangular matrix
# * &quot;op&quot; may be identity transformation, transposition
# Multiplication result replaces X.
# 
# INPUT PARAMETERS
#     N   -   matrix size, N&gt;=0
#     M   -   matrix size, N&gt;=0
#     A       -   matrix, actial matrix is stored in A[I1:I1+N-1,J1:J1+N-1]
#     I1      -   submatrix offset
#     J1      -   submatrix offset
#     IsUpper -   whether matrix is upper triangular
#     IsUnit  -   whether matrix is unitriangular
#     OpType  -   transformation type:
#                 * 0 - no transformation
#                 * 1 - transposition
#     X   -   matrix, actial matrix is stored in X[I2:I2+M-1,J2:J2+N-1]
#     I2  -   submatrix offset
#     J2  -   submatrix offset
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      15.12.2009-22.01.2018
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixrighttrsm(m, n, a, i1, j1, isupper, isunit, optype, x, i2, j2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          a:          2D array/list of float
          i1:         int
          j1:         int
          isupper:    bool
          isunit:     bool
          optype:     int
          x:          2D array/list of float
          i2:         int
          j2:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> x
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixsymv'></a><h3 class=pageheader><code>rmatrixsymv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixsymv(n, alpha, a, ia, ja, isupper, x, ix, beta, y, iy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          alpha:      float
          a:          2D array/list of float
          ia:         int
          ja:         int
          isupper:    bool
          x:          1D array/list of float
          ix:         int
          beta:       float
          y:          1D array/list of float
          iy:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> y
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixsyrk'></a><h3 class=pageheader><code>rmatrixsyrk</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates  C=alpha*A*A^T+beta*C  or  C=alpha*A^T*A+beta*C
# where:
# * C is NxN symmetric matrix given by its upper/lower triangle
# * A is NxK matrix when A*A^T is calculated, KxN matrix otherwise
# 
# Additional info:
# * multiplication result replaces C. If Beta=0, C elements are not used in
#   calculations (not multiplied by zero - just not referenced)
# * if Alpha=0, A is not used (not multiplied by zero - just not referenced)
# * if both Beta and Alpha are zero, C is filled by zeros.
# 
# INPUT PARAMETERS
#     N       -   matrix size, N&gt;=0
#     K       -   matrix size, K&gt;=0
#     Alpha   -   coefficient
#     A       -   matrix
#     IA      -   submatrix offset (row index)
#     JA      -   submatrix offset (column index)
#     OpTypeA -   multiplication type:
#                 * 0 - A*A^T is calculated
#                 * 2 - A^T*A is calculated
#     Beta    -   coefficient
#     C       -   preallocated input/output matrix
#     IC      -   submatrix offset (row index)
#     JC      -   submatrix offset (column index)
#     IsUpper -   whether C is upper triangular or lower triangular
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      16.12.2009-22.01.2018
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixsyrk(n, k, alpha, a, ia, ja, optypea, beta, c, ic, jc, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          k:          int
          alpha:      float
          a:          2D array/list of float
          ia:         int
          ja:         int
          optypea:    int
          beta:       float
          c:          2D array/list of float
          ic:         int
          jc:         int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixsyvmv'></a><h3 class=pageheader><code>rmatrixsyvmv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixsyvmv(n, a, ia, ja, isupper, x, ix, tmp)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          a:          2D array/list of float
          ia:         int
          ja:         int
          isupper:    bool
          x:          1D array/list of float
          ix:         int
          tmp:        1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> tmp
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_rmatrixtranspose'></a><h3 class=pageheader><code>rmatrixtranspose</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Cache-oblivous real &quot;copy-and-transpose&quot;
# 
# Input parameters:
#     M   -   number of rows
#     N   -   number of columns
#     A   -   source matrix, MxN submatrix is copied and transposed
#     IA  -   submatrix offset (row index)
#     JA  -   submatrix offset (column index)
#     B   -   destination matrix, must be large enough to store result
#     IB  -   submatrix offset (row index)
#     JB  -   submatrix offset (column index)
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixtranspose(m, n, a, ia, ja, b, ib, jb)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          a:          2D array/list of float
          ia:         int
          ja:         int
          b:          2D array/list of float
          ib:         int
          jb:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixtrsv'></a><h3 class=pageheader><code>rmatrixtrsv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine solves linear system op(A)*x=b where:
# * A is NxN upper/lower triangular/unitriangular matrix
# * X and B are Nx1 vectors
# * &quot;op&quot; may be identity transformation or transposition
# 
# Solution replaces X.
# 
# IMPORTANT: * no overflow/underflow/denegeracy tests is performed.
#            * no integrity checks for operand sizes, out-of-bounds accesses
#              and so on is performed
# 
# INPUT PARAMETERS
#     N   -   matrix size, N&gt;=0
#     A       -   matrix, actial matrix is stored in A[IA:IA+N-1,JA:JA+N-1]
#     IA      -   submatrix offset
#     JA      -   submatrix offset
#     IsUpper -   whether matrix is upper triangular
#     IsUnit  -   whether matrix is unitriangular
#     OpType  -   transformation type:
#                 * 0 - no transformation
#                 * 1 - transposition
#     X       -   right part, actual vector is stored in X[IX:IX+N-1]
#     IX      -   offset
# 
# OUTPUT PARAMETERS
#     X       -   solution replaces elements X[IX:IX+N-1]
# 
#   -- ALGLIB routine / remastering of LAPACK's DTRSV --
#      (c) 2017 Bochkanov Sergey - converted to ALGLIB
#      (c) 2016 Reference BLAS level1 routine (LAPACK version 3.7.0)
#      Reference BLAS is a software package provided by Univ. of Tennessee,
#      Univ. of California Berkeley, Univ. of Colorado Denver and NAG Ltd.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixtrsv(n, a, ia, ja, isupper, isunit, optype, x, ix)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          a:          2D array/list of float
          ia:         int
          ja:         int
          isupper:    bool
          isunit:     bool
          optype:     int
          x:          1D array/list of float
          ix:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> x
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rvectorcopy'></a><h3 class=pageheader><code>rvectorcopy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Copy
# 
# Input parameters:
#     N   -   subvector size
#     A   -   source vector, N elements are copied
#     IA  -   source offset (first element index)
#     B   -   destination vector, must be large enough to store result
#     IB  -   destination offset (first element index)
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rvectorcopy(n, a, ia, b, ib)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          a:          1D array/list of float
          ia:         int
          b:          1D array/list of float
          ib:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_airyf></a><h2 class=pageheader><code>airyf</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_airy' class=toc>airy</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_airy'></a><h3 class=pageheader><code>airy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Airy function
# 
# Solution of the differential equation
# 
# y&quot;(x) = xy.
# 
# The function returns the two independent solutions Ai, Bi
# and their first derivatives Ai'(x), Bi'(x).
# 
# Evaluation is by power series summation for small x,
# by rational minimax approximations for large x.
# 
# 
# 
# ACCURACY:
# Error criterion is absolute when function &lt;= 1, relative
# when function &gt; 1, except * denotes relative error criterion.
# For large negative x, the absolute error increases as x^1.5.
# For large positive x, the relative error increases as x^1.5.
# 
# Arithmetic  domain   function  # trials      peak         rms
# IEEE        -10, 0     Ai        10000       1.6e-15     2.7e-16
# IEEE          0, 10    Ai        10000       2.3e-14*    1.8e-15*
# IEEE        -10, 0     Ai'       10000       4.6e-15     7.6e-16
# IEEE          0, 10    Ai'       10000       1.8e-14*    1.5e-15*
# IEEE        -10, 10    Bi        30000       4.2e-15     5.3e-16
# IEEE        -10, 10    Bi'       30000       4.9e-15     7.3e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   ai, aip, bi, bip = xalglib.airy(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  ai:         float
          aip:        float
          bi:         float
          bip:        float

</div></pre>
<a name=unit_autogk></a><h2 class=pageheader><code>autogk</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_autogkresults' class=toc>autogkresults</a><br>
<a href='#sub_autogksingular' class=toc>autogksingular</a><br>
<a href='#sub_autogksmooth' class=toc>autogksmooth</a><br>
<a href='#sub_autogksmoothw' class=toc>autogksmoothw</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_autogkresults'></a><h3 class=pageheader><code>autogkresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Adaptive integration results
# 
# Called after AutoGKIteration returned False.
# 
# Input parameters:
#     State   -   algorithm state (used by AutoGKIteration).
# 
# Output parameters:
#     V       -   integral(f(x)dx,a,b)
#     Rep     -   optimization report (see AutoGKReport description)
# 
#   -- ALGLIB --
#      Copyright 14.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   v, rep = xalglib.autogkresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.autogkstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  v:          float
          rep:        class xalglib.autogkreport

</div></pre>
<a name='sub_autogksingular'></a><h3 class=pageheader><code>autogksingular</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Integration on a finite interval [A,B].
# Integrand have integrable singularities at A/B.
# 
# F(X) must diverge as &quot;(x-A)^alpha&quot; at A, as &quot;(B-x)^beta&quot; at B,  with known
# alpha/beta (alpha&gt;-1, beta&gt;-1).  If alpha/beta  are  not known,  estimates
# from below can be used (but these estimates should be greater than -1 too).
# 
# One  of  alpha/beta variables (or even both alpha/beta) may be equal to 0,
# which means than function F(x) is non-singular at A/B. Anyway (singular at
# bounds or not), function F(x) is supposed to be continuous on (A,B).
# 
# Fast-convergent algorithm based on a Gauss-Kronrod formula is used. Result
# is calculated with accuracy close to the machine precision.
# 
# INPUT PARAMETERS:
#     A, B    -   interval boundaries (A&lt;B, A=B or A&gt;B)
#     Alpha   -   power-law coefficient of the F(x) at A,
#                 Alpha&gt;-1
#     Beta    -   power-law coefficient of the F(x) at B,
#                 Beta&gt;-1
# 
# OUTPUT PARAMETERS
#     State   -   structure which stores algorithm state
# 
# SEE ALSO
#     AutoGKSmooth, AutoGKSmoothW, AutoGKResults.
# 
# 
#   -- ALGLIB --
#      Copyright 06.05.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.autogksingular(a, b, alpha, beta)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          float
          b:          float
          alpha:      float
          beta:       float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.autogkstate

</div></pre>
<a name='sub_autogksmooth'></a><h3 class=pageheader><code>autogksmooth</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Integration of a smooth function F(x) on a finite interval [a,b].
# 
# Fast-convergent algorithm based on a Gauss-Kronrod formula is used. Result
# is calculated with accuracy close to the machine precision.
# 
# Algorithm works well only with smooth integrands.  It  may  be  used  with
# continuous non-smooth integrands, but with  less  performance.
# 
# It should never be used with integrands which have integrable singularities
# at lower or upper limits - algorithm may crash. Use AutoGKSingular in such
# cases.
# 
# INPUT PARAMETERS:
#     A, B    -   interval boundaries (A&lt;B, A=B or A&gt;B)
# 
# OUTPUT PARAMETERS
#     State   -   structure which stores algorithm state
# 
# SEE ALSO
#     AutoGKSmoothW, AutoGKSingular, AutoGKResults.
# 
# 
#   -- ALGLIB --
#      Copyright 06.05.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.autogksmooth(a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          float
          b:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.autogkstate

</div></pre>
<a name='sub_autogksmoothw'></a><h3 class=pageheader><code>autogksmoothw</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Integration of a smooth function F(x) on a finite interval [a,b].
# 
# This subroutine is same as AutoGKSmooth(), but it guarantees that interval
# [a,b] is partitioned into subintervals which have width at most XWidth.
# 
# Subroutine  can  be  used  when  integrating nearly-constant function with
# narrow &quot;bumps&quot; (about XWidth wide). If &quot;bumps&quot; are too narrow, AutoGKSmooth
# subroutine can overlook them.
# 
# INPUT PARAMETERS:
#     A, B    -   interval boundaries (A&lt;B, A=B or A&gt;B)
# 
# OUTPUT PARAMETERS
#     State   -   structure which stores algorithm state
# 
# SEE ALSO
#     AutoGKSmooth, AutoGKSingular, AutoGKResults.
# 
# 
#   -- ALGLIB --
#      Copyright 06.05.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.autogksmoothw(a, b, xwidth)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          float
          b:          float
          xwidth:     float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.autogkstate

</div></pre>
<a name=unit_basestat></a><h2 class=pageheader><code>basestat</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cov2' class=toc>cov2</a><br>
<a href='#sub_covm' class=toc>covm</a><br>
<a href='#sub_covm2' class=toc>covm2</a><br>
<a href='#sub_pearsoncorr2' class=toc>pearsoncorr2</a><br>
<a href='#sub_pearsoncorrelation' class=toc>pearsoncorrelation</a><br>
<a href='#sub_pearsoncorrm' class=toc>pearsoncorrm</a><br>
<a href='#sub_pearsoncorrm2' class=toc>pearsoncorrm2</a><br>
<a href='#sub_rankdata' class=toc>rankdata</a><br>
<a href='#sub_rankdatacentered' class=toc>rankdatacentered</a><br>
<a href='#sub_sampleadev' class=toc>sampleadev</a><br>
<a href='#sub_samplekurtosis' class=toc>samplekurtosis</a><br>
<a href='#sub_samplemean' class=toc>samplemean</a><br>
<a href='#sub_samplemedian' class=toc>samplemedian</a><br>
<a href='#sub_samplemoments' class=toc>samplemoments</a><br>
<a href='#sub_samplepercentile' class=toc>samplepercentile</a><br>
<a href='#sub_sampleskewness' class=toc>sampleskewness</a><br>
<a href='#sub_samplevariance' class=toc>samplevariance</a><br>
<a href='#sub_spearmancorr2' class=toc>spearmancorr2</a><br>
<a href='#sub_spearmancorrm' class=toc>spearmancorrm</a><br>
<a href='#sub_spearmancorrm2' class=toc>spearmancorrm2</a><br>
<a href='#sub_spearmanrankcorrelation' class=toc>spearmanrankcorrelation</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_cov2'></a><h3 class=pageheader><code>cov2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 2-sample covariance
# 
# Input parameters:
#     X       -   sample 1 (array indexes: [0..N-1])
#     Y       -   sample 2 (array indexes: [0..N-1])
#     N       -   N&gt;=0, sample size:
#                 * if given, only N leading elements of X/Y are processed
#                 * if not given, automatically determined from input sizes
# 
# Result:
#     covariance (zero for N=0 or N=1)
# 
#   -- ALGLIB --
#      Copyright 28.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cov2(x, y, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cov2(x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_covm'></a><h3 class=pageheader><code>covm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Covariance matrix
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     X   -   array[N,M], sample matrix:
#             * J-th column corresponds to J-th variable
#             * I-th row corresponds to I-th observation
#     N   -   N&gt;=0, number of observations:
#             * if given, only leading N rows of X are used
#             * if not given, automatically determined from input size
#     M   -   M&gt;0, number of variables:
#             * if given, only leading M columns of X are used
#             * if not given, automatically determined from input size
# 
# OUTPUT PARAMETERS:
#     C   -   array[M,M], covariance matrix (zero if N=0 or N=1)
# 
#   -- ALGLIB --
#      Copyright 28.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.covm(x, n, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.covm(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          2D array/list of float
          n:          int
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          2D array/list of float

</div></pre>
<a name='sub_covm2'></a><h3 class=pageheader><code>covm2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Cross-covariance matrix
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     X   -   array[N,M1], sample matrix:
#             * J-th column corresponds to J-th variable
#             * I-th row corresponds to I-th observation
#     Y   -   array[N,M2], sample matrix:
#             * J-th column corresponds to J-th variable
#             * I-th row corresponds to I-th observation
#     N   -   N&gt;=0, number of observations:
#             * if given, only leading N rows of X/Y are used
#             * if not given, automatically determined from input sizes
#     M1  -   M1&gt;0, number of variables in X:
#             * if given, only leading M1 columns of X are used
#             * if not given, automatically determined from input size
#     M2  -   M2&gt;0, number of variables in Y:
#             * if given, only leading M1 columns of X are used
#             * if not given, automatically determined from input size
# 
# OUTPUT PARAMETERS:
#     C   -   array[M1,M2], cross-covariance matrix (zero if N=0 or N=1)
# 
#   -- ALGLIB --
#      Copyright 28.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.covm2(x, y, n, m1, m2)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.covm2(x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          2D array/list of float
          y:          2D array/list of float
          n:          int
          m1:         int
          m2:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          2D array/list of float

</div></pre>
<a name='sub_pearsoncorr2'></a><h3 class=pageheader><code>pearsoncorr2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Pearson product-moment correlation coefficient
# 
# Input parameters:
#     X       -   sample 1 (array indexes: [0..N-1])
#     Y       -   sample 2 (array indexes: [0..N-1])
#     N       -   N&gt;=0, sample size:
#                 * if given, only N leading elements of X/Y are processed
#                 * if not given, automatically determined from input sizes
# 
# Result:
#     Pearson product-moment correlation coefficient
#     (zero for N=0 or N=1)
# 
#   -- ALGLIB --
#      Copyright 28.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.pearsoncorr2(x, y, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.pearsoncorr2(x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_pearsoncorrelation'></a><h3 class=pageheader><code>pearsoncorrelation</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Obsolete function, we recommend to use PearsonCorr2().
# 
#   -- ALGLIB --
#      Copyright 09.04.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.pearsoncorrelation(x, y, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_pearsoncorrm'></a><h3 class=pageheader><code>pearsoncorrm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Pearson product-moment correlation matrix
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     X   -   array[N,M], sample matrix:
#             * J-th column corresponds to J-th variable
#             * I-th row corresponds to I-th observation
#     N   -   N&gt;=0, number of observations:
#             * if given, only leading N rows of X are used
#             * if not given, automatically determined from input size
#     M   -   M&gt;0, number of variables:
#             * if given, only leading M columns of X are used
#             * if not given, automatically determined from input size
# 
# OUTPUT PARAMETERS:
#     C   -   array[M,M], correlation matrix (zero if N=0 or N=1)
# 
#   -- ALGLIB --
#      Copyright 28.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.pearsoncorrm(x, n, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.pearsoncorrm(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          2D array/list of float
          n:          int
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          2D array/list of float

</div></pre>
<a name='sub_pearsoncorrm2'></a><h3 class=pageheader><code>pearsoncorrm2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Pearson product-moment cross-correlation matrix
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     X   -   array[N,M1], sample matrix:
#             * J-th column corresponds to J-th variable
#             * I-th row corresponds to I-th observation
#     Y   -   array[N,M2], sample matrix:
#             * J-th column corresponds to J-th variable
#             * I-th row corresponds to I-th observation
#     N   -   N&gt;=0, number of observations:
#             * if given, only leading N rows of X/Y are used
#             * if not given, automatically determined from input sizes
#     M1  -   M1&gt;0, number of variables in X:
#             * if given, only leading M1 columns of X are used
#             * if not given, automatically determined from input size
#     M2  -   M2&gt;0, number of variables in Y:
#             * if given, only leading M1 columns of X are used
#             * if not given, automatically determined from input size
# 
# OUTPUT PARAMETERS:
#     C   -   array[M1,M2], cross-correlation matrix (zero if N=0 or N=1)
# 
#   -- ALGLIB --
#      Copyright 28.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.pearsoncorrm2(x, y, n, m1, m2)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.pearsoncorrm2(x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          2D array/list of float
          y:          2D array/list of float
          n:          int
          m1:         int
          m2:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          2D array/list of float

</div></pre>
<a name='sub_rankdata'></a><h3 class=pageheader><code>rankdata</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function replaces data in XY by their ranks:
# * XY is processed row-by-row
# * rows are processed separately
# * tied data are correctly handled (tied ranks are calculated)
# * ranking starts from 0, ends at NFeatures-1
# * sum of within-row values is equal to (NFeatures-1)*NFeatures/2
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     XY      -   array[NPoints,NFeatures], dataset
#     NPoints -   number of points
#     NFeatures-  number of features
# 
# OUTPUT PARAMETERS:
#     XY      -   data are replaced by their within-row ranks;
#                 ranking starts from 0, ends at NFeatures-1
# 
#   -- ALGLIB --
#      Copyright 18.04.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rankdata(xy, npoints, nfeatures)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rankdata(xy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nfeatures:  int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> xy
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rankdatacentered'></a><h3 class=pageheader><code>rankdatacentered</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function replaces data in XY by their CENTERED ranks:
# * XY is processed row-by-row
# * rows are processed separately
# * tied data are correctly handled (tied ranks are calculated)
# * centered ranks are just usual ranks, but centered in such way  that  sum
#   of within-row values is equal to 0.0.
# * centering is performed by subtracting mean from each row, i.e it changes
#   mean value, but does NOT change higher moments
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     XY      -   array[NPoints,NFeatures], dataset
#     NPoints -   number of points
#     NFeatures-  number of features
# 
# OUTPUT PARAMETERS:
#     XY      -   data are replaced by their within-row ranks;
#                 ranking starts from 0, ends at NFeatures-1
# 
#   -- ALGLIB --
#      Copyright 18.04.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rankdatacentered(xy, npoints, nfeatures)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rankdatacentered(xy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nfeatures:  int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> xy
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sampleadev'></a><h3 class=pageheader><code>sampleadev</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# ADev
# 
# Input parameters:
#     X   -   sample
#     N   -   N&gt;=0, sample size:
#             * if given, only leading N elements of X are processed
#             * if not given, automatically determined from size of X
# 
# Output parameters:
#     ADev-   ADev
# 
#   -- ALGLIB --
#      Copyright 06.09.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   adev = xalglib.sampleadev(x, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   adev = xalglib.sampleadev(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  adev:       float

</div></pre>
<a name='sub_samplekurtosis'></a><h3 class=pageheader><code>samplekurtosis</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Calculation of the kurtosis.
# 
# INPUT PARAMETERS:
#     X       -   sample
#     N       -   N&gt;=0, sample size:
#                 * if given, only leading N elements of X are processed
#                 * if not given, automatically determined from size of X
# 
# NOTE:
# 
# This function return result  which calculated by 'SampleMoments' function
# and stored at 'Kurtosis' variable.
# 
# 
#   -- ALGLIB --
#      Copyright 06.09.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.samplekurtosis(x, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.samplekurtosis(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_samplemean'></a><h3 class=pageheader><code>samplemean</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Calculation of the mean.
# 
# INPUT PARAMETERS:
#     X       -   sample
#     N       -   N&gt;=0, sample size:
#                 * if given, only leading N elements of X are processed
#                 * if not given, automatically determined from size of X
# 
# NOTE:
# 
# This function return result  which calculated by 'SampleMoments' function
# and stored at 'Mean' variable.
# 
# 
#   -- ALGLIB --
#      Copyright 06.09.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.samplemean(x, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.samplemean(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_samplemedian'></a><h3 class=pageheader><code>samplemedian</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Median calculation.
# 
# Input parameters:
#     X   -   sample (array indexes: [0..N-1])
#     N   -   N&gt;=0, sample size:
#             * if given, only leading N elements of X are processed
#             * if not given, automatically determined from size of X
# 
# Output parameters:
#     Median
# 
#   -- ALGLIB --
#      Copyright 06.09.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   median = xalglib.samplemedian(x, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   median = xalglib.samplemedian(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  median:     float

</div></pre>
<a name='sub_samplemoments'></a><h3 class=pageheader><code>samplemoments</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Calculation of the distribution moments: mean, variance, skewness, kurtosis.
# 
# INPUT PARAMETERS:
#     X       -   sample
#     N       -   N&gt;=0, sample size:
#                 * if given, only leading N elements of X are processed
#                 * if not given, automatically determined from size of X
# 
# OUTPUT PARAMETERS
#     Mean    -   mean.
#     Variance-   variance.
#     Skewness-   skewness (if variance&lt;&gt;0; zero otherwise).
#     Kurtosis-   kurtosis (if variance&lt;&gt;0; zero otherwise).
# 
# NOTE: variance is calculated by dividing sum of squares by N-1, not N.
# 
#   -- ALGLIB --
#      Copyright 06.09.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   mean, variance, skewness, kurtosis = xalglib.samplemoments(x, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   mean, variance, skewness, kurtosis = xalglib.samplemoments(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  mean:       float
          variance:   float
          skewness:   float
          kurtosis:   float

</div></pre>
<a name='sub_samplepercentile'></a><h3 class=pageheader><code>samplepercentile</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Percentile calculation.
# 
# Input parameters:
#     X   -   sample (array indexes: [0..N-1])
#     N   -   N&gt;=0, sample size:
#             * if given, only leading N elements of X are processed
#             * if not given, automatically determined from size of X
#     P   -   percentile (0&lt;=P&lt;=1)
# 
# Output parameters:
#     V   -   percentile
# 
#   -- ALGLIB --
#      Copyright 01.03.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   v = xalglib.samplepercentile(x, n, p)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   v = xalglib.samplepercentile(x, p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          p:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  v:          float

</div></pre>
<a name='sub_sampleskewness'></a><h3 class=pageheader><code>sampleskewness</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Calculation of the skewness.
# 
# INPUT PARAMETERS:
#     X       -   sample
#     N       -   N&gt;=0, sample size:
#                 * if given, only leading N elements of X are processed
#                 * if not given, automatically determined from size of X
# 
# NOTE:
# 
# This function return result  which calculated by 'SampleMoments' function
# and stored at 'Skewness' variable.
# 
# 
#   -- ALGLIB --
#      Copyright 06.09.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sampleskewness(x, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sampleskewness(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_samplevariance'></a><h3 class=pageheader><code>samplevariance</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Calculation of the variance.
# 
# INPUT PARAMETERS:
#     X       -   sample
#     N       -   N&gt;=0, sample size:
#                 * if given, only leading N elements of X are processed
#                 * if not given, automatically determined from size of X
# 
# NOTE:
# 
# This function return result  which calculated by 'SampleMoments' function
# and stored at 'Variance' variable.
# 
# 
#   -- ALGLIB --
#      Copyright 06.09.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.samplevariance(x, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.samplevariance(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_spearmancorr2'></a><h3 class=pageheader><code>spearmancorr2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Spearman's rank correlation coefficient
# 
# Input parameters:
#     X       -   sample 1 (array indexes: [0..N-1])
#     Y       -   sample 2 (array indexes: [0..N-1])
#     N       -   N&gt;=0, sample size:
#                 * if given, only N leading elements of X/Y are processed
#                 * if not given, automatically determined from input sizes
# 
# Result:
#     Spearman's rank correlation coefficient
#     (zero for N=0 or N=1)
# 
#   -- ALGLIB --
#      Copyright 09.04.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spearmancorr2(x, y, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spearmancorr2(x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_spearmancorrm'></a><h3 class=pageheader><code>spearmancorrm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Spearman's rank correlation matrix
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     X   -   array[N,M], sample matrix:
#             * J-th column corresponds to J-th variable
#             * I-th row corresponds to I-th observation
#     N   -   N&gt;=0, number of observations:
#             * if given, only leading N rows of X are used
#             * if not given, automatically determined from input size
#     M   -   M&gt;0, number of variables:
#             * if given, only leading M columns of X are used
#             * if not given, automatically determined from input size
# 
# OUTPUT PARAMETERS:
#     C   -   array[M,M], correlation matrix (zero if N=0 or N=1)
# 
#   -- ALGLIB --
#      Copyright 28.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spearmancorrm(x, n, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spearmancorrm(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          2D array/list of float
          n:          int
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          2D array/list of float

</div></pre>
<a name='sub_spearmancorrm2'></a><h3 class=pageheader><code>spearmancorrm2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Spearman's rank cross-correlation matrix
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     X   -   array[N,M1], sample matrix:
#             * J-th column corresponds to J-th variable
#             * I-th row corresponds to I-th observation
#     Y   -   array[N,M2], sample matrix:
#             * J-th column corresponds to J-th variable
#             * I-th row corresponds to I-th observation
#     N   -   N&gt;=0, number of observations:
#             * if given, only leading N rows of X/Y are used
#             * if not given, automatically determined from input sizes
#     M1  -   M1&gt;0, number of variables in X:
#             * if given, only leading M1 columns of X are used
#             * if not given, automatically determined from input size
#     M2  -   M2&gt;0, number of variables in Y:
#             * if given, only leading M1 columns of X are used
#             * if not given, automatically determined from input size
# 
# OUTPUT PARAMETERS:
#     C   -   array[M1,M2], cross-correlation matrix (zero if N=0 or N=1)
# 
#   -- ALGLIB --
#      Copyright 28.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spearmancorrm2(x, y, n, m1, m2)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spearmancorrm2(x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          2D array/list of float
          y:          2D array/list of float
          n:          int
          m1:         int
          m2:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          2D array/list of float

</div></pre>
<a name='sub_spearmanrankcorrelation'></a><h3 class=pageheader><code>spearmanrankcorrelation</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Obsolete function, we recommend to use SpearmanCorr2().
# 
#     -- ALGLIB --
#     Copyright 09.04.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spearmanrankcorrelation(x, y, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_bdss></a><h2 class=pageheader><code>bdss</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_dsoptimalsplit2' class=toc>dsoptimalsplit2</a><br>
<a href='#sub_dsoptimalsplit2fast' class=toc>dsoptimalsplit2fast</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_dsoptimalsplit2'></a><h3 class=pageheader><code>dsoptimalsplit2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Optimal binary classification
# 
# Algorithms finds optimal (=with minimal cross-entropy) binary partition.
# Internal subroutine.
# 
# INPUT PARAMETERS:
#     A       -   array[0..N-1], variable
#     C       -   array[0..N-1], class numbers (0 or 1).
#     N       -   array size
# 
# OUTPUT PARAMETERS:
#     Info    -   completetion code:
#                 * -3, all values of A[] are same (partition is impossible)
#                 * -2, one of C[] is incorrect (&lt;0, &gt;1)
#                 * -1, incorrect pararemets were passed (N&lt;=0).
#                 *  1, OK
#     Threshold-  partiton boundary. Left part contains values which are
#                 strictly less than Threshold. Right part contains values
#                 which are greater than or equal to Threshold.
#     PAL, PBL-   probabilities P(0|v&lt;Threshold) and P(1|v&lt;Threshold)
#     PAR, PBR-   probabilities P(0|v&gt;=Threshold) and P(1|v&gt;=Threshold)
#     CVE     -   cross-validation estimate of cross-entropy
# 
#   -- ALGLIB --
#      Copyright 22.05.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, threshold, pal, pbl, par, pbr, cve = xalglib.dsoptimalsplit2(a, c, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          c:          1D array/list of int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          threshold:  float
          pal:        float
          pbl:        float
          par:        float
          pbr:        float
          cve:        float

</div></pre>
<a name='sub_dsoptimalsplit2fast'></a><h3 class=pageheader><code>dsoptimalsplit2fast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Optimal partition, internal subroutine. Fast version.
# 
# Accepts:
#     A       array[0..N-1]       array of attributes     array[0..N-1]
#     C       array[0..N-1]       array of class labels
#     TiesBuf array[0..N]         temporaries (ties)
#     CntBuf  array[0..2*NC-1]    temporaries (counts)
#     Alpha                       centering factor (0&lt;=alpha&lt;=1, recommended value - 0.05)
#     BufR    array[0..N-1]       temporaries
#     BufI    array[0..N-1]       temporaries
# 
# Output:
#     Info    error code (&quot;&gt;0&quot;=OK, &quot;&lt;0&quot;=bad)
#     RMS     training set RMS error
#     CVRMS   leave-one-out RMS error
# 
# Note:
#     content of all arrays is changed by subroutine;
#     it doesn't allocate temporaries.
# 
#   -- ALGLIB --
#      Copyright 11.12.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a, c, tiesbuf, cntbuf, bufr, bufi, info, threshold, rms, cvrms = xalglib.dsoptimalsplit2fast(a, c, tiesbuf, cntbuf, bufr, bufi, n, nc, alpha)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          c:          1D array/list of int
          tiesbuf:    1D array/list of int
          cntbuf:     1D array/list of int
          bufr:       1D array/list of float
          bufi:       1D array/list of int
          n:          int
          nc:         int
          alpha:      float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          1D array/list of float
          c:          1D array/list of int
          tiesbuf:    1D array/list of int
          cntbuf:     1D array/list of int
          bufr:       1D array/list of float
          bufi:       1D array/list of int
          info:       int
          threshold:  float
          rms:        float
          cvrms:      float

</div></pre>
<a name=unit_bdsvd></a><h2 class=pageheader><code>bdsvd</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_rmatrixbdsvd' class=toc>rmatrixbdsvd</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_rmatrixbdsvd'></a><h3 class=pageheader><code>rmatrixbdsvd</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Singular value decomposition of a bidiagonal matrix (extended algorithm)
# 
# COMMERCIAL EDITION OF ALGLIB:
# 
#   ! Commercial version of ALGLIB includes one  important  improvement   of
#   ! this function, which can be used from C++ and C#:
#   ! * Intel MKL support (lightweight Intel MKL is shipped with ALGLIB)
#   !
#   ! Intel MKL gives approximately constant  (with  respect  to  number  of
#   ! worker threads) acceleration factor which depends on CPU  being  used,
#   ! problem  size  and  &quot;baseline&quot;  ALGLIB  edition  which  is  used   for
#   ! comparison.
#   !
#   ! Generally, commercial ALGLIB is several times faster than  open-source
#   ! generic C edition, and many times faster than open-source C# edition.
#   !
#   ! Multithreaded acceleration is NOT supported for this function.
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# The algorithm performs the singular value decomposition  of  a  bidiagonal
# matrix B (upper or lower) representing it as B = Q*S*P^T, where Q and  P -
# orthogonal matrices, S - diagonal matrix with non-negative elements on the
# main diagonal, in descending order.
# 
# The  algorithm  finds  singular  values.  In  addition,  the algorithm can
# calculate  matrices  Q  and P (more precisely, not the matrices, but their
# product  with  given  matrices U and VT - U*Q and (P^T)*VT)).  Of  course,
# matrices U and VT can be of any type, including identity. Furthermore, the
# algorithm can calculate Q'*C (this product is calculated more  effectively
# than U*Q,  because  this calculation operates with rows instead  of matrix
# columns).
# 
# The feature of the algorithm is its ability to find  all  singular  values
# including those which are arbitrarily close to 0  with  relative  accuracy
# close to  machine precision. If the parameter IsFractionalAccuracyRequired
# is set to True, all singular values will have high relative accuracy close
# to machine precision. If the parameter is set to False, only  the  biggest
# singular value will have relative accuracy  close  to  machine  precision.
# The absolute error of other singular values is equal to the absolute error
# of the biggest singular value.
# 
# Input parameters:
#     D       -   main diagonal of matrix B.
#                 Array whose index ranges within [0..N-1].
#     E       -   superdiagonal (or subdiagonal) of matrix B.
#                 Array whose index ranges within [0..N-2].
#     N       -   size of matrix B.
#     IsUpper -   True, if the matrix is upper bidiagonal.
#     IsFractionalAccuracyRequired -
#                 THIS PARAMETER IS IGNORED SINCE ALGLIB 3.5.0
#                 SINGULAR VALUES ARE ALWAYS SEARCHED WITH HIGH ACCURACY.
#     U       -   matrix to be multiplied by Q.
#                 Array whose indexes range within [0..NRU-1, 0..N-1].
#                 The matrix can be bigger, in that case only the  submatrix
#                 [0..NRU-1, 0..N-1] will be multiplied by Q.
#     NRU     -   number of rows in matrix U.
#     C       -   matrix to be multiplied by Q'.
#                 Array whose indexes range within [0..N-1, 0..NCC-1].
#                 The matrix can be bigger, in that case only the  submatrix
#                 [0..N-1, 0..NCC-1] will be multiplied by Q'.
#     NCC     -   number of columns in matrix C.
#     VT      -   matrix to be multiplied by P^T.
#                 Array whose indexes range within [0..N-1, 0..NCVT-1].
#                 The matrix can be bigger, in that case only the  submatrix
#                 [0..N-1, 0..NCVT-1] will be multiplied by P^T.
#     NCVT    -   number of columns in matrix VT.
# 
# Output parameters:
#     D       -   singular values of matrix B in descending order.
#     U       -   if NRU&gt;0, contains matrix U*Q.
#     VT      -   if NCVT&gt;0, contains matrix (P^T)*VT.
#     C       -   if NCC&gt;0, contains matrix Q'*C.
# 
# Result:
#     True, if the algorithm has converged.
#     False, if the algorithm hasn't converged (rare case).
# 
# NOTE: multiplication U*Q is performed by means of transposition to internal
#       buffer, multiplication and backward transposition. It helps to avoid
#       costly columnwise operations and speed-up algorithm.
# 
# Additional information:
#     The type of convergence is controlled by the internal  parameter  TOL.
#     If the parameter is greater than 0, the singular values will have
#     relative accuracy TOL. If TOL&lt;0, the singular values will have
#     absolute accuracy ABS(TOL)*norm(B).
#     By default, |TOL| falls within the range of 10*Epsilon and 100*Epsilon,
#     where Epsilon is the machine precision. It is not  recommended  to  use
#     TOL less than 10*Epsilon since this will  considerably  slow  down  the
#     algorithm and may not lead to error decreasing.
# 
# History:
#     * 31 March, 2007.
#         changed MAXITR from 6 to 12.
# 
#   -- LAPACK routine (version 3.0) --
#      Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
#      Courant Institute, Argonne National Lab, and Rice University
#      October 31, 1999.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixbdsvd(d, e, n, isupper, isfractionalaccuracyrequired, u, nru, c, ncc, vt, ncvt)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     d:          1D array/list of float
          e:          1D array/list of float
          n:          int
          isupper:    bool
          isfractionalaccuracyrequired: bool
          u:          2D array/list of float
          nru:        int
          c:          2D array/list of float
          ncc:        int
          vt:         2D array/list of float
          ncvt:       int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> d, u, c, vt
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name=unit_bessel></a><h2 class=pageheader><code>bessel</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_besseli0' class=toc>besseli0</a><br>
<a href='#sub_besseli1' class=toc>besseli1</a><br>
<a href='#sub_besselj0' class=toc>besselj0</a><br>
<a href='#sub_besselj1' class=toc>besselj1</a><br>
<a href='#sub_besseljn' class=toc>besseljn</a><br>
<a href='#sub_besselk0' class=toc>besselk0</a><br>
<a href='#sub_besselk1' class=toc>besselk1</a><br>
<a href='#sub_besselkn' class=toc>besselkn</a><br>
<a href='#sub_bessely0' class=toc>bessely0</a><br>
<a href='#sub_bessely1' class=toc>bessely1</a><br>
<a href='#sub_besselyn' class=toc>besselyn</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_besseli0'></a><h3 class=pageheader><code>besseli0</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modified Bessel function of order zero
# 
# Returns modified Bessel function of order zero of the
# argument.
# 
# The function is defined as i0(x) = j0( ix ).
# 
# The range is partitioned into the two intervals [0,8] and
# (8, infinity).  Chebyshev polynomial expansions are employed
# in each interval.
# 
# ACCURACY:
# 
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE      0,30        30000       5.8e-16     1.4e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.besseli0(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_besseli1'></a><h3 class=pageheader><code>besseli1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modified Bessel function of order one
# 
# Returns modified Bessel function of order one of the
# argument.
# 
# The function is defined as i1(x) = -i j1( ix ).
# 
# The range is partitioned into the two intervals [0,8] and
# (8, infinity).  Chebyshev polynomial expansions are employed
# in each interval.
# 
# ACCURACY:
# 
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE      0, 30       30000       1.9e-15     2.1e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1985, 1987, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.besseli1(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_besselj0'></a><h3 class=pageheader><code>besselj0</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Bessel function of order zero
# 
# Returns Bessel function of order zero of the argument.
# 
# The domain is divided into the intervals [0, 5] and
# (5, infinity). In the first interval the following rational
# approximation is used:
# 
# 
#        2         2
# (w - r  ) (w - r  ) P (w) / Q (w)
#       1         2    3       8
# 
#            2
# where w = x  and the two r's are zeros of the function.
# 
# In the second interval, the Hankel asymptotic expansion
# is employed with two rational functions of degree 6/6
# and 7/7.
# 
# ACCURACY:
# 
#                      Absolute error:
# arithmetic   domain     # trials      peak         rms
#    IEEE      0, 30       60000       4.2e-16     1.1e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.besselj0(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_besselj1'></a><h3 class=pageheader><code>besselj1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Bessel function of order one
# 
# Returns Bessel function of order one of the argument.
# 
# The domain is divided into the intervals [0, 8] and
# (8, infinity). In the first interval a 24 term Chebyshev
# expansion is used. In the second, the asymptotic
# trigonometric representation is employed using two
# rational functions of degree 5/5.
# 
# ACCURACY:
# 
#                      Absolute error:
# arithmetic   domain      # trials      peak         rms
#    IEEE      0, 30       30000       2.6e-16     1.1e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.besselj1(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_besseljn'></a><h3 class=pageheader><code>besseljn</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Bessel function of integer order
# 
# Returns Bessel function of order n, where n is a
# (possibly negative) integer.
# 
# The ratio of jn(x) to j0(x) is computed by backward
# recurrence.  First the ratio jn/jn-1 is found by a
# continued fraction expansion.  Then the recurrence
# relating successive orders is applied until j0 or j1 is
# reached.
# 
# If n = 0 or 1 the routine for j0 or j1 is called
# directly.
# 
# ACCURACY:
# 
#                      Absolute error:
# arithmetic   range      # trials      peak         rms
#    IEEE      0, 30        5000       4.4e-16     7.9e-17
# 
# 
# Not suitable for large n or x. Use jv() (fractional order) instead.
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.besseljn(n, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_besselk0'></a><h3 class=pageheader><code>besselk0</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modified Bessel function, second kind, order zero
# 
# Returns modified Bessel function of the second kind
# of order zero of the argument.
# 
# The range is partitioned into the two intervals [0,8] and
# (8, infinity).  Chebyshev polynomial expansions are employed
# in each interval.
# 
# ACCURACY:
# 
# Tested at 2000 random points between 0 and 8.  Peak absolute
# error (relative when K0 &gt; 1) was 1.46e-14; rms, 4.26e-15.
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE      0, 30       30000       1.2e-15     1.6e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.besselk0(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_besselk1'></a><h3 class=pageheader><code>besselk1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modified Bessel function, second kind, order one
# 
# Computes the modified Bessel function of the second kind
# of order one of the argument.
# 
# The range is partitioned into the two intervals [0,2] and
# (2, infinity).  Chebyshev polynomial expansions are employed
# in each interval.
# 
# ACCURACY:
# 
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE      0, 30       30000       1.2e-15     1.6e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.besselk1(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_besselkn'></a><h3 class=pageheader><code>besselkn</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modified Bessel function, second kind, integer order
# 
# Returns modified Bessel function of the second kind
# of order n of the argument.
# 
# The range is partitioned into the two intervals [0,9.55] and
# (9.55, infinity).  An ascending power series is used in the
# low range, and an asymptotic expansion in the high range.
# 
# ACCURACY:
# 
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE      0,30        90000       1.8e-8      3.0e-10
# 
# Error is high only near the crossover point x = 9.55
# between the two expansions used.
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1988, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.besselkn(nn, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nn:         int
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_bessely0'></a><h3 class=pageheader><code>bessely0</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Bessel function of the second kind, order zero
# 
# Returns Bessel function of the second kind, of order
# zero, of the argument.
# 
# The domain is divided into the intervals [0, 5] and
# (5, infinity). In the first interval a rational approximation
# R(x) is employed to compute
#   y0(x)  = R(x)  +   2 * log(x) * j0(x) / PI.
# Thus a call to j0() is required.
# 
# In the second interval, the Hankel asymptotic expansion
# is employed with two rational functions of degree 6/6
# and 7/7.
# 
# 
# 
# ACCURACY:
# 
#  Absolute error, when y0(x) &lt; 1; else relative error:
# 
# arithmetic   domain     # trials      peak         rms
#    IEEE      0, 30       30000       1.3e-15     1.6e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.bessely0(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_bessely1'></a><h3 class=pageheader><code>bessely1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Bessel function of second kind of order one
# 
# Returns Bessel function of the second kind of order one
# of the argument.
# 
# The domain is divided into the intervals [0, 8] and
# (8, infinity). In the first interval a 25 term Chebyshev
# expansion is used, and a call to j1() is required.
# In the second, the asymptotic trigonometric representation
# is employed using two rational functions of degree 5/5.
# 
# ACCURACY:
# 
#                      Absolute error:
# arithmetic   domain      # trials      peak         rms
#    IEEE      0, 30       30000       1.0e-15     1.3e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.bessely1(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_besselyn'></a><h3 class=pageheader><code>besselyn</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Bessel function of second kind of integer order
# 
# Returns Bessel function of order n, where n is a
# (possibly negative) integer.
# 
# The function is evaluated by forward recurrence on
# n, starting with values computed by the routines
# y0() and y1().
# 
# If n = 0 or 1 the routine for y0 or y1 is called
# directly.
# 
# ACCURACY:
#                      Absolute error, except relative
#                      when y &gt; 1:
# arithmetic   domain     # trials      peak         rms
#    IEEE      0, 30       30000       3.4e-15     4.3e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.besselyn(n, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_betaf></a><h2 class=pageheader><code>betaf</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_beta' class=toc>beta</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_beta'></a><h3 class=pageheader><code>beta</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Beta function
# 
# 
#                   -     -
#                  | (a) | (b)
# beta( a, b )  =  -----------.
#                     -
#                    | (a+b)
# 
# For large arguments the logarithm of the function is
# evaluated using lgam(), then exponentiated.
# 
# ACCURACY:
# 
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE       0,30       30000       8.1e-14     1.1e-14
# 
# Cephes Math Library Release 2.0:  April, 1987
# Copyright 1984, 1987 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.beta(a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          float
          b:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_binomialdistr></a><h2 class=pageheader><code>binomialdistr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_binomialcdistribution' class=toc>binomialcdistribution</a><br>
<a href='#sub_binomialdistribution' class=toc>binomialdistribution</a><br>
<a href='#sub_invbinomialdistribution' class=toc>invbinomialdistribution</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_binomialcdistribution'></a><h3 class=pageheader><code>binomialcdistribution</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Complemented binomial distribution
# 
# Returns the sum of the terms k+1 through n of the Binomial
# probability density:
# 
#   n
#   --  ( n )   j      n-j
#   &gt;   (   )  p  (1-p)
#   --  ( j )
#  j=k+1
# 
# The terms are not summed directly; instead the incomplete
# beta integral is employed, according to the formula
# 
# y = bdtrc( k, n, p ) = incbet( k+1, n-k, p ).
# 
# The arguments must be positive, with p ranging from 0 to 1.
# 
# ACCURACY:
# 
# Tested at random points (a,b,p).
# 
#               a,b                     Relative error:
# arithmetic  domain     # trials      peak         rms
#  For p between 0.001 and 1:
#    IEEE     0,100       100000      6.7e-15     8.2e-16
#  For p between 0 and .001:
#    IEEE     0,100       100000      1.5e-13     2.7e-15
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.binomialcdistribution(k, n, p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     k:          int
          n:          int
          p:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_binomialdistribution'></a><h3 class=pageheader><code>binomialdistribution</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Binomial distribution
# 
# Returns the sum of the terms 0 through k of the Binomial
# probability density:
# 
#   k
#   --  ( n )   j      n-j
#   &gt;   (   )  p  (1-p)
#   --  ( j )
#  j=0
# 
# The terms are not summed directly; instead the incomplete
# beta integral is employed, according to the formula
# 
# y = bdtr( k, n, p ) = incbet( n-k, k+1, 1-p ).
# 
# The arguments must be positive, with p ranging from 0 to 1.
# 
# ACCURACY:
# 
# Tested at random points (a,b,p), with p between 0 and 1.
# 
#               a,b                     Relative error:
# arithmetic  domain     # trials      peak         rms
#  For p between 0.001 and 1:
#    IEEE     0,100       100000      4.3e-15     2.6e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.binomialdistribution(k, n, p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     k:          int
          n:          int
          p:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_invbinomialdistribution'></a><h3 class=pageheader><code>invbinomialdistribution</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inverse binomial distribution
# 
# Finds the event probability p such that the sum of the
# terms 0 through k of the Binomial probability density
# is equal to the given cumulative probability y.
# 
# This is accomplished using the inverse beta integral
# function and the relation
# 
# 1 - p = incbi( n-k, k+1, y ).
# 
# ACCURACY:
# 
# Tested at random points (a,b,p).
# 
#               a,b                     Relative error:
# arithmetic  domain     # trials      peak         rms
#  For p between 0.001 and 1:
#    IEEE     0,100       100000      2.3e-14     6.4e-16
#    IEEE     0,10000     100000      6.6e-12     1.2e-13
#  For p between 10^-6 and 0.001:
#    IEEE     0,100       100000      2.0e-12     1.3e-14
#    IEEE     0,10000     100000      1.5e-12     3.2e-14
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.invbinomialdistribution(k, n, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     k:          int
          n:          int
          y:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_chebyshev></a><h2 class=pageheader><code>chebyshev</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_chebyshevcalculate' class=toc>chebyshevcalculate</a><br>
<a href='#sub_chebyshevcoefficients' class=toc>chebyshevcoefficients</a><br>
<a href='#sub_chebyshevsum' class=toc>chebyshevsum</a><br>
<a href='#sub_fromchebyshev' class=toc>fromchebyshev</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_chebyshevcalculate'></a><h3 class=pageheader><code>chebyshevcalculate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Calculation of the value of the Chebyshev polynomials of the
# first and second kinds.
# 
# Parameters:
#     r   -   polynomial kind, either 1 or 2.
#     n   -   degree, n&gt;=0
#     x   -   argument, -1 &lt;= x &lt;= 1
# 
# Result:
#     the value of the Chebyshev polynomial at x
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.chebyshevcalculate(r, n, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     r:          int
          n:          int
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_chebyshevcoefficients'></a><h3 class=pageheader><code>chebyshevcoefficients</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Representation of Tn as C[0] + C[1]*X + ... + C[N]*X^N
# 
# Input parameters:
#     N   -   polynomial degree, n&gt;=0
# 
# Output parameters:
#     C   -   coefficients
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.chebyshevcoefficients(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of float

</div></pre>
<a name='sub_chebyshevsum'></a><h3 class=pageheader><code>chebyshevsum</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Summation of Chebyshev polynomials using Clenshaw's recurrence formula.
# 
# This routine calculates
#     c[0]*T0(x) + c[1]*T1(x) + ... + c[N]*TN(x)
# or
#     c[0]*U0(x) + c[1]*U1(x) + ... + c[N]*UN(x)
# depending on the R.
# 
# Parameters:
#     r   -   polynomial kind, either 1 or 2.
#     n   -   degree, n&gt;=0
#     x   -   argument
# 
# Result:
#     the value of the Chebyshev polynomial at x
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.chebyshevsum(c, r, n, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          1D array/list of float
          r:          int
          n:          int
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_fromchebyshev'></a><h3 class=pageheader><code>fromchebyshev</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Conversion of a series of Chebyshev polynomials to a power series.
# 
# Represents A[0]*T0(x) + A[1]*T1(x) + ... + A[N]*Tn(x) as
# B[0] + B[1]*X + ... + B[N]*X^N.
# 
# Input parameters:
#     A   -   Chebyshev series coefficients
#     N   -   degree, N&gt;=0
# 
# Output parameters
#     B   -   power series coefficients
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   b = xalglib.fromchebyshev(a, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  b:          1D array/list of float

</div></pre>
<a name=unit_chisquaredistr></a><h2 class=pageheader><code>chisquaredistr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_chisquarecdistribution' class=toc>chisquarecdistribution</a><br>
<a href='#sub_chisquaredistribution' class=toc>chisquaredistribution</a><br>
<a href='#sub_invchisquaredistribution' class=toc>invchisquaredistribution</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_chisquarecdistribution'></a><h3 class=pageheader><code>chisquarecdistribution</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Complemented Chi-square distribution
# 
# Returns the area under the right hand tail (from x to
# infinity) of the Chi square probability density function
# with v degrees of freedom:
# 
#                                  inf.
#                                    -
#                        1          | |  v/2-1  -t/2
#  P( x | v )   =   -----------     |   t      e     dt
#                    v/2  -       | |
#                   2    | (v/2)   -
#                                   x
# 
# where x is the Chi-square variable.
# 
# The incomplete gamma integral is used, according to the
# formula
# 
# y = chdtr( v, x ) = igamc( v/2.0, x/2.0 ).
# 
# The arguments must both be positive.
# 
# ACCURACY:
# 
# See incomplete gamma function
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.chisquarecdistribution(v, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     v:          float
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_chisquaredistribution'></a><h3 class=pageheader><code>chisquaredistribution</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Chi-square distribution
# 
# Returns the area under the left hand tail (from 0 to x)
# of the Chi square probability density function with
# v degrees of freedom.
# 
# 
#                                   x
#                                    -
#                        1          | |  v/2-1  -t/2
#  P( x | v )   =   -----------     |   t      e     dt
#                    v/2  -       | |
#                   2    | (v/2)   -
#                                   0
# 
# where x is the Chi-square variable.
# 
# The incomplete gamma integral is used, according to the
# formula
# 
# y = chdtr( v, x ) = igam( v/2.0, x/2.0 ).
# 
# The arguments must both be positive.
# 
# ACCURACY:
# 
# See incomplete gamma function
# 
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.chisquaredistribution(v, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     v:          float
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_invchisquaredistribution'></a><h3 class=pageheader><code>invchisquaredistribution</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inverse of complemented Chi-square distribution
# 
# Finds the Chi-square argument x such that the integral
# from x to infinity of the Chi-square density is equal
# to the given cumulative probability y.
# 
# This is accomplished using the inverse gamma integral
# function and the relation
# 
#    x/2 = igami( df/2, y );
# 
# ACCURACY:
# 
# See inverse incomplete gamma function
# 
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.invchisquaredistribution(v, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     v:          float
          y:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_clustering></a><h2 class=pageheader><code>clustering</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_clusterizercreate' class=toc>clusterizercreate</a><br>
<a href='#sub_clusterizergetdistances' class=toc>clusterizergetdistances</a><br>
<a href='#sub_clusterizergetkclusters' class=toc>clusterizergetkclusters</a><br>
<a href='#sub_clusterizerrunahc' class=toc>clusterizerrunahc</a><br>
<a href='#sub_clusterizerrunkmeans' class=toc>clusterizerrunkmeans</a><br>
<a href='#sub_clusterizerseparatedbycorr' class=toc>clusterizerseparatedbycorr</a><br>
<a href='#sub_clusterizerseparatedbydist' class=toc>clusterizerseparatedbydist</a><br>
<a href='#sub_clusterizersetahcalgo' class=toc>clusterizersetahcalgo</a><br>
<a href='#sub_clusterizersetdistances' class=toc>clusterizersetdistances</a><br>
<a href='#sub_clusterizersetkmeansinit' class=toc>clusterizersetkmeansinit</a><br>
<a href='#sub_clusterizersetkmeanslimits' class=toc>clusterizersetkmeanslimits</a><br>
<a href='#sub_clusterizersetpoints' class=toc>clusterizersetpoints</a><br>
<a href='#sub_clusterizersetseed' class=toc>clusterizersetseed</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_clusterizercreate'></a><h3 class=pageheader><code>clusterizercreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function initializes clusterizer object. Newly initialized object  is
# empty, i.e. it does not contain dataset. You should use it as follows:
# 1. creation
# 2. dataset is added with ClusterizerSetPoints()
# 3. additional parameters are set
# 3. clusterization is performed with one of the clustering functions
# 
#   -- ALGLIB --
#      Copyright 10.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.clusterizercreate()
<span style='font-weight: bold; color: navy;'>ARGS:</span>     
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.clusterizerstate

</div></pre>
<a name='sub_clusterizergetdistances'></a><h3 class=pageheader><code>clusterizergetdistances</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns distance matrix for dataset
# 
# INPUT PARAMETERS:
#     XY      -   array[NPoints,NFeatures], dataset
#     NPoints -   number of points, &gt;=0
#     NFeatures-  number of features, &gt;=1
#     DistType-   distance function:
#                 *  0    Chebyshev distance  (L-inf norm)
#                 *  1    city block distance (L1 norm)
#                 *  2    Euclidean distance  (L2 norm, non-squared)
#                 * 10    Pearson correlation:
#                         dist(a,b) = 1-corr(a,b)
#                 * 11    Absolute Pearson correlation:
#                         dist(a,b) = 1-|corr(a,b)|
#                 * 12    Uncentered Pearson correlation (cosine of the angle):
#                         dist(a,b) = a'*b/(|a|*|b|)
#                 * 13    Absolute uncentered Pearson correlation
#                         dist(a,b) = |a'*b|/(|a|*|b|)
#                 * 20    Spearman rank correlation:
#                         dist(a,b) = 1-rankcorr(a,b)
#                 * 21    Absolute Spearman rank correlation
#                         dist(a,b) = 1-|rankcorr(a,b)|
# 
# OUTPUT PARAMETERS:
#     D       -   array[NPoints,NPoints], distance matrix
#                 (full matrix is returned, with lower and upper triangles)
# 
# NOTE:  different distance functions have different performance penalty:
#        * Euclidean or Pearson correlation distances are the fastest ones
#        * Spearman correlation distance function is a bit slower
#        * city block and Chebyshev distances are order of magnitude slower
# 
#        The reason behing difference in performance is that correlation-based
#        distance functions are computed using optimized linear algebra kernels,
#        while Chebyshev and city block distance functions are computed using
#        simple nested loops with two branches at each iteration.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 10.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   d = xalglib.clusterizergetdistances(xy, npoints, nfeatures, disttype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nfeatures:  int
          disttype:   int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  d:          2D array/list of float

</div></pre>
<a name='sub_clusterizergetkclusters'></a><h3 class=pageheader><code>clusterizergetkclusters</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function takes as input clusterization report Rep,  desired  clusters
# count K, and builds top K clusters from hierarchical clusterization  tree.
# It returns assignment of points to clusters (array of cluster indexes).
# 
# INPUT PARAMETERS:
#     Rep     -   report from ClusterizerRunAHC() performed on XY
#     K       -   desired number of clusters, 1&lt;=K&lt;=NPoints.
#                 K can be zero only when NPoints=0.
# 
# OUTPUT PARAMETERS:
#     CIdx    -   array[NPoints], I-th element contains cluster index  (from
#                 0 to K-1) for I-th point of the dataset.
#     CZ      -   array[K]. This array allows  to  convert  cluster  indexes
#                 returned by this function to indexes used by  Rep.Z.  J-th
#                 cluster returned by this function corresponds to  CZ[J]-th
#                 cluster stored in Rep.Z/PZ/PM.
#                 It is guaranteed that CZ[I]&lt;CZ[I+1].
# 
# NOTE: K clusters built by this subroutine are assumed to have no hierarchy.
#       Although  they  were  obtained  by  manipulation with top K nodes of
#       dendrogram  (i.e.  hierarchical  decomposition  of  dataset),   this
#       function does not return information about hierarchy.  Each  of  the
#       clusters stand on its own.
# 
# NOTE: Cluster indexes returned by this function  does  not  correspond  to
#       indexes returned in Rep.Z/PZ/PM. Either you work  with  hierarchical
#       representation of the dataset (dendrogram), or you work with  &quot;flat&quot;
#       representation returned by this function.  Each  of  representations
#       has its own clusters indexing system (former uses [0, 2*NPoints-2]),
#       while latter uses [0..K-1]), although  it  is  possible  to  perform
#       conversion from one system to another by means of CZ array, returned
#       by this function, which allows you to convert indexes stored in CIdx
#       to the numeration system used by Rep.Z.
# 
# NOTE: this subroutine is optimized for moderate values of K. Say, for  K=5
#       it will perform many times faster than  for  K=100.  Its  worst-case
#       performance is O(N*K), although in average case  it  perform  better
#       (up to O(N*log(K))).
# 
#   -- ALGLIB --
#      Copyright 10.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   cidx, cz = xalglib.clusterizergetkclusters(rep, k)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     rep:        class xalglib.ahcreport
          k:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  cidx:       1D array/list of int
          cz:         1D array/list of int

</div></pre>
<a name='sub_clusterizerrunahc'></a><h3 class=pageheader><code>clusterizerrunahc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function performs agglomerative hierarchical clustering
# 
# NOTE: Agglomerative  hierarchical  clustering  algorithm  has two  phases:
#       distance matrix calculation and clustering  itself. Only first phase
#       (distance matrix calculation) is accelerated by SIMD and SMP.  Thus,
#       acceleration is significant  only  for  medium  or  high-dimensional
#       problems.
# 
#       Although activating multithreading gives some speedup  over  single-
#       threaded execution, you  should  not  expect  nearly-linear  scaling
#       with respect to cores count.
# 
# INPUT PARAMETERS:
#     S       -   clusterizer state, initialized by ClusterizerCreate()
# 
# OUTPUT PARAMETERS:
#     Rep     -   clustering results; see description of AHCReport
#                 structure for more information.
# 
# NOTE 1: hierarchical clustering algorithms require large amounts of memory.
#         In particular, this implementation needs  sizeof(double)*NPoints^2
#         bytes, which are used to store distance matrix. In  case  we  work
#         with user-supplied matrix, this amount is multiplied by 2 (we have
#         to store original matrix and to work with its copy).
# 
#         For example, problem with 10000 points  would require 800M of RAM,
#         even when working in a 1-dimensional space.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 10.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.clusterizerrunahc(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.clusterizerstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.ahcreport

</div></pre>
<a name='sub_clusterizerrunkmeans'></a><h3 class=pageheader><code>clusterizerrunkmeans</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function performs clustering by k-means++ algorithm.
# 
# You may change algorithm properties by calling:
# * ClusterizerSetKMeansLimits() to change number of restarts or iterations
# * ClusterizerSetKMeansInit() to change initialization algorithm
# 
# By  default,  one  restart  and  unlimited number of iterations are  used.
# Initialization algorithm is chosen automatically.
# 
# NOTE: k-means clustering  algorithm has two  phases:  selection of initial
#       centers and clustering  itself.  ALGLIB  parallelizes  both  phases.
#       Parallel version is optimized for the following  scenario: medium or
#       high-dimensional problem (8 or more dimensions) with large number of
#       points and clusters. However, some speed-up  can  be  obtained  even
#       when assumptions above are violated.
# 
# INPUT PARAMETERS:
#     S       -   clusterizer state, initialized by ClusterizerCreate()
#     K       -   number of clusters, K&gt;=0.
#                 K  can  be  zero only when algorithm is called  for  empty
#                 dataset,  in   this   case   completion  code  is  set  to
#                 success (+1).
#                 If  K=0  and  dataset  size  is  non-zero,  we   can   not
#                 meaningfully assign points to some center  (there  are  no
#                 centers because K=0) and  return  -3  as  completion  code
#                 (failure).
# 
# OUTPUT PARAMETERS:
#     Rep     -   clustering results; see description of KMeansReport
#                 structure for more information.
# 
# NOTE 1: k-means  clustering  can  be  performed  only  for  datasets  with
#         Euclidean  distance  function.  Algorithm  will  return   negative
#         completion code in Rep.TerminationType in case dataset  was  added
#         to clusterizer with DistType other than Euclidean (or dataset  was
#         specified by distance matrix instead of explicitly given points).
# 
# NOTE 2: by default, k-means uses non-deterministic seed to initialize  RNG
#         which is used to select initial centers. As  result,  each  run of
#         algorithm may return different values. If you  need  deterministic
#         behavior, use ClusterizerSetSeed() function.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 10.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.clusterizerrunkmeans(s, k)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.clusterizerstate
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.kmeansreport

</div></pre>
<a name='sub_clusterizerseparatedbycorr'></a><h3 class=pageheader><code>clusterizerseparatedbycorr</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  accepts  AHC  report  Rep,  desired  maximum  intercluster
# correlation and returns top clusters from hierarchical clusterization tree
# which are separated by correlation R or LOWER.
# 
# It returns assignment of points to clusters (array of cluster indexes).
# 
# There is one more function with similar name - ClusterizerSeparatedByDist,
# which returns clusters with intercluster distance equal  to  R  or  HIGHER
# (note: higher for distance, lower for correlation).
# 
# INPUT PARAMETERS:
#     Rep     -   report from ClusterizerRunAHC() performed on XY
#     R       -   desired maximum intercluster correlation, -1&lt;=R&lt;=+1
# 
# OUTPUT PARAMETERS:
#     K       -   number of clusters, 1&lt;=K&lt;=NPoints
#     CIdx    -   array[NPoints], I-th element contains cluster index  (from
#                 0 to K-1) for I-th point of the dataset.
#     CZ      -   array[K]. This array allows  to  convert  cluster  indexes
#                 returned by this function to indexes used by  Rep.Z.  J-th
#                 cluster returned by this function corresponds to  CZ[J]-th
#                 cluster stored in Rep.Z/PZ/PM.
#                 It is guaranteed that CZ[I]&lt;CZ[I+1].
# 
# NOTE: K clusters built by this subroutine are assumed to have no hierarchy.
#       Although  they  were  obtained  by  manipulation with top K nodes of
#       dendrogram  (i.e.  hierarchical  decomposition  of  dataset),   this
#       function does not return information about hierarchy.  Each  of  the
#       clusters stand on its own.
# 
# NOTE: Cluster indexes returned by this function  does  not  correspond  to
#       indexes returned in Rep.Z/PZ/PM. Either you work  with  hierarchical
#       representation of the dataset (dendrogram), or you work with  &quot;flat&quot;
#       representation returned by this function.  Each  of  representations
#       has its own clusters indexing system (former uses [0, 2*NPoints-2]),
#       while latter uses [0..K-1]), although  it  is  possible  to  perform
#       conversion from one system to another by means of CZ array, returned
#       by this function, which allows you to convert indexes stored in CIdx
#       to the numeration system used by Rep.Z.
# 
# NOTE: this subroutine is optimized for moderate values of K. Say, for  K=5
#       it will perform many times faster than  for  K=100.  Its  worst-case
#       performance is O(N*K), although in average case  it  perform  better
#       (up to O(N*log(K))).
# 
#   -- ALGLIB --
#      Copyright 10.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   k, cidx, cz = xalglib.clusterizerseparatedbycorr(rep, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     rep:        class xalglib.ahcreport
          r:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  k:          int
          cidx:       1D array/list of int
          cz:         1D array/list of int

</div></pre>
<a name='sub_clusterizerseparatedbydist'></a><h3 class=pageheader><code>clusterizerseparatedbydist</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  accepts  AHC  report  Rep,  desired  minimum  intercluster
# distance and returns top clusters from  hierarchical  clusterization  tree
# which are separated by distance R or HIGHER.
# 
# It returns assignment of points to clusters (array of cluster indexes).
# 
# There is one more function with similar name - ClusterizerSeparatedByCorr,
# which returns clusters with intercluster correlation equal to R  or  LOWER
# (note: higher for distance, lower for correlation).
# 
# INPUT PARAMETERS:
#     Rep     -   report from ClusterizerRunAHC() performed on XY
#     R       -   desired minimum intercluster distance, R&gt;=0
# 
# OUTPUT PARAMETERS:
#     K       -   number of clusters, 1&lt;=K&lt;=NPoints
#     CIdx    -   array[NPoints], I-th element contains cluster index  (from
#                 0 to K-1) for I-th point of the dataset.
#     CZ      -   array[K]. This array allows  to  convert  cluster  indexes
#                 returned by this function to indexes used by  Rep.Z.  J-th
#                 cluster returned by this function corresponds to  CZ[J]-th
#                 cluster stored in Rep.Z/PZ/PM.
#                 It is guaranteed that CZ[I]&lt;CZ[I+1].
# 
# NOTE: K clusters built by this subroutine are assumed to have no hierarchy.
#       Although  they  were  obtained  by  manipulation with top K nodes of
#       dendrogram  (i.e.  hierarchical  decomposition  of  dataset),   this
#       function does not return information about hierarchy.  Each  of  the
#       clusters stand on its own.
# 
# NOTE: Cluster indexes returned by this function  does  not  correspond  to
#       indexes returned in Rep.Z/PZ/PM. Either you work  with  hierarchical
#       representation of the dataset (dendrogram), or you work with  &quot;flat&quot;
#       representation returned by this function.  Each  of  representations
#       has its own clusters indexing system (former uses [0, 2*NPoints-2]),
#       while latter uses [0..K-1]), although  it  is  possible  to  perform
#       conversion from one system to another by means of CZ array, returned
#       by this function, which allows you to convert indexes stored in CIdx
#       to the numeration system used by Rep.Z.
# 
# NOTE: this subroutine is optimized for moderate values of K. Say, for  K=5
#       it will perform many times faster than  for  K=100.  Its  worst-case
#       performance is O(N*K), although in average case  it  perform  better
#       (up to O(N*log(K))).
# 
#   -- ALGLIB --
#      Copyright 10.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   k, cidx, cz = xalglib.clusterizerseparatedbydist(rep, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     rep:        class xalglib.ahcreport
          r:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  k:          int
          cidx:       1D array/list of int
          cz:         1D array/list of int

</div></pre>
<a name='sub_clusterizersetahcalgo'></a><h3 class=pageheader><code>clusterizersetahcalgo</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets agglomerative hierarchical clustering algorithm
# 
# INPUT PARAMETERS:
#     S       -   clusterizer state, initialized by ClusterizerCreate()
#     Algo    -   algorithm type:
#                 * 0     complete linkage (default algorithm)
#                 * 1     single linkage
#                 * 2     unweighted average linkage
#                 * 3     weighted average linkage
#                 * 4     Ward's method
# 
# NOTE: Ward's method works correctly only with Euclidean  distance,  that's
#       why algorithm will return negative termination  code  (failure)  for
#       any other distance type.
# 
#       It is possible, however,  to  use  this  method  with  user-supplied
#       distance matrix. It  is  your  responsibility  to pass one which was
#       calculated with Euclidean distance function.
# 
#   -- ALGLIB --
#      Copyright 10.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.clusterizersetahcalgo(s, algo)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.clusterizerstate
          algo:       int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_clusterizersetdistances'></a><h3 class=pageheader><code>clusterizersetdistances</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function adds dataset given by distance  matrix  to  the  clusterizer
# structure. It is important that dataset is not  given  explicitly  -  only
# distance matrix is given.
# 
# This function overrides all previous calls  of  ClusterizerSetPoints()  or
# ClusterizerSetDistances().
# 
# INPUT PARAMETERS:
#     S       -   clusterizer state, initialized by ClusterizerCreate()
#     D       -   array[NPoints,NPoints], distance matrix given by its upper
#                 or lower triangle (main diagonal is  ignored  because  its
#                 entries are expected to be zero).
#     NPoints -   number of points
#     IsUpper -   whether upper or lower triangle of D is given.
# 
# NOTE 1: different clustering algorithms have different limitations:
#         * agglomerative hierarchical clustering algorithms may be used with
#           any kind of distance metric, including one  which  is  given  by
#           distance matrix
#         * k-means++ clustering algorithm may be used only  with  Euclidean
#           distance function and explicitly given points - it  can  not  be
#           used with dataset given by distance matrix
#         Thus, if you call this function, you will be unable to use k-means
#         clustering algorithm to process your problem.
# 
#   -- ALGLIB --
#      Copyright 10.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.clusterizersetdistances(s, d, npoints, isupper)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.clusterizersetdistances(s, d, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.clusterizerstate
          d:          2D array/list of float
          npoints:    int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_clusterizersetkmeansinit'></a><h3 class=pageheader><code>clusterizersetkmeansinit</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets k-means  initialization  algorithm.  Several  different
# algorithms can be chosen, including k-means++.
# 
# INPUT PARAMETERS:
#     S       -   clusterizer state, initialized by ClusterizerCreate()
#     InitAlgo-   initialization algorithm:
#                 * 0  automatic selection ( different  versions  of  ALGLIB
#                      may select different algorithms)
#                 * 1  random initialization
#                 * 2  k-means++ initialization  (best  quality  of  initial
#                      centers, but long  non-parallelizable  initialization
#                      phase with bad cache locality)
#                 * 3  &quot;fast-greedy&quot;  algorithm  with  efficient,  easy   to
#                      parallelize initialization. Quality of initial centers
#                      is  somewhat  worse  than  that  of  k-means++.  This
#                      algorithm is a default one in the current version  of
#                      ALGLIB.
#                 *-1  &quot;debug&quot; algorithm which always selects first  K  rows
#                      of dataset; this algorithm is used for debug purposes
#                      only. Do not use it in the industrial code!
# 
#   -- ALGLIB --
#      Copyright 21.01.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.clusterizersetkmeansinit(s, initalgo)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.clusterizerstate
          initalgo:   int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_clusterizersetkmeanslimits'></a><h3 class=pageheader><code>clusterizersetkmeanslimits</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  sets k-means properties:  number  of  restarts and maximum
# number of iterations per one run.
# 
# INPUT PARAMETERS:
#     S       -   clusterizer state, initialized by ClusterizerCreate()
#     Restarts-   restarts count, &gt;=1.
#                 k-means++ algorithm performs several restarts and  chooses
#                 best set of centers (one with minimum squared distance).
#     MaxIts  -   maximum number of k-means iterations performed during  one
#                 run. &gt;=0, zero value means that algorithm performs unlimited
#                 number of iterations.
# 
#   -- ALGLIB --
#      Copyright 10.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.clusterizersetkmeanslimits(s, restarts, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.clusterizerstate
          restarts:   int
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_clusterizersetpoints'></a><h3 class=pageheader><code>clusterizersetpoints</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function adds dataset to the clusterizer structure.
# 
# This function overrides all previous calls  of  ClusterizerSetPoints()  or
# ClusterizerSetDistances().
# 
# INPUT PARAMETERS:
#     S       -   clusterizer state, initialized by ClusterizerCreate()
#     XY      -   array[NPoints,NFeatures], dataset
#     NPoints -   number of points, &gt;=0
#     NFeatures-  number of features, &gt;=1
#     DistType-   distance function:
#                 *  0    Chebyshev distance  (L-inf norm)
#                 *  1    city block distance (L1 norm)
#                 *  2    Euclidean distance  (L2 norm), non-squared
#                 * 10    Pearson correlation:
#                         dist(a,b) = 1-corr(a,b)
#                 * 11    Absolute Pearson correlation:
#                         dist(a,b) = 1-|corr(a,b)|
#                 * 12    Uncentered Pearson correlation (cosine of the angle):
#                         dist(a,b) = a'*b/(|a|*|b|)
#                 * 13    Absolute uncentered Pearson correlation
#                         dist(a,b) = |a'*b|/(|a|*|b|)
#                 * 20    Spearman rank correlation:
#                         dist(a,b) = 1-rankcorr(a,b)
#                 * 21    Absolute Spearman rank correlation
#                         dist(a,b) = 1-|rankcorr(a,b)|
# 
# NOTE 1: different distance functions have different performance penalty:
#         * Euclidean or Pearson correlation distances are the fastest ones
#         * Spearman correlation distance function is a bit slower
#         * city block and Chebyshev distances are order of magnitude slower
# 
#         The reason behing difference in performance is that correlation-based
#         distance functions are computed using optimized linear algebra kernels,
#         while Chebyshev and city block distance functions are computed using
#         simple nested loops with two branches at each iteration.
# 
# NOTE 2: different clustering algorithms have different limitations:
#         * agglomerative hierarchical clustering algorithms may be used with
#           any kind of distance metric
#         * k-means++ clustering algorithm may be used only  with  Euclidean
#           distance function
#         Thus, list of specific clustering algorithms you may  use  depends
#         on distance function you specify when you set your dataset.
# 
#   -- ALGLIB --
#      Copyright 10.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.clusterizersetpoints(s, xy, npoints, nfeatures, disttype)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.clusterizersetpoints(s, xy, disttype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.clusterizerstate
          xy:         2D array/list of float
          npoints:    int
          nfeatures:  int
          disttype:   int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_clusterizersetseed'></a><h3 class=pageheader><code>clusterizersetseed</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  sets  seed  which  is  used to initialize internal RNG. By
# default, deterministic seed is used - same for each run of clusterizer. If
# you specify non-deterministic  seed  value,  then  some  algorithms  which
# depend on random initialization (in current version: k-means)  may  return
# slightly different results after each run.
# 
# INPUT PARAMETERS:
#     S       -   clusterizer state, initialized by ClusterizerCreate()
#     Seed    -   seed:
#                 * positive values = use deterministic seed for each run of
#                   algorithms which depend on random initialization
#                 * zero or negative values = use non-deterministic seed
# 
#   -- ALGLIB --
#      Copyright 08.06.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.clusterizersetseed(s, seed)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.clusterizerstate
          seed:       int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_conv></a><h2 class=pageheader><code>conv</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_convc1d' class=toc>convc1d</a><br>
<a href='#sub_convc1dbuf' class=toc>convc1dbuf</a><br>
<a href='#sub_convc1dcircular' class=toc>convc1dcircular</a><br>
<a href='#sub_convc1dcircularbuf' class=toc>convc1dcircularbuf</a><br>
<a href='#sub_convc1dcircularinv' class=toc>convc1dcircularinv</a><br>
<a href='#sub_convc1dcircularinvbuf' class=toc>convc1dcircularinvbuf</a><br>
<a href='#sub_convc1dinv' class=toc>convc1dinv</a><br>
<a href='#sub_convc1dinvbuf' class=toc>convc1dinvbuf</a><br>
<a href='#sub_convr1d' class=toc>convr1d</a><br>
<a href='#sub_convr1dbuf' class=toc>convr1dbuf</a><br>
<a href='#sub_convr1dcircular' class=toc>convr1dcircular</a><br>
<a href='#sub_convr1dcircularbuf' class=toc>convr1dcircularbuf</a><br>
<a href='#sub_convr1dcircularinv' class=toc>convr1dcircularinv</a><br>
<a href='#sub_convr1dcircularinvbuf' class=toc>convr1dcircularinvbuf</a><br>
<a href='#sub_convr1dinv' class=toc>convr1dinv</a><br>
<a href='#sub_convr1dinvbuf' class=toc>convr1dinvbuf</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_convc1d'></a><h3 class=pageheader><code>convc1d</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional complex convolution.
# 
# For given A/B returns conv(A,B) (non-circular). Subroutine can automatically
# choose between three implementations: straightforward O(M*N)  formula  for
# very small N (or M), overlap-add algorithm for  cases  where  max(M,N)  is
# significantly larger than min(M,N), but O(M*N) algorithm is too slow,  and
# general FFT-based formula for cases where two previous algorithms are  too
# slow.
# 
# Algorithm has max(M,N)*log(max(M,N)) complexity for any M/N.
# 
# INPUT PARAMETERS
#     A   -   array[M] - complex function to be transformed
#     M   -   problem size
#     B   -   array[N] - complex function to be transformed
#     N   -   problem size
# 
# OUTPUT PARAMETERS
#     R   -   convolution: A*B. array[N+M-1]
# 
# NOTE:
#     It is assumed that A is zero at T&lt;0, B is zero too.  If  one  or  both
#     functions have non-zero values at negative T's, you can still use this
#     subroutine - just shift its result correspondingly.
# 
# NOTE: there is a buffered version of this  function,  ConvC1DBuf(),  which
#       can reuse space previously allocated in its output parameter R.
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.convc1d(a, m, b, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of complex
          m:          int
          b:          1D array/list of complex
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of complex

</div></pre>
<a name='sub_convc1dbuf'></a><h3 class=pageheader><code>convc1dbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional complex convolution, buffered version of ConvC1DBuf(), which
# does not reallocate R[] if its length is enough to store the result  (i.e.
# it reuses previously allocated memory as much as possible).
# 
#   -- ALGLIB --
#      Copyright 30.11.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.convc1dbuf(a, m, b, n, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of complex
          m:          int
          b:          1D array/list of complex
          n:          int
          r:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of complex

</div></pre>
<a name='sub_convc1dcircular'></a><h3 class=pageheader><code>convc1dcircular</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional circular complex convolution.
# 
# For given S/R returns conv(S,R) (circular). Algorithm has linearithmic
# complexity for any M/N.
# 
# IMPORTANT:  normal convolution is commutative,  i.e.   it  is symmetric  -
# conv(A,B)=conv(B,A).  Cyclic convolution IS NOT.  One function - S - is  a
# signal,  periodic function, and another - R - is a response,  non-periodic
# function with limited length.
# 
# INPUT PARAMETERS
#     S   -   array[M] - complex periodic signal
#     M   -   problem size
#     B   -   array[N] - complex non-periodic response
#     N   -   problem size
# 
# OUTPUT PARAMETERS
#     R   -   convolution: A*B. array[M].
# 
# NOTE:
#     It is assumed that B is zero at T&lt;0. If  it  has  non-zero  values  at
# negative T's, you can still use this subroutine - just  shift  its  result
# correspondingly.
# 
# NOTE: there is a buffered version of this  function,  ConvC1DCircularBuf(),
#       which can reuse space previously allocated in its output parameter R.
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.convc1dcircular(s, m, r, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          1D array/list of complex
          m:          int
          r:          1D array/list of complex
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of complex

</div></pre>
<a name='sub_convc1dcircularbuf'></a><h3 class=pageheader><code>convc1dcircularbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional circular complex convolution.
# 
# Buffered version of ConvC1DCircular(), which does not  reallocate  C[]  if
# its length is enough to  store  the  result  (i.e.  it  reuses  previously
# allocated memory as much as possible).
# 
#   -- ALGLIB --
#      Copyright 30.11.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.convc1dcircularbuf(s, m, r, n, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          1D array/list of complex
          m:          int
          r:          1D array/list of complex
          n:          int
          c:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of complex

</div></pre>
<a name='sub_convc1dcircularinv'></a><h3 class=pageheader><code>convc1dcircularinv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional circular complex deconvolution (inverse of ConvC1DCircular()).
# 
# Algorithm has M*log(M)) complexity for any M (composite or prime).
# 
# INPUT PARAMETERS
#     A   -   array[0..M-1] - convolved periodic signal, A = conv(R, B)
#     M   -   convolved signal length
#     B   -   array[0..N-1] - non-periodic response
#     N   -   response length
# 
# OUTPUT PARAMETERS
#     R   -   deconvolved signal. array[0..M-1].
# 
# NOTE:
#     deconvolution is unstable process and may result in division  by  zero
# (if your response function is degenerate, i.e. has zero Fourier coefficient).
# 
# NOTE:
#     It is assumed that B is zero at T&lt;0. If  it  has  non-zero  values  at
# negative T's, you can still use this subroutine - just  shift  its  result
# correspondingly.
# 
# NOTE: there is a buffered version of this  function,  ConvC1DCircularInvBuf(),
#       which can reuse space previously allocated in its output parameter R.
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.convc1dcircularinv(a, m, b, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of complex
          m:          int
          b:          1D array/list of complex
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of complex

</div></pre>
<a name='sub_convc1dcircularinvbuf'></a><h3 class=pageheader><code>convc1dcircularinvbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional circular complex deconvolution (inverse of ConvC1DCircular()).
# 
# Buffered version of ConvC1DCircularInv(), which does not reallocate R[] if
# its length is enough to  store  the  result  (i.e.  it  reuses  previously
# allocated memory as much as possible).
# 
#   -- ALGLIB --
#      Copyright 30.11.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.convc1dcircularinvbuf(a, m, b, n, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of complex
          m:          int
          b:          1D array/list of complex
          n:          int
          r:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of complex

</div></pre>
<a name='sub_convc1dinv'></a><h3 class=pageheader><code>convc1dinv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional complex non-circular deconvolution (inverse of ConvC1D()).
# 
# Algorithm has M*log(M)) complexity for any M (composite or prime).
# 
# INPUT PARAMETERS
#     A   -   array[0..M-1] - convolved signal, A = conv(R, B)
#     M   -   convolved signal length
#     B   -   array[0..N-1] - response
#     N   -   response length, N&lt;=M
# 
# OUTPUT PARAMETERS
#     R   -   deconvolved signal. array[0..M-N].
# 
# NOTE:
#     deconvolution is unstable process and may result in division  by  zero
# (if your response function is degenerate, i.e. has zero Fourier coefficient).
# 
# NOTE:
#     It is assumed that A is zero at T&lt;0, B is zero too.  If  one  or  both
# functions have non-zero values at negative T's, you  can  still  use  this
# subroutine - just shift its result correspondingly.
# 
# NOTE: there is a buffered version of this  function,  ConvC1DInvBuf(),
#       which can reuse space previously allocated in its output parameter R
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.convc1dinv(a, m, b, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of complex
          m:          int
          b:          1D array/list of complex
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of complex

</div></pre>
<a name='sub_convc1dinvbuf'></a><h3 class=pageheader><code>convc1dinvbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional complex non-circular deconvolution (inverse of ConvC1D()).
# 
# A buffered version, which does not reallocate R[] if its length is  enough
# to store the result (i.e. it reuses previously allocated memory as much as
# possible).
# 
#   -- ALGLIB --
#      Copyright 30.11.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.convc1dinvbuf(a, m, b, n, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of complex
          m:          int
          b:          1D array/list of complex
          n:          int
          r:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of complex

</div></pre>
<a name='sub_convr1d'></a><h3 class=pageheader><code>convr1d</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional real convolution.
# 
# Analogous to ConvC1D(), see ConvC1D() comments for more details.
# 
# INPUT PARAMETERS
#     A   -   array[0..M-1] - real function to be transformed
#     M   -   problem size
#     B   -   array[0..N-1] - real function to be transformed
#     N   -   problem size
# 
# OUTPUT PARAMETERS
#     R   -   convolution: A*B. array[0..N+M-2].
# 
# NOTE:
#     It is assumed that A is zero at T&lt;0, B is zero too.  If  one  or  both
# functions have non-zero values at negative T's, you  can  still  use  this
# subroutine - just shift its result correspondingly.
# 
# NOTE: there is a buffered version of this  function,  ConvR1DBuf(),
#       which can reuse space previously allocated in its output parameter R.
# 
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.convr1d(a, m, b, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          m:          int
          b:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of float

</div></pre>
<a name='sub_convr1dbuf'></a><h3 class=pageheader><code>convr1dbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional real convolution.
# 
# Buffered version of ConvR1D(), which does not reallocate R[] if its length
# is enough to store the result (i.e. it reuses previously allocated  memory
# as much as possible).
# 
#   -- ALGLIB --
#      Copyright 30.11.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.convr1dbuf(a, m, b, n, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          m:          int
          b:          1D array/list of float
          n:          int
          r:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of float

</div></pre>
<a name='sub_convr1dcircular'></a><h3 class=pageheader><code>convr1dcircular</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional circular real convolution.
# 
# Analogous to ConvC1DCircular(), see ConvC1DCircular() comments for more details.
# 
# INPUT PARAMETERS
#     S   -   array[0..M-1] - real signal
#     M   -   problem size
#     B   -   array[0..N-1] - real response
#     N   -   problem size
# 
# OUTPUT PARAMETERS
#     R   -   convolution: A*B. array[0..M-1].
# 
# NOTE:
#     It is assumed that B is zero at T&lt;0. If  it  has  non-zero  values  at
# negative T's, you can still use this subroutine - just  shift  its  result
# correspondingly.
# 
# NOTE: there is a buffered version of this  function,  ConvR1DCurcularBuf(),
#       which can reuse space previously allocated in its output parameter R.
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.convr1dcircular(s, m, r, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          1D array/list of float
          m:          int
          r:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of float

</div></pre>
<a name='sub_convr1dcircularbuf'></a><h3 class=pageheader><code>convr1dcircularbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional circular real convolution, buffered version, which  does not
# reallocate C[] if its length is enough to store the result (i.e. it reuses
# previously allocated memory as much as possible).
# 
#   -- ALGLIB --
#      Copyright 30.11.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.convr1dcircularbuf(s, m, r, n, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          1D array/list of float
          m:          int
          r:          1D array/list of float
          n:          int
          c:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of float

</div></pre>
<a name='sub_convr1dcircularinv'></a><h3 class=pageheader><code>convr1dcircularinv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional complex deconvolution (inverse of ConvC1D()).
# 
# Algorithm has M*log(M)) complexity for any M (composite or prime).
# 
# INPUT PARAMETERS
#     A   -   array[0..M-1] - convolved signal, A = conv(R, B)
#     M   -   convolved signal length
#     B   -   array[0..N-1] - response
#     N   -   response length
# 
# OUTPUT PARAMETERS
#     R   -   deconvolved signal. array[0..M-N].
# 
# NOTE:
#     deconvolution is unstable process and may result in division  by  zero
# (if your response function is degenerate, i.e. has zero Fourier coefficient).
# 
# NOTE:
#     It is assumed that B is zero at T&lt;0. If  it  has  non-zero  values  at
# negative T's, you can still use this subroutine - just  shift  its  result
# correspondingly.
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.convr1dcircularinv(a, m, b, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          m:          int
          b:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of float

</div></pre>
<a name='sub_convr1dcircularinvbuf'></a><h3 class=pageheader><code>convr1dcircularinvbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional complex deconvolution, inverse of ConvR1DCircular().
# 
# Buffered version, which does not reallocate R[] if its length is enough to
# store the result (i.e. it reuses previously allocated memory  as  much  as
# possible).
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.convr1dcircularinvbuf(a, m, b, n, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          m:          int
          b:          1D array/list of float
          n:          int
          r:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of float

</div></pre>
<a name='sub_convr1dinv'></a><h3 class=pageheader><code>convr1dinv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional real deconvolution (inverse of ConvC1D()).
# 
# Algorithm has M*log(M)) complexity for any M (composite or prime).
# 
# INPUT PARAMETERS
#     A   -   array[0..M-1] - convolved signal, A = conv(R, B)
#     M   -   convolved signal length
#     B   -   array[0..N-1] - response
#     N   -   response length, N&lt;=M
# 
# OUTPUT PARAMETERS
#     R   -   deconvolved signal. array[0..M-N].
# 
# NOTE:
#     deconvolution is unstable process and may result in division  by  zero
# (if your response function is degenerate, i.e. has zero Fourier coefficient).
# 
# NOTE:
#     It is assumed that A is zero at T&lt;0, B is zero too.  If  one  or  both
# functions have non-zero values at negative T's, you  can  still  use  this
# subroutine - just shift its result correspondingly.
# 
# NOTE: there is a buffered version of this  function,  ConvR1DInvBuf(),
#       which can reuse space previously allocated in its output parameter R.
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.convr1dinv(a, m, b, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          m:          int
          b:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of float

</div></pre>
<a name='sub_convr1dinvbuf'></a><h3 class=pageheader><code>convr1dinvbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional real deconvolution (inverse of ConvR1D()), buffered version,
# which does not reallocate R[] if its length is enough to store the  result
# (i.e. it reuses previously allocated memory as much as possible).
# 
# 
#   -- ALGLIB --
#      Copyright 30.11.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.convr1dinvbuf(a, m, b, n, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          m:          int
          b:          1D array/list of float
          n:          int
          r:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of float

</div></pre>
<a name=unit_corr></a><h2 class=pageheader><code>corr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_corrc1d' class=toc>corrc1d</a><br>
<a href='#sub_corrc1dbuf' class=toc>corrc1dbuf</a><br>
<a href='#sub_corrc1dcircular' class=toc>corrc1dcircular</a><br>
<a href='#sub_corrc1dcircularbuf' class=toc>corrc1dcircularbuf</a><br>
<a href='#sub_corrr1d' class=toc>corrr1d</a><br>
<a href='#sub_corrr1dbuf' class=toc>corrr1dbuf</a><br>
<a href='#sub_corrr1dcircular' class=toc>corrr1dcircular</a><br>
<a href='#sub_corrr1dcircularbuf' class=toc>corrr1dcircularbuf</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_corrc1d'></a><h3 class=pageheader><code>corrc1d</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional complex cross-correlation.
# 
# For given Pattern/Signal returns corr(Pattern,Signal) (non-circular).
# 
# Correlation is calculated using reduction to  convolution.  Algorithm with
# max(N,N)*log(max(N,N)) complexity is used (see  ConvC1D()  for  more  info
# about performance).
# 
# IMPORTANT:
#     for  historical reasons subroutine accepts its parameters in  reversed
#     order: CorrC1D(Signal, Pattern) = Pattern x Signal (using  traditional
#     definition of cross-correlation, denoting cross-correlation as &quot;x&quot;).
# 
# INPUT PARAMETERS
#     Signal  -   array[0..N-1] - complex function to be transformed,
#                 signal containing pattern
#     N       -   problem size
#     Pattern -   array[0..M-1] - complex function to be transformed,
#                 pattern to 'search' within a signal
#     M       -   problem size
# 
# OUTPUT PARAMETERS
#     R       -   cross-correlation, array[0..N+M-2]:
#                 * positive lags are stored in R[0..N-1],
#                   R[i] = sum(conj(pattern[j])*signal[i+j]
#                 * negative lags are stored in R[N..N+M-2],
#                   R[N+M-1-i] = sum(conj(pattern[j])*signal[-i+j]
# 
# NOTE:
#     It is assumed that pattern domain is [0..M-1].  If Pattern is non-zero
# on [-K..M-1],  you can still use this subroutine, just shift result by K.
# 
# NOTE: there is a buffered version of this  function,  CorrC1DBuf(), which
#      can reuse space previously allocated in its output parameter R.
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.corrc1d(signal, n, pattern, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     signal:     1D array/list of complex
          n:          int
          pattern:    1D array/list of complex
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of complex

</div></pre>
<a name='sub_corrc1dbuf'></a><h3 class=pageheader><code>corrc1dbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional complex cross-correlation, a buffered version  of  CorrC1D()
# which does not reallocate R[] if its length is enough to store the  result
# (i.e. it reuses previously allocated memory as much as possible).
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.corrc1dbuf(signal, n, pattern, m, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     signal:     1D array/list of complex
          n:          int
          pattern:    1D array/list of complex
          m:          int
          r:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of complex

</div></pre>
<a name='sub_corrc1dcircular'></a><h3 class=pageheader><code>corrc1dcircular</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional circular complex cross-correlation.
# 
# For given Pattern/Signal returns corr(Pattern,Signal) (circular).
# Algorithm has linearithmic complexity for any M/N.
# 
# IMPORTANT:
#     for  historical reasons subroutine accepts its parameters in  reversed
#     order:   CorrC1DCircular(Signal, Pattern) = Pattern x Signal    (using
#     traditional definition of cross-correlation, denoting cross-correlation
#     as &quot;x&quot;).
# 
# INPUT PARAMETERS
#     Signal  -   array[0..N-1] - complex function to be transformed,
#                 periodic signal containing pattern
#     N       -   problem size
#     Pattern -   array[0..M-1] - complex function to be transformed,
#                 non-periodic pattern to 'search' within a signal
#     M       -   problem size
# 
# OUTPUT PARAMETERS
#     R   -   convolution: A*B. array[0..M-1].
# 
# NOTE: there is a buffered version of this  function,  CorrC1DCircular(),
#       which can reuse space previously allocated in its output parameter R.
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.corrc1dcircular(signal, m, pattern, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     signal:     1D array/list of complex
          m:          int
          pattern:    1D array/list of complex
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of complex

</div></pre>
<a name='sub_corrc1dcircularbuf'></a><h3 class=pageheader><code>corrc1dcircularbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional circular complex cross-correlation.
# 
# A buffered function which does not reallocate C[] if its length is  enough
# to store the result (i.e. it reuses previously allocated memory as much as
# possible).
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.corrc1dcircularbuf(signal, m, pattern, n, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     signal:     1D array/list of complex
          m:          int
          pattern:    1D array/list of complex
          n:          int
          c:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of complex

</div></pre>
<a name='sub_corrr1d'></a><h3 class=pageheader><code>corrr1d</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional real cross-correlation.
# 
# For given Pattern/Signal returns corr(Pattern,Signal) (non-circular).
# 
# Correlation is calculated using reduction to  convolution.  Algorithm with
# max(N,N)*log(max(N,N)) complexity is used (see  ConvC1D()  for  more  info
# about performance).
# 
# IMPORTANT:
#     for  historical reasons subroutine accepts its parameters in  reversed
#     order: CorrR1D(Signal, Pattern) = Pattern x Signal (using  traditional
#     definition of cross-correlation, denoting cross-correlation as &quot;x&quot;).
# 
# INPUT PARAMETERS
#     Signal  -   array[0..N-1] - real function to be transformed,
#                 signal containing pattern
#     N       -   problem size
#     Pattern -   array[0..M-1] - real function to be transformed,
#                 pattern to 'search' withing signal
#     M       -   problem size
# 
# OUTPUT PARAMETERS
#     R       -   cross-correlation, array[0..N+M-2]:
#                 * positive lags are stored in R[0..N-1],
#                   R[i] = sum(pattern[j]*signal[i+j]
#                 * negative lags are stored in R[N..N+M-2],
#                   R[N+M-1-i] = sum(pattern[j]*signal[-i+j]
# 
# NOTE:
#     It is assumed that pattern domain is [0..M-1].  If Pattern is non-zero
# on [-K..M-1],  you can still use this subroutine, just shift result by K.
# 
# NOTE: there is a buffered version of this  function,  CorrR1DBuf(),  which
#       can reuse space previously allocated in its output parameter R.
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.corrr1d(signal, n, pattern, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     signal:     1D array/list of float
          n:          int
          pattern:    1D array/list of float
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of float

</div></pre>
<a name='sub_corrr1dbuf'></a><h3 class=pageheader><code>corrr1dbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional real cross-correlation, buffered function,  which  does  not
# reallocate R[] if its length is enough to store the result (i.e. it reuses
# previously allocated memory as much as possible).
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.corrr1dbuf(signal, n, pattern, m, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     signal:     1D array/list of float
          n:          int
          pattern:    1D array/list of float
          m:          int
          r:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of float

</div></pre>
<a name='sub_corrr1dcircular'></a><h3 class=pageheader><code>corrr1dcircular</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional circular real cross-correlation.
# 
# For given Pattern/Signal returns corr(Pattern,Signal) (circular).
# Algorithm has linearithmic complexity for any M/N.
# 
# IMPORTANT:
#     for  historical reasons subroutine accepts its parameters in  reversed
#     order:   CorrR1DCircular(Signal, Pattern) = Pattern x Signal    (using
#     traditional definition of cross-correlation, denoting cross-correlation
#     as &quot;x&quot;).
# 
# INPUT PARAMETERS
#     Signal  -   array[0..N-1] - real function to be transformed,
#                 periodic signal containing pattern
#     N       -   problem size
#     Pattern -   array[0..M-1] - real function to be transformed,
#                 non-periodic pattern to search withing signal
#     M       -   problem size
# 
# OUTPUT PARAMETERS
#     R   -   convolution: A*B. array[0..M-1].
# 
# NOTE: there is a buffered version of this  function,  CorrR1DCircularBuf(),
#       which can reuse space previously allocated in its output parameter C.
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.corrr1dcircular(signal, m, pattern, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     signal:     1D array/list of float
          m:          int
          pattern:    1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of float

</div></pre>
<a name='sub_corrr1dcircularbuf'></a><h3 class=pageheader><code>corrr1dcircularbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional circular real cross-correlation,  buffered  version ,  which
# does not reallocate C[] if its length is enough to store the result  (i.e.
# it reuses previously allocated memory as much as possible).
# 
#   -- ALGLIB --
#      Copyright 21.07.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.corrr1dcircularbuf(signal, m, pattern, n, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     signal:     1D array/list of float
          m:          int
          pattern:    1D array/list of float
          n:          int
          c:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of float

</div></pre>
<a name=unit_correlationtests></a><h2 class=pageheader><code>correlationtests</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_pearsoncorrelationsignificance' class=toc>pearsoncorrelationsignificance</a><br>
<a href='#sub_spearmanrankcorrelationsignificance' class=toc>spearmanrankcorrelationsignificance</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_pearsoncorrelationsignificance'></a><h3 class=pageheader><code>pearsoncorrelationsignificance</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Pearson's correlation coefficient significance test
# 
# This test checks hypotheses about whether X  and  Y  are  samples  of  two
# continuous  distributions  having  zero  correlation  or   whether   their
# correlation is non-zero.
# 
# The following tests are performed:
#     * two-tailed test (null hypothesis - X and Y have zero correlation)
#     * left-tailed test (null hypothesis - the correlation  coefficient  is
#       greater than or equal to 0)
#     * right-tailed test (null hypothesis - the correlation coefficient  is
#       less than or equal to 0).
# 
# Requirements:
#     * the number of elements in each sample is not less than 5
#     * normality of distributions of X and Y.
# 
# Input parameters:
#     R   -   Pearson's correlation coefficient for X and Y
#     N   -   number of elements in samples, N&gt;=5.
# 
# Output parameters:
#     BothTails   -   p-value for two-tailed test.
#                     If BothTails is less than the given significance level
#                     the null hypothesis is rejected.
#     LeftTail    -   p-value for left-tailed test.
#                     If LeftTail is less than the given significance level,
#                     the null hypothesis is rejected.
#     RightTail   -   p-value for right-tailed test.
#                     If RightTail is less than the given significance level
#                     the null hypothesis is rejected.
# 
#   -- ALGLIB --
#      Copyright 09.04.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   bothtails, lefttail, righttail = xalglib.pearsoncorrelationsignificance(r, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     r:          float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  bothtails:  float
          lefttail:   float
          righttail:  float

</div></pre>
<a name='sub_spearmanrankcorrelationsignificance'></a><h3 class=pageheader><code>spearmanrankcorrelationsignificance</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Spearman's rank correlation coefficient significance test
# 
# This test checks hypotheses about whether X  and  Y  are  samples  of  two
# continuous  distributions  having  zero  correlation  or   whether   their
# correlation is non-zero.
# 
# The following tests are performed:
#     * two-tailed test (null hypothesis - X and Y have zero correlation)
#     * left-tailed test (null hypothesis - the correlation  coefficient  is
#       greater than or equal to 0)
#     * right-tailed test (null hypothesis - the correlation coefficient  is
#       less than or equal to 0).
# 
# Requirements:
#     * the number of elements in each sample is not less than 5.
# 
# The test is non-parametric and doesn't require distributions X and Y to be
# normal.
# 
# Input parameters:
#     R   -   Spearman's rank correlation coefficient for X and Y
#     N   -   number of elements in samples, N&gt;=5.
# 
# Output parameters:
#     BothTails   -   p-value for two-tailed test.
#                     If BothTails is less than the given significance level
#                     the null hypothesis is rejected.
#     LeftTail    -   p-value for left-tailed test.
#                     If LeftTail is less than the given significance level,
#                     the null hypothesis is rejected.
#     RightTail   -   p-value for right-tailed test.
#                     If RightTail is less than the given significance level
#                     the null hypothesis is rejected.
# 
#   -- ALGLIB --
#      Copyright 09.04.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   bothtails, lefttail, righttail = xalglib.spearmanrankcorrelationsignificance(r, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     r:          float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  bothtails:  float
          lefttail:   float
          righttail:  float

</div></pre>
<a name=unit_datacomp></a><h2 class=pageheader><code>datacomp</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_kmeansgenerate' class=toc>kmeansgenerate</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_kmeansgenerate'></a><h3 class=pageheader><code>kmeansgenerate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# k-means++ clusterization.
# Backward compatibility function, we recommend to use CLUSTERING subpackage
# as better replacement.
# 
#   -- ALGLIB --
#      Copyright 21.03.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, c, xyc = xalglib.kmeansgenerate(xy, npoints, nvars, k, restarts)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nvars:      int
          k:          int
          restarts:   int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          c:          2D array/list of float
          xyc:        1D array/list of int

</div></pre>
<a name=unit_dawson></a><h2 class=pageheader><code>dawson</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_dawsonintegral' class=toc>dawsonintegral</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_dawsonintegral'></a><h3 class=pageheader><code>dawsonintegral</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dawson's Integral
# 
# Approximates the integral
# 
#                             x
#                             -
#                      2     | |        2
#  dawsn(x)  =  exp( -x  )   |    exp( t  ) dt
#                          | |
#                           -
#                           0
# 
# Three different rational approximations are employed, for
# the intervals 0 to 3.25; 3.25 to 6.25; and 6.25 up.
# 
# ACCURACY:
# 
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE      0,10        10000       6.9e-16     1.0e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.dawsonintegral(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_dforest></a><h2 class=pageheader><code>dforest</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_dfavgce' class=toc>dfavgce</a><br>
<a href='#sub_dfavgerror' class=toc>dfavgerror</a><br>
<a href='#sub_dfavgrelerror' class=toc>dfavgrelerror</a><br>
<a href='#sub_dfbinarycompression' class=toc>dfbinarycompression</a><br>
<a href='#sub_dfbuilderbuildrandomforest' class=toc>dfbuilderbuildrandomforest</a><br>
<a href='#sub_dfbuildercreate' class=toc>dfbuildercreate</a><br>
<a href='#sub_dfbuildergetprogress' class=toc>dfbuildergetprogress</a><br>
<a href='#sub_dfbuilderpeekprogress' class=toc>dfbuilderpeekprogress</a><br>
<a href='#sub_dfbuildersetdataset' class=toc>dfbuildersetdataset</a><br>
<a href='#sub_dfbuildersetimportancenone' class=toc>dfbuildersetimportancenone</a><br>
<a href='#sub_dfbuildersetimportanceoobgini' class=toc>dfbuildersetimportanceoobgini</a><br>
<a href='#sub_dfbuildersetimportancepermutation' class=toc>dfbuildersetimportancepermutation</a><br>
<a href='#sub_dfbuildersetimportancetrngini' class=toc>dfbuildersetimportancetrngini</a><br>
<a href='#sub_dfbuildersetrdfalgo' class=toc>dfbuildersetrdfalgo</a><br>
<a href='#sub_dfbuildersetrdfsplitstrength' class=toc>dfbuildersetrdfsplitstrength</a><br>
<a href='#sub_dfbuildersetrndvars' class=toc>dfbuildersetrndvars</a><br>
<a href='#sub_dfbuildersetrndvarsauto' class=toc>dfbuildersetrndvarsauto</a><br>
<a href='#sub_dfbuildersetrndvarsratio' class=toc>dfbuildersetrndvarsratio</a><br>
<a href='#sub_dfbuildersetseed' class=toc>dfbuildersetseed</a><br>
<a href='#sub_dfbuildersetsubsampleratio' class=toc>dfbuildersetsubsampleratio</a><br>
<a href='#sub_dfbuildrandomdecisionforest' class=toc>dfbuildrandomdecisionforest</a><br>
<a href='#sub_dfbuildrandomdecisionforestx1' class=toc>dfbuildrandomdecisionforestx1</a><br>
<a href='#sub_dfclassify' class=toc>dfclassify</a><br>
<a href='#sub_dfcreatebuffer' class=toc>dfcreatebuffer</a><br>
<a href='#sub_dfprocess' class=toc>dfprocess</a><br>
<a href='#sub_dfprocess0' class=toc>dfprocess0</a><br>
<a href='#sub_dfprocessi' class=toc>dfprocessi</a><br>
<a href='#sub_dfrelclserror' class=toc>dfrelclserror</a><br>
<a href='#sub_dfrmserror' class=toc>dfrmserror</a><br>
<a href='#sub_dftsprocess' class=toc>dftsprocess</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_dfavgce'></a><h3 class=pageheader><code>dfavgce</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average cross-entropy (in bits per element) on the test set
# 
# INPUT PARAMETERS:
#     DF      -   decision forest model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     CrossEntropy/(NPoints*LN(2)).
#     Zero if model solves regression task.
# 
#   -- ALGLIB --
#      Copyright 16.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.dfavgce(df, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     df:         class xalglib.decisionforest
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_dfavgerror'></a><h3 class=pageheader><code>dfavgerror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average error on the test set
# 
# INPUT PARAMETERS:
#     DF      -   decision forest model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     Its meaning for regression task is obvious. As for
#     classification task, it means average error when estimating posterior
#     probabilities.
# 
#   -- ALGLIB --
#      Copyright 16.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.dfavgerror(df, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     df:         class xalglib.decisionforest
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_dfavgrelerror'></a><h3 class=pageheader><code>dfavgrelerror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average relative error on the test set
# 
# INPUT PARAMETERS:
#     DF      -   decision forest model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     Its meaning for regression task is obvious. As for
#     classification task, it means average relative error when estimating
#     posterior probability of belonging to the correct class.
# 
#   -- ALGLIB --
#      Copyright 16.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.dfavgrelerror(df, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     df:         class xalglib.decisionforest
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_dfbinarycompression'></a><h3 class=pageheader><code>dfbinarycompression</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function performs binary compression of the decision forest.
# 
# Original decision forest produced by the  forest  builder  is stored using
# 64-bit representation for all numbers - offsets, variable  indexes,  split
# points.
# 
# It is possible to significantly reduce model size by means of:
# * using compressed  dynamic encoding for integers  (offsets  and  variable
#   indexes), which uses just 1 byte to store small ints  (less  than  128),
#   just 2 bytes for larger values (less than 128^2) and so on
# * storing floating point numbers using 8-bit exponent and 16-bit mantissa
# 
# As  result,  model  needs  significantly  less  memory (compression factor
# depends on  variable and class counts). In particular:
# * NVars&lt;128   and NClasses&lt;128 result in 4.4x-5.7x model size reduction
# * NVars&lt;16384 and NClasses&lt;128 result in 3.7x-4.5x model size reduction
# 
# Such storage format performs lossless compression  of  all  integers,  but
# compression of floating point values (split values) is lossy, with roughly
# 0.01% relative error introduced during rounding. Thus, we recommend you to
# re-evaluate model accuracy after compression.
# 
# Another downside  of  compression  is  ~1.5x reduction  in  the  inference
# speed due to necessity of dynamic decompression of the compressed model.
# 
# INPUT PARAMETERS:
#     DF      -   decision forest built by forest builder
# 
# OUTPUT PARAMETERS:
#     DF      -   replaced by compressed forest
# 
# RESULT:
#     compression factor (in-RAM size of the compressed model vs than of the
#     uncompressed one), positive number larger than 1.0
# 
#   -- ALGLIB --
#      Copyright 22.07.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.dfbinarycompression(df)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     df:         class xalglib.decisionforest
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> df
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_dfbuilderbuildrandomforest'></a><h3 class=pageheader><code>dfbuilderbuildrandomforest</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds decision forest according to current settings using
# dataset internally stored in the builder object. Dense algorithm is used.
# 
# NOTE: this   function   uses   dense  algorithm  for  forest  construction
#       independently from the dataset format (dense or sparse).
# 
# NOTE: forest built with this function is  stored  in-memory  using  64-bit
#       data structures for offsets/indexes/split values. It is possible  to
#       convert  forest  into  more  memory-efficient   compressed    binary
#       representation.  Depending  on  the  problem  properties,  3.7x-5.7x
#       compression factors are possible.
# 
#       The downsides of compression are (a) slight reduction in  the  model
#       accuracy and (b) ~1.5x reduction in  the  inference  speed  (due  to
#       increased complexity of the storage format).
# 
#       See comments on dfbinarycompression() for more info.
# 
# Default settings are used by the algorithm; you can tweak  them  with  the
# help of the following functions:
# * dfbuildersetrfactor() - to control a fraction of the  dataset  used  for
#   subsampling
# * dfbuildersetrandomvars() - to control number of variables randomly chosen
#   for decision rule creation
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     S           -   decision forest builder object
#     NTrees      -   NTrees&gt;=1, number of trees to train
# 
# OUTPUT PARAMETERS:
#     DF          -   decision forest. You can compress this forest to  more
#                     compact 16-bit representation with dfbinarycompression()
#     Rep         -   report, see below for information on its fields.
# 
# === report information produced by forest construction function ==========
# 
# Decision forest training report includes following information:
# * training set errors
# * out-of-bag estimates of errors
# * variable importance ratings
# 
# Following fields are used to store information:
# * training set errors are stored in rep.relclserror, rep.avgce, rep.rmserror,
#   rep.avgerror and rep.avgrelerror
# * out-of-bag estimates of errors are stored in rep.oobrelclserror, rep.oobavgce,
#   rep.oobrmserror, rep.oobavgerror and rep.oobavgrelerror
# 
# Variable importance reports, if requested by dfbuildersetimportancegini(),
# dfbuildersetimportancetrngini() or dfbuildersetimportancepermutation()
# call, are stored in:
# * rep.varimportances field stores importance ratings
# * rep.topvars stores variable indexes ordered from the most important to
#   less important ones
# 
# You can find more information about report fields in:
# * comments on dfreport structure
# * comments on dfbuildersetimportancegini function
# * comments on dfbuildersetimportancetrngini function
# * comments on dfbuildersetimportancepermutation function
# 
#   -- ALGLIB --
#      Copyright 21.05.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   df, rep = xalglib.dfbuilderbuildrandomforest(s, ntrees)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.decisionforestbuilder
          ntrees:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  df:         class xalglib.decisionforest
          rep:        class xalglib.dfreport

</div></pre>
<a name='sub_dfbuildercreate'></a><h3 class=pageheader><code>dfbuildercreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine creates DecisionForestBuilder  object  which  is  used  to
# train decision forests.
# 
# By default, new builder stores empty dataset and some  reasonable  default
# settings. At the very least, you should specify dataset prior to  building
# decision forest. You can also tweak settings of  the  forest  construction
# algorithm (recommended, although default setting should work well).
# 
# Following actions are mandatory:
# * calling dfbuildersetdataset() to specify dataset
# * calling dfbuilderbuildrandomforest()  to  build  decision  forest  using
#   current dataset and default settings
# 
# Additionally, you may call:
# * dfbuildersetrndvars() or dfbuildersetrndvarsratio() to specify number of
#   variables randomly chosen for each split
# * dfbuildersetsubsampleratio() to specify fraction of the dataset randomly
#   subsampled to build each tree
# * dfbuildersetseed() to control random seed chosen for tree construction
# 
# INPUT PARAMETERS:
#     none
# 
# OUTPUT PARAMETERS:
#     S           -   decision forest builder
# 
#   -- ALGLIB --
#      Copyright 21.05.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.dfbuildercreate()
<span style='font-weight: bold; color: navy;'>ARGS:</span>     
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.decisionforestbuilder

</div></pre>
<a name='sub_dfbuildergetprogress'></a><h3 class=pageheader><code>dfbuildergetprogress</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is an alias for dfbuilderpeekprogress(), left in ALGLIB  for
# backward compatibility reasons.
# 
#   -- ALGLIB --
#      Copyright 21.05.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.dfbuildergetprogress(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.decisionforestbuilder
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_dfbuilderpeekprogress'></a><h3 class=pageheader><code>dfbuilderpeekprogress</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to peek into  decision  forest  construction process
# from some other thread and get current progress indicator.
# 
# It returns value in [0,1].
# 
# INPUT PARAMETERS:
#     S           -   decision forest builder object used  to  build  forest
#                     in some other thread
# 
# RESULT:
#     progress value, in [0,1]
# 
#   -- ALGLIB --
#      Copyright 21.05.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.dfbuilderpeekprogress(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.decisionforestbuilder
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_dfbuildersetdataset'></a><h3 class=pageheader><code>dfbuildersetdataset</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine adds dense dataset to the internal storage of the  builder
# object. Specifying your dataset in the dense format means that  the  dense
# version of the forest construction algorithm will be invoked.
# 
# INPUT PARAMETERS:
#     S           -   decision forest builder object
#     XY          -   array[NPoints,NVars+1] (minimum size; actual size  can
#                     be larger, only leading part is used anyway), dataset:
#                     * first NVars elements of each row store values of the
#                       independent variables
#                     * last  column  store class number (in 0...NClasses-1)
#                       or real value of the dependent variable
#     NPoints     -   number of rows in the dataset, NPoints&gt;=1
#     NVars       -   number of independent variables, NVars&gt;=1
#     NClasses    -   indicates type of the problem being solved:
#                     * NClasses&gt;=2 means  that  classification  problem  is
#                       solved  (last  column  of  the  dataset stores class
#                       number)
#                     * NClasses=1 means that regression problem  is  solved
#                       (last column of the dataset stores variable value)
# 
# OUTPUT PARAMETERS:
#     S           -   decision forest builder
# 
#   -- ALGLIB --
#      Copyright 21.05.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.dfbuildersetdataset(s, xy, npoints, nvars, nclasses)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.decisionforestbuilder
          xy:         2D array/list of float
          npoints:    int
          nvars:      int
          nclasses:   int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_dfbuildersetimportancenone'></a><h3 class=pageheader><code>dfbuildersetimportancenone</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  tells  decision  forest  construction  algorithm  to  skip
# variable importance estimation.
# 
# INPUT PARAMETERS:
#     S           -   decision forest builder object
# 
# OUTPUT PARAMETERS:
#     S           -   decision forest builder object. Next call to the forest
#                     construction function will result in forest being built
#                     without variable importance estimation.
# 
#   -- ALGLIB --
#      Copyright 29.07.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.dfbuildersetimportancenone(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.decisionforestbuilder
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_dfbuildersetimportanceoobgini'></a><h3 class=pageheader><code>dfbuildersetimportanceoobgini</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  tells  decision  forest  construction  algorithm  to   use
# out-of-bag version of Gini variable importance estimation (also  known  as
# OOB-MDI).
# 
# This version of importance estimation algorithm analyzes mean decrease  in
# impurity (MDI) on out-of-bag sample during splits. The result  is  divided
# by impurity at the root node in order to produce estimate in [0,1] range.
# 
# Such estimates are fast to calculate and resistant to  overfitting  issues
# (thanks to the  out-of-bag  estimates  used). However, OOB Gini rating has
# following downsides:
# * there exist some bias towards continuous and high-cardinality categorical
#   variables
# * Gini rating allows us to order variables by importance, but it  is  hard
#   to define importance of the variable by itself.
# 
# NOTE: informally speaking, MDA (permutation importance) rating answers the
#       question  &quot;what  part  of  the  model  predictive power is ruined by
#       permuting k-th variable?&quot; while MDI tells us &quot;what part of the model
#       predictive power was achieved due to usage of k-th variable&quot;.
# 
#       Thus, MDA rates each variable independently at &quot;0 to 1&quot;  scale while
#       MDI (and OOB-MDI too) tends to divide &quot;unit  amount  of  importance&quot;
#       between several important variables.
# 
#       If  all  variables  are  equally  important,  they  will  have  same
#       MDI/OOB-MDI rating, equal (for OOB-MDI: roughly equal)  to  1/NVars.
#       However, roughly  same  picture  will  be  produced   for  the  &quot;all
#       variables provide information no one is critical&quot; situation  and for
#       the &quot;all variables are critical, drop any one, everything is ruined&quot;
#       situation.
# 
#       Contrary to that, MDA will rate critical variable as ~1.0 important,
#       and important but non-critical variable will  have  less  than  unit
#       rating.
# 
# NOTE: quite an often MDA and MDI return same results. It generally happens
#       on problems with low test set error (a few  percents  at  most)  and
#       large enough training set to avoid overfitting.
# 
#       The difference between MDA, MDI and OOB-MDI becomes  important  only
#       on &quot;hard&quot; tasks with high test set error and/or small training set.
# 
# INPUT PARAMETERS:
#     S           -   decision forest builder object
# 
# OUTPUT PARAMETERS:
#     S           -   decision forest builder object. Next call to the forest
#                     construction function will produce:
#                     * importance estimates in rep.varimportances field
#                     * variable ranks in rep.topvars field
# 
#   -- ALGLIB --
#      Copyright 29.07.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.dfbuildersetimportanceoobgini(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.decisionforestbuilder
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_dfbuildersetimportancepermutation'></a><h3 class=pageheader><code>dfbuildersetimportancepermutation</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  tells  decision  forest  construction  algorithm  to   use
# permutation variable importance estimator (also known as MDA).
# 
# This version of importance estimation algorithm analyzes mean increase  in
# out-of-bag sum of squared  residuals  after  random  permutation  of  J-th
# variable. The result is divided by error computed with all variables being
# perturbed in order to produce R-squared-like estimate in [0,1] range.
# 
# Such estimate  is  slower to calculate than Gini-based rating  because  it
# needs multiple inference runs for each of variables being studied.
# 
# ALGLIB uses parallelized and highly  optimized  algorithm  which  analyzes
# path through the decision tree and allows  to  handle  most  perturbations
# in O(1) time; nevertheless, requesting MDA importances may increase forest
# construction time from 10% to 200% (or more,  if  you  have  thousands  of
# variables).
# 
# However, MDA rating has following benefits over Gini-based ones:
# * no bias towards specific variable types
# * ability to directly evaluate &quot;absolute&quot; importance of some  variable  at
#   &quot;0 to 1&quot; scale (contrary to Gini-based rating, which returns comparative
#   importances).
# 
# NOTE: informally speaking, MDA (permutation importance) rating answers the
#       question  &quot;what  part  of  the  model  predictive power is ruined by
#       permuting k-th variable?&quot; while MDI tells us &quot;what part of the model
#       predictive power was achieved due to usage of k-th variable&quot;.
# 
#       Thus, MDA rates each variable independently at &quot;0 to 1&quot;  scale while
#       MDI (and OOB-MDI too) tends to divide &quot;unit  amount  of  importance&quot;
#       between several important variables.
# 
#       If  all  variables  are  equally  important,  they  will  have  same
#       MDI/OOB-MDI rating, equal (for OOB-MDI: roughly equal)  to  1/NVars.
#       However, roughly  same  picture  will  be  produced   for  the  &quot;all
#       variables provide information no one is critical&quot; situation  and for
#       the &quot;all variables are critical, drop any one, everything is ruined&quot;
#       situation.
# 
#       Contrary to that, MDA will rate critical variable as ~1.0 important,
#       and important but non-critical variable will  have  less  than  unit
#       rating.
# 
# NOTE: quite an often MDA and MDI return same results. It generally happens
#       on problems with low test set error (a few  percents  at  most)  and
#       large enough training set to avoid overfitting.
# 
#       The difference between MDA, MDI and OOB-MDI becomes  important  only
#       on &quot;hard&quot; tasks with high test set error and/or small training set.
# 
# INPUT PARAMETERS:
#     S           -   decision forest builder object
# 
# OUTPUT PARAMETERS:
#     S           -   decision forest builder object. Next call to the forest
#                     construction function will produce:
#                     * importance estimates in rep.varimportances field
#                     * variable ranks in rep.topvars field
# 
#   -- ALGLIB --
#      Copyright 29.07.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.dfbuildersetimportancepermutation(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.decisionforestbuilder
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_dfbuildersetimportancetrngini'></a><h3 class=pageheader><code>dfbuildersetimportancetrngini</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  tells  decision  forest  construction  algorithm  to   use
# Gini impurity based variable importance estimation (also known as MDI).
# 
# This version of importance estimation algorithm analyzes mean decrease  in
# impurity (MDI) on training sample during  splits.  The result  is  divided
# by impurity at the root node in order to produce estimate in [0,1] range.
# 
# Such estimates are fast to calculate and beautifully  normalized  (sum  to
# one) but have following downsides:
# * They ALWAYS sum to 1.0, even if output is completely unpredictable. I.e.
#   MDI allows to order variables by importance, but does not  tell us about
#   &quot;absolute&quot; importances of variables
# * there exist some bias towards continuous and high-cardinality categorical
#   variables
# 
# NOTE: informally speaking, MDA (permutation importance) rating answers the
#       question  &quot;what  part  of  the  model  predictive power is ruined by
#       permuting k-th variable?&quot; while MDI tells us &quot;what part of the model
#       predictive power was achieved due to usage of k-th variable&quot;.
# 
#       Thus, MDA rates each variable independently at &quot;0 to 1&quot;  scale while
#       MDI (and OOB-MDI too) tends to divide &quot;unit  amount  of  importance&quot;
#       between several important variables.
# 
#       If  all  variables  are  equally  important,  they  will  have  same
#       MDI/OOB-MDI rating, equal (for OOB-MDI: roughly equal)  to  1/NVars.
#       However, roughly  same  picture  will  be  produced   for  the  &quot;all
#       variables provide information no one is critical&quot; situation  and for
#       the &quot;all variables are critical, drop any one, everything is ruined&quot;
#       situation.
# 
#       Contrary to that, MDA will rate critical variable as ~1.0 important,
#       and important but non-critical variable will  have  less  than  unit
#       rating.
# 
# NOTE: quite an often MDA and MDI return same results. It generally happens
#       on problems with low test set error (a few  percents  at  most)  and
#       large enough training set to avoid overfitting.
# 
#       The difference between MDA, MDI and OOB-MDI becomes  important  only
#       on &quot;hard&quot; tasks with high test set error and/or small training set.
# 
# INPUT PARAMETERS:
#     S           -   decision forest builder object
# 
# OUTPUT PARAMETERS:
#     S           -   decision forest builder object. Next call to the forest
#                     construction function will produce:
#                     * importance estimates in rep.varimportances field
#                     * variable ranks in rep.topvars field
# 
#   -- ALGLIB --
#      Copyright 29.07.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.dfbuildersetimportancetrngini(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.decisionforestbuilder
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_dfbuildersetrdfalgo'></a><h3 class=pageheader><code>dfbuildersetrdfalgo</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets random decision forest construction algorithm.
# 
# As for now, only one decision forest construction algorithm is supported -
# a dense &quot;baseline&quot; RDF algorithm.
# 
# INPUT PARAMETERS:
#     S           -   decision forest builder object
#     AlgoType    -   algorithm type:
#                     * 0 = baseline dense RDF
# 
# OUTPUT PARAMETERS:
#     S           -   decision forest builder, see
# 
#   -- ALGLIB --
#      Copyright 21.05.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.dfbuildersetrdfalgo(s, algotype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.decisionforestbuilder
          algotype:   int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_dfbuildersetrdfsplitstrength'></a><h3 class=pageheader><code>dfbuildersetrdfsplitstrength</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  sets  split  selection  algorithm used by decision  forest
# classifier. You may choose several algorithms, with  different  speed  and
# quality of the results.
# 
# INPUT PARAMETERS:
#     S           -   decision forest builder object
#     SplitStrength-  split type:
#                     * 0 = split at the random position, fastest one
#                     * 1 = split at the middle of the range
#                     * 2 = strong split at the best point of the range (default)
# 
# OUTPUT PARAMETERS:
#     S           -   decision forest builder, see
# 
#   -- ALGLIB --
#      Copyright 21.05.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.dfbuildersetrdfsplitstrength(s, splitstrength)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.decisionforestbuilder
          splitstrength: int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_dfbuildersetrndvars'></a><h3 class=pageheader><code>dfbuildersetrndvars</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets number  of  variables  (in  [1,NVars]  range)  used  by
# decision forest construction algorithm.
# 
# The default option is to use roughly sqrt(NVars) variables.
# 
# INPUT PARAMETERS:
#     S           -   decision forest builder object
#     RndVars     -   number of randomly selected variables; values  outside
#                     of [1,NVars] range are silently clipped.
# 
# OUTPUT PARAMETERS:
#     S           -   decision forest builder
# 
#   -- ALGLIB --
#      Copyright 21.05.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.dfbuildersetrndvars(s, rndvars)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.decisionforestbuilder
          rndvars:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_dfbuildersetrndvarsauto'></a><h3 class=pageheader><code>dfbuildersetrndvarsauto</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function tells decision forest builder to automatically choose number
# of  variables  used  by  decision forest construction  algorithm.  Roughly
# sqrt(NVars) variables will be used.
# 
# INPUT PARAMETERS:
#     S           -   decision forest builder object
# 
# OUTPUT PARAMETERS:
#     S           -   decision forest builder
# 
#   -- ALGLIB --
#      Copyright 21.05.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.dfbuildersetrndvarsauto(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.decisionforestbuilder
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_dfbuildersetrndvarsratio'></a><h3 class=pageheader><code>dfbuildersetrndvarsratio</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets number of variables used by decision forest construction
# algorithm as a fraction of total variable count (0,1) range.
# 
# The default option is to use roughly sqrt(NVars) variables.
# 
# INPUT PARAMETERS:
#     S           -   decision forest builder object
#     F           -   round(NVars*F) variables are selected
# 
# OUTPUT PARAMETERS:
#     S           -   decision forest builder
# 
#   -- ALGLIB --
#      Copyright 21.05.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.dfbuildersetrndvarsratio(s, f)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.decisionforestbuilder
          f:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_dfbuildersetseed'></a><h3 class=pageheader><code>dfbuildersetseed</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets seed used by internal RNG for  random  subsampling  and
# random selection of variable subsets.
# 
# By default random seed is used, i.e. every time you build decision forest,
# we seed generator with new value  obtained  from  system-wide  RNG.  Thus,
# decision forest builder returns non-deterministic results. You can  change
# such behavior by specyfing fixed positive seed value.
# 
# INPUT PARAMETERS:
#     S           -   decision forest builder object
#     SeedVal     -   seed value:
#                     * positive values are used for seeding RNG with fixed
#                       seed, i.e. subsequent runs on same data will return
#                       same decision forests
#                     * non-positive seed means that random seed is used
#                       for every run of builder, i.e. subsequent  runs  on
#                       same  datasets  will  return   slightly   different
#                       decision forests
# 
# OUTPUT PARAMETERS:
#     S           -   decision forest builder, see
# 
#   -- ALGLIB --
#      Copyright 21.05.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.dfbuildersetseed(s, seedval)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.decisionforestbuilder
          seedval:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_dfbuildersetsubsampleratio'></a><h3 class=pageheader><code>dfbuildersetsubsampleratio</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets size of dataset subsample generated the decision forest
# construction algorithm. Size is specified as a fraction of  total  dataset
# size.
# 
# The default option is to use 50% of the dataset for training, 50% for  the
# OOB estimates. You can decrease fraction F down to 10%, 1% or  even  below
# in order to reduce overfitting.
# 
# INPUT PARAMETERS:
#     S           -   decision forest builder object
#     F           -   fraction of the dataset to use, in (0,1] range. Values
#                     outside of this range will  be  silently  clipped.  At
#                     least one element is always selected for the  training
#                     set.
# 
# OUTPUT PARAMETERS:
#     S           -   decision forest builder
# 
#   -- ALGLIB --
#      Copyright 21.05.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.dfbuildersetsubsampleratio(s, f)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.decisionforestbuilder
          f:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_dfbuildrandomdecisionforest'></a><h3 class=pageheader><code>dfbuildrandomdecisionforest</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds random decision forest.
# 
# --------- DEPRECATED VERSION! USE DECISION FOREST BUILDER OBJECT ---------
# 
#   -- ALGLIB --
#      Copyright 19.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, df, rep = xalglib.dfbuildrandomdecisionforest(xy, npoints, nvars, nclasses, ntrees, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nvars:      int
          nclasses:   int
          ntrees:     int
          r:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          df:         class xalglib.decisionforest
          rep:        class xalglib.dfreport

</div></pre>
<a name='sub_dfbuildrandomdecisionforestx1'></a><h3 class=pageheader><code>dfbuildrandomdecisionforestx1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds random decision forest.
# 
# --------- DEPRECATED VERSION! USE DECISION FOREST BUILDER OBJECT ---------
# 
#   -- ALGLIB --
#      Copyright 19.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, df, rep = xalglib.dfbuildrandomdecisionforestx1(xy, npoints, nvars, nclasses, ntrees, nrndvars, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nvars:      int
          nclasses:   int
          ntrees:     int
          nrndvars:   int
          r:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          df:         class xalglib.decisionforest
          rep:        class xalglib.dfreport

</div></pre>
<a name='sub_dfclassify'></a><h3 class=pageheader><code>dfclassify</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns most probable class number for an  input  X.  It  is
# same as calling  dfprocess(model,x,y), then determining i=argmax(y[i]) and
# returning i.
# 
# A class number in [0,NOut) range in returned for classification  problems,
# -1 is returned when this function is called for regression problems.
# 
# IMPORTANT: this function is thread-unsafe and modifies internal structures
#            of the model! You can not use same model  object  for  parallel
#            evaluation from several threads.
# 
#            Use dftsprocess()  with independent  thread-local  buffers,  if
#            you need thread-safe evaluation.
# 
# INPUT PARAMETERS:
#     Model   -   decision forest model
#     X       -   input vector,  array[0..NVars-1].
# 
# RESULT:
#     class number, -1 for regression tasks
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.dfclassify(model, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     model:      class xalglib.decisionforest
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> model
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_dfcreatebuffer'></a><h3 class=pageheader><code>dfcreatebuffer</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates buffer  structure  which  can  be  used  to  perform
# parallel inference requests.
# 
# DF subpackage  provides two sets of computing functions - ones  which  use
# internal buffer of DF model  (these  functions are single-threaded because
# they use same buffer, which can not  shared  between  threads),  and  ones
# which use external buffer.
# 
# This function is used to initialize external buffer.
# 
# INPUT PARAMETERS
#     Model       -   DF model which is associated with newly created buffer
# 
# OUTPUT PARAMETERS
#     Buf         -   external buffer.
# 
# 
# IMPORTANT: buffer object should be used only with model which was used  to
#            initialize buffer. Any attempt to  use  buffer  with  different
#            object is dangerous - you  may   get  integrity  check  failure
#            (exception) because sizes of internal  arrays  do  not  fit  to
#            dimensions of the model structure.
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   buf = xalglib.dfcreatebuffer(model)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     model:      class xalglib.decisionforest
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  buf:        class xalglib.decisionforestbuffer

</div></pre>
<a name='sub_dfprocess'></a><h3 class=pageheader><code>dfprocess</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inference using decision forest
# 
# IMPORTANT: this  function  is  thread-unsafe  and  may   modify   internal
#            structures of the model! You can not use same model  object for
#            parallel evaluation from several threads.
# 
#            Use dftsprocess()  with  independent  thread-local  buffers  if
#            you need thread-safe evaluation.
# 
# INPUT PARAMETERS:
#     DF      -   decision forest model
#     X       -   input vector,  array[NVars]
#     Y       -   possibly preallocated buffer, reallocated if too small
# 
# OUTPUT PARAMETERS:
#     Y       -   result. Regression estimate when solving regression  task,
#                 vector of posterior probabilities for classification task.
# 
# See also DFProcessI.
# 
# 
#   -- ALGLIB --
#      Copyright 16.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.dfprocess(df, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     df:         class xalglib.decisionforest
          x:          1D array/list of float
          y:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_dfprocess0'></a><h3 class=pageheader><code>dfprocess0</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns first component of the  inferred  vector  (i.e.  one
# with index #0).
# 
# It is a convenience wrapper for dfprocess() intended for either:
# * 1-dimensional regression problems
# * 2-class classification problems
# 
# In the former case this function returns inference result as scalar, which
# is definitely more convenient that wrapping it as vector.  In  the  latter
# case it returns probability of object belonging to class #0.
# 
# If you call it for anything different from two cases above, it  will  work
# as defined, i.e. return y[0], although it is of less use in such cases.
# 
# IMPORTANT: this function is thread-unsafe and modifies internal structures
#            of the model! You can not use same model  object  for  parallel
#            evaluation from several threads.
# 
#            Use dftsprocess() with  independent  thread-local  buffers,  if
#            you need thread-safe evaluation.
# 
# INPUT PARAMETERS:
#     Model   -   DF model
#     X       -   input vector,  array[0..NVars-1].
# 
# RESULT:
#     Y[0]
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.dfprocess0(model, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     model:      class xalglib.decisionforest
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> model
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_dfprocessi'></a><h3 class=pageheader><code>dfprocessi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 'interactive' variant of DFProcess for languages like Python which support
# constructs like &quot;Y = DFProcessI(DF,X)&quot; and interactive mode of interpreter
# 
# This function allocates new array on each call,  so  it  is  significantly
# slower than its 'non-interactive' counterpart, but it is  more  convenient
# when you call it from command line.
# 
# IMPORTANT: this  function  is  thread-unsafe  and  may   modify   internal
#            structures of the model! You can not use same model  object for
#            parallel evaluation from several threads.
# 
#            Use dftsprocess()  with  independent  thread-local  buffers  if
#            you need thread-safe evaluation.
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.dfprocessi(df, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     df:         class xalglib.decisionforest
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_dfrelclserror'></a><h3 class=pageheader><code>dfrelclserror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Relative classification error on the test set
# 
# INPUT PARAMETERS:
#     DF      -   decision forest model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     percent of incorrectly classified cases.
#     Zero if model solves regression task.
# 
#   -- ALGLIB --
#      Copyright 16.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.dfrelclserror(df, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     df:         class xalglib.decisionforest
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_dfrmserror'></a><h3 class=pageheader><code>dfrmserror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# RMS error on the test set
# 
# INPUT PARAMETERS:
#     DF      -   decision forest model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     root mean square error.
#     Its meaning for regression task is obvious. As for
#     classification task, RMS error means error when estimating posterior
#     probabilities.
# 
#   -- ALGLIB --
#      Copyright 16.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.dfrmserror(df, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     df:         class xalglib.decisionforest
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_dftsprocess'></a><h3 class=pageheader><code>dftsprocess</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inference using decision forest
# 
# Thread-safe procesing using external buffer for temporaries.
# 
# This function is thread-safe (i.e .  you  can  use  same  DF   model  from
# multiple threads) as long as you use different buffer objects for different
# threads.
# 
# INPUT PARAMETERS:
#     DF      -   decision forest model
#     Buf     -   buffer object, must be  allocated  specifically  for  this
#                 model with dfcreatebuffer().
#     X       -   input vector,  array[NVars]
#     Y       -   possibly preallocated buffer, reallocated if too small
# 
# OUTPUT PARAMETERS:
#     Y       -   result. Regression estimate when solving regression  task,
#                 vector of posterior probabilities for classification task.
# 
# See also DFProcessI.
# 
# 
#   -- ALGLIB --
#      Copyright 16.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.dftsprocess(df, buf, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     df:         class xalglib.decisionforest
          buf:        class xalglib.decisionforestbuffer
          x:          1D array/list of float
          y:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> buf
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name=unit_directdensesolvers></a><h2 class=pageheader><code>directdensesolvers</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cmatrixlusolve' class=toc>cmatrixlusolve</a><br>
<a href='#sub_cmatrixlusolvefast' class=toc>cmatrixlusolvefast</a><br>
<a href='#sub_cmatrixlusolvem' class=toc>cmatrixlusolvem</a><br>
<a href='#sub_cmatrixlusolvemfast' class=toc>cmatrixlusolvemfast</a><br>
<a href='#sub_cmatrixmixedsolve' class=toc>cmatrixmixedsolve</a><br>
<a href='#sub_cmatrixmixedsolvem' class=toc>cmatrixmixedsolvem</a><br>
<a href='#sub_cmatrixsolve' class=toc>cmatrixsolve</a><br>
<a href='#sub_cmatrixsolvefast' class=toc>cmatrixsolvefast</a><br>
<a href='#sub_cmatrixsolvem' class=toc>cmatrixsolvem</a><br>
<a href='#sub_cmatrixsolvemfast' class=toc>cmatrixsolvemfast</a><br>
<a href='#sub_hpdmatrixcholeskysolve' class=toc>hpdmatrixcholeskysolve</a><br>
<a href='#sub_hpdmatrixcholeskysolvefast' class=toc>hpdmatrixcholeskysolvefast</a><br>
<a href='#sub_hpdmatrixcholeskysolvem' class=toc>hpdmatrixcholeskysolvem</a><br>
<a href='#sub_hpdmatrixcholeskysolvemfast' class=toc>hpdmatrixcholeskysolvemfast</a><br>
<a href='#sub_hpdmatrixsolve' class=toc>hpdmatrixsolve</a><br>
<a href='#sub_hpdmatrixsolvefast' class=toc>hpdmatrixsolvefast</a><br>
<a href='#sub_hpdmatrixsolvem' class=toc>hpdmatrixsolvem</a><br>
<a href='#sub_hpdmatrixsolvemfast' class=toc>hpdmatrixsolvemfast</a><br>
<a href='#sub_rmatrixlusolve' class=toc>rmatrixlusolve</a><br>
<a href='#sub_rmatrixlusolvefast' class=toc>rmatrixlusolvefast</a><br>
<a href='#sub_rmatrixlusolvem' class=toc>rmatrixlusolvem</a><br>
<a href='#sub_rmatrixlusolvemfast' class=toc>rmatrixlusolvemfast</a><br>
<a href='#sub_rmatrixmixedsolve' class=toc>rmatrixmixedsolve</a><br>
<a href='#sub_rmatrixmixedsolvem' class=toc>rmatrixmixedsolvem</a><br>
<a href='#sub_rmatrixsolve' class=toc>rmatrixsolve</a><br>
<a href='#sub_rmatrixsolvefast' class=toc>rmatrixsolvefast</a><br>
<a href='#sub_rmatrixsolvels' class=toc>rmatrixsolvels</a><br>
<a href='#sub_rmatrixsolvem' class=toc>rmatrixsolvem</a><br>
<a href='#sub_rmatrixsolvemfast' class=toc>rmatrixsolvemfast</a><br>
<a href='#sub_spdmatrixcholeskysolve' class=toc>spdmatrixcholeskysolve</a><br>
<a href='#sub_spdmatrixcholeskysolvefast' class=toc>spdmatrixcholeskysolvefast</a><br>
<a href='#sub_spdmatrixcholeskysolvem' class=toc>spdmatrixcholeskysolvem</a><br>
<a href='#sub_spdmatrixcholeskysolvemfast' class=toc>spdmatrixcholeskysolvemfast</a><br>
<a href='#sub_spdmatrixsolve' class=toc>spdmatrixsolve</a><br>
<a href='#sub_spdmatrixsolvefast' class=toc>spdmatrixsolvefast</a><br>
<a href='#sub_spdmatrixsolvem' class=toc>spdmatrixsolvem</a><br>
<a href='#sub_spdmatrixsolvemfast' class=toc>spdmatrixsolvemfast</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_cmatrixlusolve'></a><h3 class=pageheader><code>cmatrixlusolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Complex dense linear solver for A*x=b with complex N*N A  given  by its LU
# decomposition and N*1 vectors x and b. This is  &quot;slow-but-robust&quot;  version
# of  the  complex  linear  solver  with  additional  features   which   add
# significant performance overhead. Faster version  is  CMatrixLUSolveFast()
# function.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * O(N^2) complexity
# * condition number estimation
# 
# No iterative refinement is provided because exact form of original matrix
# is not known to subroutine. Use CMatrixSolve or CMatrixMixedSolve  if  you
# need iterative refinement.
# 
# IMPORTANT: ! this function is NOT the most efficient linear solver provided
#            ! by ALGLIB. It estimates condition  number  of  linear system,
#            ! which results in 10-15x  performance  penalty  when  compared
#            ! with &quot;fast&quot; version which just calls triangular solver.
#            !
#            ! This performance penalty is insignificant  when compared with
#            ! cost of large LU decomposition.  However,  if you  call  this
#            ! function many times for the same  left  side,  this  overhead
#            ! BECOMES significant. It  also  becomes significant for small-
#            ! scale problems.
#            !
#            ! In such cases we strongly recommend you to use faster solver,
#            ! CMatrixLUSolveFast() function.
# 
# INPUT PARAMETERS
#     LUA     -   array[0..N-1,0..N-1], LU decomposition, CMatrixLU result
#     P       -   array[0..N-1], pivots array, CMatrixLU result
#     N       -   size of A
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned or exactly singular matrix
#                 * rep.r1    condition number in 1-norm
#                 * rep.rinf  condition number in inf-norm
#     X       -   array[N], it contains:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.cmatrixlusolve(lua, p, n, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.cmatrixlusolve(lua, p, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lua:        2D array/list of complex
          p:          1D array/list of int
          n:          int
          b:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of complex
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_cmatrixlusolvefast'></a><h3 class=pageheader><code>cmatrixlusolvefast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Complex dense linear solver for A*x=b with N*N complex A given by  its  LU
# decomposition and N*1 vectors x and b. This is  fast  lightweight  version
# of solver, which is significantly faster than CMatrixLUSolve(),  but  does
# not provide additional information (like condition numbers).
# 
# Algorithm features:
# * O(N^2) complexity
# * no additional time-consuming features, just triangular solver
# 
# INPUT PARAMETERS
#     LUA     -   array[0..N-1,0..N-1], LU decomposition, CMatrixLU result
#     P       -   array[0..N-1], pivots array, CMatrixLU result
#     N       -   size of A
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS
#     B       -   array[N]:
#                 * result=true    =&gt;  overwritten by solution
#                 * result=false   =&gt;  filled by zeros
# 
# NOTE: unlike  CMatrixLUSolve(),  this   function   does   NOT   check  for
#       near-degeneracy of input matrix. It  checks  for  EXACT  degeneracy,
#       because this check is easy to do. However,  very  badly  conditioned
#       matrices may went unnoticed.
# 
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixlusolvefast(lua, p, n, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixlusolvefast(lua, p, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lua:        2D array/list of complex
          p:          1D array/list of int
          n:          int
          b:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_cmatrixlusolvem'></a><h3 class=pageheader><code>cmatrixlusolvem</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*X=B with N*N complex A given by its  LU  decomposition,
# and N*M matrices X and B (multiple right sides).   &quot;Slow-but-feature-rich&quot;
# version of the solver.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * O(M*N^2) complexity
# * condition number estimation
# 
# No iterative refinement  is provided because exact form of original matrix
# is not known to subroutine. Use CMatrixSolve or CMatrixMixedSolve  if  you
# need iterative refinement.
# 
# IMPORTANT: ! this function is NOT the most efficient linear solver provided
#            ! by ALGLIB. It estimates condition  number  of  linear system,
#            ! which  results  in  significant  performance   penalty   when
#            ! compared with &quot;fast&quot;  version  which  just  calls  triangular
#            ! solver.
#            !
#            ! This performance penalty is especially apparent when you  use
#            ! ALGLIB parallel capabilities (condition number estimation  is
#            ! inherently  sequential).  It   also   becomes significant for
#            ! small-scale problems.
#            !
#            ! In such cases we strongly recommend you to use faster solver,
#            ! CMatrixLUSolveMFast() function.
# 
# INPUT PARAMETERS
#     LUA     -   array[0..N-1,0..N-1], LU decomposition, RMatrixLU result
#     P       -   array[0..N-1], pivots array, RMatrixLU result
#     N       -   size of A
#     B       -   array[0..N-1,0..M-1], right part
#     M       -   right part size
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned or exactly singular matrix
#                 * rep.r1    condition number in 1-norm
#                 * rep.rinf  condition number in inf-norm
#     X       -   array[N,M], it contains:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.cmatrixlusolvem(lua, p, n, b, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.cmatrixlusolvem(lua, p, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lua:        2D array/list of complex
          p:          1D array/list of int
          n:          int
          b:          2D array/list of complex
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          2D array/list of complex
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_cmatrixlusolvemfast'></a><h3 class=pageheader><code>cmatrixlusolvemfast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*X=B with N*N complex A given by its  LU  decomposition,
# and N*M matrices X and B (multiple  right  sides).  &quot;Fast-but-lightweight&quot;
# version of the solver.
# 
# Algorithm features:
# * O(M*N^2) complexity
# * no additional time-consuming features
# 
# INPUT PARAMETERS
#     LUA     -   array[0..N-1,0..N-1], LU decomposition, RMatrixLU result
#     P       -   array[0..N-1], pivots array, RMatrixLU result
#     N       -   size of A
#     B       -   array[0..N-1,0..M-1], right part
#     M       -   right part size
# 
# OUTPUT PARAMETERS
#     B       -   array[N,M]:
#                 * result=true    =&gt;  overwritten by solution
#                 * result=false   =&gt;  filled by zeros
# 
# RETURNS:
#     True, if the system was solved
#     False, for an extremely badly conditioned or exactly singular system
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixlusolvemfast(lua, p, n, b, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixlusolvemfast(lua, p, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lua:        2D array/list of complex
          p:          1D array/list of int
          n:          int
          b:          2D array/list of complex
          m:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_cmatrixmixedsolve'></a><h3 class=pageheader><code>cmatrixmixedsolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver. Same as RMatrixMixedSolve(), but for complex matrices.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * condition number estimation
# * iterative refinement
# * O(N^2) complexity
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     LUA     -   array[0..N-1,0..N-1], LU decomposition, CMatrixLU result
#     P       -   array[0..N-1], pivots array, CMatrixLU result
#     N       -   size of A
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned or exactly singular matrix
#                 * rep.r1    condition number in 1-norm
#                 * rep.rinf  condition number in inf-norm
#     X       -   array[N], it contains:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.cmatrixmixedsolve(a, lua, p, n, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.cmatrixmixedsolve(a, lua, p, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          lua:        2D array/list of complex
          p:          1D array/list of int
          n:          int
          b:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of complex
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_cmatrixmixedsolvem'></a><h3 class=pageheader><code>cmatrixmixedsolvem</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver. Same as RMatrixMixedSolveM(), but for complex matrices.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * condition number estimation
# * iterative refinement
# * O(M*N^2) complexity
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     LUA     -   array[0..N-1,0..N-1], LU decomposition, CMatrixLU result
#     P       -   array[0..N-1], pivots array, CMatrixLU result
#     N       -   size of A
#     B       -   array[0..N-1,0..M-1], right part
#     M       -   right part size
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned or exactly singular matrix
#                 * rep.r1    condition number in 1-norm
#                 * rep.rinf  condition number in inf-norm
#     X       -   array[N,M], it contains:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.cmatrixmixedsolvem(a, lua, p, n, b, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.cmatrixmixedsolvem(a, lua, p, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          lua:        2D array/list of complex
          p:          1D array/list of int
          n:          int
          b:          2D array/list of complex
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          2D array/list of complex
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_cmatrixsolve'></a><h3 class=pageheader><code>cmatrixsolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Complex dense solver for A*x=B with N*N complex matrix A and  N*1  complex
# vectors x and b. &quot;Slow-but-feature-rich&quot; version of the solver.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * condition number estimation
# * iterative refinement
# * O(N^3) complexity
# 
# IMPORTANT: ! this function is NOT the most efficient linear solver provided
#            ! by ALGLIB. It estimates condition  number  of  linear  system
#            ! and  performs  iterative   refinement,   which   results   in
#            ! significant performance penalty  when  compared  with  &quot;fast&quot;
#            ! version  which  just  performs  LU  decomposition  and  calls
#            ! triangular solver.
#            !
#            ! This  performance  penalty  is  especially  visible  in   the
#            ! multithreaded mode, because both condition number  estimation
#            ! and   iterative    refinement   are   inherently   sequential
#            ! calculations.
#            !
#            ! Thus, if you need high performance and if you are pretty sure
#            ! that your system is well conditioned, we  strongly  recommend
#            ! you to use faster solver, CMatrixSolveFast() function.
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     N       -   size of A
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned or exactly singular matrix
#                 * rep.r1    condition number in 1-norm
#                 * rep.rinf  condition number in inf-norm
#     X       -   array[N], it contains:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.cmatrixsolve(a, n, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.cmatrixsolve(a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          b:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of complex
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_cmatrixsolvefast'></a><h3 class=pageheader><code>cmatrixsolvefast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Complex dense solver for A*x=B with N*N complex matrix A and  N*1  complex
# vectors x and b. &quot;Fast-but-lightweight&quot; version of the solver.
# 
# Algorithm features:
# * O(N^3) complexity
# * no additional time consuming features, just triangular solver
# 
# INPUT PARAMETERS:
#     A       -   array[0..N-1,0..N-1], system matrix
#     N       -   size of A
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS:
#     B       -   array[N]:
#                 * result=true    =&gt;  overwritten by solution
#                 * result=false   =&gt;  filled by zeros
# 
# RETURNS:
#     True, if the system was solved
#     False, for an extremely badly conditioned or exactly singular system
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixsolvefast(a, n, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixsolvefast(a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          b:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_cmatrixsolvem'></a><h3 class=pageheader><code>cmatrixsolvem</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Complex dense solver for A*X=B with N*N  complex  matrix  A,  N*M  complex
# matrices  X  and  B.  &quot;Slow-but-feature-rich&quot;   version   which   provides
# additional functions, at the cost of slower  performance.  Faster  version
# may be invoked with CMatrixSolveMFast() function.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * condition number estimation
# * iterative refinement
# * O(N^3+M*N^2) complexity
# 
# IMPORTANT: ! this function is NOT the most efficient linear solver provided
#            ! by ALGLIB. It estimates condition  number  of  linear  system
#            ! and  performs  iterative   refinement,   which   results   in
#            ! significant performance penalty  when  compared  with  &quot;fast&quot;
#            ! version  which  just  performs  LU  decomposition  and  calls
#            ! triangular solver.
#            !
#            ! This  performance  penalty  is  especially  visible  in   the
#            ! multithreaded mode, because both condition number  estimation
#            ! and   iterative    refinement   are   inherently   sequential
#            ! calculations.
#            !
#            ! Thus, if you need high performance and if you are pretty sure
#            ! that your system is well conditioned, we  strongly  recommend
#            ! you to use faster solver, CMatrixSolveMFast() function.
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     N       -   size of A
#     B       -   array[0..N-1,0..M-1], right part
#     M       -   right part size
#     RFS     -   iterative refinement switch:
#                 * True - refinement is used.
#                   Less performance, more precision.
#                 * False - refinement is not used.
#                   More performance, less precision.
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned or exactly singular matrix
#                 * rep.r1    condition number in 1-norm
#                 * rep.rinf  condition number in inf-norm
#     X       -   array[N,M], it contains:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.cmatrixsolvem(a, n, b, m, rfs)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.cmatrixsolvem(a, b, rfs)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          b:          2D array/list of complex
          m:          int
          rfs:        bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          2D array/list of complex
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_cmatrixsolvemfast'></a><h3 class=pageheader><code>cmatrixsolvemfast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Complex dense solver for A*X=B with N*N  complex  matrix  A,  N*M  complex
# matrices  X  and  B.  &quot;Fast-but-lightweight&quot; version which  provides  just
# triangular solver - and no additional functions like iterative  refinement
# or condition number estimation.
# 
# Algorithm features:
# * O(N^3+M*N^2) complexity
# * no additional time consuming functions
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     N       -   size of A
#     B       -   array[0..N-1,0..M-1], right part
#     M       -   right part size
# 
# OUTPUT PARAMETERS:
#     B       -   array[N,M]:
#                 * result=true    =&gt;  overwritten by solution
#                 * result=false   =&gt;  filled by zeros
# 
# RETURNS:
#     True, if the system was solved
#     False, for an extremely badly conditioned or exactly singular system
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 16.03.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixsolvemfast(a, n, b, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixsolvemfast(a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          b:          2D array/list of complex
          m:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_hpdmatrixcholeskysolve'></a><h3 class=pageheader><code>hpdmatrixcholeskysolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*x=b with N*N Hermitian positive definite matrix A given
# by its Cholesky decomposition, and N*1 complex vectors x and  b.  This  is
# &quot;slow-but-feature-rich&quot; version of the solver  which  estimates  condition
# number of the system.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * O(N^2) complexity
# * condition number estimation
# * matrix is represented by its upper or lower triangle
# 
# No iterative refinement is provided because such partial representation of
# matrix does not allow efficient calculation of extra-precise  matrix-vector
# products for large matrices. Use RMatrixSolve or RMatrixMixedSolve  if  you
# need iterative refinement.
# 
# IMPORTANT: ! this function is NOT the most efficient linear solver provided
#            ! by ALGLIB. It estimates condition  number  of  linear system,
#            ! which results in 10-15x  performance  penalty  when  compared
#            ! with &quot;fast&quot; version which just calls triangular solver.
#            !
#            ! This performance penalty is insignificant  when compared with
#            ! cost of large LU decomposition.  However,  if you  call  this
#            ! function many times for the same  left  side,  this  overhead
#            ! BECOMES significant. It  also  becomes significant for small-
#            ! scale problems (N&lt;50).
#            !
#            ! In such cases we strongly recommend you to use faster solver,
#            ! HPDMatrixCholeskySolveFast() function.
# 
# INPUT PARAMETERS
#     CHA     -   array[0..N-1,0..N-1], Cholesky decomposition,
#                 SPDMatrixCholesky result
#     N       -   size of A
#     IsUpper -   what half of CHA is provided
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned or indefinite matrix
#                 * rep.r1                condition number in 1-norm
#                 * rep.rinf              condition number in inf-norm
#     X       -   array[N], it contains:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.hpdmatrixcholeskysolve(cha, n, isupper, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.hpdmatrixcholeskysolve(cha, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     cha:        2D array/list of complex
          n:          int
          isupper:    bool
          b:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of complex
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_hpdmatrixcholeskysolvefast'></a><h3 class=pageheader><code>hpdmatrixcholeskysolvefast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*x=b with N*N Hermitian positive definite matrix A given
# by its Cholesky decomposition, and N*1 complex vectors x and  b.  This  is
# &quot;fast-but-lightweight&quot; version of the solver.
# 
# Algorithm features:
# * O(N^2) complexity
# * matrix is represented by its upper or lower triangle
# * no additional time-consuming features
# 
# INPUT PARAMETERS
#     CHA     -   array[0..N-1,0..N-1], Cholesky decomposition,
#                 SPDMatrixCholesky result
#     N       -   size of A
#     IsUpper -   what half of CHA is provided
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS
#     B       -   array[N]:
#                 * result=true    =&gt;  overwritten by solution
#                 * result=false   =&gt;  filled by zeros
# 
# RETURNS:
#     True, if the system was solved
#     False, for an extremely badly conditioned or indefinite system
# 
#   -- ALGLIB --
#      Copyright 18.03.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hpdmatrixcholeskysolvefast(cha, n, isupper, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hpdmatrixcholeskysolvefast(cha, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     cha:        2D array/list of complex
          n:          int
          isupper:    bool
          b:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_hpdmatrixcholeskysolvem'></a><h3 class=pageheader><code>hpdmatrixcholeskysolvem</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*X=B with N*N Hermitian positive definite matrix A given
# by its Cholesky decomposition and N*M complex matrices X  and  B.  This is
# &quot;slow-but-feature-rich&quot; version of the solver which, in  addition  to  the
# solution, estimates condition number of the system.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * O(M*N^2) complexity
# * condition number estimation
# * matrix is represented by its upper or lower triangle
# 
# No iterative refinement is provided because such partial representation of
# matrix does not allow efficient calculation of extra-precise  matrix-vector
# products for large matrices. Use RMatrixSolve or RMatrixMixedSolve  if  you
# need iterative refinement.
# 
# IMPORTANT: ! this function is NOT the most efficient linear solver provided
#            ! by ALGLIB. It estimates condition  number  of  linear system,
#            ! which  results  in  significant  performance   penalty   when
#            ! compared with &quot;fast&quot;  version  which  just  calls  triangular
#            ! solver. Amount of  overhead  introduced  depends  on  M  (the
#            ! larger - the more efficient).
#            !
#            ! This performance penalty is insignificant  when compared with
#            ! cost of large Cholesky decomposition.  However,  if  you call
#            ! this  function  many  times  for  the same  left  side,  this
#            ! overhead BECOMES significant. It  also   becomes  significant
#            ! for small-scale problems (N&lt;50).
#            !
#            ! In such cases we strongly recommend you to use faster solver,
#            ! HPDMatrixCholeskySolveMFast() function.
# 
# 
# INPUT PARAMETERS
#     CHA     -   array[N,N], Cholesky decomposition,
#                 HPDMatrixCholesky result
#     N       -   size of CHA
#     IsUpper -   what half of CHA is provided
#     B       -   array[N,M], right part
#     M       -   right part size
# 
# OUTPUT PARAMETERS:
#     Rep     -   additional report, following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned or indefinite matrix
#                 * rep.r1                condition number in 1-norm
#                 * rep.rinf              condition number in inf-norm
#     X       -   array[N], it contains:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.hpdmatrixcholeskysolvem(cha, n, isupper, b, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.hpdmatrixcholeskysolvem(cha, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     cha:        2D array/list of complex
          n:          int
          isupper:    bool
          b:          2D array/list of complex
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          2D array/list of complex
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_hpdmatrixcholeskysolvemfast'></a><h3 class=pageheader><code>hpdmatrixcholeskysolvemfast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*X=B with N*N Hermitian positive definite matrix A given
# by its Cholesky decomposition and N*M complex matrices X  and  B.  This is
# &quot;fast-but-lightweight&quot; version of the solver.
# 
# Algorithm features:
# * O(M*N^2) complexity
# * matrix is represented by its upper or lower triangle
# * no additional time-consuming features
# 
# INPUT PARAMETERS
#     CHA     -   array[N,N], Cholesky decomposition,
#                 HPDMatrixCholesky result
#     N       -   size of CHA
#     IsUpper -   what half of CHA is provided
#     B       -   array[N,M], right part
#     M       -   right part size
# 
# OUTPUT PARAMETERS:
#     B       -   array[N]:
#                 * result=true    =&gt;  overwritten by solution
#                 * result=false   =&gt;  filled by zeros
# 
# RETURNS:
#     True, if the system was solved
#     False, for an extremely badly conditioned or indefinite system
# 
#   -- ALGLIB --
#      Copyright 18.03.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hpdmatrixcholeskysolvemfast(cha, n, isupper, b, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hpdmatrixcholeskysolvemfast(cha, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     cha:        2D array/list of complex
          n:          int
          isupper:    bool
          b:          2D array/list of complex
          m:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_hpdmatrixsolve'></a><h3 class=pageheader><code>hpdmatrixsolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*x=b, with N*N Hermitian positive definite matrix A, and
# N*1 complex vectors  x  and  b.  &quot;Slow-but-feature-rich&quot;  version  of  the
# solver.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * condition number estimation
# * O(N^3) complexity
# * matrix is represented by its upper or lower triangle
# 
# No iterative refinement is provided because such partial representation of
# matrix does not allow efficient calculation of extra-precise  matrix-vector
# products for large matrices. Use RMatrixSolve or RMatrixMixedSolve  if  you
# need iterative refinement.
# 
# IMPORTANT: ! this function is NOT the most efficient linear solver provided
#            ! by ALGLIB. It estimates condition  number  of  linear system,
#            ! which  results  in  significant   performance   penalty  when
#            ! compared with &quot;fast&quot; version  which  just  performs  Cholesky
#            ! decomposition and calls triangular solver.
#            !
#            ! This  performance  penalty  is  especially  visible  in   the
#            ! multithreaded mode, because both condition number  estimation
#            ! and   iterative    refinement   are   inherently   sequential
#            ! calculations.
#            !
#            ! Thus, if you need high performance and if you are pretty sure
#            ! that your system is well conditioned, we  strongly  recommend
#            ! you to use faster solver, HPDMatrixSolveFast() function.
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     N       -   size of A
#     IsUpper -   what half of A is provided
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS
#     Rep     -   same as in RMatrixSolve
#     X       -   same as in RMatrixSolve
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.hpdmatrixsolve(a, n, isupper, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.hpdmatrixsolve(a, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          isupper:    bool
          b:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of complex
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_hpdmatrixsolvefast'></a><h3 class=pageheader><code>hpdmatrixsolvefast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*x=b, with N*N Hermitian positive definite matrix A, and
# N*1 complex vectors  x  and  b.  &quot;Fast-but-lightweight&quot;  version  of   the
# solver without additional functions.
# 
# Algorithm features:
# * O(N^3) complexity
# * matrix is represented by its upper or lower triangle
# * no additional time consuming functions
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     N       -   size of A
#     IsUpper -   what half of A is provided
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS
#     B       -   array[0..N-1]:
#                 * result=true    =&gt;  overwritten by solution
#                 * result=false   =&gt;  filled by zeros
# 
# RETURNS:
#     True, if the system was solved
#     False, for an extremely badly conditioned or indefinite system
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 17.03.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hpdmatrixsolvefast(a, n, isupper, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hpdmatrixsolvefast(a, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          isupper:    bool
          b:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_hpdmatrixsolvem'></a><h3 class=pageheader><code>hpdmatrixsolvem</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*X=B, with N*N Hermitian positive definite matrix A  and
# N*M  complex  matrices  X  and  B.  &quot;Slow-but-feature-rich&quot; version of the
# solver.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * condition number estimation
# * O(N^3+M*N^2) complexity
# * matrix is represented by its upper or lower triangle
# 
# No iterative refinement is provided because such partial representation of
# matrix does not allow efficient calculation of extra-precise  matrix-vector
# products for large matrices. Use RMatrixSolve or RMatrixMixedSolve  if  you
# need iterative refinement.
# 
# IMPORTANT: ! this function is NOT the most efficient linear solver provided
#            ! by ALGLIB. It estimates condition  number  of  linear system,
#            ! which  results  in  significant  performance   penalty   when
#            ! compared with &quot;fast&quot;  version  which  just  calls  triangular
#            ! solver.
#            !
#            ! This performance penalty is especially apparent when you  use
#            ! ALGLIB parallel capabilities (condition number estimation  is
#            ! inherently  sequential).  It   also   becomes significant for
#            ! small-scale problems (N&lt;100).
#            !
#            ! In such cases we strongly recommend you to use faster solver,
#            ! HPDMatrixSolveMFast() function.
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     N       -   size of A
#     IsUpper -   what half of A is provided
#     B       -   array[0..N-1,0..M-1], right part
#     M       -   right part size
# 
# OUTPUT PARAMETERS
#     Rep     -   same as in RMatrixSolve
#     X       -   same as in RMatrixSolve
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.hpdmatrixsolvem(a, n, isupper, b, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.hpdmatrixsolvem(a, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          isupper:    bool
          b:          2D array/list of complex
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          2D array/list of complex
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_hpdmatrixsolvemfast'></a><h3 class=pageheader><code>hpdmatrixsolvemfast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*X=B, with N*N Hermitian positive definite matrix A  and
# N*M complex matrices X and B. &quot;Fast-but-lightweight&quot; version of the solver.
# 
# Algorithm features:
# * O(N^3+M*N^2) complexity
# * matrix is represented by its upper or lower triangle
# * no additional time consuming features like condition number estimation
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     N       -   size of A
#     IsUpper -   what half of A is provided
#     B       -   array[0..N-1,0..M-1], right part
#     M       -   right part size
# 
# OUTPUT PARAMETERS
#     B       -   array[0..N-1]:
#                 * result=true    =&gt;  overwritten by solution
#                 * result=false   =&gt;  filled by zeros
# 
# RETURNS:
#     True, if the system was solved
#     False, for an extremely badly conditioned or indefinite system
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 17.03.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hpdmatrixsolvemfast(a, n, isupper, b, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hpdmatrixsolvemfast(a, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          isupper:    bool
          b:          2D array/list of complex
          m:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_rmatrixlusolve'></a><h3 class=pageheader><code>rmatrixlusolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver.
# 
# This  subroutine  solves  a  system  A*x=b,  where A is NxN non-denegerate
# real matrix given by its LU decomposition, x and b are real vectors.  This
# is &quot;slow-but-robust&quot; version of the linear LU-based solver. Faster version
# is RMatrixLUSolveFast() function.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * O(N^2) complexity
# * condition number estimation
# 
# No iterative refinement  is provided because exact form of original matrix
# is not known to subroutine. Use RMatrixSolve or RMatrixMixedSolve  if  you
# need iterative refinement.
# 
# IMPORTANT: ! this function is NOT the most efficient linear solver provided
#            ! by ALGLIB. It estimates condition  number  of  linear system,
#            ! which results in 10-15x  performance  penalty  when  compared
#            ! with &quot;fast&quot; version which just calls triangular solver.
#            !
#            ! This performance penalty is insignificant  when compared with
#            ! cost of large LU decomposition.  However,  if you  call  this
#            ! function many times for the same  left  side,  this  overhead
#            ! BECOMES significant. It  also  becomes significant for small-
#            ! scale problems.
#            !
#            ! In such cases we strongly recommend you to use faster solver,
#            ! RMatrixLUSolveFast() function.
# 
# INPUT PARAMETERS
#     LUA     -   array[N,N], LU decomposition, RMatrixLU result
#     P       -   array[N], pivots array, RMatrixLU result
#     N       -   size of A
#     B       -   array[N], right part
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, the following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned matrix
#                 * rep.r1                condition number in 1-norm
#                 * rep.rinf              condition number in inf-norm
#     X       -   array[N], it contains:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.rmatrixlusolve(lua, p, n, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.rmatrixlusolve(lua, p, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lua:        2D array/list of float
          p:          1D array/list of int
          n:          int
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_rmatrixlusolvefast'></a><h3 class=pageheader><code>rmatrixlusolvefast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver.
# 
# This  subroutine  solves  a  system  A*x=b,  where A is NxN non-denegerate
# real matrix given by its LU decomposition, x and b are real vectors.  This
# is &quot;fast-without-any-checks&quot; version of the linear LU-based solver. Slower
# but more robust version is RMatrixLUSolve() function.
# 
# Algorithm features:
# * O(N^2) complexity
# * fast algorithm without ANY additional checks, just triangular solver
# 
# INPUT PARAMETERS
#     LUA     -   array[0..N-1,0..N-1], LU decomposition, RMatrixLU result
#     P       -   array[0..N-1], pivots array, RMatrixLU result
#     N       -   size of A
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS
#     B       -   array[N]:
#                 * result=true    =&gt;  overwritten by solution
#                 * result=false   =&gt;  filled by zeros
# 
# RETURNS:
#     True, if the system was solved
#     False, for an extremely badly conditioned or exactly singular system
# 
# 
#   -- ALGLIB --
#      Copyright 18.03.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixlusolvefast(lua, p, n, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixlusolvefast(lua, p, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lua:        2D array/list of float
          p:          1D array/list of int
          n:          int
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_rmatrixlusolvem'></a><h3 class=pageheader><code>rmatrixlusolvem</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver.
# 
# Similar to RMatrixLUSolve() but solves  task  with  multiple  right  parts
# (where b and x are NxM matrices). This  is  &quot;robust-but-slow&quot;  version  of
# LU-based solver which performs additional  checks  for  non-degeneracy  of
# inputs (condition number estimation). If you need  best  performance,  use
# &quot;fast-without-any-checks&quot; version, RMatrixLUSolveMFast().
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * O(M*N^2) complexity
# * condition number estimation
# 
# No iterative refinement  is provided because exact form of original matrix
# is not known to subroutine. Use RMatrixSolve or RMatrixMixedSolve  if  you
# need iterative refinement.
# 
# IMPORTANT: ! this function is NOT the most efficient linear solver provided
#            ! by ALGLIB. It estimates condition  number  of  linear system,
#            ! which  results  in  significant  performance   penalty   when
#            ! compared with &quot;fast&quot;  version  which  just  calls  triangular
#            ! solver.
#            !
#            ! This performance penalty is especially apparent when you  use
#            ! ALGLIB parallel capabilities (condition number estimation  is
#            ! inherently  sequential).  It   also   becomes significant for
#            ! small-scale problems.
#            !
#            ! In such cases we strongly recommend you to use faster solver,
#            ! RMatrixLUSolveMFast() function.
# 
# INPUT PARAMETERS
#     LUA     -   array[N,N], LU decomposition, RMatrixLU result
#     P       -   array[N], pivots array, RMatrixLU result
#     N       -   size of A
#     B       -   array[0..N-1,0..M-1], right part
#     M       -   right part size
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned matrix
#                 * rep.r1                condition number in 1-norm
#                 * rep.rinf              condition number in inf-norm
#     X       -   array[N,M], it contains:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.rmatrixlusolvem(lua, p, n, b, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.rmatrixlusolvem(lua, p, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lua:        2D array/list of float
          p:          1D array/list of int
          n:          int
          b:          2D array/list of float
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          2D array/list of float
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_rmatrixlusolvemfast'></a><h3 class=pageheader><code>rmatrixlusolvemfast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver.
# 
# Similar to RMatrixLUSolve() but solves  task  with  multiple  right parts,
# where b and x are NxM matrices.  This is &quot;fast-without-any-checks&quot; version
# of LU-based solver. It does not estimate  condition number  of  a  system,
# so it is extremely fast. If you need better detection  of  near-degenerate
# cases, use RMatrixLUSolveM() function.
# 
# Algorithm features:
# * O(M*N^2) complexity
# * fast algorithm without ANY additional checks, just triangular solver
# 
# INPUT PARAMETERS:
#     LUA     -   array[0..N-1,0..N-1], LU decomposition, RMatrixLU result
#     P       -   array[0..N-1], pivots array, RMatrixLU result
#     N       -   size of A
#     B       -   array[0..N-1,0..M-1], right part
#     M       -   right part size
# 
# OUTPUT PARAMETERS:
#     B       -   array[N,M]:
#                 * result=true    =&gt;  overwritten by solution
#                 * result=false   =&gt;  filled by zeros
# 
# RETURNS:
#     True, if the system was solved
#     False, for an extremely badly conditioned or exactly singular system
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 18.03.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixlusolvemfast(lua, p, n, b, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixlusolvemfast(lua, p, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lua:        2D array/list of float
          p:          1D array/list of int
          n:          int
          b:          2D array/list of float
          m:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_rmatrixmixedsolve'></a><h3 class=pageheader><code>rmatrixmixedsolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver.
# 
# This  subroutine  solves  a  system  A*x=b,  where BOTH ORIGINAL A AND ITS
# LU DECOMPOSITION ARE KNOWN. You can use it if for some  reasons  you  have
# both A and its LU decomposition.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * condition number estimation
# * iterative refinement
# * O(N^2) complexity
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     LUA     -   array[0..N-1,0..N-1], LU decomposition, RMatrixLU result
#     P       -   array[0..N-1], pivots array, RMatrixLU result
#     N       -   size of A
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned matrix
#                 * rep.r1    condition number in 1-norm
#                 * rep.rinf  condition number in inf-norm
#     X       -   array[N], it contains:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.rmatrixmixedsolve(a, lua, p, n, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.rmatrixmixedsolve(a, lua, p, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          lua:        2D array/list of float
          p:          1D array/list of int
          n:          int
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_rmatrixmixedsolvem'></a><h3 class=pageheader><code>rmatrixmixedsolvem</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver.
# 
# Similar to RMatrixMixedSolve() but  solves task with multiple right  parts
# (where b and x are NxM matrices).
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * condition number estimation
# * iterative refinement
# * O(M*N^2) complexity
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     LUA     -   array[0..N-1,0..N-1], LU decomposition, RMatrixLU result
#     P       -   array[0..N-1], pivots array, RMatrixLU result
#     N       -   size of A
#     B       -   array[0..N-1,0..M-1], right part
#     M       -   right part size
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned matrix
#                 * rep.r1    condition number in 1-norm
#                 * rep.rinf  condition number in inf-norm
#     X       -   array[N,M], it contains:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.rmatrixmixedsolvem(a, lua, p, n, b, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.rmatrixmixedsolvem(a, lua, p, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          lua:        2D array/list of float
          p:          1D array/list of int
          n:          int
          b:          2D array/list of float
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          2D array/list of float
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_rmatrixsolve'></a><h3 class=pageheader><code>rmatrixsolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*x=b with N*N real matrix A and N*1 real vectorx  x  and
# b. This is &quot;slow-but-feature rich&quot; version of the  linear  solver.  Faster
# version is RMatrixSolveFast() function.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * condition number estimation
# * iterative refinement
# * O(N^3) complexity
# 
# IMPORTANT: ! this function is NOT the most efficient linear solver provided
#            ! by ALGLIB. It estimates condition  number  of  linear  system
#            ! and  performs  iterative   refinement,   which   results   in
#            ! significant performance penalty  when  compared  with  &quot;fast&quot;
#            ! version  which  just  performs  LU  decomposition  and  calls
#            ! triangular solver.
#            !
#            ! This  performance  penalty  is  especially  visible  in   the
#            ! multithreaded mode, because both condition number  estimation
#            ! and   iterative    refinement   are   inherently   sequential
#            ! calculations. It is also very significant on small matrices.
#            !
#            ! Thus, if you need high performance and if you are pretty sure
#            ! that your system is well conditioned, we  strongly  recommend
#            ! you to use faster solver, RMatrixSolveFast() function.
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     N       -   size of A
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, the following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned matrix
#                 * rep.r1                condition number in 1-norm
#                 * rep.rinf              condition number in inf-norm
#     X       -   array[N], it contains:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.rmatrixsolve(a, n, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.rmatrixsolve(a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_rmatrixsolvefast'></a><h3 class=pageheader><code>rmatrixsolvefast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver.
# 
# This  subroutine  solves  a  system  A*x=b,  where A is NxN non-denegerate
# real matrix, x  and  b  are  vectors.  This is a &quot;fast&quot; version of  linear
# solver which does NOT provide  any  additional  functions  like  condition
# number estimation or iterative refinement.
# 
# Algorithm features:
# * efficient algorithm O(N^3) complexity
# * no performance overhead from additional functionality
# 
# If you need condition number estimation or iterative refinement, use  more
# feature-rich version - RMatrixSolve().
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     N       -   size of A
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS
#     B       -   array[N]:
#                 * result=true    =&gt;  overwritten by solution
#                 * result=false   =&gt;  filled by zeros
# 
# RETURNS:
#     True, if the system was solved
#     False, for an extremely badly conditioned or exactly singular system
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 16.03.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixsolvefast(a, n, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixsolvefast(a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_rmatrixsolvels'></a><h3 class=pageheader><code>rmatrixsolvels</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver.
# 
# This subroutine finds solution of the linear system A*X=B with non-square,
# possibly degenerate A.  System  is  solved in the least squares sense, and
# general least squares solution  X = X0 + CX*y  which  minimizes |A*X-B| is
# returned. If A is non-degenerate, solution in the usual sense is returned.
# 
# Algorithm features:
# * automatic detection (and correct handling!) of degenerate cases
# * iterative refinement
# * O(N^3) complexity
# 
# INPUT PARAMETERS
#     A       -   array[0..NRows-1,0..NCols-1], system matrix
#     NRows   -   vertical size of A
#     NCols   -   horizontal size of A
#     B       -   array[0..NCols-1], right part
#     Threshold-  a number in [0,1]. Singular values  beyond  Threshold*Largest are
#                 considered  zero.  Set  it to 0.0, if you don't understand
#                 what it means, so the solver will choose good value on its
#                 own.
# 
# OUTPUT PARAMETERS
#     Rep     -   solver report, see below for more info
#     X       -   array[0..N-1,0..M-1], it contains:
#                 * solution of A*X=B (even for singular A)
#                 * zeros, if SVD subroutine failed
# 
# SOLVER REPORT
# 
# Subroutine sets following fields of the Rep structure:
# * TerminationType is set to:
#             * -4 for SVD failure
#             * &gt;0 for success
# * R2        reciprocal of condition number: 1/cond(A), 2-norm.
# * N         = NCols
# * K         dim(Null(A))
# * CX        array[0..N-1,0..K-1], kernel of A.
#             Columns of CX store such vectors that A*CX[i]=0.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 24.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.rmatrixsolvels(a, nrows, ncols, b, threshold)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.rmatrixsolvels(a, b, threshold)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          nrows:      int
          ncols:      int
          b:          1D array/list of float
          threshold:  float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.densesolverlsreport

</div></pre>
<a name='sub_rmatrixsolvem'></a><h3 class=pageheader><code>rmatrixsolvem</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver.
# 
# Similar to RMatrixSolve() but solves task with multiple right parts (where
# b and x are NxM matrices). This is  &quot;slow-but-robust&quot;  version  of  linear
# solver with additional functionality  like  condition  number  estimation.
# There also exists faster version - RMatrixSolveMFast().
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * condition number estimation
# * optional iterative refinement
# * O(N^3+M*N^2) complexity
# 
# IMPORTANT: ! this function is NOT the most efficient linear solver provided
#            ! by ALGLIB. It estimates condition  number  of  linear  system
#            ! and  performs  iterative   refinement,   which   results   in
#            ! significant performance penalty  when  compared  with  &quot;fast&quot;
#            ! version  which  just  performs  LU  decomposition  and  calls
#            ! triangular solver.
#            !
#            ! This  performance  penalty  is  especially  visible  in   the
#            ! multithreaded mode, because both condition number  estimation
#            ! and   iterative    refinement   are   inherently   sequential
#            ! calculations. It also very significant on small matrices.
#            !
#            ! Thus, if you need high performance and if you are pretty sure
#            ! that your system is well conditioned, we  strongly  recommend
#            ! you to use faster solver, RMatrixSolveMFast() function.
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     N       -   size of A
#     B       -   array[0..N-1,0..M-1], right part
#     M       -   right part size
#     RFS     -   iterative refinement switch:
#                 * True - refinement is used.
#                   Less performance, more precision.
#                 * False - refinement is not used.
#                   More performance, less precision.
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned or exactly singular matrix
#                 * rep.r1    condition number in 1-norm
#                 * rep.rinf  condition number in inf-norm
#     X       -   array[N], it contains:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.rmatrixsolvem(a, n, b, m, rfs)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.rmatrixsolvem(a, b, rfs)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          b:          2D array/list of float
          m:          int
          rfs:        bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          2D array/list of float
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_rmatrixsolvemfast'></a><h3 class=pageheader><code>rmatrixsolvemfast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver.
# 
# Similar to RMatrixSolve() but solves task with multiple right parts (where
# b and x are NxM matrices). This is &quot;fast&quot; version of linear  solver  which
# does NOT offer additional functions like condition  number  estimation  or
# iterative refinement.
# 
# Algorithm features:
# * O(N^3+M*N^2) complexity
# * no additional functionality, highest performance
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     N       -   size of A
#     B       -   array[0..N-1,0..M-1], right part
#     M       -   right part size
#     RFS     -   iterative refinement switch:
#                 * True - refinement is used.
#                   Less performance, more precision.
#                 * False - refinement is not used.
#                   More performance, less precision.
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, following fields are set:
#                 * rep.r1    condition number in 1-norm
#                 * rep.rinf  condition number in inf-norm
#     B       -   array[N]:
#                 * result=true    =&gt;  overwritten by solution
#                 * result=false   =&gt;  filled by zeros
# 
# RETURNS:
#     True for well-conditioned matrix
#     False for extremely badly conditioned or exactly singular problem
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixsolvemfast(a, n, b, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixsolvemfast(a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          b:          2D array/list of float
          m:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_spdmatrixcholeskysolve'></a><h3 class=pageheader><code>spdmatrixcholeskysolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*x=b with N*N symmetric positive definite matrix A given
# by its Cholesky decomposition, and N*1 real vectors x and b. This is &quot;slow-
# but-feature-rich&quot;  version  of  the  solver  which,  in  addition  to  the
# solution, performs condition number estimation.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * O(N^2) complexity
# * condition number estimation
# * matrix is represented by its upper or lower triangle
# 
# No iterative refinement is provided because such partial representation of
# matrix does not allow efficient calculation of extra-precise  matrix-vector
# products for large matrices. Use RMatrixSolve or RMatrixMixedSolve  if  you
# need iterative refinement.
# 
# IMPORTANT: ! this function is NOT the most efficient linear solver provided
#            ! by ALGLIB. It estimates condition  number  of  linear system,
#            ! which results in 10-15x  performance  penalty  when  compared
#            ! with &quot;fast&quot; version which just calls triangular solver.
#            !
#            ! This performance penalty is insignificant  when compared with
#            ! cost of large LU decomposition.  However,  if you  call  this
#            ! function many times for the same  left  side,  this  overhead
#            ! BECOMES significant. It  also  becomes significant for small-
#            ! scale problems (N&lt;50).
#            !
#            ! In such cases we strongly recommend you to use faster solver,
#            ! SPDMatrixCholeskySolveFast() function.
# 
# INPUT PARAMETERS
#     CHA     -   array[N,N], Cholesky decomposition,
#                 SPDMatrixCholesky result
#     N       -   size of A
#     IsUpper -   what half of CHA is provided
#     B       -   array[N], right part
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned or indefinite matrix
#                 * rep.r1    condition number in 1-norm
#                 * rep.rinf  condition number in inf-norm
#     X       -   array[N]:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.spdmatrixcholeskysolve(cha, n, isupper, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.spdmatrixcholeskysolve(cha, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     cha:        2D array/list of float
          n:          int
          isupper:    bool
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_spdmatrixcholeskysolvefast'></a><h3 class=pageheader><code>spdmatrixcholeskysolvefast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*x=b with N*N symmetric positive definite matrix A given
# by its Cholesky decomposition, and N*1 real vectors x and b. This is &quot;fast-
# but-lightweight&quot; version of the solver.
# 
# Algorithm features:
# * O(N^2) complexity
# * matrix is represented by its upper or lower triangle
# * no additional features
# 
# INPUT PARAMETERS
#     CHA     -   array[N,N], Cholesky decomposition,
#                 SPDMatrixCholesky result
#     N       -   size of A
#     IsUpper -   what half of CHA is provided
#     B       -   array[N], right part
# 
# OUTPUT PARAMETERS
#     B       -   array[N]:
#                 * result=true    =&gt;  overwritten by solution
#                 * result=false   =&gt;  filled by zeros
# 
# RETURNS:
#     True, if the system was solved
#     False, for an extremely badly conditioned or exactly singular system
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixcholeskysolvefast(cha, n, isupper, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixcholeskysolvefast(cha, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     cha:        2D array/list of float
          n:          int
          isupper:    bool
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_spdmatrixcholeskysolvem'></a><h3 class=pageheader><code>spdmatrixcholeskysolvem</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*X=B with N*N symmetric positive definite matrix A given
# by its Cholesky decomposition, and N*M vectors X and B. It  is  &quot;slow-but-
# feature-rich&quot; version of the solver which estimates  condition  number  of
# the system.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * O(M*N^2) complexity
# * condition number estimation
# * matrix is represented by its upper or lower triangle
# 
# No iterative refinement is provided because such partial representation of
# matrix does not allow efficient calculation of extra-precise  matrix-vector
# products for large matrices. Use RMatrixSolve or RMatrixMixedSolve  if  you
# need iterative refinement.
# 
# IMPORTANT: ! this function is NOT the most efficient linear solver provided
#            ! by ALGLIB. It estimates condition  number  of  linear system,
#            ! which  results  in  significant  performance   penalty   when
#            ! compared with &quot;fast&quot;  version  which  just  calls  triangular
#            ! solver. Amount of  overhead  introduced  depends  on  M  (the
#            ! larger - the more efficient).
#            !
#            ! This performance penalty is insignificant  when compared with
#            ! cost of large LU decomposition.  However,  if you  call  this
#            ! function many times for the same  left  side,  this  overhead
#            ! BECOMES significant. It  also  becomes significant for small-
#            ! scale problems (N&lt;50).
#            !
#            ! In such cases we strongly recommend you to use faster solver,
#            ! SPDMatrixCholeskySolveMFast() function.
# 
# INPUT PARAMETERS
#     CHA     -   array[0..N-1,0..N-1], Cholesky decomposition,
#                 SPDMatrixCholesky result
#     N       -   size of CHA
#     IsUpper -   what half of CHA is provided
#     B       -   array[0..N-1,0..M-1], right part
#     M       -   right part size
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned or indefinite matrix
#                 * rep.r1    condition number in 1-norm
#                 * rep.rinf  condition number in inf-norm
#     X       -   array[N]:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.spdmatrixcholeskysolvem(cha, n, isupper, b, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.spdmatrixcholeskysolvem(cha, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     cha:        2D array/list of float
          n:          int
          isupper:    bool
          b:          2D array/list of float
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          2D array/list of float
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_spdmatrixcholeskysolvemfast'></a><h3 class=pageheader><code>spdmatrixcholeskysolvemfast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*X=B with N*N symmetric positive definite matrix A given
# by its Cholesky decomposition, and N*M vectors X and B. It  is  &quot;fast-but-
# lightweight&quot; version of  the  solver  which  just  solves  linear  system,
# without any additional functions.
# 
# Algorithm features:
# * O(M*N^2) complexity
# * matrix is represented by its upper or lower triangle
# * no additional functionality
# 
# INPUT PARAMETERS
#     CHA     -   array[N,N], Cholesky decomposition,
#                 SPDMatrixCholesky result
#     N       -   size of CHA
#     IsUpper -   what half of CHA is provided
#     B       -   array[N,M], right part
#     M       -   right part size
# 
# OUTPUT PARAMETERS
#     B       -   array[N]:
#                 * result=true    =&gt;  overwritten by solution
#                 * result=false   =&gt;  filled by zeros
# 
# RETURNS:
#     True, if the system was solved
#     False, for an extremely badly conditioned or exactly singular system
# 
#   -- ALGLIB --
#      Copyright 18.03.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixcholeskysolvemfast(cha, n, isupper, b, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixcholeskysolvemfast(cha, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     cha:        2D array/list of float
          n:          int
          isupper:    bool
          b:          2D array/list of float
          m:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_spdmatrixsolve'></a><h3 class=pageheader><code>spdmatrixsolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense linear solver for A*x=b with N*N real  symmetric  positive  definite
# matrix A,  N*1 vectors x and b.  &quot;Slow-but-feature-rich&quot;  version  of  the
# solver.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * condition number estimation
# * O(N^3) complexity
# * matrix is represented by its upper or lower triangle
# 
# No iterative refinement is provided because such partial representation of
# matrix does not allow efficient calculation of extra-precise  matrix-vector
# products for large matrices. Use RMatrixSolve or RMatrixMixedSolve  if  you
# need iterative refinement.
# 
# IMPORTANT: ! this function is NOT the most efficient linear solver provided
#            ! by ALGLIB. It estimates condition  number  of  linear system,
#            ! which  results  in  significant   performance   penalty  when
#            ! compared with &quot;fast&quot; version  which  just  performs  Cholesky
#            ! decomposition and calls triangular solver.
#            !
#            ! This  performance  penalty  is  especially  visible  in   the
#            ! multithreaded mode, because both condition number  estimation
#            ! and   iterative    refinement   are   inherently   sequential
#            ! calculations.
#            !
#            ! Thus, if you need high performance and if you are pretty sure
#            ! that your system is well conditioned, we  strongly  recommend
#            ! you to use faster solver, SPDMatrixSolveFast() function.
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     N       -   size of A
#     IsUpper -   what half of A is provided
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned or indefinite matrix
#                 * rep.r1    condition number in 1-norm
#                 * rep.rinf  condition number in inf-norm
#     X       -   array[N], it contains:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.spdmatrixsolve(a, n, isupper, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.spdmatrixsolve(a, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_spdmatrixsolvefast'></a><h3 class=pageheader><code>spdmatrixsolvefast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense linear solver for A*x=b with N*N real  symmetric  positive  definite
# matrix A,  N*1 vectors x and  b.  &quot;Fast-but-lightweight&quot;  version  of  the
# solver.
# 
# Algorithm features:
# * O(N^3) complexity
# * matrix is represented by its upper or lower triangle
# * no additional time consuming features like condition number estimation
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     N       -   size of A
#     IsUpper -   what half of A is provided
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS
#     B       -   array[N], it contains:
#                 * result=true    =&gt;  overwritten by solution
#                 * result=false   =&gt;  filled by zeros
# 
# RETURNS:
#     True, if the system was solved
#     False, for an extremely badly conditioned or exactly singular system
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 17.03.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixsolvefast(a, n, isupper, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixsolvefast(a, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_spdmatrixsolvem'></a><h3 class=pageheader><code>spdmatrixsolvem</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*X=B with N*N symmetric positive definite matrix A,  and
# N*M vectors X and B. It is &quot;slow-but-feature-rich&quot; version of the solver.
# 
# Algorithm features:
# * automatic detection of degenerate cases
# * condition number estimation
# * O(N^3+M*N^2) complexity
# * matrix is represented by its upper or lower triangle
# 
# No iterative refinement is provided because such partial representation of
# matrix does not allow efficient calculation of extra-precise  matrix-vector
# products for large matrices. Use RMatrixSolve or RMatrixMixedSolve  if  you
# need iterative refinement.
# 
# IMPORTANT: ! this function is NOT the most efficient linear solver provided
#            ! by ALGLIB. It estimates condition  number  of  linear system,
#            ! which  results  in  significant   performance   penalty  when
#            ! compared with &quot;fast&quot; version  which  just  performs  Cholesky
#            ! decomposition and calls triangular solver.
#            !
#            ! This  performance  penalty  is  especially  visible  in   the
#            ! multithreaded mode, because both condition number  estimation
#            ! and   iterative    refinement   are   inherently   sequential
#            ! calculations.
#            !
#            ! Thus, if you need high performance and if you are pretty sure
#            ! that your system is well conditioned, we  strongly  recommend
#            ! you to use faster solver, SPDMatrixSolveMFast() function.
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     N       -   size of A
#     IsUpper -   what half of A is provided
#     B       -   array[0..N-1,0..M-1], right part
#     M       -   right part size
# 
# OUTPUT PARAMETERS
#     Rep     -   additional report, following fields are set:
#                 * rep.terminationtype   &gt;0 for success
#                                         -3 for badly conditioned or indefinite matrix
#                 * rep.r1    condition number in 1-norm
#                 * rep.rinf  condition number in inf-norm
#     X       -   array[N,M], it contains:
#                 * rep.terminationtype&gt;0  =&gt; solution
#                 * rep.terminationtype=-3 =&gt; filled by zeros
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 27.01.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.spdmatrixsolvem(a, n, isupper, b, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.spdmatrixsolvem(a, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
          b:          2D array/list of float
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          2D array/list of float
          rep:        class xalglib.densesolverreport

</div></pre>
<a name='sub_spdmatrixsolvemfast'></a><h3 class=pageheader><code>spdmatrixsolvemfast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Dense solver for A*X=B with N*N symmetric positive definite matrix A,  and
# N*M vectors X and B. It is &quot;fast-but-lightweight&quot; version of the solver.
# 
# Algorithm features:
# * O(N^3+M*N^2) complexity
# * matrix is represented by its upper or lower triangle
# * no additional time consuming features
# 
# INPUT PARAMETERS
#     A       -   array[0..N-1,0..N-1], system matrix
#     N       -   size of A
#     IsUpper -   what half of A is provided
#     B       -   array[0..N-1,0..M-1], right part
#     M       -   right part size
# 
# OUTPUT PARAMETERS
#     B       -   array[N,M], it contains:
#                 * result=true    =&gt;  overwritten by solution
#                 * result=false   =&gt;  filled by zeros
# 
# RETURNS:
#     True, if the system was solved
#     False, for an extremely badly conditioned or exactly singular system
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 17.03.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixsolvemfast(a, n, isupper, b, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixsolvemfast(a, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
          b:          2D array/list of float
          m:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name=unit_directsparsesolvers></a><h2 class=pageheader><code>directsparsesolvers</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_sparselusolve' class=toc>sparselusolve</a><br>
<a href='#sub_sparsesolve' class=toc>sparsesolve</a><br>
<a href='#sub_sparsesolvelsreg' class=toc>sparsesolvelsreg</a><br>
<a href='#sub_sparsespdcholeskysolve' class=toc>sparsespdcholeskysolve</a><br>
<a href='#sub_sparsespdsolve' class=toc>sparsespdsolve</a><br>
<a href='#sub_sparsespdsolvesks' class=toc>sparsespdsolvesks</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_sparselusolve'></a><h3 class=pageheader><code>sparselusolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sparse linear solver for A*x=b with general (nonsymmetric) N*N sparse real
# matrix A given by its LU factorization, N*1 vectors x and b.
# 
# IMPORTANT: this solver requires input matrix  to  be  in  the  CRS  sparse
#            storage format. An exception will  be  generated  if  you  pass
#            matrix in some other format (HASH or SKS).
# 
# INPUT PARAMETERS
#     A       -   LU factorization of the sparse matrix, must be NxN exactly
#                 in CRS storage format
#     P, Q    -   pivot indexes from LU factorization
#     N       -   size of A, N&gt;0
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS
#     X       -   array[N], it contains:
#                 * rep.terminationtype&gt;0    =&gt;  solution
#                 * rep.terminationtype=-3   =&gt;  filled by zeros
#     Rep     -   solver report, following fields are set:
#                 * rep.terminationtype - solver status; &gt;0 for success,
#                   set to -3 on failure (degenerate system).
# 
#   -- ALGLIB --
#      Copyright 26.12.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.sparselusolve(a, p, q, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          p:          1D array/list of int
          q:          1D array/list of int
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.sparsesolverreport

</div></pre>
<a name='sub_sparsesolve'></a><h3 class=pageheader><code>sparsesolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sparse linear solver for A*x=b with general (nonsymmetric) N*N sparse real
# matrix A, N*1 vectors x and b.
# 
# This function internally uses several solvers:
# * supernodal solver with static pivoting applied to  a  2N*2N  regularized
#   augmented  system, followed by iterative refinement. This solver  is   a
#   recommended option because it provides the best speed and has the lowest
#   memory requirements.
# * sparse LU with dynamic pivoting for stability. Provides better  accuracy
#   at the cost of a significantly lower performance. Recommended  only  for
#   extremely unstable problems.
# 
# INPUT PARAMETERS
#     A       -   sparse matrix, must be NxN exactly, any storage format
#     B       -   array[N], right part
#     SolverType- solver type to use:
#                 * 0     use the best solver. It is augmented system in the
#                         current version, but may change in future releases
#                 * 10    use 'default profile' of the supernodal solver with
#                         static   pivoting.   The  'default'   profile   is
#                         intended for systems with plenty of memory; it  is
#                         optimized for the best convergence at the cost  of
#                         increased RAM usage. Recommended option.
#                 * 11    use 'limited memory'  profile  of  the  supernodal
#                         solver with static  pivoting.  The  limited-memory
#                         profile is intended for problems with millions  of
#                         variables.  On  most  systems  it  has  the   same
#                         convergence as the default profile, having somewhat
#                         worse results only for ill-conditioned systems.
#                 * 20    use sparse LU with dynamic pivoting for stability.
#                         Not intended for large-scale problems.
# 
# OUTPUT PARAMETERS
#     X       -   array[N], it contains:
#                 * rep.terminationtype&gt;0    =&gt;  solution
#                 * rep.terminationtype=-3   =&gt;  filled by zeros
#     Rep     -   solver report, following fields are set:
#                 * rep.terminationtype - solver status; &gt;0 for success,
#                   set to -3 on failure (degenerate system).
# 
#   -- ALGLIB --
#      Copyright 18.11.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.sparsesolve(a, b, solvertype)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.sparsesolve(a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          b:          1D array/list of float
          solvertype: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.sparsesolverreport

</div></pre>
<a name='sub_sparsesolvelsreg'></a><h3 class=pageheader><code>sparsesolvelsreg</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sparse linear least squares solver for A*x=b with  general  (nonsymmetric)
# N*N sparse real matrix A, N*1 vectors x and b.
# 
# This function solves a regularized linear least squares problem of the form
# 
#         (                      )
#     min ( |Ax-b|^2 + reg*|x|^2 ), with reg&gt;=sqrt(MachineAccuracy)
#         (                      )
# 
# The function internally uses supernodal  solver  to  solve  an  augmented-
# regularized sparse system. The solver, which was initially used  to  solve
# sparse square system, can also  be  used  to  solve  rectangular  systems,
# provided that the system is regularized with regularizing  coefficient  at
# least sqrt(MachineAccuracy), which is ~10^8 (double precision).
# 
# It can be used to solve both full rank and rank deficient systems.
# 
# INPUT PARAMETERS
#     A       -   sparse MxN matrix, any storage format
#     B       -   array[M], right part
#     Reg     -   regularization coefficient, Reg&gt;=sqrt(MachineAccuracy),
#                 lower values will be silently increased.
#     SolverType- solver type to use:
#                 * 0     use the best solver. It is augmented system in the
#                         current version, but may change in future releases
#                 * 10    use 'default profile' of the supernodal solver with
#                         static   pivoting.   The  'default'   profile   is
#                         intended for systems with plenty of memory; it  is
#                         optimized for the best convergence at the cost  of
#                         increased RAM usage. Recommended option.
#                 * 11    use 'limited memory'  profile  of  the  supernodal
#                         solver with static  pivoting.  The  limited-memory
#                         profile is intended for problems with millions  of
#                         variables.  On  most  systems  it  has  the   same
#                         convergence as the default profile, having somewhat
#                         worse results only for ill-conditioned systems.
# 
# OUTPUT PARAMETERS
#     X       -   array[N], least squares solution
#     Rep     -   solver report, following fields are set:
#                 * rep.terminationtype - solver status; &gt;0 for success.
# 
#                   Present version of the solver does NOT returns negative
#                   completion codes because  it  does  not  fail.  However,
#                   future ALGLIB versions may include solvers which  return
#                   negative completion codes.
# 
#   -- ALGLIB --
#      Copyright 18.11.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.sparsesolvelsreg(a, b, reg, solvertype)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.sparsesolvelsreg(a, b, reg)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          b:          1D array/list of float
          reg:        float
          solvertype: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.sparsesolverreport

</div></pre>
<a name='sub_sparsespdcholeskysolve'></a><h3 class=pageheader><code>sparsespdcholeskysolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sparse linear solver for A*x=b with N*N real  symmetric  positive definite
# matrix A given by its Cholesky decomposition, and N*1 vectors x and b.
# 
# IMPORTANT: this solver requires input matrix to be in  the  SKS  (Skyline)
#            or CRS (compressed row storage) format. An  exception  will  be
#            generated if you pass matrix in some other format.
# 
# INPUT PARAMETERS
#     A       -   sparse NxN matrix stored in CRs or SKS format, must be NxN
#                 exactly
#     IsUpper -   which half of A is provided (another half is ignored)
#     B       -   array[N], right part
# 
# OUTPUT PARAMETERS
#     X       -   array[N], it contains:
#                 * rep.terminationtype&gt;0    =&gt;  solution
#                 * rep.terminationtype=-3   =&gt;  filled by zeros
#     Rep     -   solver report, following fields are set:
#                 * rep.terminationtype - solver status; &gt;0 for success,
#                   set to -3 on failure (degenerate or non-SPD system).
# 
#   -- ALGLIB --
#      Copyright 26.12.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.sparsespdcholeskysolve(a, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          isupper:    bool
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.sparsesolverreport

</div></pre>
<a name='sub_sparsespdsolve'></a><h3 class=pageheader><code>sparsespdsolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sparse linear solver for A*x=b with N*N  sparse  real  symmetric  positive
# definite matrix A, N*1 vectors x and b.
# 
# This solver  converts  input  matrix  to  CRS  format,  performs  Cholesky
# factorization using supernodal Cholesky  decomposition  with  permutation-
# reducing ordering and uses sparse triangular solver to get solution of the
# original system.
# 
# INPUT PARAMETERS
#     A       -   sparse matrix, must be NxN exactly.
#                 Can be stored in any sparse storage format, CRS is preferred.
#     IsUpper -   which half of A is provided (another half is ignored).
#                 It is better to store the lower triangle because it allows
#                 us to avoid one transposition during internal conversion.
#     B       -   array[N], right part
# 
# OUTPUT PARAMETERS
#     X       -   array[N], it contains:
#                 * rep.terminationtype&gt;0    =&gt;  solution
#                 * rep.terminationtype=-3   =&gt;  filled by zeros
#     Rep     -   solver report, following fields are set:
#                 * rep.terminationtype - solver status; &gt;0 for success,
#                   set to -3 on failure (degenerate or non-SPD system).
# 
#   -- ALGLIB --
#      Copyright 26.12.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.sparsespdsolve(a, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          isupper:    bool
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.sparsesolverreport

</div></pre>
<a name='sub_sparsespdsolvesks'></a><h3 class=pageheader><code>sparsespdsolvesks</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sparse linear solver for A*x=b with N*N  sparse  real  symmetric  positive
# definite matrix A, N*1 vectors x and b.
# 
# This solver  converts  input  matrix  to  SKS  format,  performs  Cholesky
# factorization using  SKS  Cholesky  subroutine  (works  well  for  limited
# bandwidth matrices) and uses sparse triangular solvers to get solution  of
# the original system.
# 
# IMPORTANT: this  function  is  intended  for  low  profile (variable band)
#            linear systems with dense or nearly-dense bands. Only  in  such
#            cases  it  provides  some  performance  improvement  over  more
#            general sparsrspdsolve(). If your  system  has  high  bandwidth
#            or sparse band, the general sparsrspdsolve() is  likely  to  be
#            more efficient.
# 
# INPUT PARAMETERS
#     A       -   sparse matrix, must be NxN exactly
#     IsUpper -   which half of A is provided (another half is ignored)
#     B       -   array[0..N-1], right part
# 
# OUTPUT PARAMETERS
#     X       -   array[N], it contains:
#                 * rep.terminationtype&gt;0    =&gt;  solution
#                 * rep.terminationtype=-3   =&gt;  filled by zeros
#     Rep     -   solver report, following fields are set:
#                 * rep.terminationtype - solver status; &gt;0 for success,
#                   set to -3 on failure (degenerate or non-SPD system).
# 
#   -- ALGLIB --
#      Copyright 26.12.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.sparsespdsolvesks(a, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          isupper:    bool
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.sparsesolverreport

</div></pre>
<a name=unit_elliptic></a><h2 class=pageheader><code>elliptic</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_ellipticintegrale' class=toc>ellipticintegrale</a><br>
<a href='#sub_ellipticintegralk' class=toc>ellipticintegralk</a><br>
<a href='#sub_ellipticintegralkhighprecision' class=toc>ellipticintegralkhighprecision</a><br>
<a href='#sub_incompleteellipticintegrale' class=toc>incompleteellipticintegrale</a><br>
<a href='#sub_incompleteellipticintegralk' class=toc>incompleteellipticintegralk</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_ellipticintegrale'></a><h3 class=pageheader><code>ellipticintegrale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Complete elliptic integral of the second kind
# 
# Approximates the integral
# 
# 
#            pi/2
#             -
#            | |                 2
# E(m)  =    |    sqrt( 1 - m sin t ) dt
#          | |
#           -
#            0
# 
# using the approximation
# 
#      P(x)  -  x log x Q(x).
# 
# ACCURACY:
# 
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE       0, 1       10000       2.1e-16     7.3e-17
# 
# Cephes Math Library, Release 2.8: June, 2000
# Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.ellipticintegrale(m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_ellipticintegralk'></a><h3 class=pageheader><code>ellipticintegralk</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Complete elliptic integral of the first kind
# 
# Approximates the integral
# 
# 
# 
#            pi/2
#             -
#            | |
#            |           dt
# K(m)  =    |    ------------------
#            |                   2
#          | |    sqrt( 1 - m sin t )
#           -
#            0
# 
# using the approximation
# 
#     P(x)  -  log x Q(x).
# 
# ACCURACY:
# 
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE       0,1        30000       2.5e-16     6.8e-17
# 
# Cephes Math Library, Release 2.8:  June, 2000
# Copyright 1984, 1987, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.ellipticintegralk(m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_ellipticintegralkhighprecision'></a><h3 class=pageheader><code>ellipticintegralkhighprecision</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Complete elliptic integral of the first kind
# 
# Approximates the integral
# 
# 
# 
#            pi/2
#             -
#            | |
#            |           dt
# K(m)  =    |    ------------------
#            |                   2
#          | |    sqrt( 1 - m sin t )
#           -
#            0
# 
# where m = 1 - m1, using the approximation
# 
#     P(x)  -  log x Q(x).
# 
# The argument m1 is used rather than m so that the logarithmic
# singularity at m = 1 will be shifted to the origin; this
# preserves maximum accuracy.
# 
# K(0) = pi/2.
# 
# ACCURACY:
# 
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE       0,1        30000       2.5e-16     6.8e-17
# 
# Cephes Math Library, Release 2.8:  June, 2000
# Copyright 1984, 1987, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.ellipticintegralkhighprecision(m1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m1:         float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_incompleteellipticintegrale'></a><h3 class=pageheader><code>incompleteellipticintegrale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Incomplete elliptic integral of the second kind
# 
# Approximates the integral
# 
# 
#                phi
#                 -
#                | |
#                |                   2
# E(phi_\m)  =    |    sqrt( 1 - m sin t ) dt
#                |
#              | |
#               -
#                0
# 
# of amplitude phi and modulus m, using the arithmetic -
# geometric mean algorithm.
# 
# ACCURACY:
# 
# Tested at random arguments with phi in [-10, 10] and m in
# [0, 1].
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE     -10,10      150000       3.3e-15     1.4e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1993, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.incompleteellipticintegrale(phi, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     phi:        float
          m:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_incompleteellipticintegralk'></a><h3 class=pageheader><code>incompleteellipticintegralk</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Incomplete elliptic integral of the first kind F(phi|m)
# 
# Approximates the integral
# 
# 
# 
#                phi
#                 -
#                | |
#                |           dt
# F(phi_\m)  =    |    ------------------
#                |                   2
#              | |    sqrt( 1 - m sin t )
#               -
#                0
# 
# of amplitude phi and modulus m, using the arithmetic -
# geometric mean algorithm.
# 
# 
# 
# 
# ACCURACY:
# 
# Tested at random points with m in [0, 1] and phi as indicated.
# 
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE     -10,10       200000      7.4e-16     1.0e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.incompleteellipticintegralk(phi, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     phi:        float
          m:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_evd></a><h2 class=pageheader><code>evd</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_eigsubspacecreate' class=toc>eigsubspacecreate</a><br>
<a href='#sub_eigsubspacecreatebuf' class=toc>eigsubspacecreatebuf</a><br>
<a href='#sub_eigsubspaceooccontinue' class=toc>eigsubspaceooccontinue</a><br>
<a href='#sub_eigsubspaceoocgetrequestdata' class=toc>eigsubspaceoocgetrequestdata</a><br>
<a href='#sub_eigsubspaceoocgetrequestinfo' class=toc>eigsubspaceoocgetrequestinfo</a><br>
<a href='#sub_eigsubspaceoocsendresult' class=toc>eigsubspaceoocsendresult</a><br>
<a href='#sub_eigsubspaceoocstart' class=toc>eigsubspaceoocstart</a><br>
<a href='#sub_eigsubspaceoocstop' class=toc>eigsubspaceoocstop</a><br>
<a href='#sub_eigsubspacesetcond' class=toc>eigsubspacesetcond</a><br>
<a href='#sub_eigsubspacesetwarmstart' class=toc>eigsubspacesetwarmstart</a><br>
<a href='#sub_eigsubspacesolvedenses' class=toc>eigsubspacesolvedenses</a><br>
<a href='#sub_eigsubspacesolvesparses' class=toc>eigsubspacesolvesparses</a><br>
<a href='#sub_hmatrixevd' class=toc>hmatrixevd</a><br>
<a href='#sub_hmatrixevdi' class=toc>hmatrixevdi</a><br>
<a href='#sub_hmatrixevdr' class=toc>hmatrixevdr</a><br>
<a href='#sub_rmatrixevd' class=toc>rmatrixevd</a><br>
<a href='#sub_smatrixevd' class=toc>smatrixevd</a><br>
<a href='#sub_smatrixevdi' class=toc>smatrixevdi</a><br>
<a href='#sub_smatrixevdr' class=toc>smatrixevdr</a><br>
<a href='#sub_smatrixtdevd' class=toc>smatrixtdevd</a><br>
<a href='#sub_smatrixtdevdi' class=toc>smatrixtdevdi</a><br>
<a href='#sub_smatrixtdevdr' class=toc>smatrixtdevdr</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_eigsubspacecreate'></a><h3 class=pageheader><code>eigsubspacecreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function initializes subspace iteration solver. This solver  is  used
# to solve symmetric real eigenproblems where just a few (top K) eigenvalues
# and corresponding eigenvectors is required.
# 
# This solver can be significantly faster than  complete  EVD  decomposition
# in the following case:
# * when only just a small fraction  of  top  eigenpairs  of dense matrix is
#   required. When K approaches N, this solver is slower than complete dense
#   EVD
# * when problem matrix is sparse (and/or is not known explicitly, i.e. only
#   matrix-matrix product can be performed)
# 
# USAGE (explicit dense/sparse matrix):
# 1. User initializes algorithm state with eigsubspacecreate() call
# 2. [optional] User tunes solver parameters by calling eigsubspacesetcond()
#    or other functions
# 3. User  calls  eigsubspacesolvedense() or eigsubspacesolvesparse() methods,
#    which take algorithm state and 2D array or alglib.sparsematrix object.
# 
# USAGE (out-of-core mode):
# 1. User initializes algorithm state with eigsubspacecreate() call
# 2. [optional] User tunes solver parameters by calling eigsubspacesetcond()
#    or other functions
# 3. User activates out-of-core mode of  the  solver  and  repeatedly  calls
#    communication functions in a loop like below:
#    &gt; alglib.eigsubspaceoocstart(state)
#    &gt; while alglib.eigsubspaceooccontinue(state) do
#    &gt;     alglib.eigsubspaceoocgetrequestinfo(state, out RequestType, out M)
#    &gt;     alglib.eigsubspaceoocgetrequestdata(state, out X)
#    &gt;     [calculate  Y=A*X, with X=R^NxM]
#    &gt;     alglib.eigsubspaceoocsendresult(state, in Y)
#    &gt; alglib.eigsubspaceoocstop(state, out W, out Z, out Report)
# 
# INPUT PARAMETERS:
#     N       -   problem dimensionality, N&gt;0
#     K       -   number of top eigenvector to calculate, 0&lt;K&lt;=N.
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# NOTE: if you solve many similar EVD problems you may  find  it  useful  to
#       reuse previous subspace as warm-start point for new EVD problem.  It
#       can be done with eigsubspacesetwarmstart() function.
# 
#   -- ALGLIB --
#      Copyright 16.01.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.eigsubspacecreate(n, k)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          k:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.eigsubspacestate

</div></pre>
<a name='sub_eigsubspacecreatebuf'></a><h3 class=pageheader><code>eigsubspacecreatebuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Buffered version of constructor which aims to reuse  previously  allocated
# memory as much as possible.
# 
#   -- ALGLIB --
#      Copyright 16.01.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.eigsubspacecreatebuf(n, k, state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          k:          int
          state:      class xalglib.eigsubspacestate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_eigsubspaceooccontinue'></a><h3 class=pageheader><code>eigsubspaceooccontinue</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function performs subspace iteration  in  the  out-of-core  mode.  It
# should be used in conjunction with other out-of-core-related functions  of
# this subspackage in a loop like below:
# 
# &gt; alglib.eigsubspaceoocstart(state)
# &gt; while alglib.eigsubspaceooccontinue(state) do
# &gt;     alglib.eigsubspaceoocgetrequestinfo(state, out RequestType, out M)
# &gt;     alglib.eigsubspaceoocgetrequestdata(state, out X)
# &gt;     [calculate  Y=A*X, with X=R^NxM]
# &gt;     alglib.eigsubspaceoocsendresult(state, in Y)
# &gt; alglib.eigsubspaceoocstop(state, out W, out Z, out Report)
# 
# 
#   -- ALGLIB --
#      Copyright 16.01.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.eigsubspaceooccontinue(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.eigsubspacestate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_eigsubspaceoocgetrequestdata'></a><h3 class=pageheader><code>eigsubspaceoocgetrequestdata</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to retrieve information  about  out-of-core  request
# sent by solver to user code: matrix X (array[N,RequestSize) which have  to
# be multiplied by out-of-core matrix A in a product A*X.
# 
# This function returns just request data; in order to get size of  the data
# prior to processing requestm, use eigsubspaceoocgetrequestinfo().
# 
# It should be used in conjunction with other out-of-core-related  functions
# of this subspackage in a loop like below:
# 
# &gt; alglib.eigsubspaceoocstart(state)
# &gt; while alglib.eigsubspaceooccontinue(state) do
# &gt;     alglib.eigsubspaceoocgetrequestinfo(state, out RequestType, out M)
# &gt;     alglib.eigsubspaceoocgetrequestdata(state, out X)
# &gt;     [calculate  Y=A*X, with X=R^NxM]
# &gt;     alglib.eigsubspaceoocsendresult(state, in Y)
# &gt; alglib.eigsubspaceoocstop(state, out W, out Z, out Report)
# 
# INPUT PARAMETERS:
#     State           -   solver running in out-of-core mode
#     X               -   possibly  preallocated   storage;  reallocated  if
#                         needed, left unchanged, if large enough  to  store
#                         request data.
# 
# OUTPUT PARAMETERS:
#     X               -   array[N,RequestSize] or larger, leading  rectangle
#                         is filled with dense matrix X.
# 
# 
#   -- ALGLIB --
#      Copyright 16.01.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.eigsubspaceoocgetrequestdata(state, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.eigsubspacestate
          x:          2D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          2D array/list of float

</div></pre>
<a name='sub_eigsubspaceoocgetrequestinfo'></a><h3 class=pageheader><code>eigsubspaceoocgetrequestinfo</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to retrieve information  about  out-of-core  request
# sent by solver to user code: request type (current version  of  the solver
# sends only requests for matrix-matrix products) and request size (size  of
# the matrices being multiplied).
# 
# This function returns just request metrics; in order  to  get contents  of
# the matrices being multiplied, use eigsubspaceoocgetrequestdata().
# 
# It should be used in conjunction with other out-of-core-related  functions
# of this subspackage in a loop like below:
# 
# &gt; alglib.eigsubspaceoocstart(state)
# &gt; while alglib.eigsubspaceooccontinue(state) do
# &gt;     alglib.eigsubspaceoocgetrequestinfo(state, out RequestType, out M)
# &gt;     alglib.eigsubspaceoocgetrequestdata(state, out X)
# &gt;     [calculate  Y=A*X, with X=R^NxM]
# &gt;     alglib.eigsubspaceoocsendresult(state, in Y)
# &gt; alglib.eigsubspaceoocstop(state, out W, out Z, out Report)
# 
# INPUT PARAMETERS:
#     State           -   solver running in out-of-core mode
# 
# OUTPUT PARAMETERS:
#     RequestType     -   type of the request to process:
#                         * 0 - for matrix-matrix product A*X, with A  being
#                           NxN matrix whose eigenvalues/vectors are needed,
#                           and X being NxREQUESTSIZE one which is  returned
#                           by the eigsubspaceoocgetrequestdata().
#     RequestSize     -   size of the X matrix (number of columns),  usually
#                         it is several times larger than number of  vectors
#                         K requested by user.
# 
# 
#   -- ALGLIB --
#      Copyright 16.01.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   requesttype, requestsize = xalglib.eigsubspaceoocgetrequestinfo(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.eigsubspacestate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  requesttype: int
          requestsize: int

</div></pre>
<a name='sub_eigsubspaceoocsendresult'></a><h3 class=pageheader><code>eigsubspaceoocsendresult</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to send user reply to out-of-core  request  sent  by
# solver. Usually it is product A*X for returned by solver matrix X.
# 
# It should be used in conjunction with other out-of-core-related  functions
# of this subspackage in a loop like below:
# 
# &gt; alglib.eigsubspaceoocstart(state)
# &gt; while alglib.eigsubspaceooccontinue(state) do
# &gt;     alglib.eigsubspaceoocgetrequestinfo(state, out RequestType, out M)
# &gt;     alglib.eigsubspaceoocgetrequestdata(state, out X)
# &gt;     [calculate  Y=A*X, with X=R^NxM]
# &gt;     alglib.eigsubspaceoocsendresult(state, in Y)
# &gt; alglib.eigsubspaceoocstop(state, out W, out Z, out Report)
# 
# INPUT PARAMETERS:
#     State           -   solver running in out-of-core mode
#     AX              -   array[N,RequestSize] or larger, leading  rectangle
#                         is filled with product A*X.
# 
# 
#   -- ALGLIB --
#      Copyright 16.01.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.eigsubspaceoocsendresult(state, ax)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.eigsubspacestate
          ax:         2D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_eigsubspaceoocstart'></a><h3 class=pageheader><code>eigsubspaceoocstart</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  initiates  out-of-core  mode  of  subspace eigensolver. It
# should be used in conjunction with other out-of-core-related functions  of
# this subspackage in a loop like below:
# 
# &gt; alglib.eigsubspaceoocstart(state)
# &gt; while alglib.eigsubspaceooccontinue(state) do
# &gt;     alglib.eigsubspaceoocgetrequestinfo(state, out RequestType, out M)
# &gt;     alglib.eigsubspaceoocgetrequestdata(state, out X)
# &gt;     [calculate  Y=A*X, with X=R^NxM]
# &gt;     alglib.eigsubspaceoocsendresult(state, in Y)
# &gt; alglib.eigsubspaceoocstop(state, out W, out Z, out Report)
# 
# INPUT PARAMETERS:
#     State       -   solver object
#     MType       -   matrix type and solver mode:
# 
#                     * 0 =   real symmetric matrix A, products  of the form
#                             A*X are computed. At every step  the  basis of
#                             the  invariant  subspace  is  reorthogonalized
#                             with LQ decomposition  which  makes  the  algo
#                             more robust.
# 
#                             The first mode introduced in ALGLIB, the  most
#                             precise and robust. However, it is  suboptimal
#                             for easy problems which can be solved  in  3-5
#                             iterations without LQ step.
# 
#                     * 1 =   real symmetric matrix A, products  of the form
#                             A*X are computed. The  invariant  subspace  is
#                             NOT reorthogonalized,  no  error  checks.  The
#                             solver  stops  after   specified   number   of
#                             iterations which should be small, 5 at most.
# 
#                             This mode is intended for easy  problems  with
#                             extremely fast convergence.
# 
#                     Future versions of ALGLIB may  introduce  support  for
#                     other  matrix   types;   for   now,   only   symmetric
#                     eigenproblems are supported.
# 
# 
#   -- ALGLIB --
#      Copyright 07.06.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.eigsubspaceoocstart(state, mtype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.eigsubspacestate
          mtype:      int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_eigsubspaceoocstop'></a><h3 class=pageheader><code>eigsubspaceoocstop</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  finalizes out-of-core  mode  of  subspace eigensolver.  It
# should be used in conjunction with other out-of-core-related functions  of
# this subspackage in a loop like below:
# 
# &gt; alglib.eigsubspaceoocstart(state)
# &gt; while alglib.eigsubspaceooccontinue(state) do
# &gt;     alglib.eigsubspaceoocgetrequestinfo(state, out RequestType, out M)
# &gt;     alglib.eigsubspaceoocgetrequestdata(state, out X)
# &gt;     [calculate  Y=A*X, with X=R^NxM]
# &gt;     alglib.eigsubspaceoocsendresult(state, in Y)
# &gt; alglib.eigsubspaceoocstop(state, out W, out Z, out Report)
# 
# INPUT PARAMETERS:
#     State       -   solver state
# 
# OUTPUT PARAMETERS:
#     W           -   array[K], depending on solver settings:
#                     * top  K  eigenvalues ordered  by  descending   -   if
#                       eigenvectors are returned in Z
#                     * zeros - if invariant subspace is returned in Z
#     Z           -   array[N,K], depending on solver settings either:
#                     * matrix of eigenvectors found
#                     * orthogonal basis of K-dimensional invariant subspace
#     Rep         -   report with additional parameters
# 
#   -- ALGLIB --
#      Copyright 16.01.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   w, z, rep = xalglib.eigsubspaceoocstop(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.eigsubspacestate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  w:          1D array/list of float
          z:          2D array/list of float
          rep:        class xalglib.eigsubspacereport

</div></pre>
<a name='sub_eigsubspacesetcond'></a><h3 class=pageheader><code>eigsubspacesetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping critera for the solver:
# * error in eigenvector/value allowed by solver
# * maximum number of iterations to perform
# 
# INPUT PARAMETERS:
#     State       -   solver structure
#     Eps         -   eps&gt;=0,  with non-zero value used to tell solver  that
#                     it can  stop  after  all  eigenvalues  converged  with
#                     error  roughly  proportional  to  eps*MAX(LAMBDA_MAX),
#                     where LAMBDA_MAX is a maximum eigenvalue.
#                     Zero  value  means  that  no  check  for  precision is
#                     performed.
#     MaxIts      -   maxits&gt;=0,  with non-zero value used  to  tell  solver
#                     that it can stop after maxits  steps  (no  matter  how
#                     precise current estimate is)
# 
# NOTE: passing  eps=0  and  maxits=0  results  in  automatic  selection  of
#       moderate eps as stopping criteria (1.0E-6 in current implementation,
#       but it may change without notice).
# 
# NOTE: very small values of eps are possible (say, 1.0E-12),  although  the
#       larger problem you solve (N and/or K), the  harder  it  is  to  find
#       precise eigenvectors because rounding errors tend to accumulate.
# 
# NOTE: passing non-zero eps results in  some performance  penalty,  roughly
#       equal to 2N*(2K)^2 FLOPs per iteration. These additional computations
#       are required in order to estimate current error in  eigenvalues  via
#       Rayleigh-Ritz process.
#       Most of this additional time is  spent  in  construction  of  ~2Kx2K
#       symmetric  subproblem  whose  eigenvalues  are  checked  with  exact
#       eigensolver.
#       This additional time is negligible if you search for eigenvalues  of
#       the large dense matrix, but may become noticeable on  highly  sparse
#       EVD problems, where cost of matrix-matrix product is low.
#       If you set eps to exactly zero,  Rayleigh-Ritz  phase  is completely
#       turned off.
# 
#   -- ALGLIB --
#      Copyright 16.01.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.eigsubspacesetcond(state, eps, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.eigsubspacestate
          eps:        float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_eigsubspacesetwarmstart'></a><h3 class=pageheader><code>eigsubspacesetwarmstart</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets warm-start mode of the solver: next call to the  solver
# will reuse previous subspace as warm-start  point.  It  can  significantly
# speed-up convergence when you solve many similar eigenproblems.
# 
# INPUT PARAMETERS:
#     State       -   solver structure
#     UseWarmStart-   either True or False
# 
#   -- ALGLIB --
#      Copyright 12.11.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.eigsubspacesetwarmstart(state, usewarmstart)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.eigsubspacestate
          usewarmstart: bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_eigsubspacesolvedenses'></a><h3 class=pageheader><code>eigsubspacesolvedenses</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function runs subspace eigensolver for dense NxN symmetric matrix A,
# given by its upper or lower triangle.
# 
# This function can not process nonsymmetric matrices.
# 
# INPUT PARAMETERS:
#     State       -   solver state
#     A           -   array[N,N], symmetric NxN matrix given by one  of  its
#                     triangles
#     IsUpper     -   whether upper or lower triangle of  A  is  given  (the
#                     other one is not referenced at all).
# 
# OUTPUT PARAMETERS:
#     W           -   array[K], top  K  eigenvalues ordered  by   descending
#                     of their absolute values
#     Z           -   array[N,K], matrix of eigenvectors found
#     Rep         -   report with additional parameters
# 
# NOTE: internally this function allocates a copy of NxN dense A. You should
#       take it into account when working with very large matrices occupying
#       almost all RAM.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 16.01.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   w, z, rep = xalglib.eigsubspacesolvedenses(state, a, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.eigsubspacestate
          a:          2D array/list of float
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  w:          1D array/list of float
          z:          2D array/list of float
          rep:        class xalglib.eigsubspacereport

</div></pre>
<a name='sub_eigsubspacesolvesparses'></a><h3 class=pageheader><code>eigsubspacesolvesparses</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function runs eigensolver for dense NxN symmetric matrix A, given by
# upper or lower triangle.
# 
# This function can not process nonsymmetric matrices.
# 
# INPUT PARAMETERS:
#     State       -   solver state
#     A           -   NxN symmetric matrix given by one of its triangles
#     IsUpper     -   whether upper or lower triangle of  A  is  given  (the
#                     other one is not referenced at all).
# 
# OUTPUT PARAMETERS:
#     W           -   array[K], top  K  eigenvalues ordered  by   descending
#                     of their absolute values
#     Z           -   array[N,K], matrix of eigenvectors found
#     Rep         -   report with additional parameters
# 
#   -- ALGLIB --
#      Copyright 16.01.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   w, z, rep = xalglib.eigsubspacesolvesparses(state, a, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.eigsubspacestate
          a:          class xalglib.sparsematrix
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  w:          1D array/list of float
          z:          2D array/list of float
          rep:        class xalglib.eigsubspacereport

</div></pre>
<a name='sub_hmatrixevd'></a><h3 class=pageheader><code>hmatrixevd</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Finding the eigenvalues and eigenvectors of a Hermitian matrix
# 
# The algorithm finds eigen pairs of a Hermitian matrix by  reducing  it  to
# real tridiagonal form and using the QL/QR algorithm.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# Input parameters:
#     A       -   Hermitian matrix which is given  by  its  upper  or  lower
#                 triangular part.
#                 Array whose indexes range within [0..N-1, 0..N-1].
#     N       -   size of matrix A.
#     IsUpper -   storage format.
#     ZNeeded -   flag controlling whether the eigenvectors  are  needed  or
#                 not. If ZNeeded is equal to:
#                  * 0, the eigenvectors are not returned;
#                  * 1, the eigenvectors are returned.
# 
# Output parameters:
#     D       -   eigenvalues in ascending order.
#                 Array whose index ranges within [0..N-1].
#     Z       -   if ZNeeded is equal to:
#                  * 0, Z hasn't changed;
#                  * 1, Z contains the eigenvectors.
#                 Array whose indexes range within [0..N-1, 0..N-1].
#                 The eigenvectors are stored in the matrix columns.
# 
# Result:
#     True, if the algorithm has converged.
#     False, if the algorithm hasn't converged (rare case).
# 
# Note:
#     eigenvectors of Hermitian matrix are defined up to  multiplication  by
#     a complex number L, such that |L|=1.
# 
#   -- ALGLIB --
#      Copyright 2005, 23 March 2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, d, z = xalglib.hmatrixevd(a, n, zneeded, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          zneeded:    int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          d:          1D array/list of float
          z:          2D array/list of complex

</div></pre>
<a name='sub_hmatrixevdi'></a><h3 class=pageheader><code>hmatrixevdi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Subroutine for finding the eigenvalues and  eigenvectors  of  a  Hermitian
# matrix with given indexes by using bisection and inverse iteration methods
# 
# Input parameters:
#     A       -   Hermitian matrix which is given  by  its  upper  or  lower
#                 triangular part.
#                 Array whose indexes range within [0..N-1, 0..N-1].
#     N       -   size of matrix A.
#     ZNeeded -   flag controlling whether the eigenvectors  are  needed  or
#                 not. If ZNeeded is equal to:
#                  * 0, the eigenvectors are not returned;
#                  * 1, the eigenvectors are returned.
#     IsUpperA -  storage format of matrix A.
#     I1, I2 -    index interval for searching (from I1 to I2).
#                 0 &lt;= I1 &lt;= I2 &lt;= N-1.
# 
# Output parameters:
#     W       -   array of the eigenvalues found.
#                 Array whose index ranges within [0..I2-I1].
#     Z       -   if ZNeeded is equal to:
#                  * 0, Z hasn't changed;
#                  * 1, Z contains eigenvectors.
#                 Array whose indexes range within [0..N-1, 0..I2-I1].
#                 In  that  case,  the eigenvectors are stored in the matrix
#                 columns.
# 
# Result:
#     True, if successful. W contains the eigenvalues, Z contains the
#     eigenvectors (if needed).
# 
#     False, if the bisection method subroutine  wasn't  able  to  find  the
#     eigenvalues  in  the  given  interval  or  if  the  inverse  iteration
#     subroutine wasn't able to find  all  the  corresponding  eigenvectors.
#     In that case, the eigenvalues and eigenvectors are not returned.
# 
# Note:
#     eigen vectors of Hermitian matrix are defined up to multiplication  by
#     a complex number L, such as |L|=1.
# 
#   -- ALGLIB --
#      Copyright 07.01.2006, 24.03.2007 by Bochkanov Sergey.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, w, z = xalglib.hmatrixevdi(a, n, zneeded, isupper, i1, i2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          zneeded:    int
          isupper:    bool
          i1:         int
          i2:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          w:          1D array/list of float
          z:          2D array/list of complex

</div></pre>
<a name='sub_hmatrixevdr'></a><h3 class=pageheader><code>hmatrixevdr</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Subroutine for finding the eigenvalues (and eigenvectors) of  a  Hermitian
# matrix  in  a  given half-interval (A, B] by using a bisection and inverse
# iteration
# 
# Input parameters:
#     A       -   Hermitian matrix which is given  by  its  upper  or  lower
#                 triangular  part.  Array  whose   indexes   range   within
#                 [0..N-1, 0..N-1].
#     N       -   size of matrix A.
#     ZNeeded -   flag controlling whether the eigenvectors  are  needed  or
#                 not. If ZNeeded is equal to:
#                  * 0, the eigenvectors are not returned;
#                  * 1, the eigenvectors are returned.
#     IsUpperA -  storage format of matrix A.
#     B1, B2 -    half-interval (B1, B2] to search eigenvalues in.
# 
# Output parameters:
#     M       -   number of eigenvalues found in a given half-interval, M&gt;=0
#     W       -   array of the eigenvalues found.
#                 Array whose index ranges within [0..M-1].
#     Z       -   if ZNeeded is equal to:
#                  * 0, Z hasn't changed;
#                  * 1, Z contains eigenvectors.
#                 Array whose indexes range within [0..N-1, 0..M-1].
#                 The eigenvectors are stored in the matrix columns.
# 
# Result:
#     True, if successful. M contains the number of eigenvalues in the given
#     half-interval (could be equal to 0), W contains the eigenvalues,
#     Z contains the eigenvectors (if needed).
# 
#     False, if the bisection method subroutine  wasn't  able  to  find  the
#     eigenvalues  in  the  given  interval  or  if  the  inverse  iteration
#     subroutine  wasn't  able  to  find all the corresponding eigenvectors.
#     In that case, the eigenvalues and eigenvectors are not returned, M  is
#     equal to 0.
# 
# Note:
#     eigen vectors of Hermitian matrix are defined up to multiplication  by
#     a complex number L, such as |L|=1.
# 
#   -- ALGLIB --
#      Copyright 07.01.2006, 24.03.2007 by Bochkanov Sergey.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, m, w, z = xalglib.hmatrixevdr(a, n, zneeded, isupper, b1, b2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          zneeded:    int
          isupper:    bool
          b1:         float
          b2:         float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          m:          int
          w:          1D array/list of float
          z:          2D array/list of complex

</div></pre>
<a name='sub_rmatrixevd'></a><h3 class=pageheader><code>rmatrixevd</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Finding eigenvalues and eigenvectors of a general (unsymmetric) matrix
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# The algorithm finds eigenvalues and eigenvectors of a general matrix by
# using the QR algorithm with multiple shifts. The algorithm can find
# eigenvalues and both left and right eigenvectors.
# 
# The right eigenvector is a vector x such that A*x = w*x, and the left
# eigenvector is a vector y such that y'*A = w*y' (here y' implies a complex
# conjugate transposition of vector y).
# 
# Input parameters:
#     A       -   matrix. Array whose indexes range within [0..N-1, 0..N-1].
#     N       -   size of matrix A.
#     VNeeded -   flag controlling whether eigenvectors are needed or not.
#                 If VNeeded is equal to:
#                  * 0, eigenvectors are not returned;
#                  * 1, right eigenvectors are returned;
#                  * 2, left eigenvectors are returned;
#                  * 3, both left and right eigenvectors are returned.
# 
# Output parameters:
#     WR      -   real parts of eigenvalues.
#                 Array whose index ranges within [0..N-1].
#     WR      -   imaginary parts of eigenvalues.
#                 Array whose index ranges within [0..N-1].
#     VL, VR  -   arrays of left and right eigenvectors (if they are needed).
#                 If WI[i]=0, the respective eigenvalue is a real number,
#                 and it corresponds to the column number I of matrices VL/VR.
#                 If WI[i]&gt;0, we have a pair of complex conjugate numbers with
#                 positive and negative imaginary parts:
#                     the first eigenvalue WR[i] + sqrt(-1)*WI[i];
#                     the second eigenvalue WR[i+1] + sqrt(-1)*WI[i+1];
#                     WI[i]&gt;0
#                     WI[i+1] = -WI[i] &lt; 0
#                 In that case, the eigenvector  corresponding to the first
#                 eigenvalue is located in i and i+1 columns of matrices
#                 VL/VR (the column number i contains the real part, and the
#                 column number i+1 contains the imaginary part), and the vector
#                 corresponding to the second eigenvalue is a complex conjugate to
#                 the first vector.
#                 Arrays whose indexes range within [0..N-1, 0..N-1].
# 
# Result:
#     True, if the algorithm has converged.
#     False, if the algorithm has not converged.
# 
# Note 1:
#     Some users may ask the following question: what if WI[N-1]&gt;0?
#     WI[N] must contain an eigenvalue which is complex conjugate to the
#     N-th eigenvalue, but the array has only size N?
#     The answer is as follows: such a situation cannot occur because the
#     algorithm finds a pairs of eigenvalues, therefore, if WI[i]&gt;0, I is
#     strictly less than N-1.
# 
# Note 2:
#     The algorithm performance depends on the value of the internal parameter
#     NS of the InternalSchurDecomposition subroutine which defines the number
#     of shifts in the QR algorithm (similarly to the block width in block-matrix
#     algorithms of linear algebra). If you require maximum performance
#     on your machine, it is recommended to adjust this parameter manually.
# 
# 
# See also the InternalTREVC subroutine.
# 
# The algorithm is based on the LAPACK 3.0 library.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, wr, wi, vl, vr = xalglib.rmatrixevd(a, n, vneeded)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          vneeded:    int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          wr:         1D array/list of float
          wi:         1D array/list of float
          vl:         2D array/list of float
          vr:         2D array/list of float

</div></pre>
<a name='sub_smatrixevd'></a><h3 class=pageheader><code>smatrixevd</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Finding the eigenvalues and eigenvectors of a symmetric matrix
# 
# The algorithm finds eigen pairs of a symmetric matrix by reducing it to
# tridiagonal form and using the QL/QR algorithm.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# Input parameters:
#     A       -   symmetric matrix which is given by its upper or lower
#                 triangular part.
#                 Array whose indexes range within [0..N-1, 0..N-1].
#     N       -   size of matrix A.
#     ZNeeded -   flag controlling whether the eigenvectors are needed or not.
#                 If ZNeeded is equal to:
#                  * 0, the eigenvectors are not returned;
#                  * 1, the eigenvectors are returned.
#     IsUpper -   storage format.
# 
# Output parameters:
#     D       -   eigenvalues in ascending order.
#                 Array whose index ranges within [0..N-1].
#     Z       -   if ZNeeded is equal to:
#                  * 0, Z hasn't changed;
#                  * 1, Z contains the eigenvectors.
#                 Array whose indexes range within [0..N-1, 0..N-1].
#                 The eigenvectors are stored in the matrix columns.
# 
# Result:
#     True, if the algorithm has converged.
#     False, if the algorithm hasn't converged (rare case).
# 
#   -- ALGLIB --
#      Copyright 2005-2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, d, z = xalglib.smatrixevd(a, n, zneeded, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          zneeded:    int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          d:          1D array/list of float
          z:          2D array/list of float

</div></pre>
<a name='sub_smatrixevdi'></a><h3 class=pageheader><code>smatrixevdi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Subroutine for finding the eigenvalues and  eigenvectors  of  a  symmetric
# matrix with given indexes by using bisection and inverse iteration methods.
# 
# Input parameters:
#     A       -   symmetric matrix which is given by its upper or lower
#                 triangular part. Array whose indexes range within [0..N-1, 0..N-1].
#     N       -   size of matrix A.
#     ZNeeded -   flag controlling whether the eigenvectors are needed or not.
#                 If ZNeeded is equal to:
#                  * 0, the eigenvectors are not returned;
#                  * 1, the eigenvectors are returned.
#     IsUpperA -  storage format of matrix A.
#     I1, I2 -    index interval for searching (from I1 to I2).
#                 0 &lt;= I1 &lt;= I2 &lt;= N-1.
# 
# Output parameters:
#     W       -   array of the eigenvalues found.
#                 Array whose index ranges within [0..I2-I1].
#     Z       -   if ZNeeded is equal to:
#                  * 0, Z hasn't changed;
#                  * 1, Z contains eigenvectors.
#                 Array whose indexes range within [0..N-1, 0..I2-I1].
#                 In that case, the eigenvectors are stored in the matrix columns.
# 
# Result:
#     True, if successful. W contains the eigenvalues, Z contains the
#     eigenvectors (if needed).
# 
#     False, if the bisection method subroutine wasn't able to find the
#     eigenvalues in the given interval or if the inverse iteration subroutine
#     wasn't able to find all the corresponding eigenvectors.
#     In that case, the eigenvalues and eigenvectors are not returned.
# 
#   -- ALGLIB --
#      Copyright 07.01.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, w, z = xalglib.smatrixevdi(a, n, zneeded, isupper, i1, i2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          zneeded:    int
          isupper:    bool
          i1:         int
          i2:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          w:          1D array/list of float
          z:          2D array/list of float

</div></pre>
<a name='sub_smatrixevdr'></a><h3 class=pageheader><code>smatrixevdr</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Subroutine for finding the eigenvalues (and eigenvectors) of  a  symmetric
# matrix  in  a  given half open interval (A, B] by using  a  bisection  and
# inverse iteration
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# Input parameters:
#     A       -   symmetric matrix which is given by its upper or lower
#                 triangular part. Array [0..N-1, 0..N-1].
#     N       -   size of matrix A.
#     ZNeeded -   flag controlling whether the eigenvectors are needed or not.
#                 If ZNeeded is equal to:
#                  * 0, the eigenvectors are not returned;
#                  * 1, the eigenvectors are returned.
#     IsUpperA -  storage format of matrix A.
#     B1, B2 -    half open interval (B1, B2] to search eigenvalues in.
# 
# Output parameters:
#     M       -   number of eigenvalues found in a given half-interval (M&gt;=0).
#     W       -   array of the eigenvalues found.
#                 Array whose index ranges within [0..M-1].
#     Z       -   if ZNeeded is equal to:
#                  * 0, Z hasn't changed;
#                  * 1, Z contains eigenvectors.
#                 Array whose indexes range within [0..N-1, 0..M-1].
#                 The eigenvectors are stored in the matrix columns.
# 
# Result:
#     True, if successful. M contains the number of eigenvalues in the given
#     half-interval (could be equal to 0), W contains the eigenvalues,
#     Z contains the eigenvectors (if needed).
# 
#     False, if the bisection method subroutine wasn't able to find the
#     eigenvalues in the given interval or if the inverse iteration subroutine
#     wasn't able to find all the corresponding eigenvectors.
#     In that case, the eigenvalues and eigenvectors are not returned,
#     M is equal to 0.
# 
#   -- ALGLIB --
#      Copyright 07.01.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, m, w, z = xalglib.smatrixevdr(a, n, zneeded, isupper, b1, b2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          zneeded:    int
          isupper:    bool
          b1:         float
          b2:         float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          m:          int
          w:          1D array/list of float
          z:          2D array/list of float

</div></pre>
<a name='sub_smatrixtdevd'></a><h3 class=pageheader><code>smatrixtdevd</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Finding the eigenvalues and eigenvectors of a tridiagonal symmetric matrix
# 
# The algorithm finds the eigen pairs of a tridiagonal symmetric matrix by
# using an QL/QR algorithm with implicit shifts.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# Input parameters:
#     D       -   the main diagonal of a tridiagonal matrix.
#                 Array whose index ranges within [0..N-1].
#     E       -   the secondary diagonal of a tridiagonal matrix.
#                 Array whose index ranges within [0..N-2].
#     N       -   size of matrix A.
#     ZNeeded -   flag controlling whether the eigenvectors are needed or not.
#                 If ZNeeded is equal to:
#                  * 0, the eigenvectors are not needed;
#                  * 1, the eigenvectors of a tridiagonal matrix
#                    are multiplied by the square matrix Z. It is used if the
#                    tridiagonal matrix is obtained by the similarity
#                    transformation of a symmetric matrix;
#                  * 2, the eigenvectors of a tridiagonal matrix replace the
#                    square matrix Z;
#                  * 3, matrix Z contains the first row of the eigenvectors
#                    matrix.
#     Z       -   if ZNeeded=1, Z contains the square matrix by which the
#                 eigenvectors are multiplied.
#                 Array whose indexes range within [0..N-1, 0..N-1].
# 
# Output parameters:
#     D       -   eigenvalues in ascending order.
#                 Array whose index ranges within [0..N-1].
#     Z       -   if ZNeeded is equal to:
#                  * 0, Z hasn't changed;
#                  * 1, Z contains the product of a given matrix (from the left)
#                    and the eigenvectors matrix (from the right);
#                  * 2, Z contains the eigenvectors.
#                  * 3, Z contains the first row of the eigenvectors matrix.
#                 If ZNeeded&lt;3, Z is the array whose indexes range within [0..N-1, 0..N-1].
#                 In that case, the eigenvectors are stored in the matrix columns.
#                 If ZNeeded=3, Z is the array whose indexes range within [0..0, 0..N-1].
# 
# Result:
#     True, if the algorithm has converged.
#     False, if the algorithm hasn't converged.
# 
#   -- LAPACK routine (version 3.0) --
#      Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
#      Courant Institute, Argonne National Lab, and Rice University
#      September 30, 1994
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, z = xalglib.smatrixtdevd(d, e, n, zneeded, z)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     d:          1D array/list of float
          e:          1D array/list of float
          n:          int
          zneeded:    int
          z:          2D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> d
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          z:          2D array/list of float

</div></pre>
<a name='sub_smatrixtdevdi'></a><h3 class=pageheader><code>smatrixtdevdi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Subroutine for finding tridiagonal matrix eigenvalues/vectors with given
# indexes (in ascending order) by using the bisection and inverse iteraion.
# 
# Input parameters:
#     D       -   the main diagonal of a tridiagonal matrix.
#                 Array whose index ranges within [0..N-1].
#     E       -   the secondary diagonal of a tridiagonal matrix.
#                 Array whose index ranges within [0..N-2].
#     N       -   size of matrix. N&gt;=0.
#     ZNeeded -   flag controlling whether the eigenvectors are needed or not.
#                 If ZNeeded is equal to:
#                  * 0, the eigenvectors are not needed;
#                  * 1, the eigenvectors of a tridiagonal matrix are multiplied
#                    by the square matrix Z. It is used if the
#                    tridiagonal matrix is obtained by the similarity transformation
#                    of a symmetric matrix.
#                  * 2, the eigenvectors of a tridiagonal matrix replace
#                    matrix Z.
#     I1, I2  -   index interval for searching (from I1 to I2).
#                 0 &lt;= I1 &lt;= I2 &lt;= N-1.
#     Z       -   if ZNeeded is equal to:
#                  * 0, Z isn't used and remains unchanged;
#                  * 1, Z contains the square matrix (array whose indexes range within [0..N-1, 0..N-1])
#                    which reduces the given symmetric matrix to  tridiagonal form;
#                  * 2, Z isn't used (but changed on the exit).
# 
# Output parameters:
#     D       -   array of the eigenvalues found.
#                 Array whose index ranges within [0..I2-I1].
#     Z       -   if ZNeeded is equal to:
#                  * 0, doesn't contain any information;
#                  * 1, contains the product of a given NxN matrix Z (from the left) and
#                    Nx(I2-I1) matrix of the eigenvectors found (from the right).
#                    Array whose indexes range within [0..N-1, 0..I2-I1].
#                  * 2, contains the matrix of the eigenvalues found.
#                    Array whose indexes range within [0..N-1, 0..I2-I1].
# 
# 
# Result:
# 
#     True, if successful. In that case, D contains the eigenvalues,
#     Z contains the eigenvectors (if needed).
#     It should be noted that the subroutine changes the size of arrays D and Z.
# 
#     False, if the bisection method subroutine wasn't able to find the eigenvalues
#     in the given interval or if the inverse iteration subroutine wasn't able
#     to find all the corresponding eigenvectors. In that case, the eigenvalues
#     and eigenvectors are not returned.
# 
#   -- ALGLIB --
#      Copyright 25.12.2005 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, d, z = xalglib.smatrixtdevdi(d, e, n, zneeded, i1, i2, z)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     d:          1D array/list of float
          e:          1D array/list of float
          n:          int
          zneeded:    int
          i1:         int
          i2:         int
          z:          2D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          d:          1D array/list of float
          z:          2D array/list of float

</div></pre>
<a name='sub_smatrixtdevdr'></a><h3 class=pageheader><code>smatrixtdevdr</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Subroutine for finding the tridiagonal matrix eigenvalues/vectors in a
# given half-interval (A, B] by using bisection and inverse iteration.
# 
# Input parameters:
#     D       -   the main diagonal of a tridiagonal matrix.
#                 Array whose index ranges within [0..N-1].
#     E       -   the secondary diagonal of a tridiagonal matrix.
#                 Array whose index ranges within [0..N-2].
#     N       -   size of matrix, N&gt;=0.
#     ZNeeded -   flag controlling whether the eigenvectors are needed or not.
#                 If ZNeeded is equal to:
#                  * 0, the eigenvectors are not needed;
#                  * 1, the eigenvectors of a tridiagonal matrix are multiplied
#                    by the square matrix Z. It is used if the tridiagonal
#                    matrix is obtained by the similarity transformation
#                    of a symmetric matrix.
#                  * 2, the eigenvectors of a tridiagonal matrix replace matrix Z.
#     A, B    -   half-interval (A, B] to search eigenvalues in.
#     Z       -   if ZNeeded is equal to:
#                  * 0, Z isn't used and remains unchanged;
#                  * 1, Z contains the square matrix (array whose indexes range
#                    within [0..N-1, 0..N-1]) which reduces the given symmetric
#                    matrix to tridiagonal form;
#                  * 2, Z isn't used (but changed on the exit).
# 
# Output parameters:
#     D       -   array of the eigenvalues found.
#                 Array whose index ranges within [0..M-1].
#     M       -   number of eigenvalues found in the given half-interval (M&gt;=0).
#     Z       -   if ZNeeded is equal to:
#                  * 0, doesn't contain any information;
#                  * 1, contains the product of a given NxN matrix Z (from the
#                    left) and NxM matrix of the eigenvectors found (from the
#                    right). Array whose indexes range within [0..N-1, 0..M-1].
#                  * 2, contains the matrix of the eigenvectors found.
#                    Array whose indexes range within [0..N-1, 0..M-1].
# 
# Result:
# 
#     True, if successful. In that case, M contains the number of eigenvalues
#     in the given half-interval (could be equal to 0), D contains the eigenvalues,
#     Z contains the eigenvectors (if needed).
#     It should be noted that the subroutine changes the size of arrays D and Z.
# 
#     False, if the bisection method subroutine wasn't able to find the
#     eigenvalues in the given interval or if the inverse iteration subroutine
#     wasn't able to find all the corresponding eigenvectors. In that case,
#     the eigenvalues and eigenvectors are not returned, M is equal to 0.
# 
#   -- ALGLIB --
#      Copyright 31.03.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, d, m, z = xalglib.smatrixtdevdr(d, e, n, zneeded, a, b, z)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     d:          1D array/list of float
          e:          1D array/list of float
          n:          int
          zneeded:    int
          a:          float
          b:          float
          z:          2D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          d:          1D array/list of float
          m:          int
          z:          2D array/list of float

</div></pre>
<a name=unit_expintegrals></a><h2 class=pageheader><code>expintegrals</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_exponentialintegralei' class=toc>exponentialintegralei</a><br>
<a href='#sub_exponentialintegralen' class=toc>exponentialintegralen</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_exponentialintegralei'></a><h3 class=pageheader><code>exponentialintegralei</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Exponential integral Ei(x)
# 
#               x
#                -     t
#               | |   e
#    Ei(x) =   -|-   ---  dt .
#             | |     t
#              -
#             -inf
# 
# Not defined for x &lt;= 0.
# See also expn.c.
# 
# 
# 
# ACCURACY:
# 
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE       0,100       50000      8.6e-16     1.3e-16
# 
# Cephes Math Library Release 2.8:  May, 1999
# Copyright 1999 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.exponentialintegralei(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_exponentialintegralen'></a><h3 class=pageheader><code>exponentialintegralen</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Exponential integral En(x)
# 
# Evaluates the exponential integral
# 
#                 inf.
#                   -
#                  | |   -xt
#                  |    e
#      E (x)  =    |    ----  dt.
#       n          |      n
#                | |     t
#                 -
#                  1
# 
# 
# Both n and x must be nonnegative.
# 
# The routine employs either a power series, a continued
# fraction, or an asymptotic formula depending on the
# relative values of n and x.
# 
# ACCURACY:
# 
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE      0, 30       10000       1.7e-15     3.6e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1985, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.exponentialintegralen(x, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_fdistr></a><h2 class=pageheader><code>fdistr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_fcdistribution' class=toc>fcdistribution</a><br>
<a href='#sub_fdistribution' class=toc>fdistribution</a><br>
<a href='#sub_invfdistribution' class=toc>invfdistribution</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_fcdistribution'></a><h3 class=pageheader><code>fcdistribution</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Complemented F distribution
# 
# Returns the area from x to infinity under the F density
# function (also known as Snedcor's density or the
# variance ratio density).
# 
# 
#                      inf.
#                       -
#              1       | |  a-1      b-1
# 1-P(x)  =  ------    |   t    (1-t)    dt
#            B(a,b)  | |
#                     -
#                      x
# 
# 
# The incomplete beta integral is used, according to the
# formula
# 
# P(x) = incbet( df2/2, df1/2, (df2/(df2 + df1*x) ).
# 
# 
# ACCURACY:
# 
# Tested at random points (a,b,x) in the indicated intervals.
#                x     a,b                     Relative error:
# arithmetic  domain  domain     # trials      peak         rms
#    IEEE      0,1    1,100       100000      3.7e-14     5.9e-16
#    IEEE      1,5    1,100       100000      8.0e-15     1.6e-15
#    IEEE      0,1    1,10000     100000      1.8e-11     3.5e-13
#    IEEE      1,5    1,10000     100000      2.0e-11     3.0e-12
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.fcdistribution(a, b, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          int
          b:          int
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_fdistribution'></a><h3 class=pageheader><code>fdistribution</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# F distribution
# 
# Returns the area from zero to x under the F density
# function (also known as Snedcor's density or the
# variance ratio density).  This is the density
# of x = (u1/df1)/(u2/df2), where u1 and u2 are random
# variables having Chi square distributions with df1
# and df2 degrees of freedom, respectively.
# The incomplete beta integral is used, according to the
# formula
# 
# P(x) = incbet( df1/2, df2/2, (df1*x/(df2 + df1*x) ).
# 
# 
# The arguments a and b are greater than zero, and x is
# nonnegative.
# 
# ACCURACY:
# 
# Tested at random points (a,b,x).
# 
#                x     a,b                     Relative error:
# arithmetic  domain  domain     # trials      peak         rms
#    IEEE      0,1    0,100       100000      9.8e-15     1.7e-15
#    IEEE      1,5    0,100       100000      6.5e-15     3.5e-16
#    IEEE      0,1    1,10000     100000      2.2e-11     3.3e-12
#    IEEE      1,5    1,10000     100000      1.1e-11     1.7e-13
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.fdistribution(a, b, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          int
          b:          int
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_invfdistribution'></a><h3 class=pageheader><code>invfdistribution</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inverse of complemented F distribution
# 
# Finds the F density argument x such that the integral
# from x to infinity of the F density is equal to the
# given probability p.
# 
# This is accomplished using the inverse beta integral
# function and the relations
# 
#      z = incbi( df2/2, df1/2, p )
#      x = df2 (1-z) / (df1 z).
# 
# Note: the following relations hold for the inverse of
# the uncomplemented F distribution:
# 
#      z = incbi( df1/2, df2/2, p )
#      x = df2 z / (df1 (1-z)).
# 
# ACCURACY:
# 
# Tested at random points (a,b,p).
# 
#              a,b                     Relative error:
# arithmetic  domain     # trials      peak         rms
#  For p between .001 and 1:
#    IEEE     1,100       100000      8.3e-15     4.7e-16
#    IEEE     1,10000     100000      2.1e-11     1.4e-13
#  For p between 10^-6 and 10^-3:
#    IEEE     1,100        50000      1.3e-12     8.4e-15
#    IEEE     1,10000      50000      3.0e-12     4.8e-14
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.invfdistribution(a, b, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          int
          b:          int
          y:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_fft></a><h2 class=pageheader><code>fft</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_fftc1d' class=toc>fftc1d</a><br>
<a href='#sub_fftc1dinv' class=toc>fftc1dinv</a><br>
<a href='#sub_fftr1d' class=toc>fftr1d</a><br>
<a href='#sub_fftr1dbuf' class=toc>fftr1dbuf</a><br>
<a href='#sub_fftr1dinv' class=toc>fftr1dinv</a><br>
<a href='#sub_fftr1dinvbuf' class=toc>fftr1dinvbuf</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_fftc1d'></a><h3 class=pageheader><code>fftc1d</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional complex FFT.
# 
# Array size N may be arbitrary number (composite or prime).  Composite  N's
# are handled with cache-oblivious variation of  a  Cooley-Tukey  algorithm.
# Small prime-factors are transformed using hard coded  codelets (similar to
# FFTW codelets, but without low-level  optimization),  large  prime-factors
# are handled with Bluestein's algorithm.
# 
# Fastests transforms are for smooth N's (prime factors are 2, 3,  5  only),
# most fast for powers of 2. When N have prime factors  larger  than  these,
# but orders of magnitude smaller than N, computations will be about 4 times
# slower than for nearby highly composite N's. When N itself is prime, speed
# will be 6 times lower.
# 
# Algorithm has O(N*logN) complexity for any N (composite or prime).
# 
# INPUT PARAMETERS
#     A   -   array[0..N-1] - complex function to be transformed
#     N   -   problem size
# 
# OUTPUT PARAMETERS
#     A   -   DFT of a input array, array[0..N-1]
#             A_out[j] = SUM(A_in[k]*exp(-2*pi*sqrt(-1)*j*k/N), k = 0..N-1)
# 
# 
#   -- ALGLIB --
#      Copyright 29.05.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.fftc1d(a, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.fftc1d(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of complex
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_fftc1dinv'></a><h3 class=pageheader><code>fftc1dinv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional complex inverse FFT.
# 
# Array size N may be arbitrary number (composite or prime).  Algorithm  has
# O(N*logN) complexity for any N (composite or prime).
# 
# See FFTC1D() description for more information about algorithm performance.
# 
# INPUT PARAMETERS
#     A   -   array[0..N-1] - complex array to be transformed
#     N   -   problem size
# 
# OUTPUT PARAMETERS
#     A   -   inverse DFT of a input array, array[0..N-1]
#             A_out[j] = SUM(A_in[k]/N*exp(+2*pi*sqrt(-1)*j*k/N), k = 0..N-1)
# 
# 
#   -- ALGLIB --
#      Copyright 29.05.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.fftc1dinv(a, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.fftc1dinv(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of complex
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_fftr1d'></a><h3 class=pageheader><code>fftr1d</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional real FFT.
# 
# Algorithm has O(N*logN) complexity for any N (composite or prime).
# 
# INPUT PARAMETERS
#     A   -   array[0..N-1] - real function to be transformed
#     N   -   problem size
# 
# OUTPUT PARAMETERS
#     F   -   DFT of a input array, array[0..N-1]
#             F[j] = SUM(A[k]*exp(-2*pi*sqrt(-1)*j*k/N), k = 0..N-1)
# 
# NOTE: there is a buffered version  of  this  function, FFTR1DBuf(),  which
#       reuses memory previously allocated for A as much as possible.
# 
# NOTE:
#     F[] satisfies symmetry property F[k] = conj(F[N-k]),  so just one half
# of  array  is  usually needed. But for convinience subroutine returns full
# complex array (with frequencies above N/2), so its result may be  used  by
# other FFT-related subroutines.
# 
# 
#   -- ALGLIB --
#      Copyright 01.06.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   f = xalglib.fftr1d(a, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   f = xalglib.fftr1d(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  f:          1D array/list of complex

</div></pre>
<a name='sub_fftr1dbuf'></a><h3 class=pageheader><code>fftr1dbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional real FFT, a buffered function which does not reallocate  F[]
# if its length is enough to store the result  (i.e.  it  reuses  previously
# allocated memory as much as possible).
# 
#   -- ALGLIB --
#      Copyright 01.06.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   f = xalglib.fftr1dbuf(a, n, f)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   f = xalglib.fftr1dbuf(a, f)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          n:          int
          f:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  f:          1D array/list of complex

</div></pre>
<a name='sub_fftr1dinv'></a><h3 class=pageheader><code>fftr1dinv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional real inverse FFT.
# 
# Algorithm has O(N*logN) complexity for any N (composite or prime).
# 
# INPUT PARAMETERS
#     F   -   array[0..floor(N/2)] - frequencies from forward real FFT
#     N   -   problem size
# 
# OUTPUT PARAMETERS
#     A   -   inverse DFT of a input array, array[0..N-1]
# 
# NOTE: there is a buffered version of this function, FFTR1DInvBuf(),  which
#       reuses memory previously allocated for A as much as possible.
# 
# NOTE:
#     F[] should satisfy symmetry property F[k] = conj(F[N-k]), so just  one
# half of frequencies array is needed - elements from 0 to floor(N/2).  F[0]
# is ALWAYS real. If N is even F[floor(N/2)] is real too. If N is odd,  then
# F[floor(N/2)] has no special properties.
# 
# Relying on properties noted above, FFTR1DInv subroutine uses only elements
# from 0th to floor(N/2)-th. It ignores imaginary part of F[0],  and in case
# N is even it ignores imaginary part of F[floor(N/2)] too.
# 
# When you call this function using full arguments list - &quot;FFTR1DInv(F,N,A)&quot;
# - you can pass either either frequencies array with N elements or  reduced
# array with roughly N/2 elements - subroutine will  successfully  transform
# both.
# 
# If you call this function using reduced arguments list -  &quot;FFTR1DInv(F,A)&quot;
# - you must pass FULL array with N elements (although higher  N/2 are still
# not used) because array size is used to automatically determine FFT length
# 
#   -- ALGLIB --
#      Copyright 01.06.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.fftr1dinv(f, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.fftr1dinv(f)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     f:          1D array/list of complex
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          1D array/list of float

</div></pre>
<a name='sub_fftr1dinvbuf'></a><h3 class=pageheader><code>fftr1dinvbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional real inverse FFT, buffered version, which does not reallocate
# A[] if its length is enough to store the result (i.e. it reuses previously
# allocated memory as much as possible).
# 
#   -- ALGLIB --
#      Copyright 01.06.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.fftr1dinvbuf(f, n, a)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.fftr1dinvbuf(f, a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     f:          1D array/list of complex
          n:          int
          a:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          1D array/list of float

</div></pre>
<a name=unit_fht></a><h2 class=pageheader><code>fht</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_fhtr1d' class=toc>fhtr1d</a><br>
<a href='#sub_fhtr1dinv' class=toc>fhtr1dinv</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_fhtr1d'></a><h3 class=pageheader><code>fhtr1d</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional Fast Hartley Transform.
# 
# Algorithm has O(N*logN) complexity for any N (composite or prime).
# 
# INPUT PARAMETERS
#     A   -   array[0..N-1] - real function to be transformed
#     N   -   problem size
# 
# OUTPUT PARAMETERS
#     A   -   FHT of a input array, array[0..N-1],
#             A_out[k] = sum(A_in[j]*(cos(2*pi*j*k/N)+sin(2*pi*j*k/N)), j=0..N-1)
# 
# 
#   -- ALGLIB --
#      Copyright 04.06.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.fhtr1d(a, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_fhtr1dinv'></a><h3 class=pageheader><code>fhtr1dinv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 1-dimensional inverse FHT.
# 
# Algorithm has O(N*logN) complexity for any N (composite or prime).
# 
# INPUT PARAMETERS
#     A   -   array[0..N-1] - complex array to be transformed
#     N   -   problem size
# 
# OUTPUT PARAMETERS
#     A   -   inverse FHT of a input array, array[0..N-1]
# 
# 
#   -- ALGLIB --
#      Copyright 29.05.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.fhtr1dinv(a, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_filters></a><h2 class=pageheader><code>filters</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_filterema' class=toc>filterema</a><br>
<a href='#sub_filterlrma' class=toc>filterlrma</a><br>
<a href='#sub_filtersma' class=toc>filtersma</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_filterema'></a><h3 class=pageheader><code>filterema</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Filters: exponential moving averages.
# 
# This filter replaces array by results of EMA(alpha) filter. EMA(alpha) is
# defined as filter which replaces X[] by S[]:
#     S[0] = X[0]
#     S[t] = alpha*X[t] + (1-alpha)*S[t-1]
# 
# INPUT PARAMETERS:
#     X           -   array[N], array to process. It can be larger than N,
#                     in this case only first N points are processed.
#     N           -   points count, N&gt;=0
#     alpha       -   0&lt;alpha&lt;=1, smoothing parameter.
# 
# OUTPUT PARAMETERS:
#     X           -   array, whose first N elements were processed
#                     with EMA(alpha)
# 
# NOTE 1: this function uses efficient in-place  algorithm  which  does not
#         allocate temporary arrays.
# 
# NOTE 2: this algorithm uses BOTH previous points and  current  one,  i.e.
#         new value of X[i] depends on BOTH previous point and X[i] itself.
# 
# NOTE 3: technical analytis users quite often work  with  EMA  coefficient
#         expressed in DAYS instead of fractions. If you want to  calculate
#         EMA(N), where N is a number of days, you can use alpha=2/(N+1).
# 
#   -- ALGLIB --
#      Copyright 25.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.filterema(x, n, alpha)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.filterema(x, alpha)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          alpha:      float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> x
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_filterlrma'></a><h3 class=pageheader><code>filterlrma</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Filters: linear regression moving averages.
# 
# This filter replaces array by results of LRMA(K) filter.
# 
# LRMA(K) is defined as filter which, for each data  point,  builds  linear
# regression  model  using  K  prevous  points (point itself is included in
# these K points) and calculates value of this linear model at the point in
# question.
# 
# INPUT PARAMETERS:
#     X           -   array[N], array to process. It can be larger than N,
#                     in this case only first N points are processed.
#     N           -   points count, N&gt;=0
#     K           -   K&gt;=1 (K can be larger than N ,  such  cases  will  be
#                     correctly handled). Window width. K=1 corresponds  to
#                     identity transformation (nothing changes).
# 
# OUTPUT PARAMETERS:
#     X           -   array, whose first N elements were processed with LRMA(K)
# 
# NOTE 1: this function uses efficient in-place  algorithm  which  does not
#         allocate temporary arrays.
# 
# NOTE 2: this algorithm makes only one pass through array and uses running
#         sum  to speed-up calculation of the averages. Additional measures
#         are taken to ensure that running sum on a long sequence  of  zero
#         elements will be correctly reset to zero even in the presence  of
#         round-off error.
# 
# NOTE 3: this  is  unsymmetric version of the algorithm,  which  does  NOT
#         averages points after the current one. Only X[i], X[i-1], ... are
#         used when calculating new value of X[i]. We should also note that
#         this algorithm uses BOTH previous points and  current  one,  i.e.
#         new value of X[i] depends on BOTH previous point and X[i] itself.
# 
#   -- ALGLIB --
#      Copyright 25.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.filterlrma(x, n, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.filterlrma(x, k)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> x
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_filtersma'></a><h3 class=pageheader><code>filtersma</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Filters: simple moving averages (unsymmetric).
# 
# This filter replaces array by results of SMA(K) filter. SMA(K) is defined
# as filter which averages at most K previous points (previous - not points
# AROUND central point) - or less, in case of the first K-1 points.
# 
# INPUT PARAMETERS:
#     X           -   array[N], array to process. It can be larger than N,
#                     in this case only first N points are processed.
#     N           -   points count, N&gt;=0
#     K           -   K&gt;=1 (K can be larger than N ,  such  cases  will  be
#                     correctly handled). Window width. K=1 corresponds  to
#                     identity transformation (nothing changes).
# 
# OUTPUT PARAMETERS:
#     X           -   array, whose first N elements were processed with SMA(K)
# 
# NOTE 1: this function uses efficient in-place  algorithm  which  does not
#         allocate temporary arrays.
# 
# NOTE 2: this algorithm makes only one pass through array and uses running
#         sum  to speed-up calculation of the averages. Additional measures
#         are taken to ensure that running sum on a long sequence  of  zero
#         elements will be correctly reset to zero even in the presence  of
#         round-off error.
# 
# NOTE 3: this  is  unsymmetric version of the algorithm,  which  does  NOT
#         averages points after the current one. Only X[i], X[i-1], ... are
#         used when calculating new value of X[i]. We should also note that
#         this algorithm uses BOTH previous points and  current  one,  i.e.
#         new value of X[i] depends on BOTH previous point and X[i] itself.
# 
#   -- ALGLIB --
#      Copyright 25.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.filtersma(x, n, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.filtersma(x, k)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> x
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_fitsphere></a><h2 class=pageheader><code>fitsphere</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_fitspherels' class=toc>fitspherels</a><br>
<a href='#sub_fitspheremc' class=toc>fitspheremc</a><br>
<a href='#sub_fitspheremi' class=toc>fitspheremi</a><br>
<a href='#sub_fitspheremz' class=toc>fitspheremz</a><br>
<a href='#sub_fitspherex' class=toc>fitspherex</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_fitspherels'></a><h3 class=pageheader><code>fitspherels</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Fits least squares (LS) circle (or NX-dimensional sphere) to data  (a  set
# of points in NX-dimensional space).
# 
# Least squares circle minimizes sum of squared deviations between distances
# from points to the center and  some  &quot;candidate&quot;  radius,  which  is  also
# fitted to the data.
# 
# INPUT PARAMETERS:
#     XY      -   array[NPoints,NX] (or larger), contains dataset.
#                 One row = one point in NX-dimensional space.
#     NPoints -   dataset size, NPoints&gt;0
#     NX      -   space dimensionality, NX&gt;0 (1, 2, 3, 4, 5 and so on)
# 
# OUTPUT PARAMETERS:
#     CX      -   central point for a sphere
#     R       -   radius
# 
#   -- ALGLIB --
#      Copyright 07.05.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   cx, r = xalglib.fitspherels(xy, npoints, nx)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nx:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  cx:         1D array/list of float
          r:          float

</div></pre>
<a name='sub_fitspheremc'></a><h3 class=pageheader><code>fitspheremc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Fits minimum circumscribed (MC) circle (or NX-dimensional sphere) to  data
# (a set of points in NX-dimensional space).
# 
# INPUT PARAMETERS:
#     XY      -   array[NPoints,NX] (or larger), contains dataset.
#                 One row = one point in NX-dimensional space.
#     NPoints -   dataset size, NPoints&gt;0
#     NX      -   space dimensionality, NX&gt;0 (1, 2, 3, 4, 5 and so on)
# 
# OUTPUT PARAMETERS:
#     CX      -   central point for a sphere
#     RHi     -   radius
# 
# NOTE: this function is an easy-to-use wrapper around more powerful &quot;expert&quot;
#       function fitspherex().
# 
#       This  wrapper  is optimized  for  ease of use and stability - at the
#       cost of somewhat lower  performance  (we  have  to  use  very  tight
#       stopping criteria for inner optimizer because we want to  make  sure
#       that it will converge on any dataset).
# 
#       If you are ready to experiment with settings of  &quot;expert&quot;  function,
#       you can achieve ~2-4x speedup over standard &quot;bulletproof&quot; settings.
# 
# 
#   -- ALGLIB --
#      Copyright 14.04.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   cx, rhi = xalglib.fitspheremc(xy, npoints, nx)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nx:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  cx:         1D array/list of float
          rhi:        float

</div></pre>
<a name='sub_fitspheremi'></a><h3 class=pageheader><code>fitspheremi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Fits maximum inscribed circle (or NX-dimensional sphere) to data (a set of
# points in NX-dimensional space).
# 
# INPUT PARAMETERS:
#     XY      -   array[NPoints,NX] (or larger), contains dataset.
#                 One row = one point in NX-dimensional space.
#     NPoints -   dataset size, NPoints&gt;0
#     NX      -   space dimensionality, NX&gt;0 (1, 2, 3, 4, 5 and so on)
# 
# OUTPUT PARAMETERS:
#     CX      -   central point for a sphere
#     RLo     -   radius
# 
# NOTE: this function is an easy-to-use wrapper around more powerful &quot;expert&quot;
#       function fitspherex().
# 
#       This  wrapper  is optimized  for  ease of use and stability - at the
#       cost of somewhat lower  performance  (we  have  to  use  very  tight
#       stopping criteria for inner optimizer because we want to  make  sure
#       that it will converge on any dataset).
# 
#       If you are ready to experiment with settings of  &quot;expert&quot;  function,
#       you can achieve ~2-4x speedup over standard &quot;bulletproof&quot; settings.
# 
# 
#   -- ALGLIB --
#      Copyright 14.04.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   cx, rlo = xalglib.fitspheremi(xy, npoints, nx)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nx:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  cx:         1D array/list of float
          rlo:        float

</div></pre>
<a name='sub_fitspheremz'></a><h3 class=pageheader><code>fitspheremz</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Fits minimum zone circle (or NX-dimensional sphere)  to  data  (a  set  of
# points in NX-dimensional space).
# 
# INPUT PARAMETERS:
#     XY      -   array[NPoints,NX] (or larger), contains dataset.
#                 One row = one point in NX-dimensional space.
#     NPoints -   dataset size, NPoints&gt;0
#     NX      -   space dimensionality, NX&gt;0 (1, 2, 3, 4, 5 and so on)
# 
# OUTPUT PARAMETERS:
#     CX      -   central point for a sphere
#     RLo     -   radius of inscribed circle
#     RHo     -   radius of circumscribed circle
# 
# NOTE: this function is an easy-to-use wrapper around more powerful &quot;expert&quot;
#       function fitspherex().
# 
#       This  wrapper  is optimized  for  ease of use and stability - at the
#       cost of somewhat lower  performance  (we  have  to  use  very  tight
#       stopping criteria for inner optimizer because we want to  make  sure
#       that it will converge on any dataset).
# 
#       If you are ready to experiment with settings of  &quot;expert&quot;  function,
#       you can achieve ~2-4x speedup over standard &quot;bulletproof&quot; settings.
# 
# 
#   -- ALGLIB --
#      Copyright 14.04.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   cx, rlo, rhi = xalglib.fitspheremz(xy, npoints, nx)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nx:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  cx:         1D array/list of float
          rlo:        float
          rhi:        float

</div></pre>
<a name='sub_fitspherex'></a><h3 class=pageheader><code>fitspherex</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Fitting minimum circumscribed, maximum inscribed or minimum  zone  circles
# (or NX-dimensional spheres)  to  data  (a  set of points in NX-dimensional
# space).
# 
# This  is  expert  function  which  allows  to  tweak  many  parameters  of
# underlying nonlinear solver:
# * stopping criteria for inner iterations
# * number of outer iterations
# 
# You may tweak all these parameters or only some  of  them,  leaving  other
# ones at their default state - just specify zero  value,  and  solver  will
# fill it with appropriate default one.
# 
# These comments also include some discussion of  approach  used  to  handle
# such unusual fitting problem,  its  stability,  drawbacks  of  alternative
# methods, and convergence properties.
# 
# INPUT PARAMETERS:
#     XY      -   array[NPoints,NX] (or larger), contains dataset.
#                 One row = one point in NX-dimensional space.
#     NPoints -   dataset size, NPoints&gt;0
#     NX      -   space dimensionality, NX&gt;0 (1, 2, 3, 4, 5 and so on)
#     ProblemType-used to encode problem type:
#                 * 0 for least squares circle
#                 * 1 for minimum circumscribed circle/sphere fitting (MC)
#                 * 2 for  maximum inscribed circle/sphere fitting (MI)
#                 * 3 for minimum zone circle fitting (difference between
#                     Rhi and Rlo is minimized), denoted as MZ
#     EpsX    -   stopping condition for NLC optimizer:
#                 * must be non-negative
#                 * use 0 to choose default value (1.0E-12 is used by default)
#                 * you may specify larger values, up to 1.0E-6, if you want
#                   to   speed-up   solver;   NLC   solver  performs several
#                   preconditioned  outer  iterations,   so   final   result
#                   typically has precision much better than EpsX.
#     AULIts  -   number of outer iterations performed by NLC optimizer:
#                 * must be non-negative
#                 * use 0 to choose default value (20 is used by default)
#                 * you may specify values smaller than 20 if you want to
#                   speed up solver; 10 often results in good combination of
#                   precision and speed; sometimes you may get good results
#                   with just 6 outer iterations.
#                 Ignored for ProblemType=0.
# 
# OUTPUT PARAMETERS:
#     CX      -   central point for a sphere
#     RLo     -   radius:
#                 * for ProblemType=2,3, radius of the inscribed sphere
#                 * for ProblemType=0 - radius of the least squares sphere
#                 * for ProblemType=1 - zero
#     RHo     -   radius:
#                 * for ProblemType=1,3, radius of the circumscribed sphere
#                 * for ProblemType=0 - radius of the least squares sphere
#                 * for ProblemType=2 - zero
# 
# NOTE: ON THE UNIQUENESS OF SOLUTIONS
# 
# ALGLIB provides solution to several related circle fitting  problems:   MC
# (minimum circumscribed), MI (maximum inscribed)   and   MZ  (minimum zone)
# fitting, LS (least squares) fitting.
# 
# It  is  important  to  note  that  among these problems only MC and LS are
# convex and have unique solution independently from starting point.
# 
# As  for MI,  it  may (or  may  not, depending on dataset properties)  have
# multiple solutions, and it always  has  one degenerate solution C=infinity
# which corresponds to infinitely large radius. Thus, there are no guarantees
# that solution to  MI returned by this solver will be the best one (and  no
# one can provide you with such guarantee because problem is  NP-hard).  The
# only guarantee you have is that this solution is locally optimal, i.e.  it
# can not be improved by infinitesimally small tweaks in the parameters.
# 
# It  is  also  possible  to &quot;run away&quot; to infinity when  started  from  bad
# initial point located outside of point cloud (or when point cloud does not
# span entire circumference/surface of the sphere).
# 
# Finally,  MZ (minimum zone circle) stands somewhere between MC  and  MI in
# stability. It is somewhat regularized by &quot;circumscribed&quot; term of the merit
# function; however, solutions to  MZ may be non-unique, and in some unlucky
# cases it is also possible to &quot;run away to infinity&quot;.
# 
# 
# NOTE: ON THE NONLINEARLY CONSTRAINED PROGRAMMING APPROACH
# 
# The problem formulation for MC  (minimum circumscribed   circle;  for  the
# sake of simplicity we omit MZ and MI here) is:
# 
#         [     [         ]2 ]
#     min [ max [ XY[i]-C ]  ]
#      C  [  i  [         ]  ]
# 
# i.e. it is unconstrained nonsmooth optimization problem of finding  &quot;best&quot;
# central point, with radius R being unambiguously  determined  from  C.  In
# order to move away from non-smoothness we use following reformulation:
# 
#         [   ]                  [         ]2
#     min [ R ] subject to R&gt;=0, [ XY[i]-C ]  &lt;= R^2
#     C,R [   ]                  [         ]
# 
# i.e. it becomes smooth quadratically constrained optimization problem with
# linear target function. Such problem statement is 100% equivalent  to  the
# original nonsmooth one, but much easier  to  approach.  We solve  it  with
# MinNLC solver provided by ALGLIB.
# 
# 
# NOTE: ON INSTABILITY OF SEQUENTIAL LINEARIZATION APPROACH
# 
# ALGLIB  has  nonlinearly  constrained  solver which proved to be stable on
# such problems. However, some authors proposed to linearize constraints  in
# the vicinity of current approximation (Ci,Ri) and to get next  approximate
# solution (Ci+1,Ri+1) as solution to linear programming problem. Obviously,
# LP problems are easier than nonlinearly constrained ones.
# 
# Indeed,  such approach  to   MC/MI/MZ   resulted   in  ~10-20x increase in
# performance (when compared with NLC solver). However, it turned  out  that
# in some cases linearized model fails to predict correct direction for next
# step and tells us that we converged to solution even when we are still 2-4
# digits of precision away from it.
# 
# It is important that it is not failure of LP solver - it is failure of the
# linear model;  even  when  solved  exactly,  it  fails  to  handle  subtle
# nonlinearities which arise near the solution. We validated it by comparing
# results returned by ALGLIB linear solver with that of MATLAB.
# 
# In our experiments with linearization:
# * MC failed most often, at both realistic and synthetic datasets
# * MI sometimes failed, but sometimes succeeded
# * MZ often  succeeded; our guess is that presence of two independent  sets
#   of constraints (one set for Rlo and another one for Rhi) and  two  terms
#   in the target function (Rlo and Rhi) regularizes task,  so  when  linear
#   model fails to handle nonlinearities from Rlo, it uses  Rhi  as  a  hint
#   (and vice versa).
# 
# Because linearization approach failed to achieve stable results, we do not
# include it in ALGLIB.
# 
# 
#   -- ALGLIB --
#      Copyright 14.04.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   cx, rlo, rhi = xalglib.fitspherex(xy, npoints, nx, problemtype, epsx, aulits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nx:         int
          problemtype: int
          epsx:       float
          aulits:     int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  cx:         1D array/list of float
          rlo:        float
          rhi:        float

</div></pre>
<a name=unit_fresnel></a><h2 class=pageheader><code>fresnel</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_fresnelintegral' class=toc>fresnelintegral</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_fresnelintegral'></a><h3 class=pageheader><code>fresnelintegral</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Fresnel integral
# 
# Evaluates the Fresnel integrals
# 
#           x
#           -
#          | |
# C(x) =   |   cos(pi/2 t**2) dt,
#        | |
#         -
#          0
# 
#           x
#           -
#          | |
# S(x) =   |   sin(pi/2 t**2) dt.
#        | |
#         -
#          0
# 
# 
# The integrals are evaluated by a power series for x &lt; 1.
# For x &gt;= 1 auxiliary functions f(x) and g(x) are employed
# such that
# 
# C(x) = 0.5 + f(x) sin( pi/2 x**2 ) - g(x) cos( pi/2 x**2 )
# S(x) = 0.5 - f(x) cos( pi/2 x**2 ) - g(x) sin( pi/2 x**2 )
# 
# 
# 
# ACCURACY:
# 
#  Relative error.
# 
# Arithmetic  function   domain     # trials      peak         rms
#   IEEE       S(x)      0, 10       10000       2.0e-15     3.2e-16
#   IEEE       C(x)      0, 10       10000       1.8e-15     3.3e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c, s = xalglib.fresnelintegral(x, c, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
          c:          float
          s:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          float
          s:          float

</div></pre>
<a name=unit_gammafunc></a><h2 class=pageheader><code>gammafunc</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_gammafunction' class=toc>gammafunction</a><br>
<a href='#sub_lngamma' class=toc>lngamma</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_gammafunction'></a><h3 class=pageheader><code>gammafunction</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Gamma function
# 
# Input parameters:
#     X   -   argument
# 
# Domain:
#     0 &lt; X &lt; 171.6
#     -170 &lt; X &lt; 0, X is not an integer.
# 
# Relative error:
#  arithmetic   domain     # trials      peak         rms
#     IEEE    -170,-33      20000       2.3e-15     3.3e-16
#     IEEE     -33,  33     20000       9.4e-16     2.2e-16
#     IEEE      33, 171.6   20000       2.3e-15     3.2e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Original copyright 1984, 1987, 1989, 1992, 2000 by Stephen L. Moshier
# Translated to AlgoPascal by Bochkanov Sergey (2005, 2006, 2007).
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.gammafunction(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_lngamma'></a><h3 class=pageheader><code>lngamma</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Natural logarithm of gamma function
# 
# Input parameters:
#     X       -   argument
# 
# Result:
#     logarithm of the absolute value of the Gamma(X).
# 
# Output parameters:
#     SgnGam  -   sign(Gamma(X))
# 
# Domain:
#     0 &lt; X &lt; 2.55e305
#     -2.55e305 &lt; X &lt; 0, X is not an integer.
# 
# ACCURACY:
# arithmetic      domain        # trials     peak         rms
#    IEEE    0, 3                 28000     5.4e-16     1.1e-16
#    IEEE    2.718, 2.556e305     40000     3.5e-16     8.3e-17
# The error criterion was relative when the function magnitude
# was greater than one but absolute when it was less than one.
# 
# The following test used the relative error criterion, though
# at certain points the relative error could be much higher than
# indicated.
#    IEEE    -200, -4             10000     4.8e-16     1.3e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1989, 1992, 2000 by Stephen L. Moshier
# Translated to AlgoPascal by Bochkanov Sergey (2005, 2006, 2007).
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, sgngam = xalglib.lngamma(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float
          sgngam:     float

</div></pre>
<a name=unit_gkq></a><h2 class=pageheader><code>gkq</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_gkqgenerategaussjacobi' class=toc>gkqgenerategaussjacobi</a><br>
<a href='#sub_gkqgenerategausslegendre' class=toc>gkqgenerategausslegendre</a><br>
<a href='#sub_gkqgeneraterec' class=toc>gkqgeneraterec</a><br>
<a href='#sub_gkqlegendrecalc' class=toc>gkqlegendrecalc</a><br>
<a href='#sub_gkqlegendretbl' class=toc>gkqlegendretbl</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_gkqgenerategaussjacobi'></a><h3 class=pageheader><code>gkqgenerategaussjacobi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Returns   Gauss   and   Gauss-Kronrod   nodes/weights   for   Gauss-Jacobi
# quadrature on [-1,1] with weight function
# 
#     W(x)=Power(1-x,Alpha)*Power(1+x,Beta).
# 
# INPUT PARAMETERS:
#     N           -   number of Kronrod nodes, must be odd number, &gt;=3.
#     Alpha       -   power-law coefficient, Alpha&gt;-1
#     Beta        -   power-law coefficient, Beta&gt;-1
# 
# OUTPUT PARAMETERS:
#     Info        -   error code:
#                     * -5    no real and positive Gauss-Kronrod formula can
#                             be created for such a weight function  with  a
#                             given number of nodes.
#                     * -4    an  error  was   detected   when   calculating
#                             weights/nodes. Alpha or  Beta  are  too  close
#                             to -1 to obtain weights/nodes with high enough
#                             accuracy, or, may be, N is too large.  Try  to
#                             use multiple precision version.
#                     * -3    internal eigenproblem solver hasn't converged
#                     * -1    incorrect N was passed
#                     * +1    OK
#                     * +2    OK, but quadrature rule have exterior  nodes,
#                             x[0]&lt;-1 or x[n-1]&gt;+1
#     X           -   array[0..N-1] - array of quadrature nodes, ordered in
#                     ascending order.
#     WKronrod    -   array[0..N-1] - Kronrod weights
#     WGauss      -   array[0..N-1] - Gauss weights (interleaved with zeros
#                     corresponding to extended Kronrod nodes).
# 
# 
#   -- ALGLIB --
#      Copyright 12.05.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, x, wkronrod, wgauss = xalglib.gkqgenerategaussjacobi(n, alpha, beta)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          alpha:      float
          beta:       float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          x:          1D array/list of float
          wkronrod:   1D array/list of float
          wgauss:     1D array/list of float

</div></pre>
<a name='sub_gkqgenerategausslegendre'></a><h3 class=pageheader><code>gkqgenerategausslegendre</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Returns   Gauss   and   Gauss-Kronrod   nodes/weights  for  Gauss-Legendre
# quadrature with N points.
# 
# GKQLegendreCalc (calculation) or  GKQLegendreTbl  (precomputed  table)  is
# used depending on machine precision and number of nodes.
# 
# INPUT PARAMETERS:
#     N           -   number of Kronrod nodes, must be odd number, &gt;=3.
# 
# OUTPUT PARAMETERS:
#     Info        -   error code:
#                     * -4    an  error   was   detected   when  calculating
#                             weights/nodes.  N  is  too  large   to  obtain
#                             weights/nodes  with  high   enough   accuracy.
#                             Try  to   use   multiple   precision  version.
#                     * -3    internal eigenproblem solver hasn't converged
#                     * -1    incorrect N was passed
#                     * +1    OK
#     X           -   array[0..N-1] - array of quadrature nodes, ordered in
#                     ascending order.
#     WKronrod    -   array[0..N-1] - Kronrod weights
#     WGauss      -   array[0..N-1] - Gauss weights (interleaved with zeros
#                     corresponding to extended Kronrod nodes).
# 
# 
#   -- ALGLIB --
#      Copyright 12.05.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, x, wkronrod, wgauss = xalglib.gkqgenerategausslegendre(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          x:          1D array/list of float
          wkronrod:   1D array/list of float
          wgauss:     1D array/list of float

</div></pre>
<a name='sub_gkqgeneraterec'></a><h3 class=pageheader><code>gkqgeneraterec</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Computation of nodes and weights of a Gauss-Kronrod quadrature formula
# 
# The algorithm generates the N-point Gauss-Kronrod quadrature formula  with
# weight  function  given  by  coefficients  alpha  and beta of a recurrence
# relation which generates a system of orthogonal polynomials:
# 
#     P-1(x)   =  0
#     P0(x)    =  1
#     Pn+1(x)  =  (x-alpha(n))*Pn(x)  -  beta(n)*Pn-1(x)
# 
# and zero moment Mu0
# 
#     Mu0 = integral(W(x)dx,a,b)
# 
# 
# INPUT PARAMETERS:
#     Alpha       -   alpha coefficients, array[0..floor(3*K/2)].
#     Beta        -   beta coefficients,  array[0..ceil(3*K/2)].
#                     Beta[0] is not used and may be arbitrary.
#                     Beta[I]&gt;0.
#     Mu0         -   zeroth moment of the weight function.
#     N           -   number of nodes of the Gauss-Kronrod quadrature formula,
#                     N &gt;= 3,
#                     N =  2*K+1.
# 
# OUTPUT PARAMETERS:
#     Info        -   error code:
#                     * -5    no real and positive Gauss-Kronrod formula can
#                             be created for such a weight function  with  a
#                             given number of nodes.
#                     * -4    N is too large, task may be ill  conditioned -
#                             x[i]=x[i+1] found.
#                     * -3    internal eigenproblem solver hasn't converged
#                     * -2    Beta[i]&lt;=0
#                     * -1    incorrect N was passed
#                     * +1    OK
#     X           -   array[0..N-1] - array of quadrature nodes,
#                     in ascending order.
#     WKronrod    -   array[0..N-1] - Kronrod weights
#     WGauss      -   array[0..N-1] - Gauss weights (interleaved with zeros
#                     corresponding to extended Kronrod nodes).
# 
#   -- ALGLIB --
#      Copyright 08.05.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, x, wkronrod, wgauss = xalglib.gkqgeneraterec(alpha, beta, mu0, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     alpha:      1D array/list of float
          beta:       1D array/list of float
          mu0:        float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          x:          1D array/list of float
          wkronrod:   1D array/list of float
          wgauss:     1D array/list of float

</div></pre>
<a name='sub_gkqlegendrecalc'></a><h3 class=pageheader><code>gkqlegendrecalc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Returns Gauss and Gauss-Kronrod nodes for quadrature with N points.
# 
# Reduction to tridiagonal eigenproblem is used.
# 
# INPUT PARAMETERS:
#     N           -   number of Kronrod nodes, must be odd number, &gt;=3.
# 
# OUTPUT PARAMETERS:
#     Info        -   error code:
#                     * -4    an  error   was   detected   when  calculating
#                             weights/nodes.  N  is  too  large   to  obtain
#                             weights/nodes  with  high   enough   accuracy.
#                             Try  to   use   multiple   precision  version.
#                     * -3    internal eigenproblem solver hasn't converged
#                     * -1    incorrect N was passed
#                     * +1    OK
#     X           -   array[0..N-1] - array of quadrature nodes, ordered in
#                     ascending order.
#     WKronrod    -   array[0..N-1] - Kronrod weights
#     WGauss      -   array[0..N-1] - Gauss weights (interleaved with zeros
#                     corresponding to extended Kronrod nodes).
# 
#   -- ALGLIB --
#      Copyright 12.05.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, x, wkronrod, wgauss = xalglib.gkqlegendrecalc(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          x:          1D array/list of float
          wkronrod:   1D array/list of float
          wgauss:     1D array/list of float

</div></pre>
<a name='sub_gkqlegendretbl'></a><h3 class=pageheader><code>gkqlegendretbl</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Returns Gauss and Gauss-Kronrod nodes for quadrature with N  points  using
# pre-calculated table. Nodes/weights were  computed  with  accuracy  up  to
# 1.0E-32 (if MPFR version of ALGLIB is used). In standard double  precision
# accuracy reduces to something about 2.0E-16 (depending  on your compiler's
# handling of long floating point constants).
# 
# INPUT PARAMETERS:
#     N           -   number of Kronrod nodes.
#                     N can be 15, 21, 31, 41, 51, 61.
# 
# OUTPUT PARAMETERS:
#     X           -   array[0..N-1] - array of quadrature nodes, ordered in
#                     ascending order.
#     WKronrod    -   array[0..N-1] - Kronrod weights
#     WGauss      -   array[0..N-1] - Gauss weights (interleaved with zeros
#                     corresponding to extended Kronrod nodes).
# 
# 
#   -- ALGLIB --
#      Copyright 12.05.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, wkronrod, wgauss, eps = xalglib.gkqlegendretbl(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          wkronrod:   1D array/list of float
          wgauss:     1D array/list of float
          eps:        float

</div></pre>
<a name=unit_gq></a><h2 class=pageheader><code>gq</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_gqgenerategausshermite' class=toc>gqgenerategausshermite</a><br>
<a href='#sub_gqgenerategaussjacobi' class=toc>gqgenerategaussjacobi</a><br>
<a href='#sub_gqgenerategausslaguerre' class=toc>gqgenerategausslaguerre</a><br>
<a href='#sub_gqgenerategausslegendre' class=toc>gqgenerategausslegendre</a><br>
<a href='#sub_gqgenerategausslobattorec' class=toc>gqgenerategausslobattorec</a><br>
<a href='#sub_gqgenerategaussradaurec' class=toc>gqgenerategaussradaurec</a><br>
<a href='#sub_gqgeneraterec' class=toc>gqgeneraterec</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_gqgenerategausshermite'></a><h3 class=pageheader><code>gqgenerategausshermite</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Returns  nodes/weights  for  Gauss-Hermite  quadrature on (-inf,+inf) with
# weight function W(x)=Exp(-x*x)
# 
# INPUT PARAMETERS:
#     N           -   number of nodes, &gt;=1
# 
# OUTPUT PARAMETERS:
#     Info        -   error code:
#                     * -4    an  error  was   detected   when   calculating
#                             weights/nodes.  May be, N is too large. Try to
#                             use multiple precision version.
#                     * -3    internal eigenproblem solver hasn't converged
#                     * -1    incorrect N/Alpha was passed
#                     * +1    OK
#     X           -   array[0..N-1] - array of quadrature nodes,
#                     in ascending order.
#     W           -   array[0..N-1] - array of quadrature weights.
# 
# 
#   -- ALGLIB --
#      Copyright 12.05.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, x, w = xalglib.gqgenerategausshermite(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          x:          1D array/list of float
          w:          1D array/list of float

</div></pre>
<a name='sub_gqgenerategaussjacobi'></a><h3 class=pageheader><code>gqgenerategaussjacobi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Returns  nodes/weights  for  Gauss-Jacobi quadrature on [-1,1] with weight
# function W(x)=Power(1-x,Alpha)*Power(1+x,Beta).
# 
# INPUT PARAMETERS:
#     N           -   number of nodes, &gt;=1
#     Alpha       -   power-law coefficient, Alpha&gt;-1
#     Beta        -   power-law coefficient, Beta&gt;-1
# 
# OUTPUT PARAMETERS:
#     Info        -   error code:
#                     * -4    an  error  was   detected   when   calculating
#                             weights/nodes. Alpha or  Beta  are  too  close
#                             to -1 to obtain weights/nodes with high enough
#                             accuracy, or, may be, N is too large.  Try  to
#                             use multiple precision version.
#                     * -3    internal eigenproblem solver hasn't converged
#                     * -1    incorrect N/Alpha/Beta was passed
#                     * +1    OK
#     X           -   array[0..N-1] - array of quadrature nodes,
#                     in ascending order.
#     W           -   array[0..N-1] - array of quadrature weights.
# 
# 
#   -- ALGLIB --
#      Copyright 12.05.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, x, w = xalglib.gqgenerategaussjacobi(n, alpha, beta)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          alpha:      float
          beta:       float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          x:          1D array/list of float
          w:          1D array/list of float

</div></pre>
<a name='sub_gqgenerategausslaguerre'></a><h3 class=pageheader><code>gqgenerategausslaguerre</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Returns  nodes/weights  for  Gauss-Laguerre  quadrature  on  [0,+inf) with
# weight function W(x)=Power(x,Alpha)*Exp(-x)
# 
# INPUT PARAMETERS:
#     N           -   number of nodes, &gt;=1
#     Alpha       -   power-law coefficient, Alpha&gt;-1
# 
# OUTPUT PARAMETERS:
#     Info        -   error code:
#                     * -4    an  error  was   detected   when   calculating
#                             weights/nodes. Alpha is too  close  to  -1  to
#                             obtain weights/nodes with high enough accuracy
#                             or, may  be,  N  is  too  large.  Try  to  use
#                             multiple precision version.
#                     * -3    internal eigenproblem solver hasn't converged
#                     * -1    incorrect N/Alpha was passed
#                     * +1    OK
#     X           -   array[0..N-1] - array of quadrature nodes,
#                     in ascending order.
#     W           -   array[0..N-1] - array of quadrature weights.
# 
# 
#   -- ALGLIB --
#      Copyright 12.05.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, x, w = xalglib.gqgenerategausslaguerre(n, alpha)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          alpha:      float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          x:          1D array/list of float
          w:          1D array/list of float

</div></pre>
<a name='sub_gqgenerategausslegendre'></a><h3 class=pageheader><code>gqgenerategausslegendre</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Returns nodes/weights for Gauss-Legendre quadrature on [-1,1] with N
# nodes.
# 
# INPUT PARAMETERS:
#     N           -   number of nodes, &gt;=1
# 
# OUTPUT PARAMETERS:
#     Info        -   error code:
#                     * -4    an  error   was   detected   when  calculating
#                             weights/nodes.  N  is  too  large   to  obtain
#                             weights/nodes  with  high   enough   accuracy.
#                             Try  to   use   multiple   precision  version.
#                     * -3    internal eigenproblem solver hasn't  converged
#                     * -1    incorrect N was passed
#                     * +1    OK
#     X           -   array[0..N-1] - array of quadrature nodes,
#                     in ascending order.
#     W           -   array[0..N-1] - array of quadrature weights.
# 
# 
#   -- ALGLIB --
#      Copyright 12.05.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, x, w = xalglib.gqgenerategausslegendre(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          x:          1D array/list of float
          w:          1D array/list of float

</div></pre>
<a name='sub_gqgenerategausslobattorec'></a><h3 class=pageheader><code>gqgenerategausslobattorec</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Computation of nodes and weights for a Gauss-Lobatto quadrature formula
# 
# The algorithm generates the N-point Gauss-Lobatto quadrature formula  with
# weight function given by coefficients alpha and beta of a recurrence which
# generates a system of orthogonal polynomials.
# 
# P-1(x)   =  0
# P0(x)    =  1
# Pn+1(x)  =  (x-alpha(n))*Pn(x)  -  beta(n)*Pn-1(x)
# 
# and zeroth moment Mu0
# 
# Mu0 = integral(W(x)dx,a,b)
# 
# INPUT PARAMETERS:
#     Alpha   -   array[0..N-2], alpha coefficients
#     Beta    -   array[0..N-2], beta coefficients.
#                 Zero-indexed element is not used, may be arbitrary.
#                 Beta[I]&gt;0
#     Mu0     -   zeroth moment of the weighting function.
#     A       -   left boundary of the integration interval.
#     B       -   right boundary of the integration interval.
#     N       -   number of nodes of the quadrature formula, N&gt;=3
#                 (including the left and right boundary nodes).
# 
# OUTPUT PARAMETERS:
#     Info    -   error code:
#                 * -3    internal eigenproblem solver hasn't converged
#                 * -2    Beta[i]&lt;=0
#                 * -1    incorrect N was passed
#                 *  1    OK
#     X       -   array[0..N-1] - array of quadrature nodes,
#                 in ascending order.
#     W       -   array[0..N-1] - array of quadrature weights.
# 
#   -- ALGLIB --
#      Copyright 2005-2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, x, w = xalglib.gqgenerategausslobattorec(alpha, beta, mu0, a, b, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     alpha:      1D array/list of float
          beta:       1D array/list of float
          mu0:        float
          a:          float
          b:          float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          x:          1D array/list of float
          w:          1D array/list of float

</div></pre>
<a name='sub_gqgenerategaussradaurec'></a><h3 class=pageheader><code>gqgenerategaussradaurec</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Computation of nodes and weights for a Gauss-Radau quadrature formula
# 
# The algorithm generates the N-point Gauss-Radau  quadrature  formula  with
# weight function given by the coefficients alpha and  beta  of a recurrence
# which generates a system of orthogonal polynomials.
# 
# P-1(x)   =  0
# P0(x)    =  1
# Pn+1(x)  =  (x-alpha(n))*Pn(x)  -  beta(n)*Pn-1(x)
# 
# and zeroth moment Mu0
# 
# Mu0 = integral(W(x)dx,a,b)
# 
# INPUT PARAMETERS:
#     Alpha   -   array[0..N-2], alpha coefficients.
#     Beta    -   array[0..N-1], beta coefficients
#                 Zero-indexed element is not used.
#                 Beta[I]&gt;0
#     Mu0     -   zeroth moment of the weighting function.
#     A       -   left boundary of the integration interval.
#     N       -   number of nodes of the quadrature formula, N&gt;=2
#                 (including the left boundary node).
# 
# OUTPUT PARAMETERS:
#     Info    -   error code:
#                 * -3    internal eigenproblem solver hasn't converged
#                 * -2    Beta[i]&lt;=0
#                 * -1    incorrect N was passed
#                 *  1    OK
#     X       -   array[0..N-1] - array of quadrature nodes,
#                 in ascending order.
#     W       -   array[0..N-1] - array of quadrature weights.
# 
# 
#   -- ALGLIB --
#      Copyright 2005-2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, x, w = xalglib.gqgenerategaussradaurec(alpha, beta, mu0, a, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     alpha:      1D array/list of float
          beta:       1D array/list of float
          mu0:        float
          a:          float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          x:          1D array/list of float
          w:          1D array/list of float

</div></pre>
<a name='sub_gqgeneraterec'></a><h3 class=pageheader><code>gqgeneraterec</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Computation of nodes and weights for a Gauss quadrature formula
# 
# The algorithm generates the N-point Gauss quadrature formula  with  weight
# function given by coefficients alpha and beta  of  a  recurrence  relation
# which generates a system of orthogonal polynomials:
# 
# P-1(x)   =  0
# P0(x)    =  1
# Pn+1(x)  =  (x-alpha(n))*Pn(x)  -  beta(n)*Pn-1(x)
# 
# and zeroth moment Mu0
# 
# Mu0 = integral(W(x)dx,a,b)
# 
# INPUT PARAMETERS:
#     Alpha   -   array[0..N-1], alpha coefficients
#     Beta    -   array[0..N-1], beta coefficients
#                 Zero-indexed element is not used and may be arbitrary.
#                 Beta[I]&gt;0.
#     Mu0     -   zeroth moment of the weight function.
#     N       -   number of nodes of the quadrature formula, N&gt;=1
# 
# OUTPUT PARAMETERS:
#     Info    -   error code:
#                 * -3    internal eigenproblem solver hasn't converged
#                 * -2    Beta[i]&lt;=0
#                 * -1    incorrect N was passed
#                 *  1    OK
#     X       -   array[0..N-1] - array of quadrature nodes,
#                 in ascending order.
#     W       -   array[0..N-1] - array of quadrature weights.
# 
#   -- ALGLIB --
#      Copyright 2005-2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, x, w = xalglib.gqgeneraterec(alpha, beta, mu0, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     alpha:      1D array/list of float
          beta:       1D array/list of float
          mu0:        float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          x:          1D array/list of float
          w:          1D array/list of float

</div></pre>
<a name=unit_hermite></a><h2 class=pageheader><code>hermite</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_hermitecalculate' class=toc>hermitecalculate</a><br>
<a href='#sub_hermitecoefficients' class=toc>hermitecoefficients</a><br>
<a href='#sub_hermitesum' class=toc>hermitesum</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_hermitecalculate'></a><h3 class=pageheader><code>hermitecalculate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Calculation of the value of the Hermite polynomial.
# 
# Parameters:
#     n   -   degree, n&gt;=0
#     x   -   argument
# 
# Result:
#     the value of the Hermite polynomial Hn at x
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hermitecalculate(n, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_hermitecoefficients'></a><h3 class=pageheader><code>hermitecoefficients</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Representation of Hn as C[0] + C[1]*X + ... + C[N]*X^N
# 
# Input parameters:
#     N   -   polynomial degree, n&gt;=0
# 
# Output parameters:
#     C   -   coefficients
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.hermitecoefficients(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of float

</div></pre>
<a name='sub_hermitesum'></a><h3 class=pageheader><code>hermitesum</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Summation of Hermite polynomials using Clenshaw's recurrence formula.
# 
# This routine calculates
#     c[0]*H0(x) + c[1]*H1(x) + ... + c[N]*HN(x)
# 
# Parameters:
#     n   -   degree, n&gt;=0
#     x   -   argument
# 
# Result:
#     the value of the Hermite polynomial at x
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hermitesum(c, n, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          1D array/list of float
          n:          int
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_hqrnd></a><h2 class=pageheader><code>hqrnd</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_hqrndcontinuous' class=toc>hqrndcontinuous</a><br>
<a href='#sub_hqrnddiscrete' class=toc>hqrnddiscrete</a><br>
<a href='#sub_hqrndexponential' class=toc>hqrndexponential</a><br>
<a href='#sub_hqrndnormal' class=toc>hqrndnormal</a><br>
<a href='#sub_hqrndnormal2' class=toc>hqrndnormal2</a><br>
<a href='#sub_hqrndnormalm' class=toc>hqrndnormalm</a><br>
<a href='#sub_hqrndnormalv' class=toc>hqrndnormalv</a><br>
<a href='#sub_hqrndrandomize' class=toc>hqrndrandomize</a><br>
<a href='#sub_hqrndseed' class=toc>hqrndseed</a><br>
<a href='#sub_hqrnduniformi' class=toc>hqrnduniformi</a><br>
<a href='#sub_hqrnduniformr' class=toc>hqrnduniformr</a><br>
<a href='#sub_hqrndunit2' class=toc>hqrndunit2</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_hqrndcontinuous'></a><h3 class=pageheader><code>hqrndcontinuous</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function generates random number from continuous  distribution  given
# by finite sample X.
# 
# INPUT PARAMETERS
#     State   -   high quality random number generator, must be
#                 initialized with HQRNDRandomize() or HQRNDSeed().
#         X   -   finite sample, array[N] (can be larger, in this  case only
#                 leading N elements are used). THIS ARRAY MUST BE SORTED BY
#                 ASCENDING.
#         N   -   number of elements to use, N&gt;=1
# 
# RESULT
#     this function returns random number from continuous distribution which
#     tries to approximate X as mush as possible. min(X)&lt;=Result&lt;=max(X).
# 
#   -- ALGLIB --
#      Copyright 08.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hqrndcontinuous(state, x, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.hqrndstate
          x:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_hqrnddiscrete'></a><h3 class=pageheader><code>hqrnddiscrete</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function generates  random number from discrete distribution given by
# finite sample X.
# 
# INPUT PARAMETERS
#     State   -   high quality random number generator, must be
#                 initialized with HQRNDRandomize() or HQRNDSeed().
#         X   -   finite sample
#         N   -   number of elements to use, N&gt;=1
# 
# RESULT
#     this function returns one of the X[i] for random i=0..N-1
# 
#   -- ALGLIB --
#      Copyright 08.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hqrnddiscrete(state, x, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.hqrndstate
          x:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_hqrndexponential'></a><h3 class=pageheader><code>hqrndexponential</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Random number generator: exponential distribution
# 
# State structure must be initialized with HQRNDRandomize() or HQRNDSeed().
# 
#   -- ALGLIB --
#      Copyright 11.08.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hqrndexponential(state, lambdav)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.hqrndstate
          lambdav:    float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_hqrndnormal'></a><h3 class=pageheader><code>hqrndnormal</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Random number generator: normal numbers
# 
# This function generates one random number from normal distribution.
# Its performance is equal to that of HQRNDNormal2()
# 
# State structure must be initialized with HQRNDRandomize() or HQRNDSeed().
# 
#   -- ALGLIB --
#      Copyright 02.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hqrndnormal(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.hqrndstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_hqrndnormal2'></a><h3 class=pageheader><code>hqrndnormal2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Random number generator: normal numbers
# 
# This function generates two independent random numbers from normal
# distribution. Its performance is equal to that of HQRNDNormal()
# 
# State structure must be initialized with HQRNDRandomize() or HQRNDSeed().
# 
#   -- ALGLIB --
#      Copyright 02.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x1, x2 = xalglib.hqrndnormal2(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.hqrndstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x1:         float
          x2:         float

</div></pre>
<a name='sub_hqrndnormalm'></a><h3 class=pageheader><code>hqrndnormalm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Random number generator: matrix with random entries (normal distribution)
# 
# This function generates MxN random matrix.
# 
# State structure must be initialized with HQRNDRandomize() or HQRNDSeed().
# 
#   -- ALGLIB --
#      Copyright 02.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.hqrndnormalm(state, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.hqrndstate
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          2D array/list of float

</div></pre>
<a name='sub_hqrndnormalv'></a><h3 class=pageheader><code>hqrndnormalv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Random number generator: vector with random entries (normal distribution)
# 
# This function generates N random numbers from normal distribution.
# 
# State structure must be initialized with HQRNDRandomize() or HQRNDSeed().
# 
#   -- ALGLIB --
#      Copyright 02.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.hqrndnormalv(state, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.hqrndstate
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float

</div></pre>
<a name='sub_hqrndrandomize'></a><h3 class=pageheader><code>hqrndrandomize</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# HQRNDState  initialization  with  random  values  which come from standard
# RNG.
# 
#   -- ALGLIB --
#      Copyright 02.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.hqrndrandomize()
<span style='font-weight: bold; color: navy;'>ARGS:</span>     
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.hqrndstate

</div></pre>
<a name='sub_hqrndseed'></a><h3 class=pageheader><code>hqrndseed</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# HQRNDState initialization with seed values
# 
#   -- ALGLIB --
#      Copyright 02.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.hqrndseed(s1, s2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s1:         int
          s2:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.hqrndstate

</div></pre>
<a name='sub_hqrnduniformi'></a><h3 class=pageheader><code>hqrnduniformi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function generates random integer number in [0, N)
# 
# 1. State structure must be initialized with HQRNDRandomize() or HQRNDSeed()
# 2. N can be any positive number except for very large numbers:
#    * close to 2^31 on 32-bit systems
#    * close to 2^62 on 64-bit systems
#    An exception will be generated if N is too large.
# 
#   -- ALGLIB --
#      Copyright 02.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hqrnduniformi(state, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.hqrndstate
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_hqrnduniformr'></a><h3 class=pageheader><code>hqrnduniformr</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function generates random real number in (0,1),
# not including interval boundaries
# 
# State structure must be initialized with HQRNDRandomize() or HQRNDSeed().
# 
#   -- ALGLIB --
#      Copyright 02.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hqrnduniformr(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.hqrndstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_hqrndunit2'></a><h3 class=pageheader><code>hqrndunit2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Random number generator: random X and Y such that X^2+Y^2=1
# 
# State structure must be initialized with HQRNDRandomize() or HQRNDSeed().
# 
#   -- ALGLIB --
#      Copyright 02.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, y = xalglib.hqrndunit2(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.hqrndstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          float
          y:          float

</div></pre>
<a name=unit_ibetaf></a><h2 class=pageheader><code>ibetaf</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_incompletebeta' class=toc>incompletebeta</a><br>
<a href='#sub_invincompletebeta' class=toc>invincompletebeta</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_incompletebeta'></a><h3 class=pageheader><code>incompletebeta</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Incomplete beta integral
# 
# Returns incomplete beta integral of the arguments, evaluated
# from zero to x.  The function is defined as
# 
#                  x
#     -            -
#    | (a+b)      | |  a-1     b-1
#  -----------    |   t   (1-t)   dt.
#   -     -     | |
#  | (a) | (b)   -
#                 0
# 
# The domain of definition is 0 &lt;= x &lt;= 1.  In this
# implementation a and b are restricted to positive values.
# The integral from x to 1 may be obtained by the symmetry
# relation
# 
#    1 - incbet( a, b, x )  =  incbet( b, a, 1-x ).
# 
# The integral is evaluated by a continued fraction expansion
# or, when b*x is small, by a power series.
# 
# ACCURACY:
# 
# Tested at uniformly distributed random points (a,b,x) with a and b
# in &quot;domain&quot; and x between 0 and 1.
#                                        Relative error
# arithmetic   domain     # trials      peak         rms
#    IEEE      0,5         10000       6.9e-15     4.5e-16
#    IEEE      0,85       250000       2.2e-13     1.7e-14
#    IEEE      0,1000      30000       5.3e-12     6.3e-13
#    IEEE      0,10000    250000       9.3e-11     7.1e-12
#    IEEE      0,100000    10000       8.7e-10     4.8e-11
# Outputs smaller than the IEEE gradual underflow threshold
# were excluded from these statistics.
# 
# Cephes Math Library, Release 2.8:  June, 2000
# Copyright 1984, 1995, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.incompletebeta(a, b, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          float
          b:          float
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_invincompletebeta'></a><h3 class=pageheader><code>invincompletebeta</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inverse of imcomplete beta integral
# 
# Given y, the function finds x such that
# 
#  incbet( a, b, x ) = y .
# 
# The routine performs interval halving or Newton iterations to find the
# root of incbet(a,b,x) - y = 0.
# 
# 
# ACCURACY:
# 
#                      Relative error:
#                x     a,b
# arithmetic   domain  domain  # trials    peak       rms
#    IEEE      0,1    .5,10000   50000    5.8e-12   1.3e-13
#    IEEE      0,1   .25,100    100000    1.8e-13   3.9e-15
#    IEEE      0,1     0,5       50000    1.1e-12   5.5e-15
# With a and b constrained to half-integer or integer values:
#    IEEE      0,1    .5,10000   50000    5.8e-12   1.1e-13
#    IEEE      0,1    .5,100    100000    1.7e-14   7.9e-16
# With a = .5, b constrained to half-integer or integer values:
#    IEEE      0,1    .5,10000   10000    8.3e-11   1.0e-11
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1996, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.invincompletebeta(a, b, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          float
          b:          float
          y:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_idw></a><h2 class=pageheader><code>idw</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_idwbuildercreate' class=toc>idwbuildercreate</a><br>
<a href='#sub_idwbuildersetalgomstab' class=toc>idwbuildersetalgomstab</a><br>
<a href='#sub_idwbuildersetalgotextbookmodshepard' class=toc>idwbuildersetalgotextbookmodshepard</a><br>
<a href='#sub_idwbuildersetalgotextbookshepard' class=toc>idwbuildersetalgotextbookshepard</a><br>
<a href='#sub_idwbuildersetconstterm' class=toc>idwbuildersetconstterm</a><br>
<a href='#sub_idwbuildersetnlayers' class=toc>idwbuildersetnlayers</a><br>
<a href='#sub_idwbuildersetpoints' class=toc>idwbuildersetpoints</a><br>
<a href='#sub_idwbuildersetuserterm' class=toc>idwbuildersetuserterm</a><br>
<a href='#sub_idwbuildersetzeroterm' class=toc>idwbuildersetzeroterm</a><br>
<a href='#sub_idwcalc' class=toc>idwcalc</a><br>
<a href='#sub_idwcalc1' class=toc>idwcalc1</a><br>
<a href='#sub_idwcalc2' class=toc>idwcalc2</a><br>
<a href='#sub_idwcalc3' class=toc>idwcalc3</a><br>
<a href='#sub_idwcalcbuf' class=toc>idwcalcbuf</a><br>
<a href='#sub_idwcreatecalcbuffer' class=toc>idwcreatecalcbuffer</a><br>
<a href='#sub_idwfit' class=toc>idwfit</a><br>
<a href='#sub_idwgridcalc2v' class=toc>idwgridcalc2v</a><br>
<a href='#sub_idwgridcalc2vsubset' class=toc>idwgridcalc2vsubset</a><br>
<a href='#sub_idwpeekprogress' class=toc>idwpeekprogress</a><br>
<a href='#sub_idwtscalcbuf' class=toc>idwtscalcbuf</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_idwbuildercreate'></a><h3 class=pageheader><code>idwbuildercreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine creates builder object used  to  generate IDW  model  from
# irregularly sampled (scattered) dataset.  Multidimensional  scalar/vector-
# -valued are supported.
# 
# Builder object is used to fit model to data as follows:
# * builder object is created with idwbuildercreate() function
# * dataset is added with idwbuildersetpoints() function
# * one of the modern IDW algorithms is chosen with either:
#   * idwbuildersetalgomstab()            - Multilayer STABilized algorithm (interpolation)
#   Alternatively, one of the textbook algorithms can be chosen (not recommended):
#   * idwbuildersetalgotextbookshepard()  - textbook Shepard algorithm
#   * idwbuildersetalgotextbookmodshepard()-textbook modified Shepard algorithm
# * finally, model construction is performed with idwfit() function.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     NX  -   dimensionality of the argument, NX&gt;=1
#     NY  -   dimensionality of the function being modeled, NY&gt;=1;
#             NY=1 corresponds to classic scalar function, NY&gt;=1 corresponds
#             to vector-valued function.
# 
# OUTPUT PARAMETERS:
#     State-  builder object
# 
#   -- ALGLIB PROJECT --
#      Copyright 22.10.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.idwbuildercreate(nx, ny)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nx:         int
          ny:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.idwbuilder

</div></pre>
<a name='sub_idwbuildersetalgomstab'></a><h3 class=pageheader><code>idwbuildersetalgomstab</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets IDW model  construction  algorithm  to  the  Multilayer
# Stabilized IDW method (IDW-MSTAB), a  latest  incarnation  of  the inverse
# distance weighting interpolation which fixes shortcomings of  the original
# and modified Shepard's variants.
# 
# The distinctive features of IDW-MSTAB are:
# 1) exact interpolation  is  pursued  (as  opposed  to  fitting  and  noise
#    suppression)
# 2) improved robustness when compared with that of other algorithms:
#    * MSTAB shows almost no strange  fitting  artifacts  like  ripples  and
#      sharp spikes (unlike N-dimensional splines and HRBFs)
#    * MSTAB does not return function values far from the  interval  spanned
#      by the dataset; say, if all your points have |f|&lt;=1, you  can be sure
#      that model value won't deviate too much from [-1,+1]
# 3) good model construction time competing with that of HRBFs  and  bicubic
#    splines
# 4) ability to work with any number of dimensions, starting from NX=1
# 
# The drawbacks of IDW-MSTAB (and all IDW algorithms in general) are:
# 1) dependence of the model evaluation time on the search radius
# 2) bad extrapolation properties, models built by this method  are  usually
#    conservative in their predictions
# 
# Thus, IDW-MSTAB is  a  good  &quot;default&quot;  option  if  you  want  to  perform
# scattered multidimensional interpolation. Although it has  its  drawbacks,
# it is easy to use and robust, which makes it a good first step.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     State   -   builder object
#     SRad    -   initial search radius, SRad&gt;0 is required. A model  value
#                 is obtained by &quot;smart&quot; averaging  of  the  dataset  points
#                 within search radius.
# 
# NOTE 1: IDW interpolation can  correctly  handle  ANY  dataset,  including
#         datasets with non-distinct points. In case non-distinct points are
#         found, an average value for this point will be calculated.
# 
# NOTE 2: the memory requirements for model storage are O(NPoints*NLayers).
#         The model construction needs twice as much memory as model storage.
# 
# NOTE 3: by default 16 IDW layers are built which is enough for most cases.
#         You can change this parameter with idwbuildersetnlayers()  method.
#         Larger values may be necessary if you need to reproduce  extrafine
#         details at distances smaller than SRad/65536.  Smaller value   may
#         be necessary if you have to save memory and  computing  time,  and
#         ready to sacrifice some model quality.
# 
# 
# ALGORITHM DESCRIPTION
# 
# ALGLIB implementation of IDW is somewhat similar to the modified Shepard's
# method (one with search radius R) but overcomes several of its  drawbacks,
# namely:
# 1) a tendency to show stepwise behavior for uniform datasets
# 2) a tendency to show terrible interpolation properties for highly
#    nonuniform datasets which often arise in geospatial tasks
#   (function values are densely sampled across multiple separated
#   &quot;tracks&quot;)
# 
# IDW-MSTAB method performs several passes over dataset and builds a sequence
# of progressively refined IDW models  (layers),  which starts from one with
# largest search radius SRad  and continues to smaller  search  radii  until
# required number of  layers  is  built.  Highest  layers  reproduce  global
# behavior of the target function at larger distances  whilst  lower  layers
# reproduce fine details at smaller distances.
# 
# Each layer is an IDW model built with following modifications:
# * weights go to zero when distance approach to the current search radius
# * an additional regularizing term is added to the distance: w=1/(d^2+lambda)
# * an additional fictional term with unit weight and zero function value is
#   added in order to promote continuity  properties  at  the  isolated  and
#   boundary points
# 
# By default, 16 layers is built, which is enough for most  cases.  You  can
# change this parameter with idwbuildersetnlayers() method.
# 
#   -- ALGLIB --
#      Copyright 22.10.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.idwbuildersetalgomstab(state, srad)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.idwbuilder
          srad:       float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_idwbuildersetalgotextbookmodshepard'></a><h3 class=pageheader><code>idwbuildersetalgotextbookmodshepard</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets  IDW  model  construction  algorithm  to the 'textbook'
# modified Shepard's algorithm with user-specified search radius.
# 
# IMPORTANT: we do NOT recommend using textbook IDW algorithms because  they
#            have terrible interpolation properties. Use MSTAB in all cases.
# 
# INPUT PARAMETERS:
#     State   -   builder object
#     R       -   search radius
# 
# NOTE 1: IDW interpolation can  correctly  handle  ANY  dataset,  including
#         datasets with non-distinct points. In case non-distinct points are
#         found, an average value for this point will be calculated.
# 
#   -- ALGLIB --
#      Copyright 22.10.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.idwbuildersetalgotextbookmodshepard(state, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.idwbuilder
          r:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_idwbuildersetalgotextbookshepard'></a><h3 class=pageheader><code>idwbuildersetalgotextbookshepard</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets  IDW  model  construction  algorithm  to  the  textbook
# Shepard's algorithm with custom (user-specified) power parameter.
# 
# IMPORTANT: we do NOT recommend using textbook IDW algorithms because  they
#            have terrible interpolation properties. Use MSTAB in all cases.
# 
# INPUT PARAMETERS:
#     State   -   builder object
#     P       -   power parameter, P&gt;0; good value to start with is 2.0
# 
# NOTE 1: IDW interpolation can  correctly  handle  ANY  dataset,  including
#         datasets with non-distinct points. In case non-distinct points are
#         found, an average value for this point will be calculated.
# 
#   -- ALGLIB --
#      Copyright 22.10.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.idwbuildersetalgotextbookshepard(state, p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.idwbuilder
          p:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_idwbuildersetconstterm'></a><h3 class=pageheader><code>idwbuildersetconstterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets constant prior term (model value at infinity).
# 
# Constant prior term is determined as mean value over dataset.
# 
# INPUT PARAMETERS:
#     S       -   spline builder
# 
#   -- ALGLIB --
#      Copyright 29.10.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.idwbuildersetconstterm(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.idwbuilder
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_idwbuildersetnlayers'></a><h3 class=pageheader><code>idwbuildersetnlayers</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function changes number of layers used by IDW-MSTAB algorithm.
# 
# The more layers you have, the finer details can  be  reproduced  with  IDW
# model. The less layers you have, the less memory and CPU time is  consumed
# by the model.
# 
# Memory consumption grows linearly with layers count,  running  time  grows
# sub-linearly.
# 
# The default number of layers is 16, which allows you to reproduce  details
# at distance down to SRad/65536. You will rarely need to change it.
# 
# INPUT PARAMETERS:
#     State   -   builder object
#     NLayers -   NLayers&gt;=1, the number of layers used by the model.
# 
#   -- ALGLIB --
#      Copyright 22.10.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.idwbuildersetnlayers(state, nlayers)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.idwbuilder
          nlayers:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_idwbuildersetpoints'></a><h3 class=pageheader><code>idwbuildersetpoints</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function adds dataset to the builder object.
# 
# This function overrides results of the previous calls, i.e. multiple calls
# of this function will result in only the last set being added.
# 
# INPUT PARAMETERS:
#     State   -   builder object
#     XY      -   points, array[N,NX+NY]. One row  corresponds to  one point
#                 in the dataset. First NX elements  are  coordinates,  next
#                 NY elements are function values. Array may  be larger than
#                 specified, in  this  case  only leading [N,NX+NY] elements
#                 will be used.
#     N       -   number of points in the dataset, N&gt;=0.
# 
#   -- ALGLIB --
#      Copyright 22.10.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.idwbuildersetpoints(state, xy, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.idwbuildersetpoints(state, xy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.idwbuilder
          xy:         2D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_idwbuildersetuserterm'></a><h3 class=pageheader><code>idwbuildersetuserterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets prior term (model value at infinity) as  user-specified
# value.
# 
# INPUT PARAMETERS:
#     S       -   spline builder
#     V       -   value for user-defined prior
# 
# NOTE: for vector-valued models all components of the prior are set to same
#       user-specified value
# 
#   -- ALGLIB --
#      Copyright 29.10.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.idwbuildersetuserterm(state, v)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.idwbuilder
          v:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_idwbuildersetzeroterm'></a><h3 class=pageheader><code>idwbuildersetzeroterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets zero prior term (model value at infinity).
# 
# INPUT PARAMETERS:
#     S       -   spline builder
# 
#   -- ALGLIB --
#      Copyright 29.10.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.idwbuildersetzeroterm(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.idwbuilder
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_idwcalc'></a><h3 class=pageheader><code>idwcalc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the IDW model at the given point.
# 
# This is general function which can be used for arbitrary NX (dimension  of
# the space of arguments) and NY (dimension of the function itself). However
# when  you  have  NY=1  you  may  find more convenient to  use  idwcalc1(),
# idwcalc2() or idwcalc3().
# 
# NOTE: this function modifies internal temporaries of the  IDW  model, thus
#       IT IS NOT  THREAD-SAFE!  If  you  want  to  perform  parallel  model
#       evaluation from the multiple threads, use idwtscalcbuf()  with  per-
#       thread buffer object.
# 
# INPUT PARAMETERS:
#     S       -   IDW model
#     X       -   coordinates, array[NX]. X may have more than NX  elements,
#                 in this case only leading NX will be used.
# 
# OUTPUT PARAMETERS:
#     Y       -   function value, array[NY]. Y is out-parameter and will  be
#                 reallocated after call to this function. In case you  want
#                 to reuse previously allocated Y, you may use idwcalcbuf(),
#                 which reallocates Y only when it is too small.
# 
#   -- ALGLIB --
#      Copyright 22.10.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.idwcalc(s, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.idwmodel
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_idwcalc1'></a><h3 class=pageheader><code>idwcalc1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# IDW interpolation: scalar target, 1-dimensional argument
# 
# NOTE: this function modifies internal temporaries of the  IDW  model, thus
#       IT IS NOT  THREAD-SAFE!  If  you  want  to  perform  parallel  model
#       evaluation from the multiple threads, use idwtscalcbuf()  with  per-
#       thread buffer object.
# 
# INPUT PARAMETERS:
#     S   -   IDW interpolant built with IDW builder
#     X0  -   argument value
# 
# Result:
#     IDW interpolant S(X0)
# 
#   -- ALGLIB --
#      Copyright 22.10.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.idwcalc1(s, x0)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.idwmodel
          x0:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_idwcalc2'></a><h3 class=pageheader><code>idwcalc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# IDW interpolation: scalar target, 2-dimensional argument
# 
# NOTE: this function modifies internal temporaries of the  IDW  model, thus
#       IT IS NOT  THREAD-SAFE!  If  you  want  to  perform  parallel  model
#       evaluation from the multiple threads, use idwtscalcbuf()  with  per-
#       thread buffer object.
# 
# INPUT PARAMETERS:
#     S       -   IDW interpolant built with IDW builder
#     X0, X1  -   argument value
# 
# Result:
#     IDW interpolant S(X0,X1)
# 
#   -- ALGLIB --
#      Copyright 22.10.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.idwcalc2(s, x0, x1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.idwmodel
          x0:         float
          x1:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_idwcalc3'></a><h3 class=pageheader><code>idwcalc3</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# IDW interpolation: scalar target, 3-dimensional argument
# 
# NOTE: this function modifies internal temporaries of the  IDW  model, thus
#       IT IS NOT  THREAD-SAFE!  If  you  want  to  perform  parallel  model
#       evaluation from the multiple threads, use idwtscalcbuf()  with  per-
#       thread buffer object.
# 
# INPUT PARAMETERS:
#     S       -   IDW interpolant built with IDW builder
#     X0,X1,X2-   argument value
# 
# Result:
#     IDW interpolant S(X0,X1,X2)
# 
#   -- ALGLIB --
#      Copyright 22.10.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.idwcalc3(s, x0, x1, x2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.idwmodel
          x0:         float
          x1:         float
          x2:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_idwcalcbuf'></a><h3 class=pageheader><code>idwcalcbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the IDW model at the given point.
# 
# Same as idwcalc(), but does not reallocate Y when in is large enough to
# store function values.
# 
# NOTE: this function modifies internal temporaries of the  IDW  model, thus
#       IT IS NOT  THREAD-SAFE!  If  you  want  to  perform  parallel  model
#       evaluation from the multiple threads, use idwtscalcbuf()  with  per-
#       thread buffer object.
# 
# INPUT PARAMETERS:
#     S       -   IDW model
#     X       -   coordinates, array[NX]. X may have more than NX  elements,
#                 in this case only leading NX will be used.
#     Y       -   possibly preallocated array
# 
# OUTPUT PARAMETERS:
#     Y       -   function value, array[NY]. Y is not reallocated when it
#                 is larger than NY.
# 
#   -- ALGLIB --
#      Copyright 22.10.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.idwcalcbuf(s, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.idwmodel
          x:          1D array/list of float
          y:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_idwcreatecalcbuffer'></a><h3 class=pageheader><code>idwcreatecalcbuffer</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates buffer  structure  which  can  be  used  to  perform
# parallel  IDW  model  evaluations  (with  one  IDW  model  instance  being
# used from multiple threads, as long as  different  threads  use  different
# instances of buffer).
# 
# This buffer object can be used with  idwtscalcbuf()  function  (here  &quot;ts&quot;
# stands for &quot;thread-safe&quot;, &quot;buf&quot; is a suffix which denotes  function  which
# reuses previously allocated output space).
# 
# How to use it:
# * create IDW model structure or load it from file
# * call idwcreatecalcbuffer(), once per thread working with IDW model  (you
#   should call this function only AFTER model initialization, see below for
#   more information)
# * call idwtscalcbuf() from different threads,  with  each  thread  working
#   with its own copy of buffer object.
# 
# INPUT PARAMETERS
#     S           -   IDW model
# 
# OUTPUT PARAMETERS
#     Buf         -   external buffer.
# 
# 
# IMPORTANT: buffer object should be used only with  IDW model object  which
#            was used to initialize buffer. Any attempt to use buffer   with
#            different object is dangerous - you may  get  memory  violation
#            error because sizes of internal arrays do not fit to dimensions
#            of the IDW structure.
# 
# IMPORTANT: you  should  call  this function only for model which was built
#            with model builder (or unserialized from file). Sizes  of  some
#            internal structures are determined only after model  is  built,
#            so buffer object created before model construction  stage  will
#            be useless (and any attempt to use it will result in exception).
# 
#   -- ALGLIB --
#      Copyright 22.10.2018 by Sergey Bochkanov
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   buf = xalglib.idwcreatecalcbuffer(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.idwmodel
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  buf:        class xalglib.idwcalcbuffer

</div></pre>
<a name='sub_idwfit'></a><h3 class=pageheader><code>idwfit</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function fits IDW model to the dataset using current IDW construction
# algorithm. A model being built and fitting report are returned.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     State   -   builder object
# 
# OUTPUT PARAMETERS:
#     Model   -   an IDW model built with current algorithm
#     Rep     -   model fitting report, fields of this structure contain
#                 information about average fitting errors.
# 
# NOTE: although IDW-MSTAB algorithm is an  interpolation  method,  i.e.  it
#       tries to fit the model exactly, it can  handle  datasets  with  non-
#       distinct points which can not be fit exactly; in such  cases  least-
#       squares fitting is performed.
# 
#   -- ALGLIB --
#      Copyright 22.10.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   model, rep = xalglib.idwfit(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.idwbuilder
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  model:      class xalglib.idwmodel
          rep:        class xalglib.idwreport

</div></pre>
<a name='sub_idwgridcalc2v'></a><h3 class=pageheader><code>idwgridcalc2v</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values  of  an  IDW  model  at  a  regular  grid,
# which  has  N0*N1 points, with Point[I,J] = (X0[I], X1[J]).  Vector-valued
# IDW models are supported.
# 
# This function returns 0.0 when:
# * the model is not initialized
# * NX&lt;&gt;2
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# NOTE: Parallel  processing  is  implemented only for modern (MSTAB) IDW's.
# 
# INPUT PARAMETERS:
#     S       -   IDW model, used in read-only mode, can be  shared  between
#                 multiple   invocations  of  this  function  from  multiple
#                 threads.
# 
#     X0      -   array of grid nodes, first coordinates, array[N0].
#                 Must be ordered by ascending. Exception is generated
#                 if the array is not correctly ordered.
#     N0      -   grid size (number of nodes) in the first dimension, N0&gt;=1
# 
#     X1      -   array of grid nodes, second coordinates, array[N1]
#                 Must be ordered by ascending. Exception is generated
#                 if the array is not correctly ordered.
#     N1      -   grid size (number of nodes) in the second dimension, N1&gt;=1
# 
# OUTPUT PARAMETERS:
#     Y       -   function values, array[NY*N0*N1], where NY is a  number of
#                 &quot;output&quot; vector values (this  function   supports  vector-
#                 valued IDW models). Y is out-variable and  is  reallocated
#                 by this function.
#                 Y[K+NY*(I0+I1*N0)]=F_k(X0[I0],X1[I1]), for:
#                 *  K=0...NY-1
#                 * I0=0...N0-1
#                 * I1=0...N1-1
# 
# NOTE: this function supports weakly ordered grid nodes, i.e. you may  have
#       X[i]=X[i+1] for some i. It does  not  provide  you  any  performance
#       benefits  due  to   duplication  of  points,  just  convenience  and
#       flexibility.
# 
# NOTE: this  function  is  re-entrant,  i.e.  you  may  use  same  idwmodel
#       structure in multiple threads calling  this function  for  different
#       grids.
# 
# NOTE: if you need function values on some subset  of  regular  grid, which
#       may be described as &quot;several compact and  dense  islands&quot;,  you  may
#       use idwgridcalc2vsubset().
# 
#   -- ALGLIB --
#      Copyright 24.11.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.idwgridcalc2v(s, x0, n0, x1, n1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.idwmodel
          x0:         1D array/list of float
          n0:         int
          x1:         1D array/list of float
          n1:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_idwgridcalc2vsubset'></a><h3 class=pageheader><code>idwgridcalc2vsubset</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of an  IDW  model  at  some  subset  of  a
# regular grid:
# * the grid has N0*N1 points, with Point[I,J] = (X0[I], X1[J])
# * only values at some subset of the grid are required
# Vector-valued IDW models are supported.
# 
# This function returns 0.0 when:
# * the model is not initialized
# * NX&lt;&gt;2
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# NOTE: Parallel processing is implemented only for modern (MSTAB) IDW's.
# 
# INPUT PARAMETERS:
#     S       -   IDW model, used in read-only mode, can be  shared  between
#                 multiple   invocations  of  this  function  from  multiple
#                 threads.
# 
#     X0      -   array of grid nodes, first coordinates, array[N0].
#                 Must be ordered by ascending. Exception is generated
#                 if the array is not correctly ordered.
#     N0      -   grid size (number of nodes) in the first dimension, N0&gt;=1
# 
#     X1      -   array of grid nodes, second coordinates, array[N1]
#                 Must be ordered by ascending. Exception is generated
#                 if the array is not correctly ordered.
#     N1      -   grid size (number of nodes) in the second dimension, N1&gt;=1
# 
#     FlagY   -   array[N0*N1]:
#                 * Y[I0+I1*N0] corresponds to node (X0[I0],X1[I1])
#                 * it is a &quot;bitmap&quot; array which contains  False  for  nodes
#                   which are NOT calculated, and True for nodes  which  are
#                   required.
# 
# OUTPUT PARAMETERS:
#     Y       -   function values, array[NY*N0*N1*N2], where NY is a  number
#                 of &quot;output&quot; vector values (this function  supports vector-
#                 valued IDW models):
#                 * Y[K+NY*(I0+I1*N0)]=F_k(X0[I0],X1[I1]),
#                   for K=0...NY-1, I0=0...N0-1, I1=0...N1-1.
#                 * elements of Y[] which correspond  to  FlagY[]=True   are
#                   loaded by model values (which may be  exactly  zero  for
#                   some nodes).
#                 * elements of Y[] which correspond to FlagY[]=False MAY be
#                   initialized by zeros OR may  be  calculated.  Generally,
#                   they  are   not   calculated,  but  future  SIMD-capable
#                   versions may compute several elements in a batch.
# 
# NOTE: this function supports weakly ordered grid nodes, i.e. you may  have
#       X[i]=X[i+1] for some i. It does  not  provide  you  any  performance
#       benefits  due  to   duplication  of  points,  just  convenience  and
#       flexibility.
# 
# NOTE: this  function  is  re-entrant,  i.e.  you  may  use  same  idwmodel
#       structure in multiple threads calling  this function  for  different
#       grids.
# 
#   -- ALGLIB --
#      Copyright 24.11.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.idwgridcalc2vsubset(s, x0, n0, x1, n1, flagy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.idwmodel
          x0:         1D array/list of float
          n0:         int
          x1:         1D array/list of float
          n1:         int
          flagy:      1D array/list of bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_idwpeekprogress'></a><h3 class=pageheader><code>idwpeekprogress</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to peek into the IDW construction  process from some
# other thread and get the progress indicator. It returns value in [0,1].
# 
# IMPORTANT: only MSTAB algorithm supports peeking into progress  indicator.
#            Legacy versions of the Shepard's method do  not support it. You
#            will always get zero as the result.
# 
# INPUT PARAMETERS:
#     S           -   RBF model object
# 
# RESULT:
#     progress value, in [0,1]
# 
#   -- ALGLIB --
#      Copyright 27.11.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.idwpeekprogress(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.idwbuilder
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_idwtscalcbuf'></a><h3 class=pageheader><code>idwtscalcbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the IDW model at the given point, using
# external  buffer  object  (internal  temporaries  of  IDW  model  are  not
# modified).
# 
# This function allows to use same IDW model object  in  different  threads,
# assuming  that  different   threads  use different instances of the buffer
# structure.
# 
# INPUT PARAMETERS:
#     S       -   IDW model, may be shared between different threads
#     Buf     -   buffer object created for this particular instance of  IDW
#                 model with idwcreatecalcbuffer().
#     X       -   coordinates, array[NX]. X may have more than NX  elements,
#                 in this case only  leading NX will be used.
#     Y       -   possibly preallocated array
# 
# OUTPUT PARAMETERS:
#     Y       -   function value, array[NY]. Y is not reallocated when it
#                 is larger than NY.
# 
#   -- ALGLIB --
#      Copyright 13.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.idwtscalcbuf(s, buf, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.idwmodel
          buf:        class xalglib.idwcalcbuffer
          x:          1D array/list of float
          y:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> buf
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name=unit_igammaf></a><h2 class=pageheader><code>igammaf</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_incompletegamma' class=toc>incompletegamma</a><br>
<a href='#sub_incompletegammac' class=toc>incompletegammac</a><br>
<a href='#sub_invincompletegammac' class=toc>invincompletegammac</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_incompletegamma'></a><h3 class=pageheader><code>incompletegamma</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Incomplete gamma integral
# 
# The function is defined by
# 
#                           x
#                            -
#                   1       | |  -t  a-1
#  igam(a,x)  =   -----     |   e   t   dt.
#                  -      | |
#                 | (a)    -
#                           0
# 
# 
# In this implementation both arguments must be positive.
# The integral is evaluated by either a power series or
# continued fraction expansion, depending on the relative
# values of a and x.
# 
# ACCURACY:
# 
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE      0,30       200000       3.6e-14     2.9e-15
#    IEEE      0,100      300000       9.9e-14     1.5e-14
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1985, 1987, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.incompletegamma(a, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          float
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_incompletegammac'></a><h3 class=pageheader><code>incompletegammac</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Complemented incomplete gamma integral
# 
# The function is defined by
# 
# 
#  igamc(a,x)   =   1 - igam(a,x)
# 
#                            inf.
#                              -
#                     1       | |  -t  a-1
#               =   -----     |   e   t   dt.
#                    -      | |
#                   | (a)    -
#                             x
# 
# 
# In this implementation both arguments must be positive.
# The integral is evaluated by either a power series or
# continued fraction expansion, depending on the relative
# values of a and x.
# 
# ACCURACY:
# 
# Tested at random a, x.
#                a         x                      Relative error:
# arithmetic   domain   domain     # trials      peak         rms
#    IEEE     0.5,100   0,100      200000       1.9e-14     1.7e-15
#    IEEE     0.01,0.5  0,100      200000       1.4e-13     1.6e-15
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1985, 1987, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.incompletegammac(a, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          float
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_invincompletegammac'></a><h3 class=pageheader><code>invincompletegammac</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inverse of complemented imcomplete gamma integral
# 
# Given p, the function finds x such that
# 
#  igamc( a, x ) = p.
# 
# Starting with the approximate value
# 
#         3
#  x = a t
# 
#  where
# 
#  t = 1 - d - ndtri(p) sqrt(d)
# 
# and
# 
#  d = 1/9a,
# 
# the routine performs up to 10 Newton iterations to find the
# root of igamc(a,x) - p = 0.
# 
# ACCURACY:
# 
# Tested at random a, p in the intervals indicated.
# 
#                a        p                      Relative error:
# arithmetic   domain   domain     # trials      peak         rms
#    IEEE     0.5,100   0,0.5       100000       1.0e-14     1.7e-15
#    IEEE     0.01,0.5  0,0.5       100000       9.0e-14     3.4e-15
#    IEEE    0.5,10000  0,0.5        20000       2.3e-13     3.8e-14
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.invincompletegammac(a, y0)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          float
          y0:         float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_intcomp></a><h2 class=pageheader><code>intcomp</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_nsfitspheremcc' class=toc>nsfitspheremcc</a><br>
<a href='#sub_nsfitspheremic' class=toc>nsfitspheremic</a><br>
<a href='#sub_nsfitspheremzc' class=toc>nsfitspheremzc</a><br>
<a href='#sub_nsfitspherex' class=toc>nsfitspherex</a><br>
<a href='#sub_spline1dfitcubic' class=toc>spline1dfitcubic</a><br>
<a href='#sub_spline1dfithermite' class=toc>spline1dfithermite</a><br>
<a href='#sub_spline1dfitpenalized' class=toc>spline1dfitpenalized</a><br>
<a href='#sub_spline1dfitpenalizedw' class=toc>spline1dfitpenalizedw</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_nsfitspheremcc'></a><h3 class=pageheader><code>nsfitspheremcc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is left for backward compatibility.
# Use fitspheremc() instead.
# 
# 
#   -- ALGLIB --
#      Copyright 14.04.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   cx, rhi = xalglib.nsfitspheremcc(xy, npoints, nx)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nx:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  cx:         1D array/list of float
          rhi:        float

</div></pre>
<a name='sub_nsfitspheremic'></a><h3 class=pageheader><code>nsfitspheremic</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is left for backward compatibility.
# Use fitspheremi() instead.
# 
#   -- ALGLIB --
#      Copyright 14.04.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   cx, rlo = xalglib.nsfitspheremic(xy, npoints, nx)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nx:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  cx:         1D array/list of float
          rlo:        float

</div></pre>
<a name='sub_nsfitspheremzc'></a><h3 class=pageheader><code>nsfitspheremzc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is left for backward compatibility.
# Use fitspheremz() instead.
# 
#   -- ALGLIB --
#      Copyright 14.04.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   cx, rlo, rhi = xalglib.nsfitspheremzc(xy, npoints, nx)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nx:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  cx:         1D array/list of float
          rlo:        float
          rhi:        float

</div></pre>
<a name='sub_nsfitspherex'></a><h3 class=pageheader><code>nsfitspherex</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is left for backward compatibility.
# Use fitspherex() instead.
# 
#   -- ALGLIB --
#      Copyright 14.04.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   cx, rlo, rhi = xalglib.nsfitspherex(xy, npoints, nx, problemtype, epsx, aulits, penalty)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nx:         int
          problemtype: int
          epsx:       float
          aulits:     int
          penalty:    float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  cx:         1D array/list of float
          rlo:        float
          rhi:        float

</div></pre>
<a name='sub_spline1dfitcubic'></a><h3 class=pageheader><code>spline1dfitcubic</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Deprecated fitting function with O(N*M^2+M^3) running time. Superseded  by
# spline1dfit().
# 
#   -- ALGLIB PROJECT --
#      Copyright 18.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s, rep = xalglib.spline1dfitcubic(x, y, n, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   s, rep = xalglib.spline1dfitcubic(x, y, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.spline1dinterpolant
          rep:        class xalglib.spline1dfitreport

</div></pre>
<a name='sub_spline1dfithermite'></a><h3 class=pageheader><code>spline1dfithermite</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Deprecated fitting function with O(N*M^2+M^3) running time. Superseded  by
# spline1dfit().
# 
#   -- ALGLIB PROJECT --
#      Copyright 18.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s, rep = xalglib.spline1dfithermite(x, y, n, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   s, rep = xalglib.spline1dfithermite(x, y, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.spline1dinterpolant
          rep:        class xalglib.spline1dfitreport

</div></pre>
<a name='sub_spline1dfitpenalized'></a><h3 class=pageheader><code>spline1dfitpenalized</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is an obsolete and deprecated version of fitting by
# penalized cubic spline.
# 
# It was superseded by spline1dfit(), which is an orders of magnitude faster
# and more memory-efficient implementation.
# 
# Do NOT use this function in the new code!
# 
#   -- ALGLIB PROJECT --
#      Copyright 18.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, s, rep = xalglib.spline1dfitpenalized(x, y, n, m, rho)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, s, rep = xalglib.spline1dfitpenalized(x, y, m, rho)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          m:          int
          rho:        float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          s:          class xalglib.spline1dinterpolant
          rep:        class xalglib.spline1dfitreport

</div></pre>
<a name='sub_spline1dfitpenalizedw'></a><h3 class=pageheader><code>spline1dfitpenalizedw</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is an obsolete and deprecated version of fitting by
# penalized cubic spline.
# 
# It was superseded by spline1dfit(), which is an orders of magnitude faster
# and more memory-efficient implementation.
# 
# Do NOT use this function in the new code!
# 
#   -- ALGLIB PROJECT --
#      Copyright 19.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, s, rep = xalglib.spline1dfitpenalizedw(x, y, w, n, m, rho)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, s, rep = xalglib.spline1dfitpenalizedw(x, y, w, m, rho)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          w:          1D array/list of float
          n:          int
          m:          int
          rho:        float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          s:          class xalglib.spline1dinterpolant
          rep:        class xalglib.spline1dfitreport

</div></pre>
<a name=unit_inverseupdate></a><h2 class=pageheader><code>inverseupdate</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_rmatrixinvupdatecolumn' class=toc>rmatrixinvupdatecolumn</a><br>
<a href='#sub_rmatrixinvupdaterow' class=toc>rmatrixinvupdaterow</a><br>
<a href='#sub_rmatrixinvupdatesimple' class=toc>rmatrixinvupdatesimple</a><br>
<a href='#sub_rmatrixinvupdateuv' class=toc>rmatrixinvupdateuv</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_rmatrixinvupdatecolumn'></a><h3 class=pageheader><code>rmatrixinvupdatecolumn</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inverse matrix update by the Sherman-Morrison formula
# 
# The algorithm updates matrix A^-1 when adding a vector to a column
# of matrix A.
# 
# Input parameters:
#     InvA        -   inverse of matrix A.
#                     Array whose indexes range within [0..N-1, 0..N-1].
#     N           -   size of matrix A.
#     UpdColumn   -   the column of A whose vector U was added.
#                     0 &lt;= UpdColumn &lt;= N-1
#     U           -   the vector to be added to a column.
#                     Array whose index ranges within [0..N-1].
# 
# Output parameters:
#     InvA        -   inverse of modified matrix A.
# 
#   -- ALGLIB --
#      Copyright 2005 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixinvupdatecolumn(inva, n, updcolumn, u)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     inva:       2D array/list of float
          n:          int
          updcolumn:  int
          u:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> inva
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixinvupdaterow'></a><h3 class=pageheader><code>rmatrixinvupdaterow</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inverse matrix update by the Sherman-Morrison formula
# 
# The algorithm updates matrix A^-1 when adding a vector to a row
# of matrix A.
# 
# Input parameters:
#     InvA    -   inverse of matrix A.
#                 Array whose indexes range within [0..N-1, 0..N-1].
#     N       -   size of matrix A.
#     UpdRow  -   the row of A whose vector V was added.
#                 0 &lt;= Row &lt;= N-1
#     V       -   the vector to be added to a row.
#                 Array whose index ranges within [0..N-1].
# 
# Output parameters:
#     InvA    -   inverse of modified matrix A.
# 
#   -- ALGLIB --
#      Copyright 2005 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixinvupdaterow(inva, n, updrow, v)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     inva:       2D array/list of float
          n:          int
          updrow:     int
          v:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> inva
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixinvupdatesimple'></a><h3 class=pageheader><code>rmatrixinvupdatesimple</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inverse matrix update by the Sherman-Morrison formula
# 
# The algorithm updates matrix A^-1 when adding a number to an element
# of matrix A.
# 
# Input parameters:
#     InvA    -   inverse of matrix A.
#                 Array whose indexes range within [0..N-1, 0..N-1].
#     N       -   size of matrix A.
#     UpdRow  -   row where the element to be updated is stored.
#     UpdColumn - column where the element to be updated is stored.
#     UpdVal  -   a number to be added to the element.
# 
# 
# Output parameters:
#     InvA    -   inverse of modified matrix A.
# 
#   -- ALGLIB --
#      Copyright 2005 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixinvupdatesimple(inva, n, updrow, updcolumn, updval)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     inva:       2D array/list of float
          n:          int
          updrow:     int
          updcolumn:  int
          updval:     float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> inva
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixinvupdateuv'></a><h3 class=pageheader><code>rmatrixinvupdateuv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inverse matrix update by the Sherman-Morrison formula
# 
# The algorithm computes the inverse of matrix A+u*v' by using the given matrix
# A^-1 and the vectors u and v.
# 
# Input parameters:
#     InvA    -   inverse of matrix A.
#                 Array whose indexes range within [0..N-1, 0..N-1].
#     N       -   size of matrix A.
#     U       -   the vector modifying the matrix.
#                 Array whose index ranges within [0..N-1].
#     V       -   the vector modifying the matrix.
#                 Array whose index ranges within [0..N-1].
# 
# Output parameters:
#     InvA - inverse of matrix A + u*v'.
# 
#   -- ALGLIB --
#      Copyright 2005 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixinvupdateuv(inva, n, u, v)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     inva:       2D array/list of float
          n:          int
          u:          1D array/list of float
          v:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> inva
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_iterativesparse></a><h2 class=pageheader><code>iterativesparse</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_sparsesolvegmres' class=toc>sparsesolvegmres</a><br>
<a href='#sub_sparsesolvercreate' class=toc>sparsesolvercreate</a><br>
<a href='#sub_sparsesolverooccontinue' class=toc>sparsesolverooccontinue</a><br>
<a href='#sub_sparsesolveroocgetrequestdata' class=toc>sparsesolveroocgetrequestdata</a><br>
<a href='#sub_sparsesolveroocgetrequestdata1' class=toc>sparsesolveroocgetrequestdata1</a><br>
<a href='#sub_sparsesolveroocgetrequestinfo' class=toc>sparsesolveroocgetrequestinfo</a><br>
<a href='#sub_sparsesolveroocsendresult' class=toc>sparsesolveroocsendresult</a><br>
<a href='#sub_sparsesolveroocstart' class=toc>sparsesolveroocstart</a><br>
<a href='#sub_sparsesolveroocstop' class=toc>sparsesolveroocstop</a><br>
<a href='#sub_sparsesolverrequesttermination' class=toc>sparsesolverrequesttermination</a><br>
<a href='#sub_sparsesolverresults' class=toc>sparsesolverresults</a><br>
<a href='#sub_sparsesolversetalgogmres' class=toc>sparsesolversetalgogmres</a><br>
<a href='#sub_sparsesolversetcond' class=toc>sparsesolversetcond</a><br>
<a href='#sub_sparsesolversetstartingpoint' class=toc>sparsesolversetstartingpoint</a><br>
<a href='#sub_sparsesolversetxrep' class=toc>sparsesolversetxrep</a><br>
<a href='#sub_sparsesolversolve' class=toc>sparsesolversolve</a><br>
<a href='#sub_sparsesolversolvesymmetric' class=toc>sparsesolversolvesymmetric</a><br>
<a href='#sub_sparsesolvesymmetricgmres' class=toc>sparsesolvesymmetricgmres</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_sparsesolvegmres'></a><h3 class=pageheader><code>sparsesolvegmres</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Solving sparse linear system A*x=b using GMRES(k) method.
# 
# This function provides convenience API for an 'expert' interface  provided
# by SparseSolverState class. Use SparseSolver  API  if  you  need  advanced
# functions like providing initial point, using out-of-core API and so on.
# 
# INPUT PARAMETERS:
#     A       -   sparse NxN matrix in any sparse storage format. Using  CRS
#                 format   is   recommended   because   it  avoids  internal
#                 conversion.
#                 An exception will be generated if  A  is  not  NxN  matrix
#                 (where  N  is  a  size   specified  during  solver  object
#                 creation).
#     B       -   right part, array[N]
#     K       -   k parameter for  GMRES(k), k&gt;=0.  Zero  value  means  that
#                 algorithm will choose it automatically.
#     EpsF    -   stopping condition, EpsF&gt;=0. The algorithm will stop  when
#                 residual will decrease below EpsF*|B|. Having EpsF=0 means
#                 that this stopping condition is ignored.
#     MaxIts  -   stopping condition, MaxIts&gt;=0.  The  algorithm  will  stop
#                 after performing MaxIts iterations. Zero  value  means  no
#                 limit.
# 
# NOTE: having both EpsF=0 and MaxIts=0 means that stopping criteria will be
#       chosen automatically.
# 
# OUTPUT PARAMETERS:
#     X       -   array[N], the solution
#     Rep     -   solution report:
#                 * Rep.TerminationType completion code:
#                     * -5    CG method was used for a matrix which  is  not
#                             positive definite
#                     * -4    overflow/underflow during solution
#                             (ill conditioned problem)
#                     *  1    ||residual||&lt;=EpsF*||b||
#                     *  5    MaxIts steps was taken
#                     *  7    rounding errors prevent further progress,
#                             best point found is returned
#                     *  8    the  algorithm  was  terminated   early  with
#                             SparseSolverRequestTermination() being called
#                             from other thread.
#                 * Rep.IterationsCount contains iterations count
#                 * Rep.NMV contains number of matrix-vector calculations
#                 * Rep.R2 contains squared residual
# 
#   -- ALGLIB --
#      Copyright 25.09.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.sparsesolvegmres(a, b, k, epsf, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          b:          1D array/list of float
          k:          int
          epsf:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.sparsesolverreport

</div></pre>
<a name='sub_sparsesolvercreate'></a><h3 class=pageheader><code>sparsesolvercreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function initializes sparse linear iterative solver object.
# 
# This solver can be used  to  solve  nonsymmetric  and  symmetric  positive
# definite NxN (square) linear systems.
# 
# The solver provides  'expert'  API  which  allows  advanced  control  over
# algorithms being used, including ability to get progress report, terminate
# long-running solver from other thread, out-of-core solution and so on.
# 
# NOTE: there are also convenience  functions  that  allows  quick  one-line
#       access to the solvers:
#       * SparseSolveCG() to solve SPD linear systems
#       * SparseSolveGMRES() to solve unsymmetric linear systems.
# 
# NOTE: if you want to solve MxN (rectangular) linear problem  you  may  use
#       LinLSQR solver provided by ALGLIB.
# 
# USAGE (A is given by the SparseMatrix structure):
# 
#     1. User initializes algorithm state with SparseSolverCreate() call
#     2. User  selects   algorithm  with one of the SparseSolverSetAlgo???()
#        functions. By default, GMRES(k) is used with automatically chosen k
#     3. Optionally, user tunes solver parameters, sets starting point, etc.
#     4. Depending on whether system is symmetric or not, user calls:
#        * SparseSolverSolveSymmetric() for a  symmetric system given by its
#          lower or upper triangle
#        * SparseSolverSolve() for a nonsymmetric system or a symmetric  one
#          given by the full matrix
#     5. User calls SparseSolverResults() to get the solution
# 
#     It is possible to call SparseSolverSolve???() again to  solve  another
#     task with same dimensionality but different matrix and/or  right  part
#     without reinitializing SparseSolverState structure.
# 
# USAGE (out-of-core mode):
# 
#     1. User initializes algorithm state with SparseSolverCreate() call
#     2. User  selects   algorithm  with one of the SparseSolverSetAlgo???()
#        functions. By default, GMRES(k) is used with automatically chosen k
#     3. Optionally, user tunes solver parameters, sets starting point, etc.
#     4. After that user should work with out-of-core interface  in  a  loop
#        like one given below:
# 
#         &gt; alglib.sparsesolveroocstart(state)
#         &gt; while alglib.sparsesolverooccontinue(state) do
#         &gt;     alglib.sparsesolveroocgetrequestinfo(state, out RequestType)
#         &gt;     alglib.sparsesolveroocgetrequestdata(state, out X)
#         &gt;     if RequestType=0 then
#         &gt;         [calculate  Y=A*X, with X=R^N]
#         &gt;     alglib.sparsesolveroocsendresult(state, in Y)
#         &gt; alglib.sparsesolveroocstop(state, out X, out Report)
# 
# INPUT PARAMETERS:
#     N       -   problem dimensionality (fixed at start-up)
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 24.09.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.sparsesolvercreate(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.sparsesolverstate

</div></pre>
<a name='sub_sparsesolverooccontinue'></a><h3 class=pageheader><code>sparsesolverooccontinue</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function performs iterative solution of  the  linear  system  in  the
# out-of-core mode. It should be used in conjunction with other out-of-core-
# related functions of this subspackage in a loop like one given below:
# 
# &gt; alglib.sparsesolveroocstart(state)
# &gt; while alglib.sparsesolverooccontinue(state) do
# &gt;     alglib.sparsesolveroocgetrequestinfo(state, out RequestType)
# &gt;     alglib.sparsesolveroocgetrequestdata(state, out X)
# &gt;     if RequestType=0 then
# &gt;         [calculate  Y=A*X, with X=R^N]
# &gt;     alglib.sparsesolveroocsendresult(state, in Y)
# &gt; alglib.sparsesolveroocstop(state, out X, out Report)
# 
#   -- ALGLIB --
#      Copyright 24.09.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sparsesolverooccontinue(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.sparsesolverstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_sparsesolveroocgetrequestdata'></a><h3 class=pageheader><code>sparsesolveroocgetrequestdata</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used  to  retrieve  vector  associated  with  out-of-core
# request sent by the solver to user code. Depending  on  the  request  type
# (returned by the SparseSolverOOCGetRequestInfo()) this  vector  should  be
# multiplied by A or subjected to another processing.
# 
# It should be used in conjunction with other out-of-core-related  functions
# of this subspackage in a loop like one given below:
# 
# &gt; alglib.sparsesolveroocstart(state)
# &gt; while alglib.sparsesolverooccontinue(state) do
# &gt;     alglib.sparsesolveroocgetrequestinfo(state, out RequestType)
# &gt;     alglib.sparsesolveroocgetrequestdata(state, out X)
# &gt;     if RequestType=0 then
# &gt;         [calculate  Y=A*X, with X=R^N]
# &gt;     alglib.sparsesolveroocsendresult(state, in Y)
# &gt; alglib.sparsesolveroocstop(state, out X, out Report)
# 
# INPUT PARAMETERS:
#     State           -   solver running in out-of-core mode
#     X               -   possibly  preallocated   storage;  reallocated  if
#                         needed, left unchanged, if large enough  to  store
#                         request data.
# 
# OUTPUT PARAMETERS:
#     X               -   array[N] or larger, leading N elements are  filled
#                         with vector X.
# 
# 
#   -- ALGLIB --
#      Copyright 24.09.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.sparsesolveroocgetrequestdata(state, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.sparsesolverstate
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float

</div></pre>
<a name='sub_sparsesolveroocgetrequestdata1'></a><h3 class=pageheader><code>sparsesolveroocgetrequestdata1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to retrieve scalar value associated with out-of-core
# request sent by the solver to user code. In  the  current  ALGLIB  version
# this function is used to retrieve squared residual  norm  during  progress
# reports.
# 
# INPUT PARAMETERS:
#     State           -   solver running in out-of-core mode
# 
# OUTPUT PARAMETERS:
#     V               -   scalar value associated with the current request
# 
# 
#   -- ALGLIB --
#      Copyright 24.09.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   v = xalglib.sparsesolveroocgetrequestdata1(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.sparsesolverstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  v:          float

</div></pre>
<a name='sub_sparsesolveroocgetrequestinfo'></a><h3 class=pageheader><code>sparsesolveroocgetrequestinfo</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to retrieve information  about  out-of-core  request
# sent by the solver:
# * RequestType=0  means that matrix-vector products A*x is requested
# * RequestType=-1 means that solver reports its progress; this  request  is
#   returned only when reports are activated wit SparseSolverSetXRep().
# 
# This function returns just request type; in order  to  get contents of the
# trial vector, use sparsesolveroocgetrequestdata().
# 
# It should be used in conjunction with other out-of-core-related  functions
# of this subspackage in a loop like one given below:
# 
# &gt; alglib.sparsesolveroocstart(state)
# &gt; while alglib.sparsesolverooccontinue(state) do
# &gt;     alglib.sparsesolveroocgetrequestinfo(state, out RequestType)
# &gt;     alglib.sparsesolveroocgetrequestdata(state, out X)
# &gt;     if RequestType=0 then
# &gt;         [calculate  Y=A*X, with X=R^N]
# &gt;     alglib.sparsesolveroocsendresult(state, in Y)
# &gt; alglib.sparsesolveroocstop(state, out X, out Report)
# 
# INPUT PARAMETERS:
#     State           -   solver running in out-of-core mode
# 
# OUTPUT PARAMETERS:
#     RequestType     -   type of the request to process:
#                         * 0   for matrix-vector product A*x, with A  being
#                           NxN system matrix  and X being N-dimensional
#                           vector
#                         *-1   for location and residual report
# 
# 
#   -- ALGLIB --
#      Copyright 24.09.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   requesttype = xalglib.sparsesolveroocgetrequestinfo(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.sparsesolverstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  requesttype: int

</div></pre>
<a name='sub_sparsesolveroocsendresult'></a><h3 class=pageheader><code>sparsesolveroocsendresult</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to send user reply to out-of-core  request  sent  by
# the solver. Usually it is product A*x for vector X returned by the solver.
# 
# It should be used in conjunction with other out-of-core-related  functions
# of this subspackage in a loop like one given below:
# 
# &gt; alglib.sparsesolveroocstart(state)
# &gt; while alglib.sparsesolverooccontinue(state) do
# &gt;     alglib.sparsesolveroocgetrequestinfo(state, out RequestType)
# &gt;     alglib.sparsesolveroocgetrequestdata(state, out X)
# &gt;     if RequestType=0 then
# &gt;         [calculate  Y=A*X, with X=R^N]
# &gt;     alglib.sparsesolveroocsendresult(state, in Y)
# &gt; alglib.sparsesolveroocstop(state, out X, out Report)
# 
# INPUT PARAMETERS:
#     State           -   solver running in out-of-core mode
#     AX              -   array[N] or larger, leading N elements contain A*x
# 
# 
#   -- ALGLIB --
#      Copyright 24.09.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsesolveroocsendresult(state, ax)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.sparsesolverstate
          ax:         1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsesolveroocstart'></a><h3 class=pageheader><code>sparsesolveroocstart</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function initiates out-of-core mode of the sparse solver.  It  should
# be used in conjunction with other out-of-core-related  functions  of  this
# subspackage in a loop like one given below:
# 
# &gt; alglib.sparsesolveroocstart(state)
# &gt; while alglib.sparsesolverooccontinue(state) do
# &gt;     alglib.sparsesolveroocgetrequestinfo(state, out RequestType)
# &gt;     alglib.sparsesolveroocgetrequestdata(state, out X)
# &gt;     if RequestType=0 then
# &gt;         [calculate  Y=A*X, with X=R^N]
# &gt;     alglib.sparsesolveroocsendresult(state, in Y)
# &gt; alglib.sparsesolveroocstop(state, out X, out Report)
# 
# INPUT PARAMETERS:
#     State       -   solver object
# 
#   -- ALGLIB --
#      Copyright 24.09.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsesolveroocstart(state, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.sparsesolverstate
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsesolveroocstop'></a><h3 class=pageheader><code>sparsesolveroocstop</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  finalizes out-of-core mode of the linear solver. It should
# be used in conjunction with other out-of-core-related  functions  of  this
# subspackage in a loop like one given below:
# 
# &gt; alglib.sparsesolveroocstart(state)
# &gt; while alglib.sparsesolverooccontinue(state) do
# &gt;     alglib.sparsesolveroocgetrequestinfo(state, out RequestType)
# &gt;     alglib.sparsesolveroocgetrequestdata(state, out X)
# &gt;     if RequestType=0 then
# &gt;         [calculate  Y=A*X, with X=R^N]
# &gt;     alglib.sparsesolveroocsendresult(state, in Y)
# &gt; alglib.sparsesolveroocstop(state, out X, out Report)
# 
# INPUT PARAMETERS:
#     State       -   solver state
# 
# OUTPUT PARAMETERS:
#     X       -   array[N], the solution.
#                 Zero-filled on the failure (Rep.TerminationType&lt;0).
#     Rep     -   report with additional info:
#                 * Rep.TerminationType completion code:
#                     * -5    CG method was used for a matrix which  is  not
#                             positive definite
#                     * -4    overflow/underflow during solution
#                             (ill conditioned problem)
#                     *  1    ||residual||&lt;=EpsF*||b||
#                     *  5    MaxIts steps was taken
#                     *  7    rounding errors prevent further progress,
#                             best point found is returned
#                     *  8    the  algorithm  was  terminated   early  with
#                             SparseSolverRequestTermination() being called
#                             from other thread.
#                 * Rep.IterationsCount contains iterations count
#                 * Rep.NMV contains number of matrix-vector calculations
#                 * Rep.R2 contains squared residual
# 
#   -- ALGLIB --
#      Copyright 24.09.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.sparsesolveroocstop(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.sparsesolverstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.sparsesolverreport

</div></pre>
<a name='sub_sparsesolverrequesttermination'></a><h3 class=pageheader><code>sparsesolverrequesttermination</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine submits request for termination of the running solver.  It
# can be called from some other thread which wants the   solver to terminate
# or when processing an out-of-core request.
# 
# As result, solver  stops  at  point  which  was  &quot;current  accepted&quot;  when
# the termination request was submitted and returns error code 8 (successful
# termination).  Such   termination   is  a smooth  process  which  properly
# deallocates all temporaries.
# 
# INPUT PARAMETERS:
#     State   -   solver structure
# 
# NOTE: calling this function on solver which is NOT running  will  have  no
#       effect.
# 
# NOTE: multiple calls to this function are possible. First call is counted,
#       subsequent calls are silently ignored.
# 
# NOTE: solver clears termination flag on its start, it means that  if  some
#       other thread will request termination too soon, its request will went
#       unnoticed.
# 
#   -- ALGLIB --
#      Copyright 01.10.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsesolverrequesttermination(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.sparsesolverstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsesolverresults'></a><h3 class=pageheader><code>sparsesolverresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sparse solver results.
# 
# This function must be called after calling one of the SparseSolverSolve()
# functions.
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     X       -   array[N], solution
#     Rep     -   solution report:
#                 * Rep.TerminationType completion code:
#                     * -5    CG method was used for a matrix which  is  not
#                             positive definite
#                     * -4    overflow/underflow during solution
#                             (ill conditioned problem)
#                     *  1    ||residual||&lt;=EpsF*||b||
#                     *  5    MaxIts steps was taken
#                     *  7    rounding errors prevent further progress,
#                             best point found is returned
#                     *  8    the  algorithm  was  terminated   early  with
#                             SparseSolverRequestTermination() being called
#                             from other thread.
#                 * Rep.IterationsCount contains iterations count
#                 * Rep.NMV contains number of matrix-vector calculations
#                 * Rep.R2 contains squared residual
# s
#   -- ALGLIB --
#      Copyright 14.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.sparsesolverresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.sparsesolverstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.sparsesolverreport

</div></pre>
<a name='sub_sparsesolversetalgogmres'></a><h3 class=pageheader><code>sparsesolversetalgogmres</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets the solver algorithm to GMRES(k).
# 
# NOTE: if you do not need advanced functionality of the  SparseSolver  API,
#       you   may   use   convenience   functions   SparseSolveGMRES()   and
#       SparseSolveSymmetricGMRES().
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     K       -   GMRES parameter, K&gt;=0:
#                 * recommended values are in 10..100 range
#                 * larger values up to N are possible but have little sense
#                   - the algorithm will be slower than any dense solver.
#                 * values above N are truncated down to N
#                 * zero value means that  default  value  is  chosen.  This
#                   value is 50 in the current version, but  it  may  change
#                   in future ALGLIB releases.
# 
#   -- ALGLIB --
#      Copyright 24.09.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsesolversetalgogmres(state, k)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.sparsesolverstate
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsesolversetcond'></a><h3 class=pageheader><code>sparsesolversetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping criteria.
# 
# INPUT PARAMETERS:
#     EpsF    -   algorithm will be stopped if norm of residual is less than
#                 EpsF*||b||.
#     MaxIts  -   algorithm will be stopped if number of iterations is  more
#                 than MaxIts.
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# NOTES:
# If  both  EpsF  and  MaxIts  are  zero then small EpsF will be set to small
# value.
# 
#   -- ALGLIB --
#      Copyright 14.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsesolversetcond(state, epsf, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.sparsesolverstate
          epsf:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsesolversetstartingpoint'></a><h3 class=pageheader><code>sparsesolversetstartingpoint</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets starting point.
# By default, zero starting point is used.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     X       -   starting point, array[N]
# 
# OUTPUT PARAMETERS:
#     State   -   new starting point was set
# 
#   -- ALGLIB --
#      Copyright 24.09.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsesolversetstartingpoint(state, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.sparsesolverstate
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsesolversetxrep'></a><h3 class=pageheader><code>sparsesolversetxrep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function turns on/off reporting during out-of-core processing.
# 
# When the solver works in the out-of-core mode, it  can  be  configured  to
# report its progress by returning current location. These location  reports
# are implemented as a special kind of the out-of-core request:
# * SparseSolverOOCGetRequestInfo() returns -1
# * SparseSolverOOCGetRequestData() returns current location
# * SparseSolverOOCGetRequestData1() returns squared norm of the residual
# * SparseSolverOOCSendResult() shall NOT be called
# 
# This function has no effect when SparseSolverSolve() is used because  this
# function has no method of reporting its progress.
# 
# NOTE: when used with GMRES(k), this function reports progress  every  k-th
#       iteration.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     NeedXRep-   whether iteration reports are needed or not
# 
#   -- ALGLIB --
#      Copyright 01.10.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsesolversetxrep(state, needxrep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.sparsesolverstate
          needxrep:   bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsesolversolve'></a><h3 class=pageheader><code>sparsesolversolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Procedure for the solution of A*x=b with sparse nonsymmetric A
# 
# IMPORTANT: this function will work with any solver algorithm  being  used,
#            symmetric solver like CG,  or  not.  However,  using  symmetric
#            solvers on nonsymmetric problems is  dangerous.  It  may  solve
#            the problem up  to  desired  precision  (sometimes,  rarely) or
#            terminate with error code signalling  violation  of  underlying
#            assumptions.
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
#     A       -   sparse NxN matrix in any sparse storage  format.
#                 Using CRS format is recommended because it avoids internal
#                 conversion.
#                 An exception will be generated if  A  is  not  NxN  matrix
#                 (where  N  is  a  size   specified  during  solver  object
#                 creation).
#     B       -   right part, array[N]
# 
# RESULT:
#     This function returns no result.
#     You can get the solution by calling SparseSolverResults()
# 
#   -- ALGLIB --
#      Copyright 25.09.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsesolversolve(state, a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.sparsesolverstate
          a:          class xalglib.sparsematrix
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsesolversolvesymmetric'></a><h3 class=pageheader><code>sparsesolversolvesymmetric</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Procedure for  the  solution of A*x=b with sparse symmetric A given by its
# lower or upper triangle.
# 
# This function will work with any solver algorithm  being   used,  SPD  one
# (like CG) or not (like GMRES). Using unsymmetric solvers (like  GMRES)  on
# SPD problems is suboptimal, but still possible.
# 
# NOTE: the  solver  behavior is ill-defined  for  a  situation  when a  SPD
#       solver is used on indefinite matrix. It  may solve the problem up to
#       desired precision (sometimes, rarely)  or  return  with  error  code
#       signalling violation of underlying assumptions.
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
#     A       -   sparse symmetric NxN matrix in any sparse storage  format.
#                 Using CRS format is recommended because it avoids internal
#                 conversion.
#                 An exception will be generated if  A  is  not  NxN  matrix
#                 (where  N  is  a  size   specified  during  solver  object
#                 creation).
#     IsUpper -   whether upper or lower triangle of A is used:
#                 * IsUpper=True  =&gt; only upper triangle is used and lower
#                                    triangle is not referenced at all
#                 * IsUpper=False =&gt; only lower triangle is used and upper
#                                    triangle is not referenced at all
#     B       -   right part, array[N]
# 
# RESULT:
#     This function returns no result.
#     You can get the solution by calling SparseSolverResults()
# 
#   -- ALGLIB --
#      Copyright 25.09.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsesolversolvesymmetric(state, a, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.sparsesolverstate
          a:          class xalglib.sparsematrix
          isupper:    bool
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsesolvesymmetricgmres'></a><h3 class=pageheader><code>sparsesolvesymmetricgmres</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Solving sparse symmetric linear system A*x=b using GMRES(k) method. Sparse
# symmetric A is given by its lower or upper triangle.
# 
# NOTE: use SparseSolveGMRES() to solve system with nonsymmetric A.
# 
# This function provides convenience API for an 'expert' interface  provided
# by SparseSolverState class. Use SparseSolver  API  if  you  need  advanced
# functions like providing initial point, using out-of-core API and so on.
# 
# INPUT PARAMETERS:
#     A       -   sparse symmetric NxN matrix in any sparse storage  format.
#                 Using CRS format is recommended because it avoids internal
#                 conversion.
#                 An exception will be generated if  A  is  not  NxN  matrix
#                 (where  N  is  a  size   specified  during  solver  object
#                 creation).
#     IsUpper -   whether upper or lower triangle of A is used:
#                 * IsUpper=True  =&gt; only upper triangle is used and lower
#                                    triangle is not referenced at all
#                 * IsUpper=False =&gt; only lower triangle is used and upper
#                                    triangle is not referenced at all
#     B       -   right part, array[N]
#     K       -   k parameter for  GMRES(k), k&gt;=0.  Zero  value  means  that
#                 algorithm will choose it automatically.
#     EpsF    -   stopping condition, EpsF&gt;=0. The algorithm will stop  when
#                 residual will decrease below EpsF*|B|. Having EpsF=0 means
#                 that this stopping condition is ignored.
#     MaxIts  -   stopping condition, MaxIts&gt;=0.  The  algorithm  will  stop
#                 after performing MaxIts iterations. Zero  value  means  no
#                 limit.
# 
# NOTE: having both EpsF=0 and MaxIts=0 means that stopping criteria will be
#       chosen automatically.
# 
# OUTPUT PARAMETERS:
#     X       -   array[N], the solution
#     Rep     -   solution report:
#                 * Rep.TerminationType completion code:
#                     * -5    CG method was used for a matrix which  is  not
#                             positive definite
#                     * -4    overflow/underflow during solution
#                             (ill conditioned problem)
#                     *  1    ||residual||&lt;=EpsF*||b||
#                     *  5    MaxIts steps was taken
#                     *  7    rounding errors prevent further progress,
#                             best point found is returned
#                     *  8    the  algorithm  was  terminated   early  with
#                             SparseSolverRequestTermination() being called
#                             from other thread.
#                 * Rep.IterationsCount contains iterations count
#                 * Rep.NMV contains number of matrix-vector calculations
#                 * Rep.R2 contains squared residual
# 
#   -- ALGLIB --
#      Copyright 25.09.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.sparsesolvesymmetricgmres(a, isupper, b, k, epsf, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          isupper:    bool
          b:          1D array/list of float
          k:          int
          epsf:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.sparsesolverreport

</div></pre>
<a name=unit_jacobianelliptic></a><h2 class=pageheader><code>jacobianelliptic</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_jacobianellipticfunctions' class=toc>jacobianellipticfunctions</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_jacobianellipticfunctions'></a><h3 class=pageheader><code>jacobianellipticfunctions</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Jacobian Elliptic Functions
# 
# Evaluates the Jacobian elliptic functions sn(u|m), cn(u|m),
# and dn(u|m) of parameter m between 0 and 1, and real
# argument u.
# 
# These functions are periodic, with quarter-period on the
# real axis equal to the complete elliptic integral
# ellpk(1.0-m).
# 
# Relation to incomplete elliptic integral:
# If u = ellik(phi,m), then sn(u|m) = sin(phi),
# and cn(u|m) = cos(phi).  Phi is called the amplitude of u.
# 
# Computation is by means of the arithmetic-geometric mean
# algorithm, except when m is within 1e-9 of 0 or 1.  In the
# latter case with m close to 1, the approximation applies
# only for phi &lt; pi/2.
# 
# ACCURACY:
# 
# Tested at random points with u between 0 and 10, m between
# 0 and 1.
# 
#            Absolute error (* = relative error):
# arithmetic   function   # trials      peak         rms
#    IEEE      phi         10000       9.2e-16*    1.4e-16*
#    IEEE      sn          50000       4.1e-15     4.6e-16
#    IEEE      cn          40000       3.6e-15     4.4e-16
#    IEEE      dn          10000       1.3e-12     1.8e-14
# 
#  Peak error observed in consistency check using addition
# theorem for sn(u+v) was 4e-16 (absolute).  Also tested by
# the above relation to the incomplete elliptic integral.
# Accuracy deteriorates when u is large.
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   sn, cn, dn, ph = xalglib.jacobianellipticfunctions(u, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     u:          float
          m:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  sn:         float
          cn:         float
          dn:         float
          ph:         float

</div></pre>
<a name=unit_jarquebera></a><h2 class=pageheader><code>jarquebera</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_jarqueberatest' class=toc>jarqueberatest</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_jarqueberatest'></a><h3 class=pageheader><code>jarqueberatest</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Jarque-Bera test
# 
# This test checks hypotheses about the fact that a  given  sample  X  is  a
# sample of normal random variable.
# 
# Requirements:
#     * the number of elements in the sample is not less than 5.
# 
# Input parameters:
#     X   -   sample. Array whose index goes from 0 to N-1.
#     N   -   size of the sample. N&gt;=5
# 
# Output parameters:
#     P           -   p-value for the test
# 
# Accuracy of the approximation used (5&lt;=N&lt;=1951):
# 
# p-value  	    relative error (5&lt;=N&lt;=1951)
# [1, 0.1]            &lt; 1%
# [0.1, 0.01]         &lt; 2%
# [0.01, 0.001]       &lt; 6%
# [0.001, 0]          wasn't measured
# 
# For N&gt;1951 accuracy wasn't measured but it shouldn't be sharply  different
# from table values.
# 
#   -- ALGLIB --
#      Copyright 09.04.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.jarqueberatest(x, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          float

</div></pre>
<a name=unit_knn></a><h2 class=pageheader><code>knn</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_knnallerrors' class=toc>knnallerrors</a><br>
<a href='#sub_knnavgce' class=toc>knnavgce</a><br>
<a href='#sub_knnavgerror' class=toc>knnavgerror</a><br>
<a href='#sub_knnavgrelerror' class=toc>knnavgrelerror</a><br>
<a href='#sub_knnbuilderbuildknnmodel' class=toc>knnbuilderbuildknnmodel</a><br>
<a href='#sub_knnbuildercreate' class=toc>knnbuildercreate</a><br>
<a href='#sub_knnbuildersetdatasetcls' class=toc>knnbuildersetdatasetcls</a><br>
<a href='#sub_knnbuildersetdatasetreg' class=toc>knnbuildersetdatasetreg</a><br>
<a href='#sub_knnbuildersetnorm' class=toc>knnbuildersetnorm</a><br>
<a href='#sub_knnclassify' class=toc>knnclassify</a><br>
<a href='#sub_knncreatebuffer' class=toc>knncreatebuffer</a><br>
<a href='#sub_knnprocess' class=toc>knnprocess</a><br>
<a href='#sub_knnprocess0' class=toc>knnprocess0</a><br>
<a href='#sub_knnprocessi' class=toc>knnprocessi</a><br>
<a href='#sub_knnrelclserror' class=toc>knnrelclserror</a><br>
<a href='#sub_knnrewritekeps' class=toc>knnrewritekeps</a><br>
<a href='#sub_knnrmserror' class=toc>knnrmserror</a><br>
<a href='#sub_knntsprocess' class=toc>knntsprocess</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_knnallerrors'></a><h3 class=pageheader><code>knnallerrors</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Calculates all kinds of errors for the model in one call.
# 
# INPUT PARAMETERS:
#     Model   -   KNN model
#     XY      -   test set:
#                 * one row per point
#                 * first NVars columns store independent variables
#                 * depending on problem type:
#                   * next column stores class number in [0,NClasses) -  for
#                     classification problems
#                   * next NOut columns  store  dependent  variables  -  for
#                     regression problems
#     NPoints -   test set size, NPoints&gt;=0
# 
# OUTPUT PARAMETERS:
#     Rep     -   following fields are loaded with errors for both regression
#                 and classification models:
#                 * rep.rmserror - RMS error for the output
#                 * rep.avgerror - average error
#                 * rep.avgrelerror - average relative error
#                 following fields are set only  for classification  models,
#                 zero for regression ones:
#                 * relclserror   - relative classification error, in [0,1]
#                 * avgce - average cross-entropy in bits per dataset entry
# 
# NOTE: the cross-entropy metric is too unstable when used to  evaluate  KNN
#       models (such models can report exactly  zero probabilities),  so  we
#       do not recommend using it.
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.knnallerrors(model, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     model:      class xalglib.knnmodel
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.knnreport

</div></pre>
<a name='sub_knnavgce'></a><h3 class=pageheader><code>knnavgce</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average cross-entropy (in bits per element) on the test set
# 
# INPUT PARAMETERS:
#     Model   -   KNN model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     CrossEntropy/NPoints.
#     Zero if model solves regression task.
# 
# NOTE: the cross-entropy metric is too unstable when used to  evaluate  KNN
#       models (such models can report exactly  zero probabilities),  so  we
#       do not recommend using it.
# 
# NOTE: if  you  need several different kinds of error metrics, it is better
#       to use knnallerrors() which computes all error metric  with just one
#       pass over dataset.
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.knnavgce(model, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     model:      class xalglib.knnmodel
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_knnavgerror'></a><h3 class=pageheader><code>knnavgerror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average error on the test set
# 
# Its meaning for regression task is obvious. As for classification problems,
# average error means error when estimating posterior probabilities.
# 
# INPUT PARAMETERS:
#     Model   -   KNN model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     average error
# 
# NOTE: if  you  need several different kinds of error metrics, it is better
#       to use knnallerrors() which computes all error metric  with just one
#       pass over dataset.
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.knnavgerror(model, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     model:      class xalglib.knnmodel
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_knnavgrelerror'></a><h3 class=pageheader><code>knnavgrelerror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average relative error on the test set
# 
# Its meaning for regression task is obvious. As for classification problems,
# average relative error means error when estimating posterior probabilities.
# 
# INPUT PARAMETERS:
#     Model   -   KNN model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     average relative error
# 
# NOTE: if  you  need several different kinds of error metrics, it is better
#       to use knnallerrors() which computes all error metric  with just one
#       pass over dataset.
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.knnavgrelerror(model, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     model:      class xalglib.knnmodel
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_knnbuilderbuildknnmodel'></a><h3 class=pageheader><code>knnbuilderbuildknnmodel</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds KNN model  according  to  current  settings,  using
# dataset internally stored in the builder object.
# 
# The model being built performs inference using Eps-approximate  K  nearest
# neighbors search algorithm, with:
# * K=1,  Eps=0 corresponding to the &quot;nearest neighbor algorithm&quot;
# * K&gt;1,  Eps=0 corresponding to the &quot;K nearest neighbors algorithm&quot;
# * K&gt;=1, Eps&gt;0 corresponding to &quot;approximate nearest neighbors algorithm&quot;
# 
# An approximate KNN is a good option for high-dimensional  datasets  (exact
# KNN works slowly when dimensions count grows).
# 
# An ALGLIB implementation of kd-trees is used to perform k-nn searches.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     S       -   KNN builder object
#     K       -   number of neighbors to search for, K&gt;=1
#     Eps     -   approximation factor:
#                 * Eps=0 means that exact kNN search is performed
#                 * Eps&gt;0 means that (1+Eps)-approximate search is performed
# 
# OUTPUT PARAMETERS:
#     Model       -   KNN model
#     Rep         -   report
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   model, rep = xalglib.knnbuilderbuildknnmodel(s, k, eps)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.knnbuilder
          k:          int
          eps:        float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  model:      class xalglib.knnmodel
          rep:        class xalglib.knnreport

</div></pre>
<a name='sub_knnbuildercreate'></a><h3 class=pageheader><code>knnbuildercreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine creates KNNBuilder object which is used to train KNN models.
# 
# By default, new builder stores empty dataset and some  reasonable  default
# settings. At the very least, you should specify dataset prior to  building
# KNN model. You can also tweak settings of the model construction algorithm
# (recommended, although default settings should work well).
# 
# Following actions are mandatory:
# * calling knnbuildersetdataset() to specify dataset
# * calling knnbuilderbuildknnmodel() to build KNN model using current
#   dataset and default settings
# 
# Additionally, you may call:
# * knnbuildersetnorm() to change norm being used
# 
# INPUT PARAMETERS:
#     none
# 
# OUTPUT PARAMETERS:
#     S           -   KNN builder
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.knnbuildercreate()
<span style='font-weight: bold; color: navy;'>ARGS:</span>     
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.knnbuilder

</div></pre>
<a name='sub_knnbuildersetdatasetcls'></a><h3 class=pageheader><code>knnbuildersetdatasetcls</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Specifies classification problem (two  or  more  classes  are  predicted).
# There also exists &quot;regression&quot; version of this function.
# 
# This subroutine adds dense dataset to the internal storage of the  builder
# object. Specifying your dataset in the dense format means that  the  dense
# version of the KNN construction algorithm will be invoked.
# 
# INPUT PARAMETERS:
#     S           -   KNN builder object
#     XY          -   array[NPoints,NVars+1] (note:   actual   size  can  be
#                     larger, only leading part is used anyway), dataset:
#                     * first NVars elements of each row store values of the
#                       independent variables
#                     * next element stores class index, in [0,NClasses)
#     NPoints     -   number of rows in the dataset, NPoints&gt;=1
#     NVars       -   number of independent variables, NVars&gt;=1
#     NClasses    -   number of classes, NClasses&gt;=2
# 
# OUTPUT PARAMETERS:
#     S           -   KNN builder
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.knnbuildersetdatasetcls(s, xy, npoints, nvars, nclasses)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.knnbuilder
          xy:         2D array/list of float
          npoints:    int
          nvars:      int
          nclasses:   int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_knnbuildersetdatasetreg'></a><h3 class=pageheader><code>knnbuildersetdatasetreg</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Specifies regression problem (one or more continuous  output variables are
# predicted). There also exists &quot;classification&quot; version of this function.
# 
# This subroutine adds dense dataset to the internal storage of the  builder
# object. Specifying your dataset in the dense format means that  the  dense
# version of the KNN construction algorithm will be invoked.
# 
# INPUT PARAMETERS:
#     S           -   KNN builder object
#     XY          -   array[NPoints,NVars+NOut] (note: actual  size  can  be
#                     larger, only leading part is used anyway), dataset:
#                     * first NVars elements of each row store values of the
#                       independent variables
#                     * next NOut elements store  values  of  the  dependent
#                       variables
#     NPoints     -   number of rows in the dataset, NPoints&gt;=1
#     NVars       -   number of independent variables, NVars&gt;=1
#     NOut        -   number of dependent variables, NOut&gt;=1
# 
# OUTPUT PARAMETERS:
#     S           -   KNN builder
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.knnbuildersetdatasetreg(s, xy, npoints, nvars, nout)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.knnbuilder
          xy:         2D array/list of float
          npoints:    int
          nvars:      int
          nout:       int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_knnbuildersetnorm'></a><h3 class=pageheader><code>knnbuildersetnorm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets norm type used for neighbor search.
# 
# INPUT PARAMETERS:
#     S           -   decision forest builder object
#     NormType    -   norm type:
#                     * 0      inf-norm
#                     * 1      1-norm
#                     * 2      Euclidean norm (default)
# 
# OUTPUT PARAMETERS:
#     S           -   decision forest builder
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.knnbuildersetnorm(s, nrmtype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.knnbuilder
          nrmtype:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_knnclassify'></a><h3 class=pageheader><code>knnclassify</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns most probable class number for an  input  X.  It  is
# same as calling knnprocess(model,x,y), then determining i=argmax(y[i]) and
# returning i.
# 
# A class number in [0,NOut) range in returned for classification  problems,
# -1 is returned when this function is called for regression problems.
# 
# IMPORTANT: this function is thread-unsafe and modifies internal structures
#            of the model! You can not use same model  object  for  parallel
#            evaluation from several threads.
# 
#            Use knntsprocess() with independent  thread-local  buffers,  if
#            you need thread-safe evaluation.
# 
# INPUT PARAMETERS:
#     Model   -   KNN model
#     X       -   input vector,  array[0..NVars-1].
# 
# RESULT:
#     class number, -1 for regression tasks
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.knnclassify(model, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     model:      class xalglib.knnmodel
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> model
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_knncreatebuffer'></a><h3 class=pageheader><code>knncreatebuffer</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates buffer  structure  which  can  be  used  to  perform
# parallel KNN requests.
# 
# KNN subpackage provides two sets of computing functions - ones  which  use
# internal buffer of KNN model (these  functions are single-threaded because
# they use same buffer, which can not  shared  between  threads),  and  ones
# which use external buffer.
# 
# This function is used to initialize external buffer.
# 
# INPUT PARAMETERS
#     Model       -   KNN model which is associated with newly created buffer
# 
# OUTPUT PARAMETERS
#     Buf         -   external buffer.
# 
# 
# IMPORTANT: buffer object should be used only with model which was used  to
#            initialize buffer. Any attempt to  use  buffer  with  different
#            object is dangerous - you  may   get  integrity  check  failure
#            (exception) because sizes of internal  arrays  do  not  fit  to
#            dimensions of the model structure.
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   buf = xalglib.knncreatebuffer(model)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     model:      class xalglib.knnmodel
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  buf:        class xalglib.knnbuffer

</div></pre>
<a name='sub_knnprocess'></a><h3 class=pageheader><code>knnprocess</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inference using KNN model.
# 
# See also knnprocess0(), knnprocessi() and knnclassify() for options with a
# bit more convenient interface.
# 
# IMPORTANT: this function is thread-unsafe and modifies internal structures
#            of the model! You can not use same model  object  for  parallel
#            evaluation from several threads.
# 
#            Use knntsprocess() with independent  thread-local  buffers,  if
#            you need thread-safe evaluation.
# 
# INPUT PARAMETERS:
#     Model   -   KNN model
#     X       -   input vector,  array[0..NVars-1].
#     Y       -   possible preallocated buffer. Reused if long enough.
# 
# OUTPUT PARAMETERS:
#     Y       -   result. Regression estimate when solving regression  task,
#                 vector of posterior probabilities for classification task.
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.knnprocess(model, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     model:      class xalglib.knnmodel
          x:          1D array/list of float
          y:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> model
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_knnprocess0'></a><h3 class=pageheader><code>knnprocess0</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns first component of the  inferred  vector  (i.e.  one
# with index #0).
# 
# It is a convenience wrapper for knnprocess() intended for either:
# * 1-dimensional regression problems
# * 2-class classification problems
# 
# In the former case this function returns inference result as scalar, which
# is definitely more convenient that wrapping it as vector.  In  the  latter
# case it returns probability of object belonging to class #0.
# 
# If you call it for anything different from two cases above, it  will  work
# as defined, i.e. return y[0], although it is of less use in such cases.
# 
# IMPORTANT: this function is thread-unsafe and modifies internal structures
#            of the model! You can not use same model  object  for  parallel
#            evaluation from several threads.
# 
#            Use knntsprocess() with independent  thread-local  buffers,  if
#            you need thread-safe evaluation.
# 
# INPUT PARAMETERS:
#     Model   -   KNN model
#     X       -   input vector,  array[0..NVars-1].
# 
# RESULT:
#     Y[0]
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.knnprocess0(model, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     model:      class xalglib.knnmodel
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> model
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_knnprocessi'></a><h3 class=pageheader><code>knnprocessi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 'interactive' variant of knnprocess()  for  languages  like  Python  which
# support constructs like &quot;y = knnprocessi(model,x)&quot; and interactive mode of
# the interpreter.
# 
# This function allocates new array on each call,  so  it  is  significantly
# slower than its 'non-interactive' counterpart, but it is  more  convenient
# when you call it from command line.
# 
# IMPORTANT: this  function  is  thread-unsafe  and  may   modify   internal
#            structures of the model! You can not use same model  object for
#            parallel evaluation from several threads.
# 
#            Use knntsprocess()  with  independent  thread-local  buffers if
#            you need thread-safe evaluation.
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.knnprocessi(model, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     model:      class xalglib.knnmodel
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> model
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_knnrelclserror'></a><h3 class=pageheader><code>knnrelclserror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Relative classification error on the test set
# 
# INPUT PARAMETERS:
#     Model   -   KNN model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     percent of incorrectly classified cases.
#     Zero if model solves regression task.
# 
# NOTE: if  you  need several different kinds of error metrics, it is better
#       to use knnallerrors() which computes all error metric  with just one
#       pass over dataset.
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.knnrelclserror(model, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     model:      class xalglib.knnmodel
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_knnrewritekeps'></a><h3 class=pageheader><code>knnrewritekeps</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Changing search settings of KNN model.
# 
# K and EPS parameters of KNN  (AKNN)  search  are  specified  during  model
# construction. However, plain KNN algorithm with Euclidean distance  allows
# you to change them at any moment.
# 
# NOTE: future versions of KNN model may support advanced versions  of  KNN,
#       such as NCA or LMNN. It is possible that such algorithms won't allow
#       you to change search settings on the fly. If you call this  function
#       for an algorithm which does not support on-the-fly changes, it  will
#       throw an exception.
# 
# INPUT PARAMETERS:
#     Model   -   KNN model
#     K       -   K&gt;=1, neighbors count
#     EPS     -   accuracy of the EPS-approximate NN search. Set to 0.0,  if
#                 you want to perform &quot;classic&quot; KNN search.  Specify  larger
#                 values  if  you  need  to  speed-up  high-dimensional  KNN
#                 queries.
# 
# OUTPUT PARAMETERS:
#     nothing on success, exception on failure
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.knnrewritekeps(model, k, eps)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     model:      class xalglib.knnmodel
          k:          int
          eps:        float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> model
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_knnrmserror'></a><h3 class=pageheader><code>knnrmserror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# RMS error on the test set.
# 
# Its meaning for regression task is obvious. As for classification problems,
# RMS error means error when estimating posterior probabilities.
# 
# INPUT PARAMETERS:
#     Model   -   KNN model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     root mean square error.
# 
# NOTE: if  you  need several different kinds of error metrics, it is better
#       to use knnallerrors() which computes all error metric  with just one
#       pass over dataset.
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.knnrmserror(model, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     model:      class xalglib.knnmodel
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_knntsprocess'></a><h3 class=pageheader><code>knntsprocess</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Thread-safe procesing using external buffer for temporaries.
# 
# This function is thread-safe (i.e .  you  can  use  same  KNN  model  from
# multiple threads) as long as you use different buffer objects for different
# threads.
# 
# INPUT PARAMETERS:
#     Model   -   KNN model
#     Buf     -   buffer object, must be  allocated  specifically  for  this
#                 model with knncreatebuffer().
#     X       -   input vector,  array[NVars]
# 
# OUTPUT PARAMETERS:
#     Y       -   result, array[NOut].   Regression  estimate  when  solving
#                 regression task,  vector  of  posterior  probabilities for
#                 a classification task.
# 
#   -- ALGLIB --
#      Copyright 15.02.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.knntsprocess(model, buf, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     model:      class xalglib.knnmodel
          buf:        class xalglib.knnbuffer
          x:          1D array/list of float
          y:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> buf
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name=unit_laguerre></a><h2 class=pageheader><code>laguerre</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_laguerrecalculate' class=toc>laguerrecalculate</a><br>
<a href='#sub_laguerrecoefficients' class=toc>laguerrecoefficients</a><br>
<a href='#sub_laguerresum' class=toc>laguerresum</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_laguerrecalculate'></a><h3 class=pageheader><code>laguerrecalculate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Calculation of the value of the Laguerre polynomial.
# 
# Parameters:
#     n   -   degree, n&gt;=0
#     x   -   argument
# 
# Result:
#     the value of the Laguerre polynomial Ln at x
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.laguerrecalculate(n, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_laguerrecoefficients'></a><h3 class=pageheader><code>laguerrecoefficients</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Representation of Ln as C[0] + C[1]*X + ... + C[N]*X^N
# 
# Input parameters:
#     N   -   polynomial degree, n&gt;=0
# 
# Output parameters:
#     C   -   coefficients
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.laguerrecoefficients(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of float

</div></pre>
<a name='sub_laguerresum'></a><h3 class=pageheader><code>laguerresum</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Summation of Laguerre polynomials using Clenshaw's recurrence formula.
# 
# This routine calculates c[0]*L0(x) + c[1]*L1(x) + ... + c[N]*LN(x)
# 
# Parameters:
#     n   -   degree, n&gt;=0
#     x   -   argument
# 
# Result:
#     the value of the Laguerre polynomial at x
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.laguerresum(c, n, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          1D array/list of float
          n:          int
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_lda></a><h2 class=pageheader><code>lda</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_fisherlda' class=toc>fisherlda</a><br>
<a href='#sub_fisherldan' class=toc>fisherldan</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_fisherlda'></a><h3 class=pageheader><code>fisherlda</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Multiclass Fisher LDA
# 
# The function finds coefficients of a linear  combination  which  optimally
# separates training set. Most suited for 2-class problems, see fisherldan()
# for an variant that returns N-dimensional basis.
# 
# INPUT PARAMETERS:
#     XY          -   training set, array[NPoints,NVars+1].
#                     First NVars columns store values of independent
#                     variables, the next column stores class index (from 0
#                     to NClasses-1) which dataset element belongs to.
#                     Fractional values are rounded to the nearest integer.
#                     The class index must be in the [0,NClasses-1] range,
#                     an exception is generated otherwise.
#     NPoints     -   training set size, NPoints&gt;=0
#     NVars       -   number of independent variables, NVars&gt;=1
#     NClasses    -   number of classes, NClasses&gt;=2
# 
# 
# OUTPUT PARAMETERS:
#     W           -   linear combination coefficients, array[NVars]
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 31.05.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   w = xalglib.fisherlda(xy, npoints, nvars, nclasses)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   w = xalglib.fisherlda(xy, nclasses)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nvars:      int
          nclasses:   int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  w:          1D array/list of float

</div></pre>
<a name='sub_fisherldan'></a><h3 class=pageheader><code>fisherldan</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# N-dimensional multiclass Fisher LDA
# 
# Subroutine finds coefficients of linear combinations which optimally separates
# training set on classes. It returns N-dimensional basis whose vector are sorted
# by quality of training set separation (in descending order).
# 
# INPUT PARAMETERS:
#     XY          -   training set, array[NPoints,NVars+1].
#                     First NVars columns store values of independent
#                     variables, the next column stores class index (from 0
#                     to NClasses-1) which dataset element belongs to.
#                     Fractional values are rounded to the nearest integer.
#                     The class index must be in the [0,NClasses-1] range,
#                     an exception is generated otherwise.
#     NPoints     -   training set size, NPoints&gt;=0
#     NVars       -   number of independent variables, NVars&gt;=1
#     NClasses    -   number of classes, NClasses&gt;=2
# 
# 
# OUTPUT PARAMETERS:
#     W           -   basis, array[NVars,NVars]
#                     columns of matrix stores basis vectors, sorted by
#                     quality of training set separation (in descending order)
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 31.05.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   w = xalglib.fisherldan(xy, npoints, nvars, nclasses)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   w = xalglib.fisherldan(xy, nclasses)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nvars:      int
          nclasses:   int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  w:          2D array/list of float

</div></pre>
<a name=unit_legendre></a><h2 class=pageheader><code>legendre</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_legendrecalculate' class=toc>legendrecalculate</a><br>
<a href='#sub_legendrecoefficients' class=toc>legendrecoefficients</a><br>
<a href='#sub_legendresum' class=toc>legendresum</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_legendrecalculate'></a><h3 class=pageheader><code>legendrecalculate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Calculation of the value of the Legendre polynomial Pn.
# 
# Parameters:
#     n   -   degree, n&gt;=0
#     x   -   argument
# 
# Result:
#     the value of the Legendre polynomial Pn at x
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.legendrecalculate(n, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_legendrecoefficients'></a><h3 class=pageheader><code>legendrecoefficients</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Representation of Pn as C[0] + C[1]*X + ... + C[N]*X^N
# 
# Input parameters:
#     N   -   polynomial degree, n&gt;=0
# 
# Output parameters:
#     C   -   coefficients
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.legendrecoefficients(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of float

</div></pre>
<a name='sub_legendresum'></a><h3 class=pageheader><code>legendresum</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Summation of Legendre polynomials using Clenshaw's recurrence formula.
# 
# This routine calculates
#     c[0]*P0(x) + c[1]*P1(x) + ... + c[N]*PN(x)
# 
# Parameters:
#     n   -   degree, n&gt;=0
#     x   -   argument
# 
# Result:
#     the value of the Legendre polynomial at x
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.legendresum(c, n, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          1D array/list of float
          n:          int
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_lincg></a><h2 class=pageheader><code>lincg</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_lincgcreate' class=toc>lincgcreate</a><br>
<a href='#sub_lincgresults' class=toc>lincgresults</a><br>
<a href='#sub_lincgsetcond' class=toc>lincgsetcond</a><br>
<a href='#sub_lincgsetprecdiag' class=toc>lincgsetprecdiag</a><br>
<a href='#sub_lincgsetprecunit' class=toc>lincgsetprecunit</a><br>
<a href='#sub_lincgsetrestartfreq' class=toc>lincgsetrestartfreq</a><br>
<a href='#sub_lincgsetrupdatefreq' class=toc>lincgsetrupdatefreq</a><br>
<a href='#sub_lincgsetstartingpoint' class=toc>lincgsetstartingpoint</a><br>
<a href='#sub_lincgsetxrep' class=toc>lincgsetxrep</a><br>
<a href='#sub_lincgsolvesparse' class=toc>lincgsolvesparse</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_lincgcreate'></a><h3 class=pageheader><code>lincgcreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function initializes linear CG Solver. This solver is used  to  solve
# symmetric positive definite problems. If you want  to  solve  nonsymmetric
# (or non-positive definite) problem you may use LinLSQR solver provided  by
# ALGLIB.
# 
# USAGE:
# 1. User initializes algorithm state with LinCGCreate() call
# 2. User tunes solver parameters with  LinCGSetCond() and other functions
# 3. Optionally, user sets starting point with LinCGSetStartingPoint()
# 4. User  calls LinCGSolveSparse() function which takes algorithm state and
#    SparseMatrix object.
# 5. User calls LinCGResults() to get solution
# 6. Optionally, user may call LinCGSolveSparse()  again  to  solve  another
#    problem  with different matrix and/or right part without reinitializing
#    LinCGState structure.
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;0
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 14.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.lincgcreate(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.lincgstate

</div></pre>
<a name='sub_lincgresults'></a><h3 class=pageheader><code>lincgresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# CG-solver: results.
# 
# This function must be called after LinCGSolve
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     X       -   array[N], solution
#     Rep     -   optimization report:
#                 * Rep.TerminationType completetion code:
#                     * -5    input matrix is either not positive definite,
#                             too large or too small
#                     * -4    overflow/underflow during solution
#                             (ill conditioned problem)
#                     *  1    ||residual||&lt;=EpsF*||b||
#                     *  5    MaxIts steps was taken
#                     *  7    rounding errors prevent further progress,
#                             best point found is returned
#                 * Rep.IterationsCount contains iterations count
#                 * NMV countains number of matrix-vector calculations
# 
#   -- ALGLIB --
#      Copyright 14.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.lincgresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lincgstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.lincgreport

</div></pre>
<a name='sub_lincgsetcond'></a><h3 class=pageheader><code>lincgsetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping criteria.
# 
# INPUT PARAMETERS:
#     EpsF    -   algorithm will be stopped if norm of residual is less than
#                 EpsF*||b||.
#     MaxIts  -   algorithm will be stopped if number of iterations is  more
#                 than MaxIts.
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# NOTES:
# If  both  EpsF  and  MaxIts  are  zero then small EpsF will be set to small
# value.
# 
#   -- ALGLIB --
#      Copyright 14.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lincgsetcond(state, epsf, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lincgstate
          epsf:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lincgsetprecdiag'></a><h3 class=pageheader><code>lincgsetprecdiag</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  changes  preconditioning  settings  of  LinCGSolveSparse()
# function.  LinCGSolveSparse() will use diagonal of the  system  matrix  as
# preconditioner. This preconditioning mode is active by default.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 19.11.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lincgsetprecdiag(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lincgstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lincgsetprecunit'></a><h3 class=pageheader><code>lincgsetprecunit</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  changes  preconditioning  settings  of  LinCGSolveSparse()
# function. By default, SolveSparse() uses diagonal preconditioner,  but  if
# you want to use solver without preconditioning, you can call this function
# which forces solver to use unit matrix for preconditioning.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 19.11.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lincgsetprecunit(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lincgstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lincgsetrestartfreq'></a><h3 class=pageheader><code>lincgsetrestartfreq</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets restart frequency. By default, algorithm  is  restarted
# after N subsequent iterations.
# 
#   -- ALGLIB --
#      Copyright 14.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lincgsetrestartfreq(state, srf)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lincgstate
          srf:        int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lincgsetrupdatefreq'></a><h3 class=pageheader><code>lincgsetrupdatefreq</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets frequency of residual recalculations.
# 
# Algorithm updates residual r_k using iterative formula,  but  recalculates
# it from scratch after each 10 iterations. It is done to avoid accumulation
# of numerical errors and to stop algorithm when r_k starts to grow.
# 
# Such low update frequence (1/10) gives very  little  overhead,  but  makes
# algorithm a bit more robust against numerical errors. However, you may
# change it
# 
# INPUT PARAMETERS:
#     Freq    -   desired update frequency, Freq&gt;=0.
#                 Zero value means that no updates will be done.
# 
#   -- ALGLIB --
#      Copyright 14.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lincgsetrupdatefreq(state, freq)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lincgstate
          freq:       int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lincgsetstartingpoint'></a><h3 class=pageheader><code>lincgsetstartingpoint</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets starting point.
# By default, zero starting point is used.
# 
# INPUT PARAMETERS:
#     X       -   starting point, array[N]
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 14.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lincgsetstartingpoint(state, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lincgstate
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lincgsetxrep'></a><h3 class=pageheader><code>lincgsetxrep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function turns on/off reporting.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     NeedXRep-   whether iteration reports are needed or not
# 
# If NeedXRep is True, algorithm will call rep() callback function if  it is
# provided to MinCGOptimize().
# 
#   -- ALGLIB --
#      Copyright 14.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lincgsetxrep(state, needxrep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lincgstate
          needxrep:   bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lincgsolvesparse'></a><h3 class=pageheader><code>lincgsolvesparse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Procedure for solution of A*x=b with sparse A.
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
#     A       -   sparse matrix in the CRS format (you MUST contvert  it  to
#                 CRS format by calling SparseConvertToCRS() function).
#     IsUpper -   whether upper or lower triangle of A is used:
#                 * IsUpper=True  =&gt; only upper triangle is used and lower
#                                    triangle is not referenced at all
#                 * IsUpper=False =&gt; only lower triangle is used and upper
#                                    triangle is not referenced at all
#     B       -   right part, array[N]
# 
# RESULT:
#     This function returns no result.
#     You can get solution by calling LinCGResults()
# 
# NOTE: this function uses lightweight preconditioning -  multiplication  by
#       inverse of diag(A). If you want, you can turn preconditioning off by
#       calling LinCGSetPrecUnit(). However, preconditioning cost is low and
#       preconditioner  is  very  important  for  solution  of  badly scaled
#       problems.
# 
#   -- ALGLIB --
#      Copyright 14.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lincgsolvesparse(state, a, isupper, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lincgstate
          a:          class xalglib.sparsematrix
          isupper:    bool
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_linlsqr></a><h2 class=pageheader><code>linlsqr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_linlsqrcreate' class=toc>linlsqrcreate</a><br>
<a href='#sub_linlsqrcreatebuf' class=toc>linlsqrcreatebuf</a><br>
<a href='#sub_linlsqrpeekiterationscount' class=toc>linlsqrpeekiterationscount</a><br>
<a href='#sub_linlsqrrequesttermination' class=toc>linlsqrrequesttermination</a><br>
<a href='#sub_linlsqrresults' class=toc>linlsqrresults</a><br>
<a href='#sub_linlsqrsetcond' class=toc>linlsqrsetcond</a><br>
<a href='#sub_linlsqrsetlambdai' class=toc>linlsqrsetlambdai</a><br>
<a href='#sub_linlsqrsetprecdiag' class=toc>linlsqrsetprecdiag</a><br>
<a href='#sub_linlsqrsetprecunit' class=toc>linlsqrsetprecunit</a><br>
<a href='#sub_linlsqrsetxrep' class=toc>linlsqrsetxrep</a><br>
<a href='#sub_linlsqrsolvesparse' class=toc>linlsqrsolvesparse</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_linlsqrcreate'></a><h3 class=pageheader><code>linlsqrcreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function initializes linear LSQR Solver. This solver is used to solve
# non-symmetric (and, possibly, non-square) problems. Least squares solution
# is returned for non-compatible systems.
# 
# USAGE:
# 1. User initializes algorithm state with LinLSQRCreate() call
# 2. User tunes solver parameters with  LinLSQRSetCond() and other functions
# 3. User  calls  LinLSQRSolveSparse()  function which takes algorithm state
#    and SparseMatrix object.
# 4. User calls LinLSQRResults() to get solution
# 5. Optionally, user may call LinLSQRSolveSparse() again to  solve  another
#    problem  with different matrix and/or right part without reinitializing
#    LinLSQRState structure.
# 
# INPUT PARAMETERS:
#     M       -   number of rows in A
#     N       -   number of variables, N&gt;0
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# NOTE: see also linlsqrcreatebuf()  for  version  which  reuses  previously
#       allocated place as much as possible.
# 
#   -- ALGLIB --
#      Copyright 30.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.linlsqrcreate(m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.linlsqrstate

</div></pre>
<a name='sub_linlsqrcreatebuf'></a><h3 class=pageheader><code>linlsqrcreatebuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function initializes linear LSQR Solver.  It  provides  exactly  same
# functionality as linlsqrcreate(), but reuses  previously  allocated  space
# as much as possible.
# 
# INPUT PARAMETERS:
#     M       -   number of rows in A
#     N       -   number of variables, N&gt;0
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 14.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.linlsqrcreatebuf(m, n, state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          state:      class xalglib.linlsqrstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_linlsqrpeekiterationscount'></a><h3 class=pageheader><code>linlsqrpeekiterationscount</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to peek into LSQR solver and get  current  iteration
# counter. You can safely &quot;peek&quot; into the solver from another thread.
# 
# INPUT PARAMETERS:
#     S           -   solver object
# 
# RESULT:
#     iteration counter, in [0,INF)
# 
#   -- ALGLIB --
#      Copyright 21.05.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.linlsqrpeekiterationscount(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.linlsqrstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_linlsqrrequesttermination'></a><h3 class=pageheader><code>linlsqrrequesttermination</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine submits request for termination of the running solver.  It
# can be called from some other thread which wants LSQR solver to  terminate
# (obviously, the  thread  running  LSQR  solver can not request termination
# because it is already busy working on LSQR).
# 
# As result, solver  stops  at  point  which  was  &quot;current  accepted&quot;  when
# termination  request  was  submitted  and returns error code 8 (successful
# termination).  Such   termination   is  a smooth  process  which  properly
# deallocates all temporaries.
# 
# INPUT PARAMETERS:
#     State   -   solver structure
# 
# NOTE: calling this function on solver which is NOT running  will  have  no
#       effect.
# 
# NOTE: multiple calls to this function are possible. First call is counted,
#       subsequent calls are silently ignored.
# 
# NOTE: solver clears termination flag on its start, it means that  if  some
#       other thread will request termination too soon, its request will went
#       unnoticed.
# 
#   -- ALGLIB --
#      Copyright 08.10.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.linlsqrrequesttermination(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.linlsqrstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_linlsqrresults'></a><h3 class=pageheader><code>linlsqrresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# LSQR solver: results.
# 
# This function must be called after LinLSQRSolve
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     X       -   array[N], solution
#     Rep     -   optimization report:
#                 * Rep.TerminationType completetion code:
#                     *  1    ||Rk||&lt;=EpsB*||B||
#                     *  4    ||A^T*Rk||/(||A||*||Rk||)&lt;=EpsA
#                     *  5    MaxIts steps was taken
#                     *  7    rounding errors prevent further progress,
#                             X contains best point found so far.
#                             (sometimes returned on singular systems)
#                     *  8    user requested termination via calling
#                             linlsqrrequesttermination()
#                 * Rep.IterationsCount contains iterations count
#                 * NMV countains number of matrix-vector calculations
# 
#   -- ALGLIB --
#      Copyright 30.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.linlsqrresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.linlsqrstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.linlsqrreport

</div></pre>
<a name='sub_linlsqrsetcond'></a><h3 class=pageheader><code>linlsqrsetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping criteria.
# 
# INPUT PARAMETERS:
#     EpsA    -   algorithm will be stopped if ||A^T*Rk||/(||A||*||Rk||)&lt;=EpsA.
#     EpsB    -   algorithm will be stopped if ||Rk||&lt;=EpsB*||B||
#     MaxIts  -   algorithm will be stopped if number of iterations
#                 more than MaxIts.
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# NOTE: if EpsA,EpsB,EpsC and MaxIts are zero then these variables will
# be setted as default values.
# 
#   -- ALGLIB --
#      Copyright 30.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.linlsqrsetcond(state, epsa, epsb, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.linlsqrstate
          epsa:       float
          epsb:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_linlsqrsetlambdai'></a><h3 class=pageheader><code>linlsqrsetlambdai</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets optional Tikhonov regularization coefficient.
# It is zero by default.
# 
# INPUT PARAMETERS:
#     LambdaI -   regularization factor, LambdaI&gt;=0
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 30.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.linlsqrsetlambdai(state, lambdai)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.linlsqrstate
          lambdai:    float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_linlsqrsetprecdiag'></a><h3 class=pageheader><code>linlsqrsetprecdiag</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  changes  preconditioning  settings  of  LinCGSolveSparse()
# function.  LinCGSolveSparse() will use diagonal of the  system  matrix  as
# preconditioner. This preconditioning mode is active by default.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 19.11.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.linlsqrsetprecdiag(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.linlsqrstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_linlsqrsetprecunit'></a><h3 class=pageheader><code>linlsqrsetprecunit</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  changes  preconditioning  settings of LinLSQQSolveSparse()
# function. By default, SolveSparse() uses diagonal preconditioner,  but  if
# you want to use solver without preconditioning, you can call this function
# which forces solver to use unit matrix for preconditioning.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 19.11.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.linlsqrsetprecunit(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.linlsqrstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_linlsqrsetxrep'></a><h3 class=pageheader><code>linlsqrsetxrep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function turns on/off reporting.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     NeedXRep-   whether iteration reports are needed or not
# 
# If NeedXRep is True, algorithm will call rep() callback function if  it is
# provided to MinCGOptimize().
# 
#   -- ALGLIB --
#      Copyright 30.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.linlsqrsetxrep(state, needxrep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.linlsqrstate
          needxrep:   bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_linlsqrsolvesparse'></a><h3 class=pageheader><code>linlsqrsolvesparse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Procedure for solution of A*x=b with sparse A.
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
#     A       -   sparse M*N matrix in the CRS format (you MUST contvert  it
#                 to CRS format  by  calling  SparseConvertToCRS()  function
#                 BEFORE you pass it to this function).
#     B       -   right part, array[M]
# 
# RESULT:
#     This function returns no result.
#     You can get solution by calling LinCGResults()
# 
# NOTE: this function uses lightweight preconditioning -  multiplication  by
#       inverse of diag(A). If you want, you can turn preconditioning off by
#       calling LinLSQRSetPrecUnit(). However, preconditioning cost is   low
#       and preconditioner is very important for solution  of  badly  scaled
#       problems.
# 
#   -- ALGLIB --
#      Copyright 30.11.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.linlsqrsolvesparse(state, a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.linlsqrstate
          a:          class xalglib.sparsematrix
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_linreg></a><h2 class=pageheader><code>linreg</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_lravgerror' class=toc>lravgerror</a><br>
<a href='#sub_lravgrelerror' class=toc>lravgrelerror</a><br>
<a href='#sub_lrbuild' class=toc>lrbuild</a><br>
<a href='#sub_lrbuilds' class=toc>lrbuilds</a><br>
<a href='#sub_lrbuildz' class=toc>lrbuildz</a><br>
<a href='#sub_lrbuildzs' class=toc>lrbuildzs</a><br>
<a href='#sub_lrpack' class=toc>lrpack</a><br>
<a href='#sub_lrprocess' class=toc>lrprocess</a><br>
<a href='#sub_lrrmserror' class=toc>lrrmserror</a><br>
<a href='#sub_lrunpack' class=toc>lrunpack</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_lravgerror'></a><h3 class=pageheader><code>lravgerror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average error on the test set
# 
# INPUT PARAMETERS:
#     LM      -   linear model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     average error.
# 
#   -- ALGLIB --
#      Copyright 30.08.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.lravgerror(lm, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lm:         class xalglib.linearmodel
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_lravgrelerror'></a><h3 class=pageheader><code>lravgrelerror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# RMS error on the test set
# 
# INPUT PARAMETERS:
#     LM      -   linear model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     average relative error.
# 
#   -- ALGLIB --
#      Copyright 30.08.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.lravgrelerror(lm, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lm:         class xalglib.linearmodel
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_lrbuild'></a><h3 class=pageheader><code>lrbuild</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Linear regression
# 
# Subroutine builds model:
# 
#     Y = A(0)*X[0] + ... + A(N-1)*X[N-1] + A(N)
# 
# and model found in ALGLIB format, covariation matrix, training set  errors
# (rms,  average,  average  relative)   and  leave-one-out  cross-validation
# estimate of the generalization error. CV  estimate calculated  using  fast
# algorithm with O(NPoints*NVars) complexity.
# 
# When  covariation  matrix  is  calculated  standard deviations of function
# values are assumed to be equal to RMS error on the training set.
# 
# INPUT PARAMETERS:
#     XY          -   training set, array [0..NPoints-1,0..NVars]:
#                     * NVars columns - independent variables
#                     * last column - dependent variable
#     NPoints     -   training set size, NPoints&gt;NVars+1. An exception is
#                     generated otherwise.
#     NVars       -   number of independent variables
# 
# OUTPUT PARAMETERS:
#     LM          -   linear model in the ALGLIB format. Use subroutines of
#                     this unit to work with the model.
#     Rep         -   additional results, see comments on LRReport structure.
# 
#   -- ALGLIB --
#      Copyright 02.08.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   lm, rep = xalglib.lrbuild(xy, npoints, nvars)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   lm, rep = xalglib.lrbuild(xy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nvars:      int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  lm:         class xalglib.linearmodel
          rep:        class xalglib.lrreport

</div></pre>
<a name='sub_lrbuilds'></a><h3 class=pageheader><code>lrbuilds</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Linear regression
# 
# Variant of LRBuild which uses vector of standatd deviations (errors in
# function values).
# 
# INPUT PARAMETERS:
#     XY          -   training set, array [0..NPoints-1,0..NVars]:
#                     * NVars columns - independent variables
#                     * last column - dependent variable
#     S           -   standard deviations (errors in function values)
#                     array[NPoints], S[i]&gt;0.
#     NPoints     -   training set size, NPoints&gt;NVars+1
#     NVars       -   number of independent variables
# 
# OUTPUT PARAMETERS:
#     LM          -   linear model in the ALGLIB format. Use subroutines of
#                     this unit to work with the model.
#     Rep         -   additional results, see comments on LRReport structure.
# 
#   -- ALGLIB --
#      Copyright 02.08.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   lm, rep = xalglib.lrbuilds(xy, s, npoints, nvars)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   lm, rep = xalglib.lrbuilds(xy, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          s:          1D array/list of float
          npoints:    int
          nvars:      int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  lm:         class xalglib.linearmodel
          rep:        class xalglib.lrreport

</div></pre>
<a name='sub_lrbuildz'></a><h3 class=pageheader><code>lrbuildz</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Like LRBuild but builds model
# 
#     Y = A(0)*X[0] + ... + A(N-1)*X[N-1]
# 
# i.e. with zero constant term.
# 
#   -- ALGLIB --
#      Copyright 30.10.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   lm, rep = xalglib.lrbuildz(xy, npoints, nvars)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   lm, rep = xalglib.lrbuildz(xy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nvars:      int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  lm:         class xalglib.linearmodel
          rep:        class xalglib.lrreport

</div></pre>
<a name='sub_lrbuildzs'></a><h3 class=pageheader><code>lrbuildzs</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Like LRBuildS, but builds model
# 
#     Y = A(0)*X[0] + ... + A(N-1)*X[N-1]
# 
# i.e. with zero constant term.
# 
#   -- ALGLIB --
#      Copyright 30.10.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   lm, rep = xalglib.lrbuildzs(xy, s, npoints, nvars)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   lm, rep = xalglib.lrbuildzs(xy, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          s:          1D array/list of float
          npoints:    int
          nvars:      int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  lm:         class xalglib.linearmodel
          rep:        class xalglib.lrreport

</div></pre>
<a name='sub_lrpack'></a><h3 class=pageheader><code>lrpack</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# &quot;Packs&quot; coefficients and creates linear model in ALGLIB format (LRUnpack
# reversed).
# 
# INPUT PARAMETERS:
#     V           -   coefficients, array[0..NVars]
#     NVars       -   number of independent variables
# 
# OUTPUT PAREMETERS:
#     LM          -   linear model.
# 
#   -- ALGLIB --
#      Copyright 30.08.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   lm = xalglib.lrpack(v, nvars)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   lm = xalglib.lrpack(v)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     v:          1D array/list of float
          nvars:      int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  lm:         class xalglib.linearmodel

</div></pre>
<a name='sub_lrprocess'></a><h3 class=pageheader><code>lrprocess</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Procesing
# 
# INPUT PARAMETERS:
#     LM      -   linear model
#     X       -   input vector,  array[0..NVars-1].
# 
# Result:
#     value of linear model regression estimate
# 
#   -- ALGLIB --
#      Copyright 03.09.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.lrprocess(lm, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lm:         class xalglib.linearmodel
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_lrrmserror'></a><h3 class=pageheader><code>lrrmserror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# RMS error on the test set
# 
# INPUT PARAMETERS:
#     LM      -   linear model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     root mean square error.
# 
#   -- ALGLIB --
#      Copyright 30.08.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.lrrmserror(lm, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lm:         class xalglib.linearmodel
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_lrunpack'></a><h3 class=pageheader><code>lrunpack</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Unpacks coefficients of linear model.
# 
# INPUT PARAMETERS:
#     LM          -   linear model in ALGLIB format
# 
# OUTPUT PARAMETERS:
#     V           -   coefficients, array[0..NVars]
#                     constant term (intercept) is stored in the V[NVars].
#     NVars       -   number of independent variables (one less than number
#                     of coefficients)
# 
#   -- ALGLIB --
#      Copyright 30.08.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   v, nvars = xalglib.lrunpack(lm)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lm:         class xalglib.linearmodel
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  v:          1D array/list of float
          nvars:      int

</div></pre>
<a name=unit_logit></a><h2 class=pageheader><code>logit</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_mnlavgce' class=toc>mnlavgce</a><br>
<a href='#sub_mnlavgerror' class=toc>mnlavgerror</a><br>
<a href='#sub_mnlavgrelerror' class=toc>mnlavgrelerror</a><br>
<a href='#sub_mnlclserror' class=toc>mnlclserror</a><br>
<a href='#sub_mnlpack' class=toc>mnlpack</a><br>
<a href='#sub_mnlprocess' class=toc>mnlprocess</a><br>
<a href='#sub_mnlprocessi' class=toc>mnlprocessi</a><br>
<a href='#sub_mnlrelclserror' class=toc>mnlrelclserror</a><br>
<a href='#sub_mnlrmserror' class=toc>mnlrmserror</a><br>
<a href='#sub_mnltrainh' class=toc>mnltrainh</a><br>
<a href='#sub_mnlunpack' class=toc>mnlunpack</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_mnlavgce'></a><h3 class=pageheader><code>mnlavgce</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average cross-entropy (in bits per element) on the test set
# 
# INPUT PARAMETERS:
#     LM      -   logit model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     CrossEntropy/(NPoints*ln(2)).
# 
#   -- ALGLIB --
#      Copyright 10.09.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mnlavgce(lm, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lm:         class xalglib.logitmodel
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> lm
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mnlavgerror'></a><h3 class=pageheader><code>mnlavgerror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average error on the test set
# 
# INPUT PARAMETERS:
#     LM      -   logit model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     average error (error when estimating posterior probabilities).
# 
#   -- ALGLIB --
#      Copyright 30.08.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mnlavgerror(lm, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lm:         class xalglib.logitmodel
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> lm
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mnlavgrelerror'></a><h3 class=pageheader><code>mnlavgrelerror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average relative error on the test set
# 
# INPUT PARAMETERS:
#     LM      -   logit model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     average relative error (error when estimating posterior probabilities).
# 
#   -- ALGLIB --
#      Copyright 30.08.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mnlavgrelerror(lm, xy, ssize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lm:         class xalglib.logitmodel
          xy:         2D array/list of float
          ssize:      int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> lm
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mnlclserror'></a><h3 class=pageheader><code>mnlclserror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Classification error on test set = MNLRelClsError*NPoints
# 
#   -- ALGLIB --
#      Copyright 10.09.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mnlclserror(lm, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lm:         class xalglib.logitmodel
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> lm
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_mnlpack'></a><h3 class=pageheader><code>mnlpack</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# &quot;Packs&quot; coefficients and creates logit model in ALGLIB format (MNLUnpack
# reversed).
# 
# INPUT PARAMETERS:
#     A           -   model (see MNLUnpack)
#     NVars       -   number of independent variables
#     NClasses    -   number of classes
# 
# OUTPUT PARAMETERS:
#     LM          -   logit model.
# 
#   -- ALGLIB --
#      Copyright 10.09.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   lm = xalglib.mnlpack(a, nvars, nclasses)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          nvars:      int
          nclasses:   int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  lm:         class xalglib.logitmodel

</div></pre>
<a name='sub_mnlprocess'></a><h3 class=pageheader><code>mnlprocess</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Procesing
# 
# INPUT PARAMETERS:
#     LM      -   logit model, passed by non-constant reference
#                 (some fields of structure are used as temporaries
#                 when calculating model output).
#     X       -   input vector,  array[0..NVars-1].
#     Y       -   (possibly) preallocated buffer; if size of Y is less than
#                 NClasses, it will be reallocated.If it is large enough, it
#                 is NOT reallocated, so we can save some time on reallocation.
# 
# OUTPUT PARAMETERS:
#     Y       -   result, array[0..NClasses-1]
#                 Vector of posterior probabilities for classification task.
# 
#   -- ALGLIB --
#      Copyright 10.09.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.mnlprocess(lm, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lm:         class xalglib.logitmodel
          x:          1D array/list of float
          y:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> lm
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_mnlprocessi'></a><h3 class=pageheader><code>mnlprocessi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 'interactive'  variant  of  MNLProcess  for  languages  like  Python which
# support constructs like &quot;Y = MNLProcess(LM,X)&quot; and interactive mode of the
# interpreter
# 
# This function allocates new array on each call,  so  it  is  significantly
# slower than its 'non-interactive' counterpart, but it is  more  convenient
# when you call it from command line.
# 
#   -- ALGLIB --
#      Copyright 10.09.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.mnlprocessi(lm, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lm:         class xalglib.logitmodel
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> lm
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_mnlrelclserror'></a><h3 class=pageheader><code>mnlrelclserror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Relative classification error on the test set
# 
# INPUT PARAMETERS:
#     LM      -   logit model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     percent of incorrectly classified cases.
# 
#   -- ALGLIB --
#      Copyright 10.09.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mnlrelclserror(lm, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lm:         class xalglib.logitmodel
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> lm
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mnlrmserror'></a><h3 class=pageheader><code>mnlrmserror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# RMS error on the test set
# 
# INPUT PARAMETERS:
#     LM      -   logit model
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     root mean square error (error when estimating posterior probabilities).
# 
#   -- ALGLIB --
#      Copyright 30.08.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mnlrmserror(lm, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lm:         class xalglib.logitmodel
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> lm
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mnltrainh'></a><h3 class=pageheader><code>mnltrainh</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine trains logit model.
# 
# INPUT PARAMETERS:
#     XY          -   training set, array[0..NPoints-1,0..NVars]
#                     First NVars columns store values of independent
#                     variables, next column stores number of class (from 0
#                     to NClasses-1) which dataset element belongs to. Fractional
#                     values are rounded to nearest integer.
#     NPoints     -   training set size, NPoints&gt;=1
#     NVars       -   number of independent variables, NVars&gt;=1
#     NClasses    -   number of classes, NClasses&gt;=2
# 
# OUTPUT PARAMETERS:
#     Info        -   return code:
#                     * -2, if there is a point with class number
#                           outside of [0..NClasses-1].
#                     * -1, if incorrect parameters was passed
#                           (NPoints&lt;NVars+2, NVars&lt;1, NClasses&lt;2).
#                     *  1, if task has been solved
#     LM          -   model built
#     Rep         -   training report
# 
#   -- ALGLIB --
#      Copyright 10.09.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, lm, rep = xalglib.mnltrainh(xy, npoints, nvars, nclasses)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          npoints:    int
          nvars:      int
          nclasses:   int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          lm:         class xalglib.logitmodel
          rep:        class xalglib.mnlreport

</div></pre>
<a name='sub_mnlunpack'></a><h3 class=pageheader><code>mnlunpack</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Unpacks coefficients of logit model. Logit model have form:
# 
#     P(class=i) = S(i) / (S(0) + S(1) + ... +S(M-1))
#           S(i) = Exp(A[i,0]*X[0] + ... + A[i,N-1]*X[N-1] + A[i,N]), when i&lt;M-1
#         S(M-1) = 1
# 
# INPUT PARAMETERS:
#     LM          -   logit model in ALGLIB format
# 
# OUTPUT PARAMETERS:
#     V           -   coefficients, array[0..NClasses-2,0..NVars]
#     NVars       -   number of independent variables
#     NClasses    -   number of classes
# 
#   -- ALGLIB --
#      Copyright 10.09.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a, nvars, nclasses = xalglib.mnlunpack(lm)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lm:         class xalglib.logitmodel
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of float
          nvars:      int
          nclasses:   int

</div></pre>
<a name=unit_lsfit></a><h2 class=pageheader><code>lsfit</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_barycentricfitfloaterhormann' class=toc>barycentricfitfloaterhormann</a><br>
<a href='#sub_barycentricfitfloaterhormannwc' class=toc>barycentricfitfloaterhormannwc</a><br>
<a href='#sub_logisticcalc4' class=toc>logisticcalc4</a><br>
<a href='#sub_logisticcalc5' class=toc>logisticcalc5</a><br>
<a href='#sub_logisticfit4' class=toc>logisticfit4</a><br>
<a href='#sub_logisticfit45x' class=toc>logisticfit45x</a><br>
<a href='#sub_logisticfit4ec' class=toc>logisticfit4ec</a><br>
<a href='#sub_logisticfit5' class=toc>logisticfit5</a><br>
<a href='#sub_logisticfit5ec' class=toc>logisticfit5ec</a><br>
<a href='#sub_lsfitcreatef' class=toc>lsfitcreatef</a><br>
<a href='#sub_lsfitcreatefg' class=toc>lsfitcreatefg</a><br>
<a href='#sub_lsfitcreatewf' class=toc>lsfitcreatewf</a><br>
<a href='#sub_lsfitcreatewfg' class=toc>lsfitcreatewfg</a><br>
<a href='#sub_lsfitlinear' class=toc>lsfitlinear</a><br>
<a href='#sub_lsfitlinearc' class=toc>lsfitlinearc</a><br>
<a href='#sub_lsfitlinearw' class=toc>lsfitlinearw</a><br>
<a href='#sub_lsfitlinearwc' class=toc>lsfitlinearwc</a><br>
<a href='#sub_lsfitresults' class=toc>lsfitresults</a><br>
<a href='#sub_lsfitsetbc' class=toc>lsfitsetbc</a><br>
<a href='#sub_lsfitsetcond' class=toc>lsfitsetcond</a><br>
<a href='#sub_lsfitsetgradientcheck' class=toc>lsfitsetgradientcheck</a><br>
<a href='#sub_lsfitsetlc' class=toc>lsfitsetlc</a><br>
<a href='#sub_lsfitsetnonmonotonicsteps' class=toc>lsfitsetnonmonotonicsteps</a><br>
<a href='#sub_lsfitsetnumdiff' class=toc>lsfitsetnumdiff</a><br>
<a href='#sub_lsfitsetscale' class=toc>lsfitsetscale</a><br>
<a href='#sub_lsfitsetstpmax' class=toc>lsfitsetstpmax</a><br>
<a href='#sub_lsfitsetxrep' class=toc>lsfitsetxrep</a><br>
<a href='#sub_lstfitpiecewiselinearrdp' class=toc>lstfitpiecewiselinearrdp</a><br>
<a href='#sub_lstfitpiecewiselinearrdpfixed' class=toc>lstfitpiecewiselinearrdpfixed</a><br>
<a href='#sub_polynomialfit' class=toc>polynomialfit</a><br>
<a href='#sub_polynomialfitwc' class=toc>polynomialfitwc</a><br>
<a href='#sub_spline1dfitcubicwc' class=toc>spline1dfitcubicwc</a><br>
<a href='#sub_spline1dfithermitedeprecated' class=toc>spline1dfithermitedeprecated</a><br>
<a href='#sub_spline1dfithermitewc' class=toc>spline1dfithermitewc</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_barycentricfitfloaterhormann'></a><h3 class=pageheader><code>barycentricfitfloaterhormann</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Rational least squares fitting using  Floater-Hormann  rational  functions
# with optimal D chosen from [0,9].
# 
# Equidistant  grid  with M node on [min(x),max(x)]  is  used to build basis
# functions. Different values of D are tried, optimal  D  (least  root  mean
# square error) is chosen.  Task  is  linear, so linear least squares solver
# is used. Complexity  of  this  computational  scheme is  O(N*M^2)  (mostly
# dominated by the least squares solver).
# 
# INPUT PARAMETERS:
#     X   -   points, array[0..N-1].
#     Y   -   function values, array[0..N-1].
#     N   -   number of points, N&gt;0.
#     M   -   number of basis functions ( = number_of_nodes), M&gt;=2.
# 
# OUTPUT PARAMETERS:
#     B   -   barycentric interpolant.
#     Rep -   fitting report. The following fields are set:
#             * Rep.TerminationType is a completion code, always set to 1
#             * DBest         best value of the D parameter
#             * RMSError      rms error on the (X,Y).
#             * AvgError      average error on the (X,Y).
#             * AvgRelError   average relative error on the non-zero Y
#             * MaxError      maximum error
#                             NON-WEIGHTED ERRORS ARE CALCULATED
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB PROJECT --
#      Copyright 18.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   b, rep = xalglib.barycentricfitfloaterhormann(x, y, n, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  b:          class xalglib.barycentricinterpolant
          rep:        class xalglib.barycentricfitreport

</div></pre>
<a name='sub_barycentricfitfloaterhormannwc'></a><h3 class=pageheader><code>barycentricfitfloaterhormannwc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Weghted rational least  squares  fitting  using  Floater-Hormann  rational
# functions  with  optimal  D  chosen  from  [0,9],  with  constraints   and
# individual weights.
# 
# Equidistant  grid  with M node on [min(x),max(x)]  is  used to build basis
# functions. Different values of D are tried, optimal D (least WEIGHTED root
# mean square error) is chosen.  Task  is  linear,  so  linear least squares
# solver  is  used.  Complexity  of  this  computational  scheme is O(N*M^2)
# (mostly dominated by the least squares solver).
# 
# SEE ALSO
# * BarycentricFitFloaterHormann(), &quot;lightweight&quot; fitting without invididual
#   weights and constraints.
# 
# INPUT PARAMETERS:
#     X   -   points, array[0..N-1].
#     Y   -   function values, array[0..N-1].
#     W   -   weights, array[0..N-1]
#             Each summand in square  sum  of  approximation deviations from
#             given  values  is  multiplied  by  the square of corresponding
#             weight. Fill it by 1's if you don't  want  to  solve  weighted
#             task.
#     N   -   number of points, N&gt;0.
#     XC  -   points where function values/derivatives are constrained,
#             array[0..K-1].
#     YC  -   values of constraints, array[0..K-1]
#     DC  -   array[0..K-1], types of constraints:
#             * DC[i]=0   means that S(XC[i])=YC[i]
#             * DC[i]=1   means that S'(XC[i])=YC[i]
#             SEE BELOW FOR IMPORTANT INFORMATION ON CONSTRAINTS
#     K   -   number of constraints, 0&lt;=K&lt;M.
#             K=0 means no constraints (XC/YC/DC are not used in such cases)
#     M   -   number of basis functions ( = number_of_nodes), M&gt;=2.
# 
# OUTPUT PARAMETERS:
#     B   -   barycentric interpolant. Undefined for rep.terminationtype&lt;0.
#     Rep -   fitting report. The following fields are set:
#             * Rep.TerminationType is a completion code:
#               * set to  1 on success
#               * set to -3 on failure due to  problematic  constraints:
#                 either too many  constraints,  degenerate  constraints
#                 or inconsistent constraints were passed
#             * DBest         best value of the D parameter
#             * RMSError      rms error on the (X,Y).
#             * AvgError      average error on the (X,Y).
#             * AvgRelError   average relative error on the non-zero Y
#             * MaxError      maximum error
#                             NON-WEIGHTED ERRORS ARE CALCULATED
# 
# IMPORTANT:
#     this subroutine doesn't calculate task's condition number for K&lt;&gt;0.
# 
# SETTING CONSTRAINTS - DANGERS AND OPPORTUNITIES:
# 
# Setting constraints can lead  to undesired  results,  like ill-conditioned
# behavior, or inconsistency being detected. From the other side,  it allows
# us to improve quality of the fit. Here we summarize  our  experience  with
# constrained barycentric interpolants:
# * excessive  constraints  can  be  inconsistent.   Floater-Hormann   basis
#   functions aren't as flexible as splines (although they are very smooth).
# * the more evenly constraints are spread across [min(x),max(x)],  the more
#   chances that they will be consistent
# * the  greater  is  M (given  fixed  constraints),  the  more chances that
#   constraints will be consistent
# * in the general case, consistency of constraints IS NOT GUARANTEED.
# * in the several special cases, however, we CAN guarantee consistency.
# * one of this cases is constraints on the function  VALUES at the interval
#   boundaries. Note that consustency of the  constraints  on  the  function
#   DERIVATIVES is NOT guaranteed (you can use in such cases  cubic  splines
#   which are more flexible).
# * another  special  case  is ONE constraint on the function value (OR, but
#   not AND, derivative) anywhere in the interval
# 
# Our final recommendation is to use constraints  WHEN  AND  ONLY  WHEN  you
# can't solve your task without them. Anything beyond  special  cases  given
# above is not guaranteed and may result in inconsistency.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB PROJECT --
#      Copyright 18.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   b, rep = xalglib.barycentricfitfloaterhormannwc(x, y, w, n, xc, yc, dc, k, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          w:          1D array/list of float
          n:          int
          xc:         1D array/list of float
          yc:         1D array/list of float
          dc:         1D array/list of int
          k:          int
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  b:          class xalglib.barycentricinterpolant
          rep:        class xalglib.barycentricfitreport

</div></pre>
<a name='sub_logisticcalc4'></a><h3 class=pageheader><code>logisticcalc4</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates value of four-parameter logistic (4PL)  model  at
# specified point X. 4PL model has following form:
# 
#     F(x|A,B,C,D) = D+(A-D)/(1+Power(x/C,B))
# 
# INPUT PARAMETERS:
#     X       -   current point, X&gt;=0:
#                 * zero X is correctly handled even for B&lt;=0
#                 * negative X results in exception.
#     A, B, C, D- parameters of 4PL model:
#                 * A is unconstrained
#                 * B is unconstrained; zero or negative values are handled
#                   correctly.
#                 * C&gt;0, non-positive value results in exception
#                 * D is unconstrained
# 
# RESULT:
#     model value at X
# 
# NOTE: if B=0, denominator is assumed to be equal to 2.0 even  for  zero  X
#       (strictly speaking, 0^0 is undefined).
# 
# NOTE: this function also throws exception  if  all  input  parameters  are
#       correct, but overflow was detected during calculations.
# 
# NOTE: this function performs a lot of checks;  if  you  need  really  high
#       performance, consider evaluating model  yourself,  without  checking
#       for degenerate cases.
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.05.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.logisticcalc4(x, a, b, c, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
          a:          float
          b:          float
          c:          float
          d:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_logisticcalc5'></a><h3 class=pageheader><code>logisticcalc5</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates value of five-parameter logistic (5PL)  model  at
# specified point X. 5PL model has following form:
# 
#     F(x|A,B,C,D,G) = D+(A-D)/Power(1+Power(x/C,B),G)
# 
# INPUT PARAMETERS:
#     X       -   current point, X&gt;=0:
#                 * zero X is correctly handled even for B&lt;=0
#                 * negative X results in exception.
#     A, B, C, D, G- parameters of 5PL model:
#                 * A is unconstrained
#                 * B is unconstrained; zero or negative values are handled
#                   correctly.
#                 * C&gt;0, non-positive value results in exception
#                 * D is unconstrained
#                 * G&gt;0, non-positive value results in exception
# 
# RESULT:
#     model value at X
# 
# NOTE: if B=0, denominator is assumed to be equal to Power(2.0,G) even  for
#       zero X (strictly speaking, 0^0 is undefined).
# 
# NOTE: this function also throws exception  if  all  input  parameters  are
#       correct, but overflow was detected during calculations.
# 
# NOTE: this function performs a lot of checks;  if  you  need  really  high
#       performance, consider evaluating model  yourself,  without  checking
#       for degenerate cases.
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.05.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.logisticcalc5(x, a, b, c, d, g)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
          a:          float
          b:          float
          c:          float
          d:          float
          g:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_logisticfit4'></a><h3 class=pageheader><code>logisticfit4</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function fits four-parameter logistic (4PL) model  to  data  provided
# by user. 4PL model has following form:
# 
#     F(x|A,B,C,D) = D+(A-D)/(1+Power(x/C,B))
# 
# Here:
#     * A, D - unconstrained (see LogisticFit4EC() for constrained 4PL)
#     * B&gt;=0
#     * C&gt;0
# 
# IMPORTANT: output of this function is constrained in  such  way that  B&gt;0.
#            Because 4PL model is symmetric with respect to B, there  is  no
#            need to explore  B&lt;0.  Constraining  B  makes  algorithm easier
#            to stabilize and debug.
#            Users  who  for  some  reason  prefer to work with negative B's
#            should transform output themselves (swap A and D, replace B  by
#            -B).
# 
# 4PL fitting is implemented as follows:
# * we perform small number of restarts from random locations which helps to
#   solve problem of bad local extrema. Locations are only partially  random
#   - we use input data to determine good  initial  guess,  but  we  include
#   controlled amount of randomness.
# * we perform Levenberg-Marquardt fitting with very  tight  constraints  on
#   parameters B and C - it allows us to find good  initial  guess  for  the
#   second stage without risk of running into &quot;flat spot&quot;.
# * second  Levenberg-Marquardt  round  is   performed   without   excessive
#   constraints. Results from the previous round are used as initial guess.
# * after fitting is done, we compare results with best values found so far,
#   rewrite &quot;best solution&quot; if needed, and move to next random location.
# 
# Overall algorithm is very stable and is not prone to  bad  local  extrema.
# Furthermore, it automatically scales when input data have  very  large  or
# very small range.
# 
# INPUT PARAMETERS:
#     X       -   array[N], stores X-values.
#                 MUST include only non-negative numbers  (but  may  include
#                 zero values). Can be unsorted.
#     Y       -   array[N], values to fit.
#     N       -   number of points. If N is less than  length  of  X/Y, only
#                 leading N elements are used.
# 
# OUTPUT PARAMETERS:
#     A, B, C, D- parameters of 4PL model
#     Rep     -   fitting report. This structure has many fields,  but  ONLY
#                 ONES LISTED BELOW ARE SET:
#                 * Rep.IterationsCount - number of iterations performed
#                 * Rep.RMSError - root-mean-square error
#                 * Rep.AvgError - average absolute error
#                 * Rep.AvgRelError - average relative error (calculated for
#                   non-zero Y-values)
#                 * Rep.MaxError - maximum absolute error
#                 * Rep.R2 - coefficient of determination,  R-squared.  This
#                   coefficient   is  calculated  as  R2=1-RSS/TSS  (in case
#                   of nonlinear  regression  there  are  multiple  ways  to
#                   define R2, each of them giving different results).
# 
# NOTE: for stability reasons the B parameter is restricted by [1/1000,1000]
#       range. It prevents  algorithm from making trial steps  deep into the
#       area of bad parameters.
# 
# NOTE: after  you  obtained  coefficients,  you  can  evaluate  model  with
#       LogisticCalc4() function.
# 
# NOTE: if you need better control over fitting process than provided by this
#       function, you may use LogisticFit45X().
# 
# NOTE: step is automatically scaled according to scale of parameters  being
#       fitted before we compare its length with EpsX. Thus,  this  function
#       can be used to fit data with very small or very large values without
#       changing EpsX.
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.02.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a, b, c, d, rep = xalglib.logisticfit4(x, y, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          float
          b:          float
          c:          float
          d:          float
          rep:        class xalglib.lsfitreport

</div></pre>
<a name='sub_logisticfit45x'></a><h3 class=pageheader><code>logisticfit45x</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is &quot;expert&quot; 4PL/5PL fitting function, which can be used if  you  need
# better control over fitting process than provided  by  LogisticFit4()  or
# LogisticFit5().
# 
# This function fits model of the form
# 
#     F(x|A,B,C,D)   = D+(A-D)/(1+Power(x/C,B))           (4PL model)
# 
# or
# 
#     F(x|A,B,C,D,G) = D+(A-D)/Power(1+Power(x/C,B),G)    (5PL model)
# 
# Here:
#     * A, D - unconstrained
#     * B&gt;=0 for 4PL, unconstrained for 5PL
#     * C&gt;0
#     * G&gt;0 (if present)
# 
# INPUT PARAMETERS:
#     X       -   array[N], stores X-values.
#                 MUST include only non-negative numbers  (but  may  include
#                 zero values). Can be unsorted.
#     Y       -   array[N], values to fit.
#     N       -   number of points. If N is less than  length  of  X/Y, only
#                 leading N elements are used.
#     CnstrLeft-  optional equality constraint for model value at the   left
#                 boundary (at X=0). Specify NAN (Not-a-Number)  if  you  do
#                 not need constraint on the model value at X=0 (in C++  you
#                 can pass alglib::fp_nan as parameter, in  C#  it  will  be
#                 Double.NaN).
#                 See  below,  section  &quot;EQUALITY  CONSTRAINTS&quot;   for   more
#                 information about constraints.
#     CnstrRight- optional equality constraint for model value at X=infinity.
#                 Specify NAN (Not-a-Number) if you do not  need  constraint
#                 on the model value (in C++  you can pass alglib::fp_nan as
#                 parameter, in  C# it will  be Double.NaN).
#                 See  below,  section  &quot;EQUALITY  CONSTRAINTS&quot;   for   more
#                 information about constraints.
#     Is4PL   -   whether 4PL or 5PL models are fitted
#     LambdaV -   regularization coefficient, LambdaV&gt;=0.
#                 Set it to zero unless you know what you are doing.
#     EpsX    -   stopping condition (step size), EpsX&gt;=0.
#                 Zero value means that small step is automatically chosen.
#                 See notes below for more information.
#     RsCnt   -   number of repeated restarts from  random  points.  4PL/5PL
#                 models are prone to problem of bad local extrema. Utilizing
#                 multiple random restarts allows  us  to  improve algorithm
#                 convergence.
#                 RsCnt&gt;=0.
#                 Zero value means that function automatically choose  small
#                 amount of restarts (recommended).
# 
# OUTPUT PARAMETERS:
#     A, B, C, D- parameters of 4PL model
#     G       -   parameter of 5PL model; for Is4PL=True, G=1 is returned.
#     Rep     -   fitting report. This structure has many fields,  but  ONLY
#                 ONES LISTED BELOW ARE SET:
#                 * Rep.IterationsCount - number of iterations performed
#                 * Rep.RMSError - root-mean-square error
#                 * Rep.AvgError - average absolute error
#                 * Rep.AvgRelError - average relative error (calculated for
#                   non-zero Y-values)
#                 * Rep.MaxError - maximum absolute error
#                 * Rep.R2 - coefficient of determination,  R-squared.  This
#                   coefficient   is  calculated  as  R2=1-RSS/TSS  (in case
#                   of nonlinear  regression  there  are  multiple  ways  to
#                   define R2, each of them giving different results).
# 
# NOTE: for better stability B  parameter is restricted by [+-1/1000,+-1000]
#       range, and G is restricted by [1/10,10] range. It prevents algorithm
#       from making trial steps deep into the area of bad parameters.
# 
# NOTE: after  you  obtained  coefficients,  you  can  evaluate  model  with
#       LogisticCalc5() function.
# 
# NOTE: step is automatically scaled according to scale of parameters  being
#       fitted before we compare its length with EpsX. Thus,  this  function
#       can be used to fit data with very small or very large values without
#       changing EpsX.
# 
# EQUALITY CONSTRAINTS ON PARAMETERS
# 
# 4PL/5PL solver supports equality constraints on model values at  the  left
# boundary (X=0) and right  boundary  (X=infinity).  These  constraints  are
# completely optional and you can specify both of them, only  one  -  or  no
# constraints at all.
# 
# Parameter  CnstrLeft  contains  left  constraint (or NAN for unconstrained
# fitting), and CnstrRight contains right  one.  For  4PL,  left  constraint
# ALWAYS corresponds to parameter A, and right one is ALWAYS  constraint  on
# D. That's because 4PL model is normalized in such way that B&gt;=0.
# 
# For 5PL model things are different. Unlike  4PL  one,  5PL  model  is  NOT
# symmetric with respect to  change  in  sign  of  B. Thus, negative B's are
# possible, and left constraint may constrain parameter A (for positive B's)
# - or parameter D (for negative B's). Similarly changes  meaning  of  right
# constraint.
# 
# You do not have to decide what parameter to  constrain  -  algorithm  will
# automatically determine correct parameters as fitting progresses. However,
# question highlighted above is important when you interpret fitting results.
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.02.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a, b, c, d, g, rep = xalglib.logisticfit45x(x, y, n, cnstrleft, cnstrright, is4pl, lambdav, epsx, rscnt)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          cnstrleft:  float
          cnstrright: float
          is4pl:      bool
          lambdav:    float
          epsx:       float
          rscnt:      int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          float
          b:          float
          c:          float
          d:          float
          g:          float
          rep:        class xalglib.lsfitreport

</div></pre>
<a name='sub_logisticfit4ec'></a><h3 class=pageheader><code>logisticfit4ec</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function fits four-parameter logistic (4PL) model  to  data  provided
# by user, with optional constraints on parameters A and D.  4PL  model  has
# following form:
# 
#     F(x|A,B,C,D) = D+(A-D)/(1+Power(x/C,B))
# 
# Here:
#     * A, D - with optional equality constraints
#     * B&gt;=0
#     * C&gt;0
# 
# IMPORTANT: output of this function is constrained in  such  way that  B&gt;0.
#            Because 4PL model is symmetric with respect to B, there  is  no
#            need to explore  B&lt;0.  Constraining  B  makes  algorithm easier
#            to stabilize and debug.
#            Users  who  for  some  reason  prefer to work with negative B's
#            should transform output themselves (swap A and D, replace B  by
#            -B).
# 
# 4PL fitting is implemented as follows:
# * we perform small number of restarts from random locations which helps to
#   solve problem of bad local extrema. Locations are only partially  random
#   - we use input data to determine good  initial  guess,  but  we  include
#   controlled amount of randomness.
# * we perform Levenberg-Marquardt fitting with very  tight  constraints  on
#   parameters B and C - it allows us to find good  initial  guess  for  the
#   second stage without risk of running into &quot;flat spot&quot;.
# * second  Levenberg-Marquardt  round  is   performed   without   excessive
#   constraints. Results from the previous round are used as initial guess.
# * after fitting is done, we compare results with best values found so far,
#   rewrite &quot;best solution&quot; if needed, and move to next random location.
# 
# Overall algorithm is very stable and is not prone to  bad  local  extrema.
# Furthermore, it automatically scales when input data have  very  large  or
# very small range.
# 
# INPUT PARAMETERS:
#     X       -   array[N], stores X-values.
#                 MUST include only non-negative numbers  (but  may  include
#                 zero values). Can be unsorted.
#     Y       -   array[N], values to fit.
#     N       -   number of points. If N is less than  length  of  X/Y, only
#                 leading N elements are used.
#     CnstrLeft-  optional equality constraint for model value at the   left
#                 boundary (at X=0). Specify NAN (Not-a-Number)  if  you  do
#                 not need constraint on the model value at X=0 (in C++  you
#                 can pass alglib::fp_nan as parameter, in  C#  it  will  be
#                 Double.NaN).
#                 See  below,  section  &quot;EQUALITY  CONSTRAINTS&quot;   for   more
#                 information about constraints.
#     CnstrRight- optional equality constraint for model value at X=infinity.
#                 Specify NAN (Not-a-Number) if you do not  need  constraint
#                 on the model value (in C++  you can pass alglib::fp_nan as
#                 parameter, in  C# it will  be Double.NaN).
#                 See  below,  section  &quot;EQUALITY  CONSTRAINTS&quot;   for   more
#                 information about constraints.
# 
# OUTPUT PARAMETERS:
#     A, B, C, D- parameters of 4PL model
#     Rep     -   fitting report. This structure has many fields,  but  ONLY
#                 ONES LISTED BELOW ARE SET:
#                 * Rep.IterationsCount - number of iterations performed
#                 * Rep.RMSError - root-mean-square error
#                 * Rep.AvgError - average absolute error
#                 * Rep.AvgRelError - average relative error (calculated for
#                   non-zero Y-values)
#                 * Rep.MaxError - maximum absolute error
#                 * Rep.R2 - coefficient of determination,  R-squared.  This
#                   coefficient   is  calculated  as  R2=1-RSS/TSS  (in case
#                   of nonlinear  regression  there  are  multiple  ways  to
#                   define R2, each of them giving different results).
# 
# NOTE: for stability reasons the B parameter is restricted by [1/1000,1000]
#       range. It prevents  algorithm from making trial steps  deep into the
#       area of bad parameters.
# 
# NOTE: after  you  obtained  coefficients,  you  can  evaluate  model  with
#       LogisticCalc4() function.
# 
# NOTE: if you need better control over fitting process than provided by this
#       function, you may use LogisticFit45X().
# 
# NOTE: step is automatically scaled according to scale of parameters  being
#       fitted before we compare its length with EpsX. Thus,  this  function
#       can be used to fit data with very small or very large values without
#       changing EpsX.
# 
# EQUALITY CONSTRAINTS ON PARAMETERS
# 
# 4PL/5PL solver supports equality constraints on model values at  the  left
# boundary (X=0) and right  boundary  (X=infinity).  These  constraints  are
# completely optional and you can specify both of them, only  one  -  or  no
# constraints at all.
# 
# Parameter  CnstrLeft  contains  left  constraint (or NAN for unconstrained
# fitting), and CnstrRight contains right  one.  For  4PL,  left  constraint
# ALWAYS corresponds to parameter A, and right one is ALWAYS  constraint  on
# D. That's because 4PL model is normalized in such way that B&gt;=0.
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.02.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a, b, c, d, rep = xalglib.logisticfit4ec(x, y, n, cnstrleft, cnstrright)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          cnstrleft:  float
          cnstrright: float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          float
          b:          float
          c:          float
          d:          float
          rep:        class xalglib.lsfitreport

</div></pre>
<a name='sub_logisticfit5'></a><h3 class=pageheader><code>logisticfit5</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function fits five-parameter logistic (5PL) model  to  data  provided
# by user. 5PL model has following form:
# 
#     F(x|A,B,C,D,G) = D+(A-D)/Power(1+Power(x/C,B),G)
# 
# Here:
#     * A, D - unconstrained
#     * B - unconstrained
#     * C&gt;0
#     * G&gt;0
# 
# IMPORTANT: unlike in  4PL  fitting,  output  of  this  function   is   NOT
#            constrained in  such  way that B is guaranteed to be  positive.
#            Furthermore,  unlike  4PL,  5PL  model  is  NOT  symmetric with
#            respect to B, so you can NOT transform model to equivalent one,
#            with B having desired sign (&gt;0 or &lt;0).
# 
# 5PL fitting is implemented as follows:
# * we perform small number of restarts from random locations which helps to
#   solve problem of bad local extrema. Locations are only partially  random
#   - we use input data to determine good  initial  guess,  but  we  include
#   controlled amount of randomness.
# * we perform Levenberg-Marquardt fitting with very  tight  constraints  on
#   parameters B and C - it allows us to find good  initial  guess  for  the
#   second stage without risk of running into &quot;flat spot&quot;.  Parameter  G  is
#   fixed at G=1.
# * second  Levenberg-Marquardt  round  is   performed   without   excessive
#   constraints on B and C, but with G still equal to 1.  Results  from  the
#   previous round are used as initial guess.
# * third Levenberg-Marquardt round relaxes constraints on G  and  tries  two
#   different models - one with B&gt;0 and one with B&lt;0.
# * after fitting is done, we compare results with best values found so far,
#   rewrite &quot;best solution&quot; if needed, and move to next random location.
# 
# Overall algorithm is very stable and is not prone to  bad  local  extrema.
# Furthermore, it automatically scales when input data have  very  large  or
# very small range.
# 
# INPUT PARAMETERS:
#     X       -   array[N], stores X-values.
#                 MUST include only non-negative numbers  (but  may  include
#                 zero values). Can be unsorted.
#     Y       -   array[N], values to fit.
#     N       -   number of points. If N is less than  length  of  X/Y, only
#                 leading N elements are used.
# 
# OUTPUT PARAMETERS:
#     A,B,C,D,G-  parameters of 5PL model
#     Rep     -   fitting report. This structure has many fields,  but  ONLY
#                 ONES LISTED BELOW ARE SET:
#                 * Rep.IterationsCount - number of iterations performed
#                 * Rep.RMSError - root-mean-square error
#                 * Rep.AvgError - average absolute error
#                 * Rep.AvgRelError - average relative error (calculated for
#                   non-zero Y-values)
#                 * Rep.MaxError - maximum absolute error
#                 * Rep.R2 - coefficient of determination,  R-squared.  This
#                   coefficient   is  calculated  as  R2=1-RSS/TSS  (in case
#                   of nonlinear  regression  there  are  multiple  ways  to
#                   define R2, each of them giving different results).
# 
# NOTE: for better stability B  parameter is restricted by [+-1/1000,+-1000]
#       range, and G is restricted by [1/10,10] range. It prevents algorithm
#       from making trial steps deep into the area of bad parameters.
# 
# NOTE: after  you  obtained  coefficients,  you  can  evaluate  model  with
#       LogisticCalc5() function.
# 
# NOTE: if you need better control over fitting process than provided by this
#       function, you may use LogisticFit45X().
# 
# NOTE: step is automatically scaled according to scale of parameters  being
#       fitted before we compare its length with EpsX. Thus,  this  function
#       can be used to fit data with very small or very large values without
#       changing EpsX.
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.02.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a, b, c, d, g, rep = xalglib.logisticfit5(x, y, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          float
          b:          float
          c:          float
          d:          float
          g:          float
          rep:        class xalglib.lsfitreport

</div></pre>
<a name='sub_logisticfit5ec'></a><h3 class=pageheader><code>logisticfit5ec</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function fits five-parameter logistic (5PL) model  to  data  provided
# by user, subject to optional equality constraints on parameters A  and  D.
# 5PL model has following form:
# 
#     F(x|A,B,C,D,G) = D+(A-D)/Power(1+Power(x/C,B),G)
# 
# Here:
#     * A, D - with optional equality constraints
#     * B - unconstrained
#     * C&gt;0
#     * G&gt;0
# 
# IMPORTANT: unlike in  4PL  fitting,  output  of  this  function   is   NOT
#            constrained in  such  way that B is guaranteed to be  positive.
#            Furthermore,  unlike  4PL,  5PL  model  is  NOT  symmetric with
#            respect to B, so you can NOT transform model to equivalent one,
#            with B having desired sign (&gt;0 or &lt;0).
# 
# 5PL fitting is implemented as follows:
# * we perform small number of restarts from random locations which helps to
#   solve problem of bad local extrema. Locations are only partially  random
#   - we use input data to determine good  initial  guess,  but  we  include
#   controlled amount of randomness.
# * we perform Levenberg-Marquardt fitting with very  tight  constraints  on
#   parameters B and C - it allows us to find good  initial  guess  for  the
#   second stage without risk of running into &quot;flat spot&quot;.  Parameter  G  is
#   fixed at G=1.
# * second  Levenberg-Marquardt  round  is   performed   without   excessive
#   constraints on B and C, but with G still equal to 1.  Results  from  the
#   previous round are used as initial guess.
# * third Levenberg-Marquardt round relaxes constraints on G  and  tries  two
#   different models - one with B&gt;0 and one with B&lt;0.
# * after fitting is done, we compare results with best values found so far,
#   rewrite &quot;best solution&quot; if needed, and move to next random location.
# 
# Overall algorithm is very stable and is not prone to  bad  local  extrema.
# Furthermore, it automatically scales when input data have  very  large  or
# very small range.
# 
# INPUT PARAMETERS:
#     X       -   array[N], stores X-values.
#                 MUST include only non-negative numbers  (but  may  include
#                 zero values). Can be unsorted.
#     Y       -   array[N], values to fit.
#     N       -   number of points. If N is less than  length  of  X/Y, only
#                 leading N elements are used.
#     CnstrLeft-  optional equality constraint for model value at the   left
#                 boundary (at X=0). Specify NAN (Not-a-Number)  if  you  do
#                 not need constraint on the model value at X=0 (in C++  you
#                 can pass alglib::fp_nan as parameter, in  C#  it  will  be
#                 Double.NaN).
#                 See  below,  section  &quot;EQUALITY  CONSTRAINTS&quot;   for   more
#                 information about constraints.
#     CnstrRight- optional equality constraint for model value at X=infinity.
#                 Specify NAN (Not-a-Number) if you do not  need  constraint
#                 on the model value (in C++  you can pass alglib::fp_nan as
#                 parameter, in  C# it will  be Double.NaN).
#                 See  below,  section  &quot;EQUALITY  CONSTRAINTS&quot;   for   more
#                 information about constraints.
# 
# OUTPUT PARAMETERS:
#     A,B,C,D,G-  parameters of 5PL model
#     Rep     -   fitting report. This structure has many fields,  but  ONLY
#                 ONES LISTED BELOW ARE SET:
#                 * Rep.IterationsCount - number of iterations performed
#                 * Rep.RMSError - root-mean-square error
#                 * Rep.AvgError - average absolute error
#                 * Rep.AvgRelError - average relative error (calculated for
#                   non-zero Y-values)
#                 * Rep.MaxError - maximum absolute error
#                 * Rep.R2 - coefficient of determination,  R-squared.  This
#                   coefficient   is  calculated  as  R2=1-RSS/TSS  (in case
#                   of nonlinear  regression  there  are  multiple  ways  to
#                   define R2, each of them giving different results).
# 
# NOTE: for better stability B  parameter is restricted by [+-1/1000,+-1000]
#       range, and G is restricted by [1/10,10] range. It prevents algorithm
#       from making trial steps deep into the area of bad parameters.
# 
# NOTE: after  you  obtained  coefficients,  you  can  evaluate  model  with
#       LogisticCalc5() function.
# 
# NOTE: if you need better control over fitting process than provided by this
#       function, you may use LogisticFit45X().
# 
# NOTE: step is automatically scaled according to scale of parameters  being
#       fitted before we compare its length with EpsX. Thus,  this  function
#       can be used to fit data with very small or very large values without
#       changing EpsX.
# 
# EQUALITY CONSTRAINTS ON PARAMETERS
# 
# 5PL solver supports equality constraints on model  values  at   the   left
# boundary (X=0) and right  boundary  (X=infinity).  These  constraints  are
# completely optional and you can specify both of them, only  one  -  or  no
# constraints at all.
# 
# Parameter  CnstrLeft  contains  left  constraint (or NAN for unconstrained
# fitting), and CnstrRight contains right  one.
# 
# Unlike 4PL one, 5PL model is NOT symmetric with respect to  change in sign
# of B. Thus, negative B's are possible, and left constraint  may  constrain
# parameter A (for positive B's)  -  or  parameter  D  (for  negative  B's).
# Similarly changes meaning of right constraint.
# 
# You do not have to decide what parameter to  constrain  -  algorithm  will
# automatically determine correct parameters as fitting progresses. However,
# question highlighted above is important when you interpret fitting results.
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.02.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a, b, c, d, g, rep = xalglib.logisticfit5ec(x, y, n, cnstrleft, cnstrright)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          cnstrleft:  float
          cnstrright: float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          float
          b:          float
          c:          float
          d:          float
          g:          float
          rep:        class xalglib.lsfitreport

</div></pre>
<a name='sub_lsfitcreatef'></a><h3 class=pageheader><code>lsfitcreatef</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Nonlinear least squares fitting using function values only.
# 
# Combination of numerical differentiation and secant updates is used to
# obtain function Jacobian.
# 
# Nonlinear task min(F(c)) is solved, where
# 
#     F(c) = (f(c,x[0])-y[0])^2 + ... + (f(c,x[n-1])-y[n-1])^2,
# 
#     * N is a number of points,
#     * M is a dimension of a space points belong to,
#     * K is a dimension of a space of parameters being fitted,
#     * w is an N-dimensional vector of weight coefficients,
#     * x is a set of N points, each of them is an M-dimensional vector,
#     * c is a K-dimensional vector of parameters being fitted
# 
# This subroutine uses only f(c,x[i]).
# 
# INPUT PARAMETERS:
#     X       -   array[0..N-1,0..M-1], points (one row = one point)
#     Y       -   array[0..N-1], function values.
#     C       -   array[0..K-1], initial approximation to the solution,
#     N       -   number of points, N&gt;1
#     M       -   dimension of space
#     K       -   number of parameters being fitted
#     DiffStep-   numerical differentiation step, &gt;0; Obviously,  step  size
#                 should not be too large in order to get a  good  numerical
#                 derivative. However, it also  should  not  be   too  small
#                 because numerical errors are greatly amplified by numerical
#                 differentiation.
#                 By default, symmetric 3-point formula which provides  good
#                 accuracy is used. It can be changed to a  faster  but less
#                 precise 2-point one with minlmsetnumdiff() function.
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# IMPORTANT: the LSFIT optimizer  supports  parallel  model  evaluation  and
#            parallel numerical  differentiation  ('callback  parallelism').
#            This feature, which is present in commercial  ALGLIB  editions,
#            greatly accelerates fits with large datasets  and/or  expensive
#            target functions.
# 
#            Callback parallelism is usually beneficial when a  single  pass
#            over  the   entire   dataset   requires   more   than   several
#            milliseconds.
# 
#            See ALGLIB Reference Manual, 'Working with commercial  version'
#            section,  and  comments  on  lsfitfit()   function   for   more
#            information.
# 
#   -- ALGLIB --
#      Copyright 18.10.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.lsfitcreatef(x, y, c, n, m, k, diffstep)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.lsfitcreatef(x, y, c, diffstep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          2D array/list of float
          y:          1D array/list of float
          c:          1D array/list of float
          n:          int
          m:          int
          k:          int
          diffstep:   float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.lsfitstate

</div></pre>
<a name='sub_lsfitcreatefg'></a><h3 class=pageheader><code>lsfitcreatefg</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Nonlinear least squares fitting using gradient only, without individual
# weights.
# 
# Nonlinear task min(F(c)) is solved, where
# 
#     F(c) = ((f(c,x[0])-y[0]))^2 + ... + ((f(c,x[n-1])-y[n-1]))^2,
# 
#     * N is a number of points,
#     * M is a dimension of a space points belong to,
#     * K is a dimension of a space of parameters being fitted,
#     * x is a set of N points, each of them is an M-dimensional vector,
#     * c is a K-dimensional vector of parameters being fitted
# 
# This subroutine uses only f(c,x[i]) and its gradient.
# 
# INPUT PARAMETERS:
#     X       -   array[0..N-1,0..M-1], points (one row = one point)
#     Y       -   array[0..N-1], function values.
#     C       -   array[0..K-1], initial approximation to the solution,
#     N       -   number of points, N&gt;1
#     M       -   dimension of space
#     K       -   number of parameters being fitted
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# IMPORTANT: the LSFIT optimizer  supports  parallel  model  evaluation  and
#            parallel numerical  differentiation  ('callback  parallelism').
#            This feature, which is present in commercial  ALGLIB  editions,
#            greatly accelerates fits with large datasets  and/or  expensive
#            target functions.
# 
#            Callback parallelism is usually beneficial when a  single  pass
#            over  the   entire   dataset   requires   more   than   several
#            milliseconds.
# 
#            See ALGLIB Reference Manual, 'Working with commercial  version'
#            section,  and  comments  on  lsfitfit()   function   for   more
#            information.
# 
#   -- ALGLIB --
#      Copyright 17.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.lsfitcreatefg(x, y, c, n, m, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.lsfitcreatefg(x, y, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          2D array/list of float
          y:          1D array/list of float
          c:          1D array/list of float
          n:          int
          m:          int
          k:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.lsfitstate

</div></pre>
<a name='sub_lsfitcreatewf'></a><h3 class=pageheader><code>lsfitcreatewf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Weighted nonlinear least squares fitting using function values only.
# 
# Combination of numerical differentiation and secant updates is used to
# obtain function Jacobian.
# 
# Nonlinear task min(F(c)) is solved, where
# 
#     F(c) = (w[0]*(f(c,x[0])-y[0]))^2 + ... + (w[n-1]*(f(c,x[n-1])-y[n-1]))^2,
# 
#     * N is a number of points,
#     * M is a dimension of a space points belong to,
#     * K is a dimension of a space of parameters being fitted,
#     * w is an N-dimensional vector of weight coefficients,
#     * x is a set of N points, each of them is an M-dimensional vector,
#     * c is a K-dimensional vector of parameters being fitted
# 
# This subroutine uses only f(c,x[i]).
# 
# INPUT PARAMETERS:
#     X       -   array[0..N-1,0..M-1], points (one row = one point)
#     Y       -   array[0..N-1], function values.
#     W       -   weights, array[0..N-1]
#     C       -   array[0..K-1], initial approximation to the solution,
#     N       -   number of points, N&gt;1
#     M       -   dimension of space
#     K       -   number of parameters being fitted
#     DiffStep-   numerical differentiation step, &gt;0; Obviously,  step  size
#                 should not be too large in order to get a  good  numerical
#                 derivative. However, it also  should  not  be   too  small
#                 because numerical errors are greatly amplified by numerical
#                 differentiation.
#                 By default, symmetric 3-point formula which provides  good
#                 accuracy is used. It can be changed to a  faster  but less
#                 precise 2-point one with minlmsetnumdiff() function.
# 
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# IMPORTANT: the LSFIT optimizer  supports  parallel  model  evaluation  and
#            parallel numerical  differentiation  ('callback  parallelism').
#            This feature, which is present in commercial  ALGLIB  editions,
#            greatly accelerates fits with large datasets  and/or  expensive
#            target functions.
# 
#            Callback parallelism is usually beneficial when a  single  pass
#            over  the   entire   dataset   requires   more   than   several
#            milliseconds.
# 
#            See ALGLIB Reference Manual, 'Working with commercial  version'
#            section,  and  comments  on  lsfitfit()   function   for   more
#            information.
# 
#   -- ALGLIB --
#      Copyright 18.10.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.lsfitcreatewf(x, y, w, c, n, m, k, diffstep)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.lsfitcreatewf(x, y, w, c, diffstep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          2D array/list of float
          y:          1D array/list of float
          w:          1D array/list of float
          c:          1D array/list of float
          n:          int
          m:          int
          k:          int
          diffstep:   float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.lsfitstate

</div></pre>
<a name='sub_lsfitcreatewfg'></a><h3 class=pageheader><code>lsfitcreatewfg</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Weighted nonlinear least squares fitting using gradient only.
# 
# Nonlinear task min(F(c)) is solved, where
# 
#     F(c) = (w[0]*(f(c,x[0])-y[0]))^2 + ... + (w[n-1]*(f(c,x[n-1])-y[n-1]))^2,
# 
#     * N is a number of points,
#     * M is a dimension of a space points belong to,
#     * K is a dimension of a space of parameters being fitted,
#     * w is an N-dimensional vector of weight coefficients,
#     * x is a set of N points, each of them is an M-dimensional vector,
#     * c is a K-dimensional vector of parameters being fitted
# 
# This subroutine uses only f(c,x[i]) and its gradient.
# 
# INPUT PARAMETERS:
#     X       -   array[0..N-1,0..M-1], points (one row = one point)
#     Y       -   array[0..N-1], function values.
#     W       -   weights, array[0..N-1]
#     C       -   array[0..K-1], initial approximation to the solution,
#     N       -   number of points, N&gt;1
#     M       -   dimension of space
#     K       -   number of parameters being fitted
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# See also:
#     LSFitResults
#     LSFitCreateFG (fitting without weights)
#     LSFitCreateWFGH (fitting using Hessian)
# 
# IMPORTANT: the LSFIT optimizer  supports  parallel  model  evaluation  and
#            parallel numerical  differentiation  ('callback  parallelism').
#            This feature, which is present in commercial  ALGLIB  editions,
#            greatly accelerates fits with large datasets  and/or  expensive
#            target functions.
# 
#            Callback parallelism is usually beneficial when a  single  pass
#            over  the   entire   dataset   requires   more   than   several
#            milliseconds.
# 
#            See ALGLIB Reference Manual, 'Working with commercial  version'
#            section,  and  comments  on  lsfitfit()   function   for   more
#            information.
# 
#   -- ALGLIB --
#      Copyright 17.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.lsfitcreatewfg(x, y, w, c, n, m, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.lsfitcreatewfg(x, y, w, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          2D array/list of float
          y:          1D array/list of float
          w:          1D array/list of float
          c:          1D array/list of float
          n:          int
          m:          int
          k:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.lsfitstate

</div></pre>
<a name='sub_lsfitlinear'></a><h3 class=pageheader><code>lsfitlinear</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Linear least squares fitting.
# 
# QR decomposition is used to reduce task to MxM, then triangular solver  or
# SVD-based solver is used depending on condition number of the  system.  It
# allows to maximize speed and retain decent accuracy.
# 
# IMPORTANT: if you want to perform  polynomial  fitting,  it  may  be  more
#            convenient to use PolynomialFit() function. This function gives
#            best  results  on  polynomial  problems  and  solves  numerical
#            stability  issues  which  arise  when   you   fit   high-degree
#            polynomials to your data.
# 
# INPUT PARAMETERS:
#     Y       -   array[0..N-1] Function values in  N  points.
#     FMatrix -   a table of basis functions values, array[0..N-1, 0..M-1].
#                 FMatrix[I, J] - value of J-th basis function in I-th point.
#     N       -   number of points used. N&gt;=1.
#     M       -   number of basis functions, M&gt;=1.
# 
# OUTPUT PARAMETERS:
#     C       -   decomposition coefficients, array[0..M-1]
#     Rep     -   fitting report. Following fields are set:
#                 * Rep.TerminationType is a completion code, always set  to
#                   1 which denotes success
#                 * Rep.TaskRCond     reciprocal of condition number
#                 * R2                non-adjusted coefficient of determination
#                                     (non-weighted)
#                 * RMSError          rms error on the (X,Y).
#                 * AvgError          average error on the (X,Y).
#                 * AvgRelError       average relative error on the non-zero Y
#                 * MaxError          maximum error
#                                     NON-WEIGHTED ERRORS ARE CALCULATED
# 
# ERRORS IN PARAMETERS
# 
# This  solver  also  calculates different kinds of errors in parameters and
# fills corresponding fields of report:
# * Rep.CovPar        covariance matrix for parameters, array[K,K].
# * Rep.ErrPar        errors in parameters, array[K],
#                     errpar = sqrt(diag(CovPar))
# * Rep.ErrCurve      vector of fit errors - standard deviations of empirical
#                     best-fit curve from &quot;ideal&quot; best-fit curve built  with
#                     infinite number of samples, array[N].
#                     errcurve = sqrt(diag(F*CovPar*F')),
#                     where F is functions matrix.
# * Rep.Noise         vector of per-point estimates of noise, array[N]
# 
# NOTE:       noise in the data is estimated as follows:
#             * for fitting without user-supplied  weights  all  points  are
#               assumed to have same level of noise, which is estimated from
#               the data
#             * for fitting with user-supplied weights we assume that  noise
#               level in I-th point is inversely proportional to Ith weight.
#               Coefficient of proportionality is estimated from the data.
# 
# NOTE:       we apply small amount of regularization when we invert squared
#             Jacobian and calculate covariance matrix. It  guarantees  that
#             algorithm won't divide by zero  during  inversion,  but  skews
#             error estimates a bit (fractional error is about 10^-9).
# 
#             However, we believe that this difference is insignificant  for
#             all practical purposes except for the situation when you  want
#             to compare ALGLIB results with &quot;reference&quot;  implementation  up
#             to the last significant digit.
# 
# NOTE:       covariance matrix is estimated using  correction  for  degrees
#             of freedom (covariances are divided by N-M instead of dividing
#             by N).
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 17.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c, rep = xalglib.lsfitlinear(y, fmatrix, n, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c, rep = xalglib.lsfitlinear(y, fmatrix)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     y:          1D array/list of float
          fmatrix:    2D array/list of float
          n:          int
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of float
          rep:        class xalglib.lsfitreport

</div></pre>
<a name='sub_lsfitlinearc'></a><h3 class=pageheader><code>lsfitlinearc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Constained linear least squares fitting.
# 
# This  is  variation  of LSFitLinear(),  which searchs for min|A*x=b| given
# that  K  additional  constaints  C*x=bc are satisfied. It reduces original
# task to modified one: min|B*y-d| WITHOUT constraints,  then  LSFitLinear()
# is called.
# 
# IMPORTANT: if you want to perform  polynomial  fitting,  it  may  be  more
#            convenient to use PolynomialFit() function. This function gives
#            best  results  on  polynomial  problems  and  solves  numerical
#            stability  issues  which  arise  when   you   fit   high-degree
#            polynomials to your data.
# 
# INPUT PARAMETERS:
#     Y       -   array[0..N-1] Function values in  N  points.
#     FMatrix -   a table of basis functions values, array[0..N-1, 0..M-1].
#                 FMatrix[I,J] - value of J-th basis function in I-th point.
#     CMatrix -   a table of constaints, array[0..K-1,0..M].
#                 I-th row of CMatrix corresponds to I-th linear constraint:
#                 CMatrix[I,0]*C[0] + ... + CMatrix[I,M-1]*C[M-1] = CMatrix[I,M]
#     N       -   number of points used. N&gt;=1.
#     M       -   number of basis functions, M&gt;=1.
#     K       -   number of constraints, 0 &lt;= K &lt; M
#                 K=0 corresponds to absence of constraints.
# 
# OUTPUT PARAMETERS:
#     C       -   decomposition coefficients, array[0..M-1]
#     Rep     -   fitting report. Following fields are set:
#                 * Rep.TerminationType is a completion code:
#                   * set to  1 on success
#                   * set to -3 on failure due to  problematic  constraints:
#                     either too many  constraints (M or  more),  degenerate
#                     constraints (some constraints are repetead  twice)  or
#                     inconsistent constraints are specified
#                 * R2                non-adjusted coefficient of determination
#                                     (non-weighted)
#                 * RMSError          rms error on the (X,Y).
#                 * AvgError          average error on the (X,Y).
#                 * AvgRelError       average relative error on the non-zero Y
#                 * MaxError          maximum error
#                                     NON-WEIGHTED ERRORS ARE CALCULATED
# 
# IMPORTANT:
#     this subroitine doesn't calculate task's condition number for K&lt;&gt;0.
# 
# ERRORS IN PARAMETERS
# 
# This  solver  also  calculates different kinds of errors in parameters and
# fills corresponding fields of report:
# * Rep.CovPar        covariance matrix for parameters, array[K,K].
# * Rep.ErrPar        errors in parameters, array[K],
#                     errpar = sqrt(diag(CovPar))
# * Rep.ErrCurve      vector of fit errors - standard deviations of empirical
#                     best-fit curve from &quot;ideal&quot; best-fit curve built  with
#                     infinite number of samples, array[N].
#                     errcurve = sqrt(diag(F*CovPar*F')),
#                     where F is functions matrix.
# * Rep.Noise         vector of per-point estimates of noise, array[N]
# 
# IMPORTANT:  errors  in  parameters  are  calculated  without  taking  into
#             account boundary/linear constraints! Presence  of  constraints
#             changes distribution of errors, but there is no  easy  way  to
#             account for constraints when you calculate covariance matrix.
# 
# NOTE:       noise in the data is estimated as follows:
#             * for fitting without user-supplied  weights  all  points  are
#               assumed to have same level of noise, which is estimated from
#               the data
#             * for fitting with user-supplied weights we assume that  noise
#               level in I-th point is inversely proportional to Ith weight.
#               Coefficient of proportionality is estimated from the data.
# 
# NOTE:       we apply small amount of regularization when we invert squared
#             Jacobian and calculate covariance matrix. It  guarantees  that
#             algorithm won't divide by zero  during  inversion,  but  skews
#             error estimates a bit (fractional error is about 10^-9).
# 
#             However, we believe that this difference is insignificant  for
#             all practical purposes except for the situation when you  want
#             to compare ALGLIB results with &quot;reference&quot;  implementation  up
#             to the last significant digit.
# 
# NOTE:       covariance matrix is estimated using  correction  for  degrees
#             of freedom (covariances are divided by N-M instead of dividing
#             by N).
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 07.09.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c, rep = xalglib.lsfitlinearc(y, fmatrix, cmatrix, n, m, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c, rep = xalglib.lsfitlinearc(y, fmatrix, cmatrix)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     y:          1D array/list of float
          fmatrix:    2D array/list of float
          cmatrix:    2D array/list of float
          n:          int
          m:          int
          k:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of float
          rep:        class xalglib.lsfitreport

</div></pre>
<a name='sub_lsfitlinearw'></a><h3 class=pageheader><code>lsfitlinearw</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Weighted linear least squares fitting.
# 
# QR decomposition is used to reduce task to MxM, then triangular solver  or
# SVD-based solver is used depending on condition number of the  system.  It
# allows to maximize speed and retain decent accuracy.
# 
# IMPORTANT: if you want to perform  polynomial  fitting,  it  may  be  more
#            convenient to use PolynomialFit() function. This function gives
#            best  results  on  polynomial  problems  and  solves  numerical
#            stability  issues  which  arise  when   you   fit   high-degree
#            polynomials to your data.
# 
# INPUT PARAMETERS:
#     Y       -   array[0..N-1] Function values in  N  points.
#     W       -   array[0..N-1]  Weights  corresponding to function  values.
#                 Each summand in square  sum  of  approximation  deviations
#                 from  given  values  is  multiplied  by  the   square   of
#                 corresponding weight.
#     FMatrix -   a table of basis functions values, array[0..N-1, 0..M-1].
#                 FMatrix[I, J] - value of J-th basis function in I-th point.
#     N       -   number of points used. N&gt;=1.
#     M       -   number of basis functions, M&gt;=1.
# 
# OUTPUT PARAMETERS:
#     C       -   decomposition coefficients, array[0..M-1]
#     Rep     -   fitting report. Following fields are set:
#                 * Rep.TerminationType always set to 1 (success)
#                 * Rep.TaskRCond     reciprocal of condition number
#                 * R2                non-adjusted coefficient of determination
#                                     (non-weighted)
#                 * RMSError          rms error on the (X,Y).
#                 * AvgError          average error on the (X,Y).
#                 * AvgRelError       average relative error on the non-zero Y
#                 * MaxError          maximum error
#                                     NON-WEIGHTED ERRORS ARE CALCULATED
# 
# ERRORS IN PARAMETERS
# 
# This  solver  also  calculates different kinds of errors in parameters and
# fills corresponding fields of report:
# * Rep.CovPar        covariance matrix for parameters, array[K,K].
# * Rep.ErrPar        errors in parameters, array[K],
#                     errpar = sqrt(diag(CovPar))
# * Rep.ErrCurve      vector of fit errors - standard deviations of empirical
#                     best-fit curve from &quot;ideal&quot; best-fit curve built  with
#                     infinite number of samples, array[N].
#                     errcurve = sqrt(diag(F*CovPar*F')),
#                     where F is functions matrix.
# * Rep.Noise         vector of per-point estimates of noise, array[N]
# 
# NOTE:       noise in the data is estimated as follows:
#             * for fitting without user-supplied  weights  all  points  are
#               assumed to have same level of noise, which is estimated from
#               the data
#             * for fitting with user-supplied weights we assume that  noise
#               level in I-th point is inversely proportional to Ith weight.
#               Coefficient of proportionality is estimated from the data.
# 
# NOTE:       we apply small amount of regularization when we invert squared
#             Jacobian and calculate covariance matrix. It  guarantees  that
#             algorithm won't divide by zero  during  inversion,  but  skews
#             error estimates a bit (fractional error is about 10^-9).
# 
#             However, we believe that this difference is insignificant  for
#             all practical purposes except for the situation when you  want
#             to compare ALGLIB results with &quot;reference&quot;  implementation  up
#             to the last significant digit.
# 
# NOTE:       covariance matrix is estimated using  correction  for  degrees
#             of freedom (covariances are divided by N-M instead of dividing
#             by N).
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 17.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c, rep = xalglib.lsfitlinearw(y, w, fmatrix, n, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c, rep = xalglib.lsfitlinearw(y, w, fmatrix)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     y:          1D array/list of float
          w:          1D array/list of float
          fmatrix:    2D array/list of float
          n:          int
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of float
          rep:        class xalglib.lsfitreport

</div></pre>
<a name='sub_lsfitlinearwc'></a><h3 class=pageheader><code>lsfitlinearwc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Weighted constained linear least squares fitting.
# 
# This  is  variation  of LSFitLinearW(), which searchs for min|A*x=b| given
# that  K  additional  constaints  C*x=bc are satisfied. It reduces original
# task to modified one: min|B*y-d| WITHOUT constraints,  then LSFitLinearW()
# is called.
# 
# IMPORTANT: if you want to perform  polynomial  fitting,  it  may  be  more
#            convenient to use PolynomialFit() function. This function gives
#            best  results  on  polynomial  problems  and  solves  numerical
#            stability  issues  which  arise  when   you   fit   high-degree
#            polynomials to your data.
# 
# INPUT PARAMETERS:
#     Y       -   array[0..N-1] Function values in  N  points.
#     W       -   array[0..N-1]  Weights  corresponding to function  values.
#                 Each summand in square  sum  of  approximation  deviations
#                 from  given  values  is  multiplied  by  the   square   of
#                 corresponding weight.
#     FMatrix -   a table of basis functions values, array[0..N-1, 0..M-1].
#                 FMatrix[I,J] - value of J-th basis function in I-th point.
#     CMatrix -   a table of constaints, array[0..K-1,0..M].
#                 I-th row of CMatrix corresponds to I-th linear constraint:
#                 CMatrix[I,0]*C[0] + ... + CMatrix[I,M-1]*C[M-1] = CMatrix[I,M]
#     N       -   number of points used. N&gt;=1.
#     M       -   number of basis functions, M&gt;=1.
#     K       -   number of constraints, 0 &lt;= K &lt; M
#                 K=0 corresponds to absence of constraints.
# 
# OUTPUT PARAMETERS:
#     C       -   decomposition coefficients, array[0..M-1]
#     Rep     -   fitting report. The following fields are set:
#                 * Rep.TerminationType is a completion code:
#                   * set to  1 on success
#                   * set to -3 on failure due to  problematic  constraints:
#                     either too many  constraints (M or  more),  degenerate
#                     constraints (some constraints are repetead  twice)  or
#                     inconsistent constraints are specified
#                 * R2                non-adjusted coefficient of determination
#                                     (non-weighted)
#                 * RMSError          rms error on the (X,Y).
#                 * AvgError          average error on the (X,Y).
#                 * AvgRelError       average relative error on the non-zero Y
#                 * MaxError          maximum error
#                                     NON-WEIGHTED ERRORS ARE CALCULATED
# 
# IMPORTANT:
#     this subroitine doesn't calculate task's condition number for K&lt;&gt;0.
# 
# ERRORS IN PARAMETERS
# 
# This  solver  also  calculates different kinds of errors in parameters and
# fills corresponding fields of report:
# * Rep.CovPar        covariance matrix for parameters, array[K,K].
# * Rep.ErrPar        errors in parameters, array[K],
#                     errpar = sqrt(diag(CovPar))
# * Rep.ErrCurve      vector of fit errors - standard deviations of empirical
#                     best-fit curve from &quot;ideal&quot; best-fit curve built  with
#                     infinite number of samples, array[N].
#                     errcurve = sqrt(diag(F*CovPar*F')),
#                     where F is functions matrix.
# * Rep.Noise         vector of per-point estimates of noise, array[N]
# 
# IMPORTANT:  errors  in  parameters  are  calculated  without  taking  into
#             account boundary/linear constraints! Presence  of  constraints
#             changes distribution of errors, but there is no  easy  way  to
#             account for constraints when you calculate covariance matrix.
# 
# NOTE:       noise in the data is estimated as follows:
#             * for fitting without user-supplied  weights  all  points  are
#               assumed to have same level of noise, which is estimated from
#               the data
#             * for fitting with user-supplied weights we assume that  noise
#               level in I-th point is inversely proportional to Ith weight.
#               Coefficient of proportionality is estimated from the data.
# 
# NOTE:       we apply small amount of regularization when we invert squared
#             Jacobian and calculate covariance matrix. It  guarantees  that
#             algorithm won't divide by zero  during  inversion,  but  skews
#             error estimates a bit (fractional error is about 10^-9).
# 
#             However, we believe that this difference is insignificant  for
#             all practical purposes except for the situation when you  want
#             to compare ALGLIB results with &quot;reference&quot;  implementation  up
#             to the last significant digit.
# 
# NOTE:       covariance matrix is estimated using  correction  for  degrees
#             of freedom (covariances are divided by N-M instead of dividing
#             by N).
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 07.09.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c, rep = xalglib.lsfitlinearwc(y, w, fmatrix, cmatrix, n, m, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c, rep = xalglib.lsfitlinearwc(y, w, fmatrix, cmatrix)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     y:          1D array/list of float
          w:          1D array/list of float
          fmatrix:    2D array/list of float
          cmatrix:    2D array/list of float
          n:          int
          m:          int
          k:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of float
          rep:        class xalglib.lsfitreport

</div></pre>
<a name='sub_lsfitresults'></a><h3 class=pageheader><code>lsfitresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Nonlinear least squares fitting results.
# 
# Called after return from LSFitFit().
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     C       -   array[K], solution
#     Rep     -   optimization report. On success following fields are set:
#                 * TerminationType   completion code:
#                     * -8    optimizer   detected  NAN/INF  in  the  target
#                             function and/or gradient
#                     * -7    gradient verification failed.
#                             See LSFitSetGradientCheck() for more information.
#                     * -3    inconsistent constraints
#                     *  2    relative step is no more than EpsX.
#                     *  5    MaxIts steps was taken
#                     *  7    stopping conditions are too stringent,
#                             further improvement is impossible
#                 * R2                non-adjusted coefficient of determination
#                                     (non-weighted)
#                 * RMSError          rms error on the (X,Y).
#                 * AvgError          average error on the (X,Y).
#                 * AvgRelError       average relative error on the non-zero Y
#                 * MaxError          maximum error
#                                     NON-WEIGHTED ERRORS ARE CALCULATED
#                 * WRMSError         weighted rms error on the (X,Y).
# 
# ERRORS IN PARAMETERS
# 
# This  solver  also  calculates different kinds of errors in parameters and
# fills corresponding fields of report:
# * Rep.CovPar        covariance matrix for parameters, array[K,K].
# * Rep.ErrPar        errors in parameters, array[K],
#                     errpar = sqrt(diag(CovPar))
# * Rep.ErrCurve      vector of fit errors - standard deviations of empirical
#                     best-fit curve from &quot;ideal&quot; best-fit curve built  with
#                     infinite number of samples, array[N].
#                     errcurve = sqrt(diag(J*CovPar*J')),
#                     where J is Jacobian matrix.
# * Rep.Noise         vector of per-point estimates of noise, array[N]
# 
# IMPORTANT:  errors  in  parameters  are  calculated  without  taking  into
#             account boundary/linear constraints! Presence  of  constraints
#             changes distribution of errors, but there is no  easy  way  to
#             account for constraints when you calculate covariance matrix.
# 
# NOTE:       noise in the data is estimated as follows:
#             * for fitting without user-supplied  weights  all  points  are
#               assumed to have same level of noise, which is estimated from
#               the data
#             * for fitting with user-supplied weights we assume that  noise
#               level in I-th point is inversely proportional to Ith weight.
#               Coefficient of proportionality is estimated from the data.
# 
# NOTE:       we apply small amount of regularization when we invert squared
#             Jacobian and calculate covariance matrix. It  guarantees  that
#             algorithm won't divide by zero  during  inversion,  but  skews
#             error estimates a bit (fractional error is about 10^-9).
# 
#             However, we believe that this difference is insignificant  for
#             all practical purposes except for the situation when you  want
#             to compare ALGLIB results with &quot;reference&quot;  implementation  up
#             to the last significant digit.
# 
# NOTE:       covariance matrix is estimated using  correction  for  degrees
#             of freedom (covariances are divided by N-M instead of dividing
#             by N).
# 
#   -- ALGLIB --
#      Copyright 17.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c, rep = xalglib.lsfitresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lsfitstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of float
          rep:        class xalglib.lsfitreport

</div></pre>
<a name='sub_lsfitsetbc'></a><h3 class=pageheader><code>lsfitsetbc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets boundary constraints for underlying optimizer
# 
# Boundary constraints are inactive by default (after initial creation).
# They are preserved until explicitly turned off with another SetBC() call.
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     BndL    -   lower bounds, array[K].
#                 If some (all) variables are unbounded, you may specify
#                 very small number or -INF (latter is recommended because
#                 it will allow solver to use better algorithm).
#     BndU    -   upper bounds, array[K].
#                 If some (all) variables are unbounded, you may specify
#                 very large number or +INF (latter is recommended because
#                 it will allow solver to use better algorithm).
# 
# NOTE 1: it is possible to specify BndL[i]=BndU[i]. In this case I-th
# variable will be &quot;frozen&quot; at X[i]=BndL[i]=BndU[i].
# 
# NOTE 2: unlike other constrained optimization algorithms, this solver  has
# following useful properties:
# * bound constraints are always satisfied exactly
# * function is evaluated only INSIDE area specified by bound constraints
# 
#   -- ALGLIB --
#      Copyright 14.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lsfitsetbc(state, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lsfitstate
          bndl:       1D array/list of float
          bndu:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lsfitsetcond'></a><h3 class=pageheader><code>lsfitsetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Stopping conditions for nonlinear least squares fitting.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     EpsX    -   &gt;=0
#                 The subroutine finishes its work if  on  k+1-th  iteration
#                 the condition |v|&lt;=EpsX is fulfilled, where:
#                 * |.| means Euclidian norm
#                 * v - scaled step vector, v[i]=dx[i]/s[i]
#                 * dx - ste pvector, dx=X(k+1)-X(k)
#                 * s - scaling coefficients set by LSFitSetScale()
#     MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
#                 iterations   is    unlimited.   Only   Levenberg-Marquardt
#                 iterations  are  counted  (L-BFGS/CG  iterations  are  NOT
#                 counted because their cost is very low compared to that of
#                 LM).
# 
# NOTE
# 
# Passing EpsX=0  and  MaxIts=0  (simultaneously)  will  lead  to  automatic
# stopping criterion selection (according to the scheme used by MINLM unit).
# 
# 
#   -- ALGLIB --
#      Copyright 17.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lsfitsetcond(state, epsx, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lsfitstate
          epsx:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lsfitsetgradientcheck'></a><h3 class=pageheader><code>lsfitsetgradientcheck</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  subroutine  turns  on  verification  of  the  user-supplied analytic
# gradient:
# * user calls this subroutine before fitting begins
# * LSFitFit() is called
# * prior to actual fitting, for  each  point  in  data  set  X_i  and  each
#   component  of  parameters  being  fited C_j algorithm performs following
#   steps:
#   * two trial steps are made to C_j-TestStep*S[j] and C_j+TestStep*S[j],
#     where C_j is j-th parameter and S[j] is a scale of j-th parameter
#   * if needed, steps are bounded with respect to constraints on C[]
#   * F(X_i|C) is evaluated at these trial points
#   * we perform one more evaluation in the middle point of the interval
#   * we  build  cubic  model using function values and derivatives at trial
#     points and we compare its prediction with actual value in  the  middle
#     point
#   * in case difference between prediction and actual value is higher  than
#     some predetermined threshold, algorithm stops with completion code -7;
#     Rep.VarIdx is set to index of the parameter with incorrect derivative.
# * after verification is over, algorithm proceeds to the actual optimization.
# 
# NOTE 1: verification needs N*K (points count * parameters count)  gradient
#         evaluations. It is very costly and you should use it only for  low
#         dimensional  problems,  when  you  want  to  be  sure  that you've
#         correctly calculated analytic derivatives. You should not  use  it
#         in the production code  (unless  you  want  to  check  derivatives
#         provided by some third party).
# 
# NOTE 2: you  should  carefully  choose  TestStep. Value which is too large
#         (so large that function behaviour is significantly non-cubic) will
#         lead to false alarms. You may use  different  step  for  different
#         parameters by means of setting scale with LSFitSetScale().
# 
# NOTE 3: this function may lead to false positives. In case it reports that
#         I-th  derivative was calculated incorrectly, you may decrease test
#         step  and  try  one  more  time  - maybe your function changes too
#         sharply  and  your  step  is  too  large for such rapidly chanding
#         function.
# 
# NOTE 4: this function works only for optimizers created with LSFitCreateWFG()
#         or LSFitCreateFG() constructors.
# 
# INPUT PARAMETERS:
#     State       -   structure used to store algorithm state
#     TestStep    -   verification step:
#                     * TestStep=0 turns verification off
#                     * TestStep&gt;0 activates verification
# 
#   -- ALGLIB --
#      Copyright 15.06.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lsfitsetgradientcheck(state, teststep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lsfitstate
          teststep:   float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lsfitsetlc'></a><h3 class=pageheader><code>lsfitsetlc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets linear constraints for underlying optimizer
# 
# Linear constraints are inactive by default (after initial creation).
# They are preserved until explicitly turned off with another SetLC() call.
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     C       -   linear constraints, array[K,N+1].
#                 Each row of C represents one constraint, either equality
#                 or inequality (see below):
#                 * first N elements correspond to coefficients,
#                 * last element corresponds to the right part.
#                 All elements of C (including right part) must be finite.
#     CT      -   type of constraints, array[K]:
#                 * if CT[i]&gt;0, then I-th constraint is C[i,*]*x &gt;= C[i,n+1]
#                 * if CT[i]=0, then I-th constraint is C[i,*]*x  = C[i,n+1]
#                 * if CT[i]&lt;0, then I-th constraint is C[i,*]*x &lt;= C[i,n+1]
#     K       -   number of equality/inequality constraints, K&gt;=0:
#                 * if given, only leading K elements of C/CT are used
#                 * if not given, automatically determined from sizes of C/CT
# 
# IMPORTANT: if you have linear constraints, it is strongly  recommended  to
#            set scale of variables with lsfitsetscale(). QP solver which is
#            used to calculate linearly constrained steps heavily relies  on
#            good scaling of input problems.
# 
# NOTE: linear  (non-box)  constraints  are  satisfied only approximately  -
#       there  always  exists some violation due  to  numerical  errors  and
#       algorithmic limitations.
# 
# NOTE: general linear constraints  add  significant  overhead  to  solution
#       process. Although solver performs roughly same amount of  iterations
#       (when compared  with  similar  box-only  constrained  problem), each
#       iteration   now    involves  solution  of  linearly  constrained  QP
#       subproblem, which requires ~3-5 times more Cholesky  decompositions.
#       Thus, if you can reformulate your problem in such way  this  it  has
#       only box constraints, it may be beneficial to do so.
# 
#   -- ALGLIB --
#      Copyright 29.04.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lsfitsetlc(state, c, ct, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lsfitsetlc(state, c, ct)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lsfitstate
          c:          2D array/list of float
          ct:         1D array/list of int
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lsfitsetnonmonotonicsteps'></a><h3 class=pageheader><code>lsfitsetnonmonotonicsteps</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used  to  activate/deactivate  nonmonotonic  steps.  Such
# steps may improve  convergence  on  noisy  problems  or  ones  with  minor
# smoothness defects.
# 
# In  its  standard  mode,  LSFIT solver compares squared errors f[1] at the
# trial point with the value at the current  point  f[0].  Only  steps  that
# decrease f() are accepted.
# 
# When the nonmonotonic mode is activated, f[1]  is  compared  with  maximum
# over several previous  locations:  max(f[0],f[-1],...,f[-CNT]).  We  still
# accept only steps that decrease  f(),  however  our  reference  value  has
# changed. The net results is that f[1]&gt;f[0] are now allowed.
# 
# Nonmonotonic steps can help to handle minor defects in the objective (e.g.
# small  noise,  discontinuous  jumps  or  nonsmoothness).  However,  it  is
# important  that  the  overall  shape  of  the  problem  is  still  smooth.
# It  may  also  help  to  minimize  perfectly  smooth  targets with complex
# geometries by allowing to jump through curved valleys.
# 
# However, sometimes nonmonotonic steps degrade convergence by  allowing  an
# optimizer to wander too far away from the solution, so this feature should
# be used only after careful testing.
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     Cnt     -   nonmonotonic memory length, Cnt&gt;=0:
#                 * 0 for traditional monotonic steps
#                 * 2..3 is recommended for the nonmonotonic optimization
# 
#   -- ALGLIB --
#      Copyright 07.04.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lsfitsetnonmonotonicsteps(state, cnt)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lsfitstate
          cnt:        int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lsfitsetnumdiff'></a><h3 class=pageheader><code>lsfitsetnumdiff</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets specific finite  difference  formula  to  be  used  for
# numerical differentiation.
# 
# It works only for optimizers configured to use numerical  differentiation;
# in other cases it has no effect.
# 
# INPUT PARAMETERS:
#     State       -   optimizer
#     FormulaType -   formula type:
#                     * 3 for a 3-point formula, which is also  known  as  a
#                       symmetric difference quotient (the formula  actually
#                       uses only two function values per variable:  at  x+h
#                       and x-h). A good choice for medium-accuracy  setups,
#                       a default option.
#                     * 2 for a forward (or backward, depending  on variable
#                       bounds)  finite   difference  (f(x+h)-f(x))/h.  This
#                       formula has the lowest accuracy. However, it  is  4x
#                       faster than the 5-point formula and 2x  faster  than
#                       the 3-point one because, in addition to the  central
#                       value f(x), it needs only  one  additional  function
#                       evaluation per variable.
# 
# 
#   -- ALGLIB --
#      Copyright 03.12.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lsfitsetnumdiff(state, formulatype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lsfitstate
          formulatype: int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lsfitsetscale'></a><h3 class=pageheader><code>lsfitsetscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets scaling coefficients for underlying optimizer.
# 
# ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
# size and gradient are scaled before comparison with tolerances).  Scale of
# the I-th variable is a translation invariant measure of:
# a) &quot;how large&quot; the variable is
# b) how large the step should be to make significant changes in the function
# 
# Generally, scale is NOT considered to be a form of preconditioner.  But LM
# optimizer is unique in that it uses scaling matrix both  in  the  stopping
# condition tests and as Marquardt damping factor.
# 
# Proper scaling is very important for the algorithm performance. It is less
# important for the quality of results, but still has some influence (it  is
# easier  to  converge  when  variables  are  properly  scaled, so premature
# stopping is possible when very badly scalled variables are  combined  with
# relaxed stopping conditions).
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     S       -   array[N], non-zero scaling coefficients
#                 S[i] may be negative, sign doesn't matter.
# 
#   -- ALGLIB --
#      Copyright 14.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lsfitsetscale(state, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lsfitstate
          s:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lsfitsetstpmax'></a><h3 class=pageheader><code>lsfitsetstpmax</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets maximum step length
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     StpMax  -   maximum step length, &gt;=0. Set StpMax to 0.0,  if you don't
#                 want to limit step length.
# 
# Use this subroutine when you optimize target function which contains exp()
# or  other  fast  growing  functions,  and optimization algorithm makes too
# large  steps  which  leads  to overflow. This function allows us to reject
# steps  that  are  too  large  (and  therefore  expose  us  to the possible
# overflow) without actually calculating function value at the x+stp*d.
# 
# NOTE: non-zero StpMax leads to moderate  performance  degradation  because
# intermediate  step  of  preconditioned L-BFGS optimization is incompatible
# with limits on step size.
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lsfitsetstpmax(state, stpmax)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lsfitstate
          stpmax:     float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lsfitsetxrep'></a><h3 class=pageheader><code>lsfitsetxrep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function turns on/off reporting.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     NeedXRep-   whether iteration reports are needed or not
# 
# When reports are needed, State.C (current parameters) and State.F (current
# value of fitting function) are reported.
# 
# 
#   -- ALGLIB --
#      Copyright 15.08.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lsfitsetxrep(state, needxrep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.lsfitstate
          needxrep:   bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lstfitpiecewiselinearrdp'></a><h3 class=pageheader><code>lstfitpiecewiselinearrdp</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  subroutine fits piecewise linear curve to points with Ramer-Douglas-
# Peucker algorithm, which stops after achieving desired precision.
# 
# IMPORTANT:
# * it performs non-least-squares fitting; it builds curve, but  this  curve
#   does not minimize some least squares  metric.  See  description  of  RDP
#   algorithm (say, in Wikipedia) for more details on WHAT is performed.
# * this function does NOT work with parametric curves  (i.e.  curves  which
#   can be represented as {X(t),Y(t)}. It works with curves   which  can  be
#   represented as Y(X). Thus, it is impossible to model figures like circles
#   with this functions.
#   If  you  want  to  work  with  parametric   curves,   you   should   use
#   ParametricRDPFixed() function provided  by  &quot;Parametric&quot;  subpackage  of
#   &quot;Interpolation&quot; package.
# 
# INPUT PARAMETERS:
#     X       -   array of X-coordinates:
#                 * at least N elements
#                 * can be unordered (points are automatically sorted)
#                 * this function may accept non-distinct X (see below for
#                   more information on handling of such inputs)
#     Y       -   array of Y-coordinates:
#                 * at least N elements
#     N       -   number of elements in X/Y
#     Eps     -   positive number, desired precision.
# 
# 
# OUTPUT PARAMETERS:
#     X2      -   X-values of corner points for piecewise approximation,
#                 has length NSections+1 or zero (for NSections=0).
#     Y2      -   Y-values of corner points,
#                 has length NSections+1 or zero (for NSections=0).
#     NSections-  number of sections found by algorithm,
#                 NSections can be zero for degenerate datasets
#                 (N&lt;=1 or all X[] are non-distinct).
# 
# NOTE: X2/Y2 are ordered arrays, i.e. (X2[0],Y2[0]) is  a  first  point  of
#       curve, (X2[NSection-1],Y2[NSection-1]) is the last point.
# 
#   -- ALGLIB --
#      Copyright 02.10.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x2, y2, nsections = xalglib.lstfitpiecewiselinearrdp(x, y, n, eps)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          eps:        float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x2:         1D array/list of float
          y2:         1D array/list of float
          nsections:  int

</div></pre>
<a name='sub_lstfitpiecewiselinearrdpfixed'></a><h3 class=pageheader><code>lstfitpiecewiselinearrdpfixed</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  subroutine fits piecewise linear curve to points with Ramer-Douglas-
# Peucker algorithm, which stops after generating specified number of linear
# sections.
# 
# IMPORTANT:
# * it does NOT perform least-squares fitting; it  builds  curve,  but  this
#   curve does not minimize some least squares metric.  See  description  of
#   RDP algorithm (say, in Wikipedia) for more details on WHAT is performed.
# * this function does NOT work with parametric curves  (i.e.  curves  which
#   can be represented as {X(t),Y(t)}. It works with curves   which  can  be
#   represented as Y(X). Thus,  it  is  impossible  to  model  figures  like
#   circles  with  this  functions.
#   If  you  want  to  work  with  parametric   curves,   you   should   use
#   ParametricRDPFixed() function provided  by  &quot;Parametric&quot;  subpackage  of
#   &quot;Interpolation&quot; package.
# 
# INPUT PARAMETERS:
#     X       -   array of X-coordinates:
#                 * at least N elements
#                 * can be unordered (points are automatically sorted)
#                 * this function may accept non-distinct X (see below for
#                   more information on handling of such inputs)
#     Y       -   array of Y-coordinates:
#                 * at least N elements
#     N       -   number of elements in X/Y
#     M       -   desired number of sections:
#                 * at most M sections are generated by this function
#                 * less than M sections can be generated if we have N&lt;M
#                   (or some X are non-distinct).
# 
# OUTPUT PARAMETERS:
#     X2      -   X-values of corner points for piecewise approximation,
#                 has length NSections+1 or zero (for NSections=0).
#     Y2      -   Y-values of corner points,
#                 has length NSections+1 or zero (for NSections=0).
#     NSections-  number of sections found by algorithm, NSections&lt;=M,
#                 NSections can be zero for degenerate datasets
#                 (N&lt;=1 or all X[] are non-distinct).
# 
# NOTE: X2/Y2 are ordered arrays, i.e. (X2[0],Y2[0]) is  a  first  point  of
#       curve, (X2[NSection-1],Y2[NSection-1]) is the last point.
# 
#   -- ALGLIB --
#      Copyright 02.10.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x2, y2, nsections = xalglib.lstfitpiecewiselinearrdpfixed(x, y, n, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x2:         1D array/list of float
          y2:         1D array/list of float
          nsections:  int

</div></pre>
<a name='sub_polynomialfit'></a><h3 class=pageheader><code>polynomialfit</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Fitting by polynomials in barycentric form. This function provides  simple
# unterface for unconstrained unweighted fitting. See  PolynomialFitWC()  if
# you need constrained fitting.
# 
# The task is linear, thus the linear least  squares  solver  is  used.  The
# complexity of this computational scheme is O(N*M^2), mostly  dominated  by
# the least squares solver
# 
# SEE ALSO:
#     PolynomialFitWC()
# 
# NOTES:
#     you can convert P from barycentric form  to  the  power  or  Chebyshev
#     basis with PolynomialBar2Pow() or PolynomialBar2Cheb() functions  from
#     POLINT subpackage.
# 
# INPUT PARAMETERS:
#     X   -   points, array[0..N-1].
#     Y   -   function values, array[0..N-1].
#     N   -   number of points, N&gt;0
#             * if given, only leading N elements of X/Y are used
#             * if not given, automatically determined from sizes of X/Y
#     M   -   number of basis functions (= polynomial_degree + 1), M&gt;=1
# 
# OUTPUT PARAMETERS:
#     P   -   interpolant in barycentric form for Rep.TerminationType&gt;0.
#             undefined for Rep.TerminationType&lt;0.
#     Rep -   fitting report. The following fields are set:
#                 * Rep.TerminationType is a completion code which is always
#                   set to 1 (success)
#                 * RMSError      rms error on the (X,Y).
#                 * AvgError      average error on the (X,Y).
#                 * AvgRelError   average relative error on the non-zero Y
#                 * MaxError      maximum error
#                                 NON-WEIGHTED ERRORS ARE CALCULATED
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB PROJECT --
#      Copyright 10.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p, rep = xalglib.polynomialfit(x, y, n, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   p, rep = xalglib.polynomialfit(x, y, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          class xalglib.barycentricinterpolant
          rep:        class xalglib.polynomialfitreport

</div></pre>
<a name='sub_polynomialfitwc'></a><h3 class=pageheader><code>polynomialfitwc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Weighted  fitting by polynomials in barycentric form, with constraints  on
# function values or first derivatives.
# 
# Small regularizing term is used when solving constrained tasks (to improve
# stability).
# 
# Task is linear, so linear least squares solver is used. Complexity of this
# computational scheme is O(N*M^2), mostly dominated by least squares solver
# 
# SEE ALSO:
#     PolynomialFit()
# 
# NOTES:
#     you can convert P from barycentric form  to  the  power  or  Chebyshev
#     basis with PolynomialBar2Pow() or PolynomialBar2Cheb() functions  from
#     the POLINT subpackage.
# 
# INPUT PARAMETERS:
#     X   -   points, array[0..N-1].
#     Y   -   function values, array[0..N-1].
#     W   -   weights, array[0..N-1]
#             Each summand in square  sum  of  approximation deviations from
#             given  values  is  multiplied  by  the square of corresponding
#             weight. Fill it by 1's if you don't  want  to  solve  weighted
#             task.
#     N   -   number of points, N&gt;0.
#             * if given, only leading N elements of X/Y/W are used
#             * if not given, automatically determined from sizes of X/Y/W
#     XC  -   points where polynomial values/derivatives are constrained,
#             array[0..K-1].
#     YC  -   values of constraints, array[0..K-1]
#     DC  -   array[0..K-1], types of constraints:
#             * DC[i]=0   means that P(XC[i])=YC[i]
#             * DC[i]=1   means that P'(XC[i])=YC[i]
#             SEE BELOW FOR IMPORTANT INFORMATION ON CONSTRAINTS
#     K   -   number of constraints, 0&lt;=K&lt;M.
#             K=0 means no constraints (XC/YC/DC are not used in such cases)
#     M   -   number of basis functions (= polynomial_degree + 1), M&gt;=1
# 
# OUTPUT PARAMETERS:
#     P   -   interpolant in barycentric form for Rep.TerminationType&gt;0.
#             undefined for Rep.TerminationType&lt;0.
#     Rep -   fitting report. The following fields are set:
#                 * Rep.TerminationType is a completion code:
#                   * set to  1 on success
#                   * set to -3 on failure due to  problematic  constraints:
#                     either too many  constraints,  degenerate  constraints
#                     or inconsistent constraints were passed
#                 * RMSError      rms error on the (X,Y).
#                 * AvgError      average error on the (X,Y).
#                 * AvgRelError   average relative error on the non-zero Y
#                 * MaxError      maximum error
#                                 NON-WEIGHTED ERRORS ARE CALCULATED
# 
# IMPORTANT:
#     this subroitine doesn't calculate task's condition number for K&lt;&gt;0.
# 
# SETTING CONSTRAINTS - DANGERS AND OPPORTUNITIES:
# 
# Setting constraints can lead  to undesired  results,  like ill-conditioned
# behavior, or inconsistency being detected. From the other side,  it allows
# us to improve quality of the fit. Here we summarize  our  experience  with
# constrained regression splines:
# * even simple constraints can be inconsistent, see  Wikipedia  article  on
#   this subject: http://en.wikipedia.org/wiki/Birkhoff_interpolation
# * the  greater  is  M (given  fixed  constraints),  the  more chances that
#   constraints will be consistent
# * in the general case, consistency of constraints is NOT GUARANTEED.
# * in the one special cases, however, we can  guarantee  consistency.  This
#   case  is:  M&gt;1  and constraints on the function values (NOT DERIVATIVES)
# 
# Our final recommendation is to use constraints  WHEN  AND  ONLY  when  you
# can't solve your task without them. Anything beyond  special  cases  given
# above is not guaranteed and may result in inconsistency.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB PROJECT --
#      Copyright 10.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p, rep = xalglib.polynomialfitwc(x, y, w, n, xc, yc, dc, k, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   p, rep = xalglib.polynomialfitwc(x, y, w, xc, yc, dc, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          w:          1D array/list of float
          n:          int
          xc:         1D array/list of float
          yc:         1D array/list of float
          dc:         1D array/list of int
          k:          int
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          class xalglib.barycentricinterpolant
          rep:        class xalglib.polynomialfitreport

</div></pre>
<a name='sub_spline1dfitcubicwc'></a><h3 class=pageheader><code>spline1dfitcubicwc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Weighted fitting by cubic  spline,  with constraints on function values or
# derivatives.
# 
# Equidistant grid with M-2 nodes on [min(x,xc),max(x,xc)] is  used to build
# basis functions. Basis functions are cubic splines with continuous  second
# derivatives  and  non-fixed first  derivatives  at  interval  ends.  Small
# regularizing term is used  when  solving  constrained  tasks  (to  improve
# stability).
# 
# Task is linear, so linear least squares solver is used. Complexity of this
# computational scheme is O(N*M^2), mostly dominated by least squares solver
# 
# IMPORTANT: ALGLIB has a much faster version  of  the  cubic spline fitting
#            function - spline1dfit(). This function performs least  squares
#            fit in O(max(M,N)) time/memory. However, it  does  not  support
#            constraints.
# 
# INPUT PARAMETERS:
#     X   -   points, array[0..N-1].
#     Y   -   function values, array[0..N-1].
#     W   -   weights, array[0..N-1]
#             Each summand in square  sum  of  approximation deviations from
#             given  values  is  multiplied  by  the square of corresponding
#             weight. Fill it by 1's if you don't  want  to  solve  weighted
#             task.
#     N   -   number of points (optional):
#             * N&gt;0
#             * if given, only first N elements of X/Y/W are processed
#             * if not given, automatically determined from X/Y/W sizes
#     XC  -   points where spline values/derivatives are constrained,
#             array[0..K-1].
#     YC  -   values of constraints, array[0..K-1]
#     DC  -   array[0..K-1], types of constraints:
#             * DC[i]=0   means that S(XC[i])=YC[i]
#             * DC[i]=1   means that S'(XC[i])=YC[i]
#             SEE BELOW FOR IMPORTANT INFORMATION ON CONSTRAINTS
#     K   -   number of constraints (optional):
#             * 0&lt;=K&lt;M.
#             * K=0 means no constraints (XC/YC/DC are not used)
#             * if given, only first K elements of XC/YC/DC are used
#             * if not given, automatically determined from XC/YC/DC
#     M   -   number of basis functions ( = number_of_nodes+2), M&gt;=4.
# 
# OUTPUT PARAMETERS:
#     S   -   spline interpolant.
#     Rep     -   fitting report. The following fields are set:
#                 * Rep.TerminationType is a completion code:
#                   * set to  1 on success
#                   * set to -3 on failure due to  problematic  constraints:
#                     either too many  constraints,  degenerate  constraints
#                     or inconsistent constraints were passed
#                 * RMSError      rms error on the (X,Y).
#                 * AvgError      average error on the (X,Y).
#                 * AvgRelError   average relative error on the non-zero Y
#                 * MaxError      maximum error
#                                 NON-WEIGHTED ERRORS ARE CALCULATED
# 
# IMPORTANT:
#     this subroitine doesn't calculate task's condition number for K&lt;&gt;0.
# 
# 
# ORDER OF POINTS
# 
# Subroutine automatically sorts points, so caller may pass unsorted array.
# 
# SETTING CONSTRAINTS - DANGERS AND OPPORTUNITIES:
# 
# Setting constraints can lead  to undesired  results,  like ill-conditioned
# behavior, or inconsistency being detected. From the other side,  it allows
# us to improve quality of the fit. Here we summarize  our  experience  with
# constrained regression splines:
# * excessive constraints can be inconsistent. Splines are  piecewise  cubic
#   functions, and it is easy to create an example, where  large  number  of
#   constraints  concentrated  in  small  area will result in inconsistency.
#   Just because spline is not flexible enough to satisfy all of  them.  And
#   same constraints spread across the  [min(x),max(x)]  will  be  perfectly
#   consistent.
# * the more evenly constraints are spread across [min(x),max(x)],  the more
#   chances that they will be consistent
# * the  greater  is  M (given  fixed  constraints),  the  more chances that
#   constraints will be consistent
# * in the general case, consistency of constraints IS NOT GUARANTEED.
# * in the several special cases, however, we CAN guarantee consistency.
# * one of this cases is constraints  on  the  function  values  AND/OR  its
#   derivatives at the interval boundaries.
# * another  special  case  is ONE constraint on the function value (OR, but
#   not AND, derivative) anywhere in the interval
# 
# Our final recommendation is to use constraints  WHEN  AND  ONLY  WHEN  you
# can't solve your task without them. Anything beyond  special  cases  given
# above is not guaranteed and may result in inconsistency.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB PROJECT --
#      Copyright 18.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s, rep = xalglib.spline1dfitcubicwc(x, y, w, n, xc, yc, dc, k, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   s, rep = xalglib.spline1dfitcubicwc(x, y, w, xc, yc, dc, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          w:          1D array/list of float
          n:          int
          xc:         1D array/list of float
          yc:         1D array/list of float
          dc:         1D array/list of int
          k:          int
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.spline1dinterpolant
          rep:        class xalglib.spline1dfitreport

</div></pre>
<a name='sub_spline1dfithermitedeprecated'></a><h3 class=pageheader><code>spline1dfithermitedeprecated</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Deprecated fitting function with O(N*M^2+M^3) running time. Superseded  by
# spline1dfit().
# 
#   -- ALGLIB PROJECT --
#      Copyright 18.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s, rep = xalglib.spline1dfithermitedeprecated(x, y, n, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   s, rep = xalglib.spline1dfithermitedeprecated(x, y, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.spline1dinterpolant
          rep:        class xalglib.spline1dfitreport

</div></pre>
<a name='sub_spline1dfithermitewc'></a><h3 class=pageheader><code>spline1dfithermitewc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Weighted  fitting  by Hermite spline,  with constraints on function values
# or first derivatives.
# 
# Equidistant grid with M nodes on [min(x,xc),max(x,xc)] is  used  to  build
# basis functions. Basis functions are Hermite splines.  Small  regularizing
# term is used when solving constrained tasks (to improve stability).
# 
# Task is linear, so linear least squares solver is used. Complexity of this
# computational scheme is O(N*M^2), mostly dominated by least squares solver
# 
# IMPORTANT: ALGLIB has a much faster version  of  the  cubic spline fitting
#            function - spline1dfit(). This function performs least  squares
#            fit in O(max(M,N)) time/memory. However, it  does  not  support
#            constraints.
# 
# INPUT PARAMETERS:
#     X   -   points, array[0..N-1].
#     Y   -   function values, array[0..N-1].
#     W   -   weights, array[0..N-1]
#             Each summand in square  sum  of  approximation deviations from
#             given  values  is  multiplied  by  the square of corresponding
#             weight. Fill it by 1's if you don't  want  to  solve  weighted
#             task.
#     N   -   number of points (optional):
#             * N&gt;0
#             * if given, only first N elements of X/Y/W are processed
#             * if not given, automatically determined from X/Y/W sizes
#     XC  -   points where spline values/derivatives are constrained,
#             array[0..K-1].
#     YC  -   values of constraints, array[0..K-1]
#     DC  -   array[0..K-1], types of constraints:
#             * DC[i]=0   means that S(XC[i])=YC[i]
#             * DC[i]=1   means that S'(XC[i])=YC[i]
#             SEE BELOW FOR IMPORTANT INFORMATION ON CONSTRAINTS
#     K   -   number of constraints (optional):
#             * 0&lt;=K&lt;M.
#             * K=0 means no constraints (XC/YC/DC are not used)
#             * if given, only first K elements of XC/YC/DC are used
#             * if not given, automatically determined from XC/YC/DC
#     M   -   number of basis functions (= 2 * number of nodes),
#             M&gt;=4,
#             M IS EVEN!
# 
# OUTPUT PARAMETERS:
#     S   -   spline interpolant.
#     Rep     -   fitting report. The following fields are set:
#                 * Rep.TerminationType is a completion code:
#                   * set to  1 on success
#                   * set to -3 on failure due to  problematic  constraints:
#                     either too many  constraints,  degenerate  constraints
#                     or inconsistent constraints were passed
#                   * RMSError      rms error on the (X,Y).
#                 * AvgError      average error on the (X,Y).
#                 * AvgRelError   average relative error on the non-zero Y
#                 * MaxError      maximum error
#                                 NON-WEIGHTED ERRORS ARE CALCULATED
# 
# IMPORTANT:
#     this subroitine doesn't calculate task's condition number for K&lt;&gt;0.
# 
# IMPORTANT:
#     this subroitine supports only even M's
# 
# 
# ORDER OF POINTS
# 
# Subroutine automatically sorts points, so caller may pass unsorted array.
# 
# SETTING CONSTRAINTS - DANGERS AND OPPORTUNITIES:
# 
# Setting constraints can lead  to undesired  results,  like ill-conditioned
# behavior, or inconsistency being detected. From the other side,  it allows
# us to improve quality of the fit. Here we summarize  our  experience  with
# constrained regression splines:
# * excessive constraints can be inconsistent. Splines are  piecewise  cubic
#   functions, and it is easy to create an example, where  large  number  of
#   constraints  concentrated  in  small  area will result in inconsistency.
#   Just because spline is not flexible enough to satisfy all of  them.  And
#   same constraints spread across the  [min(x),max(x)]  will  be  perfectly
#   consistent.
# * the more evenly constraints are spread across [min(x),max(x)],  the more
#   chances that they will be consistent
# * the  greater  is  M (given  fixed  constraints),  the  more chances that
#   constraints will be consistent
# * in the general case, consistency of constraints is NOT GUARANTEED.
# * in the several special cases, however, we can guarantee consistency.
# * one of this cases is  M&gt;=4  and   constraints  on   the  function  value
#   (AND/OR its derivative) at the interval boundaries.
# * another special case is M&gt;=4  and  ONE  constraint on the function value
#   (OR, BUT NOT AND, derivative) anywhere in [min(x),max(x)]
# 
# Our final recommendation is to use constraints  WHEN  AND  ONLY  when  you
# can't solve your task without them. Anything beyond  special  cases  given
# above is not guaranteed and may result in inconsistency.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB PROJECT --
#      Copyright 18.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s, rep = xalglib.spline1dfithermitewc(x, y, w, n, xc, yc, dc, k, m)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   s, rep = xalglib.spline1dfithermitewc(x, y, w, xc, yc, dc, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          w:          1D array/list of float
          n:          int
          xc:         1D array/list of float
          yc:         1D array/list of float
          dc:         1D array/list of int
          k:          int
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.spline1dinterpolant
          rep:        class xalglib.spline1dfitreport

</div></pre>
<a name=unit_mannwhitneyu></a><h2 class=pageheader><code>mannwhitneyu</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_mannwhitneyutest' class=toc>mannwhitneyutest</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_mannwhitneyutest'></a><h3 class=pageheader><code>mannwhitneyutest</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Mann-Whitney U-test
# 
# This test checks hypotheses about whether X  and  Y  are  samples  of  two
# continuous distributions of the same shape  and  same  median  or  whether
# their medians are different.
# 
# The following tests are performed:
#     * two-tailed test (null hypothesis - the medians are equal)
#     * left-tailed test (null hypothesis - the median of the  first  sample
#       is greater than or equal to the median of the second sample)
#     * right-tailed test (null hypothesis - the median of the first  sample
#       is less than or equal to the median of the second sample).
# 
# Requirements:
#     * the samples are independent
#     * X and Y are continuous distributions (or discrete distributions well-
#       approximating continuous distributions)
#     * distributions of X and Y have the  same  shape.  The  only  possible
#       difference is their position (i.e. the value of the median)
#     * the number of elements in each sample is not less than 5
#     * the scale of measurement should be ordinal, interval or ratio  (i.e.
#       the test could not be applied to nominal variables).
# 
# The test is non-parametric and doesn't require distributions to be normal.
# 
# Input parameters:
#     X   -   sample 1. Array whose index goes from 0 to N-1.
#     N   -   size of the sample. N&gt;=5
#     Y   -   sample 2. Array whose index goes from 0 to M-1.
#     M   -   size of the sample. M&gt;=5
# 
# Output parameters:
#     BothTails   -   p-value for two-tailed test.
#                     If BothTails is less than the given significance level
#                     the null hypothesis is rejected.
#     LeftTail    -   p-value for left-tailed test.
#                     If LeftTail is less than the given significance level,
#                     the null hypothesis is rejected.
#     RightTail   -   p-value for right-tailed test.
#                     If RightTail is less than the given significance level
#                     the null hypothesis is rejected.
# 
# To calculate p-values, special approximation is used. This method lets  us
# calculate p-values with satisfactory  accuracy  in  interval  [0.0001, 1].
# There is no approximation outside the [0.0001, 1] interval. Therefore,  if
# the significance level outlies this interval, the test returns 0.0001.
# 
# Relative precision of approximation of p-value:
# 
# N          M          Max.err.   Rms.err.
# 5..10      N..10      1.4e-02    6.0e-04
# 5..10      N..100     2.2e-02    5.3e-06
# 10..15     N..15      1.0e-02    3.2e-04
# 10..15     N..100     1.0e-02    2.2e-05
# 15..100    N..100     6.1e-03    2.7e-06
# 
# For N,M&gt;100 accuracy checks weren't put into  practice,  but  taking  into
# account characteristics of asymptotic approximation used, precision should
# not be sharply different from the values for interval [5, 100].
# 
# NOTE: P-value approximation was  optimized  for  0.0001&lt;=p&lt;=0.2500.  Thus,
#       P's outside of this interval are enforced to these bounds. Say,  you
#       may quite often get P equal to exactly 0.25 or 0.0001.
# 
#   -- ALGLIB --
#      Copyright 09.04.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   bothtails, lefttail, righttail = xalglib.mannwhitneyutest(x, n, y, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          y:          1D array/list of float
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  bothtails:  float
          lefttail:   float
          righttail:  float

</div></pre>
<a name=unit_matdet></a><h2 class=pageheader><code>matdet</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cmatrixdet' class=toc>cmatrixdet</a><br>
<a href='#sub_cmatrixludet' class=toc>cmatrixludet</a><br>
<a href='#sub_rmatrixdet' class=toc>rmatrixdet</a><br>
<a href='#sub_rmatrixludet' class=toc>rmatrixludet</a><br>
<a href='#sub_spdmatrixcholeskydet' class=toc>spdmatrixcholeskydet</a><br>
<a href='#sub_spdmatrixdet' class=toc>spdmatrixdet</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_cmatrixdet'></a><h3 class=pageheader><code>cmatrixdet</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Calculation of the determinant of a general matrix
# 
# Input parameters:
#     A       -   matrix, array[0..N-1, 0..N-1]
#     N       -   (optional) size of matrix A:
#                 * if given, only principal NxN submatrix is processed and
#                   overwritten. other elements are unchanged.
#                 * if not given, automatically determined from matrix size
#                   (A must be square matrix)
# 
# Result: determinant of matrix A.
# 
#   -- ALGLIB --
#      Copyright 2005 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixdet(a, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixdet(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     complex

</div></pre>
<a name='sub_cmatrixludet'></a><h3 class=pageheader><code>cmatrixludet</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Determinant calculation of the matrix given by its LU decomposition.
# 
# Input parameters:
#     A       -   LU decomposition of the matrix (output of
#                 RMatrixLU subroutine).
#     Pivots  -   table of permutations which were made during
#                 the LU decomposition.
#                 Output of RMatrixLU subroutine.
#     N       -   (optional) size of matrix A:
#                 * if given, only principal NxN submatrix is processed and
#                   overwritten. other elements are unchanged.
#                 * if not given, automatically determined from matrix size
#                   (A must be square matrix)
# 
# Result: matrix determinant.
# 
#   -- ALGLIB --
#      Copyright 2005 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixludet(a, pivots, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixludet(a, pivots)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          pivots:     1D array/list of int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     complex

</div></pre>
<a name='sub_rmatrixdet'></a><h3 class=pageheader><code>rmatrixdet</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Calculation of the determinant of a general matrix
# 
# Input parameters:
#     A       -   matrix, array[0..N-1, 0..N-1]
#     N       -   (optional) size of matrix A:
#                 * if given, only principal NxN submatrix is processed and
#                   overwritten. other elements are unchanged.
#                 * if not given, automatically determined from matrix size
#                   (A must be square matrix)
# 
# Result: determinant of matrix A.
# 
#   -- ALGLIB --
#      Copyright 2005 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixdet(a, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixdet(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_rmatrixludet'></a><h3 class=pageheader><code>rmatrixludet</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Determinant calculation of the matrix given by its LU decomposition.
# 
# Input parameters:
#     A       -   LU decomposition of the matrix (output of
#                 RMatrixLU subroutine).
#     Pivots  -   table of permutations which were made during
#                 the LU decomposition.
#                 Output of RMatrixLU subroutine.
#     N       -   (optional) size of matrix A:
#                 * if given, only principal NxN submatrix is processed and
#                   overwritten. other elements are unchanged.
#                 * if not given, automatically determined from matrix size
#                   (A must be square matrix)
# 
# Result: matrix determinant.
# 
#   -- ALGLIB --
#      Copyright 2005 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixludet(a, pivots, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixludet(a, pivots)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          pivots:     1D array/list of int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_spdmatrixcholeskydet'></a><h3 class=pageheader><code>spdmatrixcholeskydet</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Determinant calculation of the matrix given by the Cholesky decomposition.
# 
# Input parameters:
#     A       -   Cholesky decomposition,
#                 output of SMatrixCholesky subroutine.
#     N       -   (optional) size of matrix A:
#                 * if given, only principal NxN submatrix is processed and
#                   overwritten. other elements are unchanged.
#                 * if not given, automatically determined from matrix size
#                   (A must be square matrix)
# 
# As the determinant is equal to the product of squares of diagonal elements,
# it's not necessary to specify which triangle - lower or upper - the matrix
# is stored in.
# 
# Result:
#     matrix determinant.
# 
#   -- ALGLIB --
#      Copyright 2005-2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixcholeskydet(a, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixcholeskydet(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_spdmatrixdet'></a><h3 class=pageheader><code>spdmatrixdet</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Determinant calculation of the symmetric positive definite matrix.
# 
# Input parameters:
#     A       -   matrix, array[N,N]
#     N       -   (optional) size of matrix A:
#                 * if given, only principal NxN submatrix is processed and
#                   overwritten. other elements are unchanged.
#                 * if not given, automatically determined from matrix size
#                   (A must be square matrix)
#     IsUpper -   storage type:
#                 * if True, symmetric matrix  A  is  given  by  its  upper
#                   triangle, and the lower triangle isn't used/changed  by
#                   function
#                 * if False, symmetric matrix  A  is  given  by  its lower
#                   triangle, and the upper triangle isn't used/changed  by
#                   function
# 
# Result:
#     determinant of matrix A.
#     If matrix A is not positive definite, an exception is generated.
# 
#   -- ALGLIB --
#      Copyright 2005-2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixdet(a, n, isupper)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixdet(a, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_matgen></a><h2 class=pageheader><code>matgen</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cmatrixrndcond' class=toc>cmatrixrndcond</a><br>
<a href='#sub_cmatrixrndorthogonal' class=toc>cmatrixrndorthogonal</a><br>
<a href='#sub_cmatrixrndorthogonalfromtheleft' class=toc>cmatrixrndorthogonalfromtheleft</a><br>
<a href='#sub_cmatrixrndorthogonalfromtheright' class=toc>cmatrixrndorthogonalfromtheright</a><br>
<a href='#sub_hmatrixrndcond' class=toc>hmatrixrndcond</a><br>
<a href='#sub_hmatrixrndmultiply' class=toc>hmatrixrndmultiply</a><br>
<a href='#sub_hpdmatrixrndcond' class=toc>hpdmatrixrndcond</a><br>
<a href='#sub_rmatrixrndcond' class=toc>rmatrixrndcond</a><br>
<a href='#sub_rmatrixrndorthogonal' class=toc>rmatrixrndorthogonal</a><br>
<a href='#sub_rmatrixrndorthogonalfromtheleft' class=toc>rmatrixrndorthogonalfromtheleft</a><br>
<a href='#sub_rmatrixrndorthogonalfromtheright' class=toc>rmatrixrndorthogonalfromtheright</a><br>
<a href='#sub_smatrixrndcond' class=toc>smatrixrndcond</a><br>
<a href='#sub_smatrixrndmultiply' class=toc>smatrixrndmultiply</a><br>
<a href='#sub_spdmatrixrndcond' class=toc>spdmatrixrndcond</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_cmatrixrndcond'></a><h3 class=pageheader><code>cmatrixrndcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Generation of random NxN complex matrix with given condition number C and
# norm2(A)=1
# 
# INPUT PARAMETERS:
#     N   -   matrix size
#     C   -   condition number (in 2-norm)
# 
# OUTPUT PARAMETERS:
#     A   -   random matrix with norm2(A)=1 and cond(A)=C
# 
#   -- ALGLIB routine --
#      04.12.2009
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.cmatrixrndcond(n, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          c:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of complex

</div></pre>
<a name='sub_cmatrixrndorthogonal'></a><h3 class=pageheader><code>cmatrixrndorthogonal</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Generation of a random Haar distributed orthogonal complex matrix
# 
# INPUT PARAMETERS:
#     N   -   matrix size, N&gt;=1
# 
# OUTPUT PARAMETERS:
#     A   -   orthogonal NxN matrix, array[0..N-1,0..N-1]
# 
# NOTE: this function uses algorithm  described  in  Stewart, G. W.  (1980),
#       &quot;The Efficient Generation of  Random  Orthogonal  Matrices  with  an
#       Application to Condition Estimators&quot;.
# 
#       Speaking short, to generate an (N+1)x(N+1) orthogonal matrix, it:
#       * takes an NxN one
#       * takes uniformly distributed unit vector of dimension N+1.
#       * constructs a Householder reflection from the vector, then applies
#         it to the smaller matrix (embedded in the larger size with a 1 at
#         the bottom right corner).
# 
#   -- ALGLIB routine --
#      04.12.2009
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.cmatrixrndorthogonal(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of complex

</div></pre>
<a name='sub_cmatrixrndorthogonalfromtheleft'></a><h3 class=pageheader><code>cmatrixrndorthogonalfromtheleft</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Multiplication of MxN complex matrix by MxM random Haar distributed
# complex orthogonal matrix
# 
# INPUT PARAMETERS:
#     A   -   matrix, array[0..M-1, 0..N-1]
#     M, N-   matrix size
# 
# OUTPUT PARAMETERS:
#     A   -   Q*A, where Q is random MxM orthogonal matrix
# 
#   -- ALGLIB routine --
#      04.12.2009
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.cmatrixrndorthogonalfromtheleft(a, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_cmatrixrndorthogonalfromtheright'></a><h3 class=pageheader><code>cmatrixrndorthogonalfromtheright</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Multiplication of MxN complex matrix by NxN random Haar distributed
# complex orthogonal matrix
# 
# INPUT PARAMETERS:
#     A   -   matrix, array[0..M-1, 0..N-1]
#     M, N-   matrix size
# 
# OUTPUT PARAMETERS:
#     A   -   A*Q, where Q is random NxN orthogonal matrix
# 
#   -- ALGLIB routine --
#      04.12.2009
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.cmatrixrndorthogonalfromtheright(a, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_hmatrixrndcond'></a><h3 class=pageheader><code>hmatrixrndcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Generation of random NxN Hermitian matrix with given condition number  and
# norm2(A)=1
# 
# INPUT PARAMETERS:
#     N   -   matrix size
#     C   -   condition number (in 2-norm)
# 
# OUTPUT PARAMETERS:
#     A   -   random matrix with norm2(A)=1 and cond(A)=C
# 
#   -- ALGLIB routine --
#      04.12.2009
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.hmatrixrndcond(n, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          c:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of complex

</div></pre>
<a name='sub_hmatrixrndmultiply'></a><h3 class=pageheader><code>hmatrixrndmultiply</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Hermitian multiplication of NxN matrix by random Haar distributed
# complex orthogonal matrix
# 
# INPUT PARAMETERS:
#     A   -   matrix, array[0..N-1, 0..N-1]
#     N   -   matrix size
# 
# OUTPUT PARAMETERS:
#     A   -   Q^H*A*Q, where Q is random NxN orthogonal matrix
# 
#   -- ALGLIB routine --
#      04.12.2009
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.hmatrixrndmultiply(a, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_hpdmatrixrndcond'></a><h3 class=pageheader><code>hpdmatrixrndcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Generation of random NxN Hermitian positive definite matrix with given
# condition number and norm2(A)=1
# 
# INPUT PARAMETERS:
#     N   -   matrix size
#     C   -   condition number (in 2-norm)
# 
# OUTPUT PARAMETERS:
#     A   -   random HPD matrix with norm2(A)=1 and cond(A)=C
# 
#   -- ALGLIB routine --
#      04.12.2009
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.hpdmatrixrndcond(n, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          c:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of complex

</div></pre>
<a name='sub_rmatrixrndcond'></a><h3 class=pageheader><code>rmatrixrndcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Generation of random NxN matrix with given condition number and norm2(A)=1
# 
# INPUT PARAMETERS:
#     N   -   matrix size
#     C   -   condition number (in 2-norm)
# 
# OUTPUT PARAMETERS:
#     A   -   random matrix with norm2(A)=1 and cond(A)=C
# 
#   -- ALGLIB routine --
#      04.12.2009
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.rmatrixrndcond(n, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          c:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of float

</div></pre>
<a name='sub_rmatrixrndorthogonal'></a><h3 class=pageheader><code>rmatrixrndorthogonal</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Generation of a random uniformly distributed (Haar) orthogonal matrix
# 
# INPUT PARAMETERS:
#     N   -   matrix size, N&gt;=1
# 
# OUTPUT PARAMETERS:
#     A   -   orthogonal NxN matrix, array[0..N-1,0..N-1]
# 
# NOTE: this function uses algorithm  described  in  Stewart, G. W.  (1980),
#       &quot;The Efficient Generation of  Random  Orthogonal  Matrices  with  an
#       Application to Condition Estimators&quot;.
# 
#       Speaking short, to generate an (N+1)x(N+1) orthogonal matrix, it:
#       * takes an NxN one
#       * takes uniformly distributed unit vector of dimension N+1.
#       * constructs a Householder reflection from the vector, then applies
#         it to the smaller matrix (embedded in the larger size with a 1 at
#         the bottom right corner).
# 
#   -- ALGLIB routine --
#      04.12.2009
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.rmatrixrndorthogonal(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of float

</div></pre>
<a name='sub_rmatrixrndorthogonalfromtheleft'></a><h3 class=pageheader><code>rmatrixrndorthogonalfromtheleft</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Multiplication of MxN matrix by MxM random Haar distributed orthogonal matrix
# 
# INPUT PARAMETERS:
#     A   -   matrix, array[0..M-1, 0..N-1]
#     M, N-   matrix size
# 
# OUTPUT PARAMETERS:
#     A   -   Q*A, where Q is random MxM orthogonal matrix
# 
#   -- ALGLIB routine --
#      04.12.2009
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixrndorthogonalfromtheleft(a, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixrndorthogonalfromtheright'></a><h3 class=pageheader><code>rmatrixrndorthogonalfromtheright</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Multiplication of MxN matrix by NxN random Haar distributed orthogonal matrix
# 
# INPUT PARAMETERS:
#     A   -   matrix, array[0..M-1, 0..N-1]
#     M, N-   matrix size
# 
# OUTPUT PARAMETERS:
#     A   -   A*Q, where Q is random NxN orthogonal matrix
# 
#   -- ALGLIB routine --
#      04.12.2009
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixrndorthogonalfromtheright(a, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_smatrixrndcond'></a><h3 class=pageheader><code>smatrixrndcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Generation of random NxN symmetric matrix with given condition number  and
# norm2(A)=1
# 
# INPUT PARAMETERS:
#     N   -   matrix size
#     C   -   condition number (in 2-norm)
# 
# OUTPUT PARAMETERS:
#     A   -   random matrix with norm2(A)=1 and cond(A)=C
# 
#   -- ALGLIB routine --
#      04.12.2009
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.smatrixrndcond(n, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          c:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of float

</div></pre>
<a name='sub_smatrixrndmultiply'></a><h3 class=pageheader><code>smatrixrndmultiply</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Symmetric multiplication of NxN matrix by random Haar distributed
# orthogonal  matrix
# 
# INPUT PARAMETERS:
#     A   -   matrix, array[0..N-1, 0..N-1]
#     N   -   matrix size
# 
# OUTPUT PARAMETERS:
#     A   -   Q'*A*Q, where Q is random NxN orthogonal matrix
# 
#   -- ALGLIB routine --
#      04.12.2009
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.smatrixrndmultiply(a, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spdmatrixrndcond'></a><h3 class=pageheader><code>spdmatrixrndcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Generation of random NxN symmetric positive definite matrix with given
# condition number and norm2(A)=1
# 
# INPUT PARAMETERS:
#     N   -   matrix size
#     C   -   condition number (in 2-norm)
# 
# OUTPUT PARAMETERS:
#     A   -   random SPD matrix with norm2(A)=1 and cond(A)=C
# 
#   -- ALGLIB routine --
#      04.12.2009
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.spdmatrixrndcond(n, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          c:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of float

</div></pre>
<a name=unit_matinv></a><h2 class=pageheader><code>matinv</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cmatrixinverse' class=toc>cmatrixinverse</a><br>
<a href='#sub_cmatrixluinverse' class=toc>cmatrixluinverse</a><br>
<a href='#sub_cmatrixtrinverse' class=toc>cmatrixtrinverse</a><br>
<a href='#sub_hpdmatrixcholeskyinverse' class=toc>hpdmatrixcholeskyinverse</a><br>
<a href='#sub_hpdmatrixinverse' class=toc>hpdmatrixinverse</a><br>
<a href='#sub_rmatrixinverse' class=toc>rmatrixinverse</a><br>
<a href='#sub_rmatrixluinverse' class=toc>rmatrixluinverse</a><br>
<a href='#sub_rmatrixtrinverse' class=toc>rmatrixtrinverse</a><br>
<a href='#sub_spdmatrixcholeskyinverse' class=toc>spdmatrixcholeskyinverse</a><br>
<a href='#sub_spdmatrixinverse' class=toc>spdmatrixinverse</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_cmatrixinverse'></a><h3 class=pageheader><code>cmatrixinverse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inversion of a general matrix.
# 
# Input parameters:
#     A       -   matrix
#     N       -   size of the matrix A (optional):
#                 * if given, only principal NxN submatrix is processed  and
#                   overwritten. Trailing elements are unchanged.
#                 * if not given, the size  is automatically determined from
#                   the matrix size (A must be a square matrix)
# 
# Output parameters:
#     A       -   inverse of matrix A, array[N,N]:
#                 * for rep.terminationtype&gt;0, contains matrix inverse
#                 * for rep.terminationtype&lt;0, zero-filled
#     Rep     -   solver report:
#                 * rep.terminationtype&gt;0 for success, &lt;0 for failure
#                 * see below for more info
# 
# SOLVER REPORT
# 
# Subroutine sets following fields of the Rep structure:
# * terminationtype   completion code:
#                     *  1 for success
#                     * -3 for a singular or extremely ill-conditioned matrix
# * r1                reciprocal of condition number: 1/cond(A), 1-norm.
# * rinf              reciprocal of condition number: 1/cond(A), inf-norm.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 2005 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.cmatrixinverse(a, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.cmatrixinverse(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.matinvreport

</div></pre>
<a name='sub_cmatrixluinverse'></a><h3 class=pageheader><code>cmatrixluinverse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inversion of a matrix given by its LU decomposition.
# 
# INPUT PARAMETERS:
#     A       -   LU decomposition of the matrix
#                 (output of CMatrixLU subroutine).
#     Pivots  -   table of permutations
#                 (the output of CMatrixLU subroutine).
#     N       -   size of the matrix A (optional):
#                 * if given, only principal NxN submatrix is processed  and
#                   overwritten. Trailing elements are unchanged.
#                 * if not given, the size  is automatically determined from
#                   the matrix size (A must be a square matrix)
# 
# OUTPUT PARAMETERS:
#     A       -   inverse of matrix A, array[N,N]:
#                 * for rep.terminationtype&gt;0, contains matrix inverse
#                 * for rep.terminationtype&lt;0, zero-filled
#     Rep     -   solver report:
#                 * rep.terminationtype&gt;0 for success, &lt;0 for failure
#                 * see below for more info
# 
# SOLVER REPORT
# 
# Subroutine sets following fields of the Rep structure:
# * terminationtype   completion code:
#                     *  1 for success
#                     * -3 for a singular or extremely ill-conditioned matrix
# * r1                reciprocal of condition number: 1/cond(A), 1-norm.
# * rinf              reciprocal of condition number: 1/cond(A), inf-norm.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      05.02.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.cmatrixluinverse(a, pivots, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.cmatrixluinverse(a, pivots)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          pivots:     1D array/list of int
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.matinvreport

</div></pre>
<a name='sub_cmatrixtrinverse'></a><h3 class=pageheader><code>cmatrixtrinverse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Triangular matrix inverse (complex)
# 
# The subroutine inverts the following types of matrices:
#     * upper triangular
#     * upper triangular with unit diagonal
#     * lower triangular
#     * lower triangular with unit diagonal
# 
# In case of an upper (lower) triangular matrix,  the  inverse  matrix  will
# also be upper (lower) triangular, and after the end of the algorithm,  the
# inverse matrix replaces the source matrix. The elements  below (above) the
# main diagonal are not changed by the algorithm.
# 
# If  the matrix  has a unit diagonal, the inverse matrix also  has  a  unit
# diagonal, and the diagonal elements are not passed to the algorithm.
# 
# INPUT PARAMETERS:
#     A       -   matrix, array[0..N-1, 0..N-1].
#     N       -   size of the matrix A (optional):
#                 * if given, only principal NxN submatrix is processed  and
#                   overwritten. Trailing elements are unchanged.
#                 * if not given, the size  is automatically determined from
#                   the matrix size (A must be a square matrix)
#     IsUpper -   True, if the matrix is upper triangular.
#     IsUnit  -   diagonal type (optional):
#                 * if True, matrix has unit diagonal (a[i,i] are NOT used)
#                 * if False, matrix diagonal is arbitrary
#                 * if not given, False is assumed
# 
# OUTPUT PARAMETERS:
#     A       -   inverse of matrix A, array[N,N]:
#                 * for rep.terminationtype&gt;0, contains matrix inverse
#                 * for rep.terminationtype&lt;0, zero-filled
#     Rep     -   solver report:
#                 * rep.terminationtype&gt;0 for success, &lt;0 for failure
#                 * see below for more info
# 
# SOLVER REPORT
# 
# Subroutine sets following fields of the Rep structure:
# * terminationtype   completion code:
#                     *  1 for success
#                     * -3 for a singular or extremely ill-conditioned matrix
# * r1                reciprocal of condition number: 1/cond(A), 1-norm.
# * rinf              reciprocal of condition number: 1/cond(A), inf-norm.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 05.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.cmatrixtrinverse(a, n, isupper, isunit)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.cmatrixtrinverse(a, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          isupper:    bool
          isunit:     bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.matinvreport

</div></pre>
<a name='sub_hpdmatrixcholeskyinverse'></a><h3 class=pageheader><code>hpdmatrixcholeskyinverse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inversion of a Hermitian positive definite matrix which is given
# by Cholesky decomposition.
# 
# Input parameters:
#     A       -   Cholesky decomposition of the matrix to be inverted:
#                 A=U'*U or A = L*L'.
#                 Output of  HPDMatrixCholesky subroutine.
#     N       -   size of the matrix A (optional):
#                 * if given, only principal NxN submatrix is processed  and
#                   overwritten. Trailing elements are unchanged.
#                 * if not given, the size  is automatically determined from
#                   the matrix size (A must be a square matrix)
#     IsUpper -   storage type:
#                 * if True, symmetric  matrix  A  is  given  by  its  upper
#                   triangle, and the lower triangle isn't  used/changed  by
#                   function
#                 * if False,  symmetric matrix  A  is  given  by  its lower
#                   triangle, and the  upper triangle isn't used/changed  by
#                   function
# 
# OUTPUT PARAMETERS:
#     A       -   inverse of matrix A, array[N,N]:
#                 * for rep.terminationtype&gt;0, contains matrix inverse
#                 * for rep.terminationtype&lt;0, zero-filled
#     Rep     -   solver report:
#                 * rep.terminationtype&gt;0 for success, &lt;0 for failure
#                 * see below for more info
# 
# SOLVER REPORT
# 
# Subroutine sets following fields of the Rep structure:
# * terminationtype   completion code:
#                     *  1 for success
#                     * -3 for a singular or extremely ill-conditioned matrix
# * r1                reciprocal of condition number: 1/cond(A), 1-norm.
# * rinf              reciprocal of condition number: 1/cond(A), inf-norm.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      10.02.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.hpdmatrixcholeskyinverse(a, n, isupper)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.hpdmatrixcholeskyinverse(a, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.matinvreport

</div></pre>
<a name='sub_hpdmatrixinverse'></a><h3 class=pageheader><code>hpdmatrixinverse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inversion of a Hermitian positive definite matrix.
# 
# Given an upper or lower triangle of a Hermitian positive definite matrix,
# the algorithm generates matrix A^-1 and saves the upper or lower triangle
# depending on the input.
# 
# INPUT PARAMETERS:
#     A       -   matrix to be inverted (upper or lower triangle), array[N,N]
#     N       -   size of the matrix A (optional):
#                 * if given, only principal NxN submatrix is processed  and
#                   overwritten. Trailing elements are unchanged.
#                 * if not given, the size  is automatically determined from
#                   the matrix size (A must be a square matrix)
#     IsUpper -   storage type:
#                 * if True, symmetric  matrix  A  is  given  by  its  upper
#                   triangle, and the lower triangle isn't  used/changed  by
#                   function
#                 * if False,  symmetric matrix  A  is  given  by  its lower
#                   triangle, and the  upper triangle isn't used/changed  by
#                   function
# 
# OUTPUT PARAMETERS:
#     A       -   inverse of matrix A, array[N,N]:
#                 * for rep.terminationtype&gt;0, contains matrix inverse
#                 * for rep.terminationtype&lt;0, zero-filled
#     Rep     -   solver report:
#                 * rep.terminationtype&gt;0 for success, &lt;0 for failure
#                 * see below for more info
# 
# SOLVER REPORT
# 
# Subroutine sets following fields of the Rep structure:
# * terminationtype   completion code:
#                     *  1 for success
#                     * -3 for a singular or extremely ill-conditioned matrix
# * r1                reciprocal of condition number: 1/cond(A), 1-norm.
# * rinf              reciprocal of condition number: 1/cond(A), inf-norm.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      10.02.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.hpdmatrixinverse(a, n, isupper)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.hpdmatrixinverse(a, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.matinvreport

</div></pre>
<a name='sub_rmatrixinverse'></a><h3 class=pageheader><code>rmatrixinverse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inversion of a general matrix.
# 
# INPUT PARAMETERS:
#     A       -   matrix.
#     N       -   size of the matrix A (optional):
#                 * if given, only principal NxN submatrix is processed  and
#                   overwritten. Trailing elements are unchanged.
#                 * if not given, the size  is automatically determined from
#                   the matrix size (A must be a square matrix)
# 
# OUTPUT PARAMETERS:
#     A       -   inverse of matrix A, array[N,N]:
#                 * for rep.terminationtype&gt;0, contains matrix inverse
#                 * for rep.terminationtype&lt;0, zero-filled
#     Rep     -   solver report:
#                 * rep.terminationtype&gt;0 for success, &lt;0 for failure
#                 * see below for more info
# 
# SOLVER REPORT
# 
# Subroutine sets following fields of the Rep structure:
# * terminationtype   completion code:
#                     *  1 for success
#                     * -3 for a singular or extremely ill-conditioned matrix
# * r1                reciprocal of condition number: 1/cond(A), 1-norm.
# * rinf              reciprocal of condition number: 1/cond(A), inf-norm.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 2005-2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.rmatrixinverse(a, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.rmatrixinverse(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.matinvreport

</div></pre>
<a name='sub_rmatrixluinverse'></a><h3 class=pageheader><code>rmatrixluinverse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inversion of a matrix given by its LU decomposition.
# 
# INPUT PARAMETERS:
#     A       -   LU decomposition of the matrix
#                 (output of RMatrixLU subroutine).
#     Pivots  -   table of permutations
#                 (the output of RMatrixLU subroutine).
#     N       -   size of the matrix A (optional):
#                 * if given, only principal NxN submatrix is processed  and
#                   overwritten. Trailing elements are unchanged.
#                 * if not given, the size  is automatically determined from
#                   the matrix size (A must be a square matrix)
# 
# OUTPUT PARAMETERS:
#     A       -   inverse of matrix A, array[N,N]:
#                 * for rep.terminationtype&gt;0, contains matrix inverse
#                 * for rep.terminationtype&lt;0, zero-filled
#     Rep     -   solver report:
#                 * rep.terminationtype&gt;0 for success, &lt;0 for failure
#                 * see below for more info
# 
# SOLVER REPORT
# 
# Subroutine sets following fields of the Rep structure:
# * terminationtype   completion code:
#                     *  1 for success
#                     * -3 for a singular or extremely ill-conditioned matrix
# * r1                reciprocal of condition number: 1/cond(A), 1-norm.
# * rinf              reciprocal of condition number: 1/cond(A), inf-norm.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      05.02.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.rmatrixluinverse(a, pivots, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.rmatrixluinverse(a, pivots)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          pivots:     1D array/list of int
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.matinvreport

</div></pre>
<a name='sub_rmatrixtrinverse'></a><h3 class=pageheader><code>rmatrixtrinverse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Triangular matrix inverse (real)
# 
# The subroutine inverts the following types of matrices:
#     * upper triangular
#     * upper triangular with unit diagonal
#     * lower triangular
#     * lower triangular with unit diagonal
# 
# In case of an upper (lower) triangular matrix,  the  inverse  matrix  will
# also be upper (lower) triangular, and after the end of the algorithm,  the
# inverse matrix replaces the source matrix. The elements  below (above) the
# main diagonal are not changed by the algorithm.
# 
# If  the matrix  has a unit diagonal, the inverse matrix also  has  a  unit
# diagonal, and the diagonal elements are not passed to the algorithm.
# 
# INPUT PARAMETERS:
#     A       -   matrix, array[0..N-1, 0..N-1].
#     N       -   size of the matrix A (optional):
#                 * if given, only principal NxN submatrix is processed  and
#                   overwritten. Trailing elements are unchanged.
#                 * if not given, the size  is automatically determined from
#                   the matrix size (A must be a square matrix)
#     IsUpper -   True, if the matrix is upper triangular.
#     IsUnit  -   diagonal type (optional):
#                 * if True, matrix has unit diagonal (a[i,i] are NOT used)
#                 * if False, matrix diagonal is arbitrary
#                 * if not given, False is assumed
# 
# OUTPUT PARAMETERS:
#     A       -   inverse of matrix A, array[N,N]:
#                 * for rep.terminationtype&gt;0, contains matrix inverse
#                 * for rep.terminationtype&lt;0, zero-filled
#     Rep     -   solver report:
#                 * rep.terminationtype&gt;0 for success, &lt;0 for failure
#                 * see below for more info
# 
# SOLVER REPORT
# 
# Subroutine sets following fields of the Rep structure:
# * terminationtype   completion code:
#                     *  1 for success
#                     * -3 for a singular or extremely ill-conditioned matrix
# * r1                reciprocal of condition number: 1/cond(A), 1-norm.
# * rinf              reciprocal of condition number: 1/cond(A), inf-norm.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 05.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.rmatrixtrinverse(a, n, isupper, isunit)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.rmatrixtrinverse(a, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
          isunit:     bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.matinvreport

</div></pre>
<a name='sub_spdmatrixcholeskyinverse'></a><h3 class=pageheader><code>spdmatrixcholeskyinverse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inversion of a symmetric positive definite matrix which is given
# by Cholesky decomposition.
# 
# INPUT PARAMETERS:
#     A       -   Cholesky decomposition of the matrix to be inverted:
#                 A=U'*U or A = L*L'.
#                 Output of  SPDMatrixCholesky subroutine.
#     N       -   size of the matrix A (optional):
#                 * if given, only principal NxN submatrix is processed  and
#                   overwritten. Trailing elements are unchanged.
#                 * if not given, the size  is automatically determined from
#                   the matrix size (A must be a square matrix)
#     IsUpper -   storage type:
#                 * if True, the symmetric  matrix  A  is given by its upper
#                   triangle, and the lower triangle isn't  used/changed  by
#                   the function
#                 * if False, the symmetric matrix  A  is given by its lower
#                   triangle, and the  upper triangle isn't used/changed  by
#                   the function
# 
# OUTPUT PARAMETERS:
#     A       -   inverse of matrix A, array[N,N]:
#                 * for rep.terminationtype&gt;0,   corresponding      triangle
#                   contains inverse matrix,   the  other  triangle  is  not
#                   modified.
#                 * for rep.terminationtype&lt;0,  corresponding  triangle   is
#                   zero-filled; the other triangle is not modified.
#     Rep     -   solver report:
#                 * rep.terminationtype&gt;0 for success, &lt;0 for failure
#                 * see below for more info
# 
# SOLVER REPORT
# 
# Subroutine sets following fields of the Rep structure:
# * terminationtype   completion code:
#                     *  1 for success
#                     * -3 for a singular or extremely ill-conditioned matrix
# * r1                reciprocal of condition number: 1/cond(A), 1-norm.
# * rinf              reciprocal of condition number: 1/cond(A), inf-norm.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      10.02.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.spdmatrixcholeskyinverse(a, n, isupper)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.spdmatrixcholeskyinverse(a, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.matinvreport

</div></pre>
<a name='sub_spdmatrixinverse'></a><h3 class=pageheader><code>spdmatrixinverse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inversion of a symmetric positive definite matrix.
# 
# Given an upper or lower triangle of a symmetric positive definite matrix,
# the algorithm generates matrix A^-1 and saves the upper or lower triangle
# depending on the input.
# 
# INPUT PARAMETERS:
#     A       -   matrix to be inverted (upper or lower triangle), array[N,N]
#     N       -   size of the matrix A (optional):
#                 * if given, only principal NxN submatrix is processed  and
#                   overwritten. Trailing elements are unchanged.
#                 * if not given, the size  is automatically determined from
#                   the matrix size (A must be a square matrix)
#     IsUpper -   storage type:
#                 * if True, symmetric  matrix  A  is  given  by  its  upper
#                   triangle, and the lower triangle isn't  used/changed  by
#                   function
#                 * if False,  symmetric matrix  A  is  given  by  its lower
#                   triangle, and the  upper triangle isn't used/changed  by
#                   function
# 
# OUTPUT PARAMETERS:
#     A       -   inverse of matrix A, array[N,N]:
#                 * for rep.terminationtype&gt;0, contains matrix inverse
#                 * for rep.terminationtype&lt;0, zero-filled
#     Rep     -   solver report:
#                 * rep.terminationtype&gt;0 for success, &lt;0 for failure
#                 * see below for more info
# 
# SOLVER REPORT
# 
# Subroutine sets following fields of the Rep structure:
# * terminationtype   completion code:
#                     *  1 for success
#                     * -3 for a singular or extremely ill-conditioned matrix
# * r1                reciprocal of condition number: 1/cond(A), 1-norm.
# * rinf              reciprocal of condition number: 1/cond(A), inf-norm.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      10.02.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.spdmatrixinverse(a, n, isupper)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.spdmatrixinverse(a, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.matinvreport

</div></pre>
<a name=unit_mcpd></a><h2 class=pageheader><code>mcpd</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_mcpdaddbc' class=toc>mcpdaddbc</a><br>
<a href='#sub_mcpdaddec' class=toc>mcpdaddec</a><br>
<a href='#sub_mcpdaddtrack' class=toc>mcpdaddtrack</a><br>
<a href='#sub_mcpdcreate' class=toc>mcpdcreate</a><br>
<a href='#sub_mcpdcreateentry' class=toc>mcpdcreateentry</a><br>
<a href='#sub_mcpdcreateentryexit' class=toc>mcpdcreateentryexit</a><br>
<a href='#sub_mcpdcreateexit' class=toc>mcpdcreateexit</a><br>
<a href='#sub_mcpdresults' class=toc>mcpdresults</a><br>
<a href='#sub_mcpdsetbc' class=toc>mcpdsetbc</a><br>
<a href='#sub_mcpdsetec' class=toc>mcpdsetec</a><br>
<a href='#sub_mcpdsetlc' class=toc>mcpdsetlc</a><br>
<a href='#sub_mcpdsetpredictionweights' class=toc>mcpdsetpredictionweights</a><br>
<a href='#sub_mcpdsetprior' class=toc>mcpdsetprior</a><br>
<a href='#sub_mcpdsettikhonovregularizer' class=toc>mcpdsettikhonovregularizer</a><br>
<a href='#sub_mcpdsolve' class=toc>mcpdsolve</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_mcpdaddbc'></a><h3 class=pageheader><code>mcpdaddbc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to add bound constraints  on  the  elements  of  the
# transition matrix P.
# 
# MCPD solver has four types of constraints which can be placed on P:
# * user-specified equality constraints (optional)
# * user-specified bound constraints (optional)
# * user-specified general linear constraints (optional)
# * basic constraints (always present):
#   * non-negativity: P[i,j]&gt;=0
#   * consistency: every column of P sums to 1.0
# 
# Final  constraints  which  are  passed  to  the  underlying  optimizer are
# calculated  as  intersection  of all present constraints. For example, you
# may specify boundary constraint on P[0,0] and equality one:
#     0.1&lt;=P[0,0]&lt;=0.9
#     P[0,0]=0.5
# Such  combination  of  constraints  will  be  silently  reduced  to  their
# intersection, which is P[0,0]=0.5.
# 
# This  function  can  be  used to ADD bound constraint for one element of P
# without changing constraints for other elements.
# 
# You  can  also  use  MCPDSetBC()  function  which  allows to  place  bound
# constraints  on arbitrary subset of elements of P.   Set of constraints is
# specified  by  BndL/BndU matrices, which may contain arbitrary combination
# of finite numbers or infinities (like -INF&lt;x&lt;=0.5 or 0.1&lt;=x&lt;+INF).
# 
# These functions (MCPDSetBC and MCPDAddBC) interact as follows:
# * there is internal matrix of bound constraints which is stored in the
#   MCPD solver
# * MCPDSetBC() replaces this matrix by another one (SET)
# * MCPDAddBC() modifies one element of this matrix and  leaves  other  ones
#   unchanged (ADD)
# * thus  MCPDAddBC()  call  preserves  all  modifications  done by previous
#   calls,  while  MCPDSetBC()  completely discards all changes  done to the
#   equality constraints.
# 
# INPUT PARAMETERS:
#     S       -   solver
#     I       -   row index of element being constrained
#     J       -   column index of element being constrained
#     BndL    -   lower bound
#     BndU    -   upper bound
# 
#   -- ALGLIB --
#      Copyright 23.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mcpdaddbc(s, i, j, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mcpdstate
          i:          int
          j:          int
          bndl:       float
          bndu:       float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mcpdaddec'></a><h3 class=pageheader><code>mcpdaddec</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to add equality constraints on the elements  of  the
# transition matrix P.
# 
# MCPD solver has four types of constraints which can be placed on P:
# * user-specified equality constraints (optional)
# * user-specified bound constraints (optional)
# * user-specified general linear constraints (optional)
# * basic constraints (always present):
#   * non-negativity: P[i,j]&gt;=0
#   * consistency: every column of P sums to 1.0
# 
# Final  constraints  which  are  passed  to  the  underlying  optimizer are
# calculated  as  intersection  of all present constraints. For example, you
# may specify boundary constraint on P[0,0] and equality one:
#     0.1&lt;=P[0,0]&lt;=0.9
#     P[0,0]=0.5
# Such  combination  of  constraints  will  be  silently  reduced  to  their
# intersection, which is P[0,0]=0.5.
# 
# This function can be used to ADD equality constraint for one element of  P
# without changing constraints for other elements.
# 
# You  can  also  use  MCPDSetEC()  function  which  allows  you  to specify
# arbitrary set of equality constraints in one call.
# 
# These functions (MCPDSetEC and MCPDAddEC) interact as follows:
# * there is internal matrix of equality constraints which is stored in the
#   MCPD solver
# * MCPDSetEC() replaces this matrix by another one (SET)
# * MCPDAddEC() modifies one element of this matrix and leaves  other  ones
#   unchanged (ADD)
# * thus  MCPDAddEC()  call  preserves  all  modifications done by previous
#   calls,  while  MCPDSetEC()  completely discards all changes done to the
#   equality constraints.
# 
# INPUT PARAMETERS:
#     S       -   solver
#     I       -   row index of element being constrained
#     J       -   column index of element being constrained
#     C       -   value (constraint for P[I,J]).  Can  be  either  NAN  (no
#                 constraint) or finite value from [0,1].
# 
# NOTES:
# 
# 1. infinite values of C  will lead to exception being thrown. Values  less
# than 0.0 or greater than 1.0 will lead to error code being returned  after
# call to MCPDSolve().
# 
#   -- ALGLIB --
#      Copyright 23.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mcpdaddec(s, i, j, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mcpdstate
          i:          int
          j:          int
          c:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mcpdaddtrack'></a><h3 class=pageheader><code>mcpdaddtrack</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  is  used to add a track - sequence of system states at the
# different moments of its evolution.
# 
# You  may  add  one  or several tracks to the MCPD solver. In case you have
# several tracks, they won't overwrite each other. For example,  if you pass
# two tracks, A1-A2-A3 (system at t=A+1, t=A+2 and t=A+3) and B1-B2-B3, then
# solver will try to model transitions from t=A+1 to t=A+2, t=A+2 to  t=A+3,
# t=B+1 to t=B+2, t=B+2 to t=B+3. But it WONT mix these two tracks - i.e. it
# wont try to model transition from t=A+3 to t=B+1.
# 
# INPUT PARAMETERS:
#     S       -   solver
#     XY      -   track, array[K,N]:
#                 * I-th row is a state at t=I
#                 * elements of XY must be non-negative (exception will be
#                   thrown on negative elements)
#     K       -   number of points in a track
#                 * if given, only leading K rows of XY are used
#                 * if not given, automatically determined from size of XY
# 
# NOTES:
# 
# 1. Track may contain either proportional or population data:
#    * with proportional data all rows of XY must sum to 1.0, i.e. we have
#      proportions instead of absolute population values
#    * with population data rows of XY contain population counts and generally
#      do not sum to 1.0 (although they still must be non-negative)
# 
#   -- ALGLIB --
#      Copyright 23.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mcpdaddtrack(s, xy, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mcpdaddtrack(s, xy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mcpdstate
          xy:         2D array/list of float
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mcpdcreate'></a><h3 class=pageheader><code>mcpdcreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# DESCRIPTION:
# 
# This function creates MCPD (Markov Chains for Population Data) solver.
# 
# This  solver  can  be  used  to find transition matrix P for N-dimensional
# prediction  problem  where transition from X[i] to X[i+1] is  modelled  as
#     X[i+1] = P*X[i]
# where X[i] and X[i+1] are N-dimensional population vectors (components  of
# each X are non-negative), and P is a N*N transition matrix (elements of  P
# are non-negative, each column sums to 1.0).
# 
# Such models arise when when:
# * there is some population of individuals
# * individuals can have different states
# * individuals can transit from one state to another
# * population size is constant, i.e. there is no new individuals and no one
#   leaves population
# * you want to model transitions of individuals from one state into another
# 
# USAGE:
# 
# Here we give very brief outline of the MCPD. We strongly recommend you  to
# read examples in the ALGLIB Reference Manual and to read ALGLIB User Guide
# on data analysis which is available at http://www.alglib.net/dataanalysis/
# 
# 1. User initializes algorithm state with MCPDCreate() call
# 
# 2. User  adds  one  or  more  tracks -  sequences of states which describe
#    evolution of a system being modelled from different starting conditions
# 
# 3. User may add optional boundary, equality  and/or  linear constraints on
#    the coefficients of P by calling one of the following functions:
#    * MCPDSetEC() to set equality constraints
#    * MCPDSetBC() to set bound constraints
#    * MCPDSetLC() to set linear constraints
# 
# 4. Optionally,  user  may  set  custom  weights  for prediction errors (by
#    default, algorithm assigns non-equal, automatically chosen weights  for
#    errors in the prediction of different components of X). It can be  done
#    with a call of MCPDSetPredictionWeights() function.
# 
# 5. User calls MCPDSolve() function which takes algorithm  state and
#    pointer (delegate, etc.) to callback function which calculates F/G.
# 
# 6. User calls MCPDResults() to get solution
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;=1
# 
# OUTPUT PARAMETERS:
#     State   -   structure stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 23.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.mcpdcreate(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.mcpdstate

</div></pre>
<a name='sub_mcpdcreateentry'></a><h3 class=pageheader><code>mcpdcreateentry</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# DESCRIPTION:
# 
# This function is a specialized version of MCPDCreate()  function,  and  we
# recommend  you  to read comments for this function for general information
# about MCPD solver.
# 
# This  function  creates  MCPD (Markov Chains for Population  Data)  solver
# for &quot;Entry-state&quot; model,  i.e. model  where transition from X[i] to X[i+1]
# is modelled as
#     X[i+1] = P*X[i]
# where
#     X[i] and X[i+1] are N-dimensional state vectors
#     P is a N*N transition matrix
# and  one  selected component of X[] is called &quot;entry&quot; state and is treated
# in a special way:
#     system state always transits from &quot;entry&quot; state to some another state
#     system state can not transit from any state into &quot;entry&quot; state
# Such conditions basically mean that row of P which corresponds to  &quot;entry&quot;
# state is zero.
# 
# Such models arise when:
# * there is some population of individuals
# * individuals can have different states
# * individuals can transit from one state to another
# * population size is NOT constant -  at every moment of time there is some
#   (unpredictable) amount of &quot;new&quot; individuals, which can transit into  one
#   of the states at the next turn, but still no one leaves population
# * you want to model transitions of individuals from one state into another
# * but you do NOT want to predict amount of &quot;new&quot;  individuals  because  it
#   does not depends on individuals already present (hence  system  can  not
#   transit INTO entry state - it can only transit FROM it).
# 
# This model is discussed  in  more  details  in  the ALGLIB User Guide (see
# http://www.alglib.net/dataanalysis/ for more data).
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;=2
#     EntryState- index of entry state, in 0..N-1
# 
# OUTPUT PARAMETERS:
#     State   -   structure stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 23.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.mcpdcreateentry(n, entrystate)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          entrystate: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.mcpdstate

</div></pre>
<a name='sub_mcpdcreateentryexit'></a><h3 class=pageheader><code>mcpdcreateentryexit</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# DESCRIPTION:
# 
# This function is a specialized version of MCPDCreate()  function,  and  we
# recommend  you  to read comments for this function for general information
# about MCPD solver.
# 
# This  function  creates  MCPD (Markov Chains for Population  Data)  solver
# for &quot;Entry-Exit-states&quot; model, i.e. model where  transition  from  X[i] to
# X[i+1] is modelled as
#     X[i+1] = P*X[i]
# where
#     X[i] and X[i+1] are N-dimensional state vectors
#     P is a N*N transition matrix
# one selected component of X[] is called &quot;entry&quot; state and is treated in  a
# special way:
#     system state always transits from &quot;entry&quot; state to some another state
#     system state can not transit from any state into &quot;entry&quot; state
# and another one component of X[] is called &quot;exit&quot; state and is treated  in
# a special way too:
#     system state can transit from any state into &quot;exit&quot; state
#     system state can not transit from &quot;exit&quot; state into any other state
#     transition operator discards &quot;exit&quot; state (makes it zero at each turn)
# Such conditions basically mean that:
#     row of P which corresponds to &quot;entry&quot; state is zero
#     column of P which corresponds to &quot;exit&quot; state is zero
# Multiplication by such P may decrease sum of vector components.
# 
# Such models arise when:
# * there is some population of individuals
# * individuals can have different states
# * individuals can transit from one state to another
# * population size is NOT constant
# * at every moment of time there is some (unpredictable)  amount  of  &quot;new&quot;
#   individuals, which can transit into one of the states at the next turn
# * some  individuals  can  move  (predictably)  into &quot;exit&quot; state and leave
#   population at the next turn
# * you want to model transitions of individuals from one state into another,
#   including transitions from the &quot;entry&quot; state and into the &quot;exit&quot; state.
# * but you do NOT want to predict amount of &quot;new&quot;  individuals  because  it
#   does not depends on individuals already present (hence  system  can  not
#   transit INTO entry state - it can only transit FROM it).
# 
# This model is discussed  in  more  details  in  the ALGLIB User Guide (see
# http://www.alglib.net/dataanalysis/ for more data).
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;=2
#     EntryState- index of entry state, in 0..N-1
#     ExitState-  index of exit state, in 0..N-1
# 
# OUTPUT PARAMETERS:
#     State   -   structure stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 23.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.mcpdcreateentryexit(n, entrystate, exitstate)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          entrystate: int
          exitstate:  int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.mcpdstate

</div></pre>
<a name='sub_mcpdcreateexit'></a><h3 class=pageheader><code>mcpdcreateexit</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# DESCRIPTION:
# 
# This function is a specialized version of MCPDCreate()  function,  and  we
# recommend  you  to read comments for this function for general information
# about MCPD solver.
# 
# This  function  creates  MCPD (Markov Chains for Population  Data)  solver
# for &quot;Exit-state&quot; model,  i.e. model  where  transition from X[i] to X[i+1]
# is modelled as
#     X[i+1] = P*X[i]
# where
#     X[i] and X[i+1] are N-dimensional state vectors
#     P is a N*N transition matrix
# and  one  selected component of X[] is called &quot;exit&quot;  state and is treated
# in a special way:
#     system state can transit from any state into &quot;exit&quot; state
#     system state can not transit from &quot;exit&quot; state into any other state
#     transition operator discards &quot;exit&quot; state (makes it zero at each turn)
# Such  conditions  basically  mean  that  column  of P which corresponds to
# &quot;exit&quot; state is zero. Multiplication by such P may decrease sum of  vector
# components.
# 
# Such models arise when:
# * there is some population of individuals
# * individuals can have different states
# * individuals can transit from one state to another
# * population size is NOT constant - individuals can move into &quot;exit&quot; state
#   and leave population at the next turn, but there are no new individuals
# * amount of individuals which leave population can be predicted
# * you want to model transitions of individuals from one state into another
#   (including transitions into the &quot;exit&quot; state)
# 
# This model is discussed  in  more  details  in  the ALGLIB User Guide (see
# http://www.alglib.net/dataanalysis/ for more data).
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;=2
#     ExitState-  index of exit state, in 0..N-1
# 
# OUTPUT PARAMETERS:
#     State   -   structure stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 23.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.mcpdcreateexit(n, exitstate)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          exitstate:  int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.mcpdstate

</div></pre>
<a name='sub_mcpdresults'></a><h3 class=pageheader><code>mcpdresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# MCPD results
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     P       -   array[N,N], transition matrix
#     Rep     -   optimization report. You should check Rep.TerminationType
#                 in  order  to  distinguish  successful  termination  from
#                 unsuccessful one. Speaking short, positive values  denote
#                 success, negative ones are failures.
#                 More information about fields of this  structure  can  be
#                 found in the comments on MCPDReport datatype.
# 
# 
#   -- ALGLIB --
#      Copyright 23.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p, rep = xalglib.mcpdresults(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mcpdstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          2D array/list of float
          rep:        class xalglib.mcpdreport

</div></pre>
<a name='sub_mcpdsetbc'></a><h3 class=pageheader><code>mcpdsetbc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to add bound constraints  on  the  elements  of  the
# transition matrix P.
# 
# MCPD solver has four types of constraints which can be placed on P:
# * user-specified equality constraints (optional)
# * user-specified bound constraints (optional)
# * user-specified general linear constraints (optional)
# * basic constraints (always present):
#   * non-negativity: P[i,j]&gt;=0
#   * consistency: every column of P sums to 1.0
# 
# Final  constraints  which  are  passed  to  the  underlying  optimizer are
# calculated  as  intersection  of all present constraints. For example, you
# may specify boundary constraint on P[0,0] and equality one:
#     0.1&lt;=P[0,0]&lt;=0.9
#     P[0,0]=0.5
# Such  combination  of  constraints  will  be  silently  reduced  to  their
# intersection, which is P[0,0]=0.5.
# 
# This  function  can  be  used  to  place bound   constraints  on arbitrary
# subset  of  elements  of  P.  Set of constraints is specified by BndL/BndU
# matrices, which may contain arbitrary combination  of  finite  numbers  or
# infinities (like -INF&lt;x&lt;=0.5 or 0.1&lt;=x&lt;+INF).
# 
# You can also use MCPDAddBC() function which allows to ADD bound constraint
# for one element of P without changing constraints for other elements.
# 
# These functions (MCPDSetBC and MCPDAddBC) interact as follows:
# * there is internal matrix of bound constraints which is stored in the
#   MCPD solver
# * MCPDSetBC() replaces this matrix by another one (SET)
# * MCPDAddBC() modifies one element of this matrix and  leaves  other  ones
#   unchanged (ADD)
# * thus  MCPDAddBC()  call  preserves  all  modifications  done by previous
#   calls,  while  MCPDSetBC()  completely discards all changes  done to the
#   equality constraints.
# 
# INPUT PARAMETERS:
#     S       -   solver
#     BndL    -   lower bounds constraints, array[N,N]. Elements of BndL can
#                 be finite numbers or -INF.
#     BndU    -   upper bounds constraints, array[N,N]. Elements of BndU can
#                 be finite numbers or +INF.
# 
#   -- ALGLIB --
#      Copyright 23.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mcpdsetbc(s, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mcpdstate
          bndl:       2D array/list of float
          bndu:       2D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mcpdsetec'></a><h3 class=pageheader><code>mcpdsetec</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to add equality constraints on the elements  of  the
# transition matrix P.
# 
# MCPD solver has four types of constraints which can be placed on P:
# * user-specified equality constraints (optional)
# * user-specified bound constraints (optional)
# * user-specified general linear constraints (optional)
# * basic constraints (always present):
#   * non-negativity: P[i,j]&gt;=0
#   * consistency: every column of P sums to 1.0
# 
# Final  constraints  which  are  passed  to  the  underlying  optimizer are
# calculated  as  intersection  of all present constraints. For example, you
# may specify boundary constraint on P[0,0] and equality one:
#     0.1&lt;=P[0,0]&lt;=0.9
#     P[0,0]=0.5
# Such  combination  of  constraints  will  be  silently  reduced  to  their
# intersection, which is P[0,0]=0.5.
# 
# This  function  can  be  used  to  place equality constraints on arbitrary
# subset of elements of P. Set of constraints is specified by EC, which  may
# contain either NAN's or finite numbers from [0,1]. NAN denotes absence  of
# constraint, finite number denotes equality constraint on specific  element
# of P.
# 
# You can also  use  MCPDAddEC()  function  which  allows  to  ADD  equality
# constraint  for  one  element  of P without changing constraints for other
# elements.
# 
# These functions (MCPDSetEC and MCPDAddEC) interact as follows:
# * there is internal matrix of equality constraints which is stored in  the
#   MCPD solver
# * MCPDSetEC() replaces this matrix by another one (SET)
# * MCPDAddEC() modifies one element of this matrix and  leaves  other  ones
#   unchanged (ADD)
# * thus  MCPDAddEC()  call  preserves  all  modifications  done by previous
#   calls,  while  MCPDSetEC()  completely discards all changes  done to the
#   equality constraints.
# 
# INPUT PARAMETERS:
#     S       -   solver
#     EC      -   equality constraints, array[N,N]. Elements of  EC  can  be
#                 either NAN's or finite  numbers from  [0,1].  NAN  denotes
#                 absence  of  constraints,  while  finite  value    denotes
#                 equality constraint on the corresponding element of P.
# 
# NOTES:
# 
# 1. infinite values of EC will lead to exception being thrown. Values  less
# than 0.0 or greater than 1.0 will lead to error code being returned  after
# call to MCPDSolve().
# 
#   -- ALGLIB --
#      Copyright 23.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mcpdsetec(s, ec)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mcpdstate
          ec:         2D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mcpdsetlc'></a><h3 class=pageheader><code>mcpdsetlc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to set linear equality/inequality constraints on the
# elements of the transition matrix P.
# 
# This function can be used to set one or several general linear constraints
# on the elements of P. Two types of constraints are supported:
# * equality constraints
# * inequality constraints (both less-or-equal and greater-or-equal)
# 
# Coefficients  of  constraints  are  specified  by  matrix  C (one  of  the
# parameters).  One  row  of  C  corresponds  to  one  constraint.   Because
# transition  matrix P has N*N elements,  we  need  N*N columns to store all
# coefficients  (they  are  stored row by row), and one more column to store
# right part - hence C has N*N+1 columns.  Constraint  kind is stored in the
# CT array.
# 
# Thus, I-th linear constraint is
#     P[0,0]*C[I,0] + P[0,1]*C[I,1] + .. + P[0,N-1]*C[I,N-1] +
#         + P[1,0]*C[I,N] + P[1,1]*C[I,N+1] + ... +
#         + P[N-1,N-1]*C[I,N*N-1]  ?=?  C[I,N*N]
# where ?=? can be either &quot;=&quot; (CT[i]=0), &quot;&lt;=&quot; (CT[i]&lt;0) or &quot;&gt;=&quot; (CT[i]&gt;0).
# 
# Your constraint may involve only some subset of P (less than N*N elements).
# For example it can be something like
#     P[0,0] + P[0,1] = 0.5
# In this case you still should pass matrix  with N*N+1 columns, but all its
# elements (except for C[0,0], C[0,1] and C[0,N*N-1]) will be zero.
# 
# INPUT PARAMETERS:
#     S       -   solver
#     C       -   array[K,N*N+1] - coefficients of constraints
#                 (see above for complete description)
#     CT      -   array[K] - constraint types
#                 (see above for complete description)
#     K       -   number of equality/inequality constraints, K&gt;=0:
#                 * if given, only leading K elements of C/CT are used
#                 * if not given, automatically determined from sizes of C/CT
# 
#   -- ALGLIB --
#      Copyright 23.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mcpdsetlc(s, c, ct, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mcpdsetlc(s, c, ct)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mcpdstate
          c:          2D array/list of float
          ct:         1D array/list of int
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mcpdsetpredictionweights'></a><h3 class=pageheader><code>mcpdsetpredictionweights</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to change prediction weights
# 
# MCPD solver scales prediction errors as follows
#     Error(P) = ||W*(y-P*x)||^2
# where
#     x is a system state at time t
#     y is a system state at time t+1
#     P is a transition matrix
#     W is a diagonal scaling matrix
# 
# By default, weights are chosen in order  to  minimize  relative prediction
# error instead of absolute one. For example, if one component of  state  is
# about 0.5 in magnitude and another one is about 0.05, then algorithm  will
# make corresponding weights equal to 2.0 and 20.0.
# 
# INPUT PARAMETERS:
#     S       -   solver
#     PW      -   array[N], weights:
#                 * must be non-negative values (exception will be thrown otherwise)
#                 * zero values will be replaced by automatically chosen values
# 
#   -- ALGLIB --
#      Copyright 23.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mcpdsetpredictionweights(s, pw)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mcpdstate
          pw:         1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mcpdsetprior'></a><h3 class=pageheader><code>mcpdsetprior</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  allows to set prior values used for regularization of your
# problem.
# 
# By default, regularizing term is equal to r*||P-prior_P||^2, where r is  a
# small non-zero value,  P is transition matrix, prior_P is identity matrix,
# ||X||^2 is a sum of squared elements of X.
# 
# This  function  allows  you to change prior values prior_P. You  can  also
# change r with MCPDSetTikhonovRegularizer() function.
# 
# INPUT PARAMETERS:
#     S       -   solver
#     PP      -   array[N,N], matrix of prior values:
#                 1. elements must be real numbers from [0,1]
#                 2. columns must sum to 1.0.
#                 First property is checked (exception is thrown otherwise),
#                 while second one is not checked/enforced.
# 
#   -- ALGLIB --
#      Copyright 23.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mcpdsetprior(s, pp)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mcpdstate
          pp:         2D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mcpdsettikhonovregularizer'></a><h3 class=pageheader><code>mcpdsettikhonovregularizer</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function allows to  tune  amount  of  Tikhonov  regularization  being
# applied to your problem.
# 
# By default, regularizing term is equal to r*||P-prior_P||^2, where r is  a
# small non-zero value,  P is transition matrix, prior_P is identity matrix,
# ||X||^2 is a sum of squared elements of X.
# 
# This  function  allows  you to change coefficient r. You can  also  change
# prior values with MCPDSetPrior() function.
# 
# INPUT PARAMETERS:
#     S       -   solver
#     V       -   regularization  coefficient, finite non-negative value. It
#                 is  not  recommended  to specify zero value unless you are
#                 pretty sure that you want it.
# 
#   -- ALGLIB --
#      Copyright 23.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mcpdsettikhonovregularizer(s, v)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mcpdstate
          v:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mcpdsolve'></a><h3 class=pageheader><code>mcpdsolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to start solution of the MCPD problem.
# 
# After return from this function, you can use MCPDResults() to get solution
# and completion code.
# 
#   -- ALGLIB --
#      Copyright 23.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mcpdsolve(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mcpdstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_minbc></a><h2 class=pageheader><code>minbc</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_minbccreate' class=toc>minbccreate</a><br>
<a href='#sub_minbccreatef' class=toc>minbccreatef</a><br>
<a href='#sub_minbcoptguardgradient' class=toc>minbcoptguardgradient</a><br>
<a href='#sub_minbcoptguardnonc1test0results' class=toc>minbcoptguardnonc1test0results</a><br>
<a href='#sub_minbcoptguardnonc1test1results' class=toc>minbcoptguardnonc1test1results</a><br>
<a href='#sub_minbcoptguardresults' class=toc>minbcoptguardresults</a><br>
<a href='#sub_minbcoptguardsmoothness' class=toc>minbcoptguardsmoothness</a><br>
<a href='#sub_minbcrequesttermination' class=toc>minbcrequesttermination</a><br>
<a href='#sub_minbcrestartfrom' class=toc>minbcrestartfrom</a><br>
<a href='#sub_minbcresults' class=toc>minbcresults</a><br>
<a href='#sub_minbcresultsbuf' class=toc>minbcresultsbuf</a><br>
<a href='#sub_minbcsetbc' class=toc>minbcsetbc</a><br>
<a href='#sub_minbcsetcond' class=toc>minbcsetcond</a><br>
<a href='#sub_minbcsetprecdefault' class=toc>minbcsetprecdefault</a><br>
<a href='#sub_minbcsetprecdiag' class=toc>minbcsetprecdiag</a><br>
<a href='#sub_minbcsetprecscale' class=toc>minbcsetprecscale</a><br>
<a href='#sub_minbcsetscale' class=toc>minbcsetscale</a><br>
<a href='#sub_minbcsetstpmax' class=toc>minbcsetstpmax</a><br>
<a href='#sub_minbcsetxrep' class=toc>minbcsetxrep</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_minbccreate'></a><h3 class=pageheader><code>minbccreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
#                      BOX CONSTRAINED OPTIMIZATION
#           WITH FAST ACTIVATION OF MULTIPLE BOX CONSTRAINTS
# 
# DESCRIPTION:
# The  subroutine  minimizes  function   F(x) of N arguments subject  to box
# constraints (with some of box constraints actually being equality ones).
# 
# This optimizer uses algorithm similar to that of MinBLEIC (optimizer  with
# general linear constraints), but presence of box-only  constraints  allows
# us to use faster constraint activation strategies. On large-scale problems,
# with multiple constraints active at the solution, this  optimizer  can  be
# several times faster than BLEIC.
# 
# REQUIREMENTS:
# * user must provide function value and gradient
# * starting point X0 must be feasible or
#   not too far away from the feasible set
# * grad(f) must be Lipschitz continuous on a level set:
#   L = { x : f(x)&lt;=f(x0) }
# * function must be defined everywhere on the feasible set F
# 
# USAGE:
# 
# Constrained optimization if far more complex than the unconstrained one.
# Here we give very brief outline of the BC optimizer. We strongly recommend
# you to read examples in the ALGLIB Reference Manual and to read ALGLIB User Guide
# on optimization, which is available at http://www.alglib.net/optimization/
# 
# 1. User initializes algorithm state with MinBCCreate() call
# 
# 2. USer adds box constraints by calling MinBCSetBC() function.
# 
# 3. User sets stopping conditions with MinBCSetCond().
# 
# 4. User calls MinBCOptimize() function which takes algorithm  state and
#    pointer (delegate, etc.) to callback function which calculates F/G.
# 
# 5. User calls MinBCResults() to get solution
# 
# 6. Optionally user may call MinBCRestartFrom() to solve another problem
#    with same N but another starting point.
#    MinBCRestartFrom() allows to reuse already initialized structure.
# 
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;0:
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from size ofX
#     X       -   starting point, array[N]:
#                 * it is better to set X to a feasible point
#                 * but X can be infeasible, in which case algorithm will try
#                   to find feasible point first, using X as initial
#                   approximation.
# 
# OUTPUT PARAMETERS:
#     State   -   structure stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minbccreate(n, x)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minbccreate(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minbcstate

</div></pre>
<a name='sub_minbccreatef'></a><h3 class=pageheader><code>minbccreatef</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# The subroutine is finite difference variant of MinBCCreate().  It  uses
# finite differences in order to differentiate target function.
# 
# Description below contains information which is specific to  this function
# only. We recommend to read comments on MinBCCreate() in  order  to  get
# more information about creation of BC optimizer.
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;0:
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from size of X
#     X       -   starting point, array[0..N-1].
#     DiffStep-   differentiation step, &gt;0
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# NOTES:
# 1. algorithm uses 4-point central formula for differentiation.
# 2. differentiation step along I-th axis is equal to DiffStep*S[I] where
#    S[] is scaling vector which can be set by MinBCSetScale() call.
# 3. we recommend you to use moderate values of  differentiation  step.  Too
#    large step will result in too large truncation  errors, while too small
#    step will result in too large numerical  errors.  1.0E-6  can  be  good
#    value to start with.
# 4. Numerical  differentiation  is   very   inefficient  -   one   gradient
#    calculation needs 4*N function evaluations. This function will work for
#    any N - either small (1...10), moderate (10...100) or  large  (100...).
#    However, performance penalty will be too severe for any N's except  for
#    small ones.
#    We should also say that code which relies on numerical  differentiation
#    is  less  robust and precise. CG needs exact gradient values. Imprecise
#    gradient may slow  down  convergence, especially  on  highly  nonlinear
#    problems.
#    Thus  we  recommend to use this function for fast prototyping on small-
#    dimensional problems only, and to implement analytical gradient as soon
#    as possible.
# 
#   -- ALGLIB --
#      Copyright 16.05.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minbccreatef(n, x, diffstep)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minbccreatef(x, diffstep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          1D array/list of float
          diffstep:   float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minbcstate

</div></pre>
<a name='sub_minbcoptguardgradient'></a><h3 class=pageheader><code>minbcoptguardgradient</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  activates/deactivates verification  of  the  user-supplied
# analytic gradient.
# 
# Upon  activation  of  this  option  OptGuard  integrity  checker  performs
# numerical differentiation of your target function  at  the  initial  point
# (note: future versions may also perform check  at  the  final  point)  and
# compares numerical gradient with analytic one provided by you.
# 
# If difference is too large, an error flag is set and optimization  session
# continues. After optimization session is over, you can retrieve the report
# which  stores  both  gradients  and  specific  components  highlighted  as
# suspicious by the OptGuard.
# 
# The primary OptGuard report can be retrieved with minbcoptguardresults().
# 
# IMPORTANT: gradient check is a high-overhead option which  will  cost  you
#            about 3*N additional function evaluations. In many cases it may
#            cost as much as the rest of the optimization session.
# 
#            YOU SHOULD NOT USE IT IN THE PRODUCTION CODE UNLESS YOU WANT TO
#            CHECK DERIVATIVES PROVIDED BY SOME THIRD PARTY.
# 
# NOTE: unlike previous incarnation of the gradient checking code,  OptGuard
#       does NOT interrupt optimization even if it discovers bad gradient.
# 
# INPUT PARAMETERS:
#     State       -   structure used to store algorithm state
#     TestStep    -   verification step used for numerical differentiation:
#                     * TestStep=0 turns verification off
#                     * TestStep&gt;0 activates verification
#                     You should carefully choose TestStep. Value  which  is
#                     too large (so large that  function  behavior  is  non-
#                     cubic at this scale) will lead  to  false  alarms. Too
#                     short step will result in rounding  errors  dominating
#                     numerical derivative.
# 
#                     You may use different step for different parameters by
#                     means of setting scale with minbcsetscale().
# 
# === EXPLANATION ==========================================================
# 
# In order to verify gradient algorithm performs following steps:
#   * two trial steps are made to X[i]-TestStep*S[i] and X[i]+TestStep*S[i],
#     where X[i] is i-th component of the initial point and S[i] is a  scale
#     of i-th parameter
#   * F(X) is evaluated at these trial points
#   * we perform one more evaluation in the middle point of the interval
#   * we  build  cubic  model using function values and derivatives at trial
#     points and we compare its prediction with actual value in  the  middle
#     point
# 
#   -- ALGLIB --
#      Copyright 15.06.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbcoptguardgradient(state, teststep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
          teststep:   float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbcoptguardnonc1test0results'></a><h3 class=pageheader><code>minbcoptguardnonc1test0results</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Detailed results of the OptGuard integrity check for nonsmoothness test #0
# 
# Nonsmoothness (non-C1) test #0 studies  function  values  (not  gradient!)
# obtained during line searches and monitors  behavior  of  the  directional
# derivative estimate.
# 
# This test is less powerful than test #1, but it does  not  depend  on  the
# gradient values and thus it is more robust against artifacts introduced by
# numerical differentiation.
# 
# Two reports are returned:
# * a &quot;strongest&quot; one, corresponding  to  line   search  which  had  highest
#   value of the nonsmoothness indicator
# * a &quot;longest&quot; one, corresponding to line search which  had  more  function
#   evaluations, and thus is more detailed
# 
# In both cases following fields are returned:
# 
# * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
#   did not notice anything (in the latter cases fields below are empty).
# * x0[], d[] - arrays of length N which store initial point  and  direction
#   for line search (d[] can be normalized, but does not have to)
# * stp[], f[] - arrays of length CNT which store step lengths and  function
#   values at these points; f[i] is evaluated in x0+stp[i]*d.
# * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
#   between steps #stpidxa and #stpidxb (usually we have  stpidxb=stpidxa+3,
#   with  most  likely  position  of  the  violation  between  stpidxa+1 and
#   stpidxa+2.
# 
# ==========================================================================
# = SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -  you  will
# =                   see where C1 continuity is violated.
# ==========================================================================
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     strrep  -   C1 test #0 &quot;strong&quot; report
#     lngrep  -   C1 test #0 &quot;long&quot; report
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   strrep, lngrep = xalglib.minbcoptguardnonc1test0results(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  strrep:     class xalglib.optguardnonc1test0report
          lngrep:     class xalglib.optguardnonc1test0report

</div></pre>
<a name='sub_minbcoptguardnonc1test1results'></a><h3 class=pageheader><code>minbcoptguardnonc1test1results</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Detailed results of the OptGuard integrity check for nonsmoothness test #1
# 
# Nonsmoothness (non-C1)  test  #1  studies  individual  components  of  the
# gradient computed during line search.
# 
# When precise analytic gradient is provided this test is more powerful than
# test #0  which  works  with  function  values  and  ignores  user-provided
# gradient.  However,  test  #0  becomes  more   powerful   when   numerical
# differentiation is employed (in such cases test #1 detects  higher  levels
# of numerical noise and becomes too conservative).
# 
# This test also tells specific components of the gradient which violate  C1
# continuity, which makes it more informative than #0, which just tells that
# continuity is violated.
# 
# Two reports are returned:
# * a &quot;strongest&quot; one, corresponding  to  line   search  which  had  highest
#   value of the nonsmoothness indicator
# * a &quot;longest&quot; one, corresponding to line search which  had  more  function
#   evaluations, and thus is more detailed
# 
# In both cases following fields are returned:
# 
# * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
#   did not notice anything (in the latter cases fields below are empty).
# * vidx - is an index of the variable in [0,N) with nonsmooth derivative
# * x0[], d[] - arrays of length N which store initial point  and  direction
#   for line search (d[] can be normalized, but does not have to)
# * stp[], g[] - arrays of length CNT which store step lengths and  gradient
#   values at these points; g[i] is evaluated in  x0+stp[i]*d  and  contains
#   vidx-th component of the gradient.
# * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
#   between steps #stpidxa and #stpidxb (usually we have  stpidxb=stpidxa+3,
#   with  most  likely  position  of  the  violation  between  stpidxa+1 and
#   stpidxa+2.
# 
# ==========================================================================
# = SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -  you  will
# =                   see where C1 continuity is violated.
# ==========================================================================
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     strrep  -   C1 test #1 &quot;strong&quot; report
#     lngrep  -   C1 test #1 &quot;long&quot; report
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   strrep, lngrep = xalglib.minbcoptguardnonc1test1results(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  strrep:     class xalglib.optguardnonc1test1report
          lngrep:     class xalglib.optguardnonc1test1report

</div></pre>
<a name='sub_minbcoptguardresults'></a><h3 class=pageheader><code>minbcoptguardresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Results of OptGuard integrity check, should be called  after  optimization
# session is over.
# 
# === PRIMARY REPORT =======================================================
# 
# OptGuard performs several checks which are intended to catch common errors
# in the implementation of nonlinear function/gradient:
# * incorrect analytic gradient
# * discontinuous (non-C0) target functions (constraints)
# * nonsmooth     (non-C1) target functions (constraints)
# 
# Each of these checks is activated with appropriate function:
# * minbcoptguardgradient() for gradient verification
# * minbcoptguardsmoothness() for C0/C1 checks
# 
# Following flags are set when these errors are suspected:
# * rep.badgradsuspected, and additionally:
#   * rep.badgradvidx for specific variable (gradient element) suspected
#   * rep.badgradxbase, a point where gradient is tested
#   * rep.badgraduser, user-provided gradient  (stored  as  2D  matrix  with
#     single row in order to make  report  structure  compatible  with  more
#     complex optimizers like MinNLC or MinLM)
#   * rep.badgradnum,   reference    gradient    obtained    via   numerical
#     differentiation (stored as  2D matrix with single row in order to make
#     report structure compatible with more complex optimizers  like  MinNLC
#     or MinLM)
# * rep.nonc0suspected
# * rep.nonc1suspected
# 
# === ADDITIONAL REPORTS/LOGS ==============================================
# 
# Several different tests are performed to catch C0/C1 errors, you can  find
# out specific test signaled error by looking to:
# * rep.nonc0test0positive, for non-C0 test #0
# * rep.nonc1test0positive, for non-C1 test #0
# * rep.nonc1test1positive, for non-C1 test #1
# 
# Additional information (including line search logs)  can  be  obtained  by
# means of:
# * minbcoptguardnonc1test0results()
# * minbcoptguardnonc1test1results()
# which return detailed error reports, specific points where discontinuities
# were found, and so on.
# 
# ==========================================================================
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     rep     -   generic OptGuard report;  more  detailed  reports  can  be
#                 retrieved with other functions.
# 
# NOTE: false negatives (nonsmooth problems are not identified as  nonsmooth
#       ones) are possible although unlikely.
# 
#       The reason  is  that  you  need  to  make several evaluations around
#       nonsmoothness  in  order  to  accumulate  enough  information  about
#       function curvature. Say, if you start right from the nonsmooth point,
#       optimizer simply won't get enough data to understand what  is  going
#       wrong before it terminates due to abrupt changes in the  derivative.
#       It is also  possible  that  &quot;unlucky&quot;  step  will  move  us  to  the
#       termination too quickly.
# 
#       Our current approach is to have less than 0.1%  false  negatives  in
#       our test examples  (measured  with  multiple  restarts  from  random
#       points), and to have exactly 0% false positives.
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.minbcoptguardresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.optguardreport

</div></pre>
<a name='sub_minbcoptguardsmoothness'></a><h3 class=pageheader><code>minbcoptguardsmoothness</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  activates/deactivates nonsmoothness monitoring  option  of
# the  OptGuard  integrity  checker. Smoothness  monitor  silently  observes
# solution process and tries to detect ill-posed problems, i.e. ones with:
# a) discontinuous target function (non-C0)
# b) nonsmooth     target function (non-C1)
# 
# Smoothness monitoring does NOT interrupt optimization  even if it suspects
# that your problem is nonsmooth. It just sets corresponding  flags  in  the
# OptGuard report which can be retrieved after optimization is over.
# 
# Smoothness monitoring is a moderate overhead option which often adds  less
# than 1% to the optimizer running time. Thus, you can use it even for large
# scale problems.
# 
# NOTE: OptGuard does  NOT  guarantee  that  it  will  always  detect  C0/C1
#       continuity violations.
# 
#       First, minor errors are hard to  catch - say, a 0.0001 difference in
#       the model values at two sides of the gap may be due to discontinuity
#       of the model - or simply because the model has changed.
# 
#       Second, C1-violations  are  especially  difficult  to  detect  in  a
#       noninvasive way. The optimizer usually  performs  very  short  steps
#       near the nonsmoothness, and differentiation  usually   introduces  a
#       lot of numerical noise.  It  is  hard  to  tell  whether  some  tiny
#       discontinuity in the slope is due to real nonsmoothness or just  due
#       to numerical noise alone.
# 
#       Our top priority was to avoid false positives, so in some rare cases
#       minor errors may went unnoticed (however, in most cases they can  be
#       spotted with restart from different initial point).
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
#     level   -   monitoring level:
#                 * 0 - monitoring is disabled
#                 * 1 - noninvasive low-overhead monitoring; function values
#                       and/or gradients are recorded, but OptGuard does not
#                       try to perform additional evaluations  in  order  to
#                       get more information about suspicious locations.
# 
# === EXPLANATION ==========================================================
# 
# One major source of headache during optimization  is  the  possibility  of
# the coding errors in the target function/constraints (or their gradients).
# Such  errors   most   often   manifest   themselves  as  discontinuity  or
# nonsmoothness of the target/constraints.
# 
# Another frequent situation is when you try to optimize something involving
# lots of min() and max() operations, i.e. nonsmooth target. Although not  a
# coding error, it is nonsmoothness anyway - and smooth  optimizers  usually
# stop right after encountering nonsmoothness, well before reaching solution.
# 
# OptGuard integrity checker helps you to catch such situations: it monitors
# function values/gradients being passed  to  the  optimizer  and  tries  to
# errors. Upon discovering suspicious pair of points it  raises  appropriate
# flag (and allows you to continue optimization). When optimization is done,
# you can study OptGuard result.
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbcoptguardsmoothness(state, level)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbcoptguardsmoothness(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
          level:      int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbcrequesttermination'></a><h3 class=pageheader><code>minbcrequesttermination</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine submits request for termination of running  optimizer.  It
# should be called from user-supplied callback when user decides that it  is
# time to &quot;smoothly&quot; terminate optimization process.  As  result,  optimizer
# stops at point which was &quot;current accepted&quot; when termination  request  was
# submitted and returns error code 8 (successful termination).
# 
# INPUT PARAMETERS:
#     State   -   optimizer structure
# 
# NOTE: after  request  for  termination  optimizer  may   perform   several
#       additional calls to user-supplied callbacks. It does  NOT  guarantee
#       to stop immediately - it just guarantees that these additional calls
#       will be discarded later.
# 
# NOTE: calling this function on optimizer which is NOT running will have no
#       effect.
# 
# NOTE: multiple calls to this function are possible. First call is counted,
#       subsequent calls are silently ignored.
# 
#   -- ALGLIB --
#      Copyright 08.10.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbcrequesttermination(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbcrestartfrom'></a><h3 class=pageheader><code>minbcrestartfrom</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine restarts algorithm from new point.
# All optimization parameters (including constraints) are left unchanged.
# 
# This  function  allows  to  solve multiple  optimization  problems  (which
# must have  same number of dimensions) without object reallocation penalty.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with MinBCCreate call.
#     X       -   new starting point.
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbcrestartfrom(state, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbcresults'></a><h3 class=pageheader><code>minbcresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# BC results
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     X       -   array[0..N-1], solution
#     Rep     -   optimization report. You should check Rep.TerminationType
#                 in  order  to  distinguish  successful  termination  from
#                 unsuccessful one:
#                 * -8    internal integrity control  detected  infinite or
#                         NAN   values   in   function/gradient.   Abnormal
#                         termination signalled.
#                 * -3   inconsistent constraints.
#                 *  1   relative function improvement is no more than EpsF.
#                 *  2   scaled step is no more than EpsX.
#                 *  4   scaled gradient norm is no more than EpsG.
#                 *  5   MaxIts steps was taken
#                 *  8   terminated by user who called minbcrequesttermination().
#                        X contains point which was &quot;current accepted&quot;  when
#                        termination request was submitted.
#                 More information about fields of this  structure  can  be
#                 found in the comments on MinBCReport datatype.
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.minbcresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.minbcreport

</div></pre>
<a name='sub_minbcresultsbuf'></a><h3 class=pageheader><code>minbcresultsbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# BC results
# 
# Buffered implementation of MinBCResults() which uses pre-allocated buffer
# to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
# intended to be used in the inner cycles of performance critical algorithms
# where array reallocation penalty is too large to be ignored.
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.minbcresultsbuf(state, x, rep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
          x:          1D array/list of float
          rep:        class xalglib.minbcreport
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> rep
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float

</div></pre>
<a name='sub_minbcsetbc'></a><h3 class=pageheader><code>minbcsetbc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets boundary constraints for BC optimizer.
# 
# Boundary constraints are inactive by default (after initial creation).
# They are preserved after algorithm restart with MinBCRestartFrom().
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     BndL    -   lower bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 very small number or -INF.
#     BndU    -   upper bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 very large number or +INF.
# 
# NOTE 1: it is possible to specify BndL[i]=BndU[i]. In this case I-th
# variable will be &quot;frozen&quot; at X[i]=BndL[i]=BndU[i].
# 
# NOTE 2: this solver has following useful properties:
# * bound constraints are always satisfied exactly
# * function is evaluated only INSIDE area specified by  bound  constraints,
#   even  when  numerical  differentiation is used (algorithm adjusts  nodes
#   according to boundary constraints)
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbcsetbc(state, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
          bndl:       1D array/list of float
          bndu:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbcsetcond'></a><h3 class=pageheader><code>minbcsetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping conditions for the optimizer.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     EpsG    -   &gt;=0
#                 The  subroutine  finishes  its  work   if   the  condition
#                 |v|&lt;EpsG is satisfied, where:
#                 * |.| means Euclidian norm
#                 * v - scaled gradient vector, v[i]=g[i]*s[i]
#                 * g - gradient
#                 * s - scaling coefficients set by MinBCSetScale()
#     EpsF    -   &gt;=0
#                 The  subroutine  finishes  its work if on k+1-th iteration
#                 the  condition  |F(k+1)-F(k)|&lt;=EpsF*max{|F(k)|,|F(k+1)|,1}
#                 is satisfied.
#     EpsX    -   &gt;=0
#                 The subroutine finishes its work if  on  k+1-th  iteration
#                 the condition |v|&lt;=EpsX is fulfilled, where:
#                 * |.| means Euclidian norm
#                 * v - scaled step vector, v[i]=dx[i]/s[i]
#                 * dx - step vector, dx=X(k+1)-X(k)
#                 * s - scaling coefficients set by MinBCSetScale()
#     MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
#                 iterations is unlimited.
# 
# Passing EpsG=0, EpsF=0 and EpsX=0 and MaxIts=0 (simultaneously) will lead
# to automatic stopping criterion selection.
# 
# NOTE: when SetCond() called with non-zero MaxIts, BC solver may perform
#       slightly more than MaxIts iterations. I.e., MaxIts  sets  non-strict
#       limit on iterations count.
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbcsetcond(state, epsg, epsf, epsx, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
          epsg:       float
          epsf:       float
          epsx:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbcsetprecdefault'></a><h3 class=pageheader><code>minbcsetprecdefault</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modification of the preconditioner: preconditioning is turned off.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 13.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbcsetprecdefault(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbcsetprecdiag'></a><h3 class=pageheader><code>minbcsetprecdiag</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modification  of  the  preconditioner:  diagonal of approximate Hessian is
# used.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     D       -   diagonal of the approximate Hessian, array[0..N-1],
#                 (if larger, only leading N elements are used).
# 
# NOTE 1: D[i] should be positive. Exception will be thrown otherwise.
# 
# NOTE 2: you should pass diagonal of approximate Hessian - NOT ITS INVERSE.
# 
#   -- ALGLIB --
#      Copyright 13.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbcsetprecdiag(state, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
          d:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbcsetprecscale'></a><h3 class=pageheader><code>minbcsetprecscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modification of the preconditioner: scale-based diagonal preconditioning.
# 
# This preconditioning mode can be useful when you  don't  have  approximate
# diagonal of Hessian, but you know that your  variables  are  badly  scaled
# (for  example,  one  variable is in [1,10], and another in [1000,100000]),
# and most part of the ill-conditioning comes from different scales of vars.
# 
# In this case simple  scale-based  preconditioner,  with H[i] = 1/(s[i]^2),
# can greatly improve convergence.
# 
# IMPRTANT: you should set scale of your variables  with  MinBCSetScale()
# call  (before  or after MinBCSetPrecScale() call). Without knowledge of
# the scale of your variables scale-based preconditioner will be  just  unit
# matrix.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 13.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbcsetprecscale(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbcsetscale'></a><h3 class=pageheader><code>minbcsetscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets scaling coefficients for BC optimizer.
# 
# ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
# size and gradient are scaled before comparison with tolerances).  Scale of
# the I-th variable is a translation invariant measure of:
# a) &quot;how large&quot; the variable is
# b) how large the step should be to make significant changes in the function
# 
# Scaling is also used by finite difference variant of the optimizer  - step
# along I-th axis is equal to DiffStep*S[I].
# 
# In  most  optimizers  (and  in  the  BC  too)  scaling is NOT a form of
# preconditioning. It just  affects  stopping  conditions.  You  should  set
# preconditioner  by  separate  call  to  one  of  the  MinBCSetPrec...()
# functions.
# 
# There is a special  preconditioning  mode, however,  which  uses   scaling
# coefficients to form diagonal preconditioning matrix. You  can  turn  this
# mode on, if you want.   But  you should understand that scaling is not the
# same thing as preconditioning - these are two different, although  related
# forms of tuning solver.
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     S       -   array[N], non-zero scaling coefficients
#                 S[i] may be negative, sign doesn't matter.
# 
#   -- ALGLIB --
#      Copyright 14.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbcsetscale(state, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
          s:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbcsetstpmax'></a><h3 class=pageheader><code>minbcsetstpmax</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets maximum step length
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     StpMax  -   maximum step length, &gt;=0. Set StpMax to 0.0,  if you don't
#                 want to limit step length.
# 
# Use this subroutine when you optimize target function which contains exp()
# or  other  fast  growing  functions,  and optimization algorithm makes too
# large  steps  which  lead   to overflow. This function allows us to reject
# steps  that  are  too  large  (and  therefore  expose  us  to the possible
# overflow) without actually calculating function value at the x+stp*d.
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbcsetstpmax(state, stpmax)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
          stpmax:     float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbcsetxrep'></a><h3 class=pageheader><code>minbcsetxrep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function turns on/off reporting.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     NeedXRep-   whether iteration reports are needed or not
# 
# If NeedXRep is True, algorithm will call rep() callback function if  it is
# provided to MinBCOptimize().
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbcsetxrep(state, needxrep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbcstate
          needxrep:   bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_minbleic></a><h2 class=pageheader><code>minbleic</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_minbleiccreate' class=toc>minbleiccreate</a><br>
<a href='#sub_minbleiccreatef' class=toc>minbleiccreatef</a><br>
<a href='#sub_minbleicoptguardgradient' class=toc>minbleicoptguardgradient</a><br>
<a href='#sub_minbleicoptguardnonc1test0results' class=toc>minbleicoptguardnonc1test0results</a><br>
<a href='#sub_minbleicoptguardnonc1test1results' class=toc>minbleicoptguardnonc1test1results</a><br>
<a href='#sub_minbleicoptguardresults' class=toc>minbleicoptguardresults</a><br>
<a href='#sub_minbleicoptguardsmoothness' class=toc>minbleicoptguardsmoothness</a><br>
<a href='#sub_minbleicrequesttermination' class=toc>minbleicrequesttermination</a><br>
<a href='#sub_minbleicrestartfrom' class=toc>minbleicrestartfrom</a><br>
<a href='#sub_minbleicresults' class=toc>minbleicresults</a><br>
<a href='#sub_minbleicresultsbuf' class=toc>minbleicresultsbuf</a><br>
<a href='#sub_minbleicsetbc' class=toc>minbleicsetbc</a><br>
<a href='#sub_minbleicsetcond' class=toc>minbleicsetcond</a><br>
<a href='#sub_minbleicsetlc' class=toc>minbleicsetlc</a><br>
<a href='#sub_minbleicsetprecdefault' class=toc>minbleicsetprecdefault</a><br>
<a href='#sub_minbleicsetprecdiag' class=toc>minbleicsetprecdiag</a><br>
<a href='#sub_minbleicsetprecscale' class=toc>minbleicsetprecscale</a><br>
<a href='#sub_minbleicsetscale' class=toc>minbleicsetscale</a><br>
<a href='#sub_minbleicsetstpmax' class=toc>minbleicsetstpmax</a><br>
<a href='#sub_minbleicsetxrep' class=toc>minbleicsetxrep</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_minbleiccreate'></a><h3 class=pageheader><code>minbleiccreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
#                      BOUND CONSTRAINED OPTIMIZATION
#        WITH ADDITIONAL LINEAR EQUALITY AND INEQUALITY CONSTRAINTS
# 
# DESCRIPTION:
# The  subroutine  minimizes  function   F(x)  of N arguments subject to any
# combination of:
# * bound constraints
# * linear inequality constraints
# * linear equality constraints
# 
# REQUIREMENTS:
# * user must provide function value and gradient
# * starting point X0 must be feasible or
#   not too far away from the feasible set
# * grad(f) must be Lipschitz continuous on a level set:
#   L = { x : f(x)&lt;=f(x0) }
# * function must be defined everywhere on the feasible set F
# 
# USAGE:
# 
# Constrained optimization if far more complex than the unconstrained one.
# Here we give very brief outline of the BLEIC optimizer. We strongly recommend
# you to read examples in the ALGLIB Reference Manual and to read ALGLIB User Guide
# on optimization, which is available at http://www.alglib.net/optimization/
# 
# 1. User initializes algorithm state with MinBLEICCreate() call
# 
# 2. USer adds boundary and/or linear constraints by calling
#    MinBLEICSetBC() and MinBLEICSetLC() functions.
# 
# 3. User sets stopping conditions with MinBLEICSetCond().
# 
# 4. User calls MinBLEICOptimize() function which takes algorithm  state and
#    pointer (delegate, etc.) to callback function which calculates F/G.
# 
# 5. User calls MinBLEICResults() to get solution
# 
# 6. Optionally user may call MinBLEICRestartFrom() to solve another problem
#    with same N but another starting point.
#    MinBLEICRestartFrom() allows to reuse already initialized structure.
# 
# NOTE: if you have box-only constraints (no  general  linear  constraints),
#       then MinBC optimizer can be better option. It uses  special,  faster
#       constraint activation method, which performs better on problems with
#       multiple constraints active at the solution.
# 
#       On small-scale problems performance of MinBC is similar to  that  of
#       MinBLEIC, but on large-scale ones (hundreds and thousands of  active
#       constraints) it can be several times faster than MinBLEIC.
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;0:
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from size ofX
#     X       -   starting point, array[N]:
#                 * it is better to set X to a feasible point
#                 * but X can be infeasible, in which case algorithm will try
#                   to find feasible point first, using X as initial
#                   approximation.
# 
# OUTPUT PARAMETERS:
#     State   -   structure stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minbleiccreate(n, x)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minbleiccreate(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minbleicstate

</div></pre>
<a name='sub_minbleiccreatef'></a><h3 class=pageheader><code>minbleiccreatef</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# The subroutine is finite difference variant of MinBLEICCreate().  It  uses
# finite differences in order to differentiate target function.
# 
# Description below contains information which is specific to  this function
# only. We recommend to read comments on MinBLEICCreate() in  order  to  get
# more information about creation of BLEIC optimizer.
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;0:
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from size of X
#     X       -   starting point, array[0..N-1].
#     DiffStep-   differentiation step, &gt;0
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# NOTES:
# 1. algorithm uses 4-point central formula for differentiation.
# 2. differentiation step along I-th axis is equal to DiffStep*S[I] where
#    S[] is scaling vector which can be set by MinBLEICSetScale() call.
# 3. we recommend you to use moderate values of  differentiation  step.  Too
#    large step will result in too large truncation  errors, while too small
#    step will result in too large numerical  errors.  1.0E-6  can  be  good
#    value to start with.
# 4. Numerical  differentiation  is   very   inefficient  -   one   gradient
#    calculation needs 4*N function evaluations. This function will work for
#    any N - either small (1...10), moderate (10...100) or  large  (100...).
#    However, performance penalty will be too severe for any N's except  for
#    small ones.
#    We should also say that code which relies on numerical  differentiation
#    is  less  robust and precise. CG needs exact gradient values. Imprecise
#    gradient may slow  down  convergence, especially  on  highly  nonlinear
#    problems.
#    Thus  we  recommend to use this function for fast prototyping on small-
#    dimensional problems only, and to implement analytical gradient as soon
#    as possible.
# 
#   -- ALGLIB --
#      Copyright 16.05.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minbleiccreatef(n, x, diffstep)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minbleiccreatef(x, diffstep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          1D array/list of float
          diffstep:   float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minbleicstate

</div></pre>
<a name='sub_minbleicoptguardgradient'></a><h3 class=pageheader><code>minbleicoptguardgradient</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  activates/deactivates verification  of  the  user-supplied
# analytic gradient.
# 
# Upon  activation  of  this  option  OptGuard  integrity  checker  performs
# numerical differentiation of your target function  at  the  initial  point
# (note: future versions may also perform check  at  the  final  point)  and
# compares numerical gradient with analytic one provided by you.
# 
# If difference is too large, an error flag is set and optimization  session
# continues. After optimization session is over, you can retrieve the report
# which  stores  both  gradients  and  specific  components  highlighted  as
# suspicious by the OptGuard.
# 
# The primary OptGuard report can be retrieved with minbleicoptguardresults().
# 
# IMPORTANT: gradient check is a high-overhead option which  will  cost  you
#            about 3*N additional function evaluations. In many cases it may
#            cost as much as the rest of the optimization session.
# 
#            YOU SHOULD NOT USE IT IN THE PRODUCTION CODE UNLESS YOU WANT TO
#            CHECK DERIVATIVES PROVIDED BY SOME THIRD PARTY.
# 
# NOTE: unlike previous incarnation of the gradient checking code,  OptGuard
#       does NOT interrupt optimization even if it discovers bad gradient.
# 
# INPUT PARAMETERS:
#     State       -   structure used to store algorithm state
#     TestStep    -   verification step used for numerical differentiation:
#                     * TestStep=0 turns verification off
#                     * TestStep&gt;0 activates verification
#                     You should carefully choose TestStep. Value  which  is
#                     too large (so large that  function  behavior  is  non-
#                     cubic at this scale) will lead  to  false  alarms. Too
#                     short step will result in rounding  errors  dominating
#                     numerical derivative.
# 
#                     You may use different step for different parameters by
#                     means of setting scale with minbleicsetscale().
# 
# === EXPLANATION ==========================================================
# 
# In order to verify gradient algorithm performs following steps:
#   * two trial steps are made to X[i]-TestStep*S[i] and X[i]+TestStep*S[i],
#     where X[i] is i-th component of the initial point and S[i] is a  scale
#     of i-th parameter
#   * F(X) is evaluated at these trial points
#   * we perform one more evaluation in the middle point of the interval
#   * we  build  cubic  model using function values and derivatives at trial
#     points and we compare its prediction with actual value in  the  middle
#     point
# 
#   -- ALGLIB --
#      Copyright 15.06.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicoptguardgradient(state, teststep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
          teststep:   float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbleicoptguardnonc1test0results'></a><h3 class=pageheader><code>minbleicoptguardnonc1test0results</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Detailed results of the OptGuard integrity check for nonsmoothness test #0
# 
# Nonsmoothness (non-C1) test #0 studies  function  values  (not  gradient!)
# obtained during line searches and monitors  behavior  of  the  directional
# derivative estimate.
# 
# This test is less powerful than test #1, but it does  not  depend  on  the
# gradient values and thus it is more robust against artifacts introduced by
# numerical differentiation.
# 
# Two reports are returned:
# * a &quot;strongest&quot; one, corresponding  to  line   search  which  had  highest
#   value of the nonsmoothness indicator
# * a &quot;longest&quot; one, corresponding to line search which  had  more  function
#   evaluations, and thus is more detailed
# 
# In both cases following fields are returned:
# 
# * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
#   did not notice anything (in the latter cases fields below are empty).
# * x0[], d[] - arrays of length N which store initial point  and  direction
#   for line search (d[] can be normalized, but does not have to)
# * stp[], f[] - arrays of length CNT which store step lengths and  function
#   values at these points; f[i] is evaluated in x0+stp[i]*d.
# * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
#   between steps #stpidxa and #stpidxb (usually we have  stpidxb=stpidxa+3,
#   with  most  likely  position  of  the  violation  between  stpidxa+1 and
#   stpidxa+2.
# 
# ==========================================================================
# = SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -  you  will
# =                   see where C1 continuity is violated.
# ==========================================================================
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     strrep  -   C1 test #0 &quot;strong&quot; report
#     lngrep  -   C1 test #0 &quot;long&quot; report
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   strrep, lngrep = xalglib.minbleicoptguardnonc1test0results(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  strrep:     class xalglib.optguardnonc1test0report
          lngrep:     class xalglib.optguardnonc1test0report

</div></pre>
<a name='sub_minbleicoptguardnonc1test1results'></a><h3 class=pageheader><code>minbleicoptguardnonc1test1results</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Detailed results of the OptGuard integrity check for nonsmoothness test #1
# 
# Nonsmoothness (non-C1)  test  #1  studies  individual  components  of  the
# gradient computed during line search.
# 
# When precise analytic gradient is provided this test is more powerful than
# test #0  which  works  with  function  values  and  ignores  user-provided
# gradient.  However,  test  #0  becomes  more   powerful   when   numerical
# differentiation is employed (in such cases test #1 detects  higher  levels
# of numerical noise and becomes too conservative).
# 
# This test also tells specific components of the gradient which violate  C1
# continuity, which makes it more informative than #0, which just tells that
# continuity is violated.
# 
# Two reports are returned:
# * a &quot;strongest&quot; one, corresponding  to  line   search  which  had  highest
#   value of the nonsmoothness indicator
# * a &quot;longest&quot; one, corresponding to line search which  had  more  function
#   evaluations, and thus is more detailed
# 
# In both cases following fields are returned:
# 
# * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
#   did not notice anything (in the latter cases fields below are empty).
# * vidx - is an index of the variable in [0,N) with nonsmooth derivative
# * x0[], d[] - arrays of length N which store initial point  and  direction
#   for line search (d[] can be normalized, but does not have to)
# * stp[], g[] - arrays of length CNT which store step lengths and  gradient
#   values at these points; g[i] is evaluated in  x0+stp[i]*d  and  contains
#   vidx-th component of the gradient.
# * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
#   between steps #stpidxa and #stpidxb (usually we have  stpidxb=stpidxa+3,
#   with  most  likely  position  of  the  violation  between  stpidxa+1 and
#   stpidxa+2.
# 
# ==========================================================================
# = SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -  you  will
# =                   see where C1 continuity is violated.
# ==========================================================================
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     strrep  -   C1 test #1 &quot;strong&quot; report
#     lngrep  -   C1 test #1 &quot;long&quot; report
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   strrep, lngrep = xalglib.minbleicoptguardnonc1test1results(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  strrep:     class xalglib.optguardnonc1test1report
          lngrep:     class xalglib.optguardnonc1test1report

</div></pre>
<a name='sub_minbleicoptguardresults'></a><h3 class=pageheader><code>minbleicoptguardresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Results of OptGuard integrity check, should be called  after  optimization
# session is over.
# 
# === PRIMARY REPORT =======================================================
# 
# OptGuard performs several checks which are intended to catch common errors
# in the implementation of nonlinear function/gradient:
# * incorrect analytic gradient
# * discontinuous (non-C0) target functions (constraints)
# * nonsmooth     (non-C1) target functions (constraints)
# 
# Each of these checks is activated with appropriate function:
# * minbleicoptguardgradient() for gradient verification
# * minbleicoptguardsmoothness() for C0/C1 checks
# 
# Following flags are set when these errors are suspected:
# * rep.badgradsuspected, and additionally:
#   * rep.badgradvidx for specific variable (gradient element) suspected
#   * rep.badgradxbase, a point where gradient is tested
#   * rep.badgraduser, user-provided gradient  (stored  as  2D  matrix  with
#     single row in order to make  report  structure  compatible  with  more
#     complex optimizers like MinNLC or MinLM)
#   * rep.badgradnum,   reference    gradient    obtained    via   numerical
#     differentiation (stored as  2D matrix with single row in order to make
#     report structure compatible with more complex optimizers  like  MinNLC
#     or MinLM)
# * rep.nonc0suspected
# * rep.nonc1suspected
# 
# === ADDITIONAL REPORTS/LOGS ==============================================
# 
# Several different tests are performed to catch C0/C1 errors, you can  find
# out specific test signaled error by looking to:
# * rep.nonc0test0positive, for non-C0 test #0
# * rep.nonc1test0positive, for non-C1 test #0
# * rep.nonc1test1positive, for non-C1 test #1
# 
# Additional information (including line search logs)  can  be  obtained  by
# means of:
# * minbleicoptguardnonc1test0results()
# * minbleicoptguardnonc1test1results()
# which return detailed error reports, specific points where discontinuities
# were found, and so on.
# 
# ==========================================================================
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     rep     -   generic OptGuard report;  more  detailed  reports  can  be
#                 retrieved with other functions.
# 
# NOTE: false negatives (nonsmooth problems are not identified as  nonsmooth
#       ones) are possible although unlikely.
# 
#       The reason  is  that  you  need  to  make several evaluations around
#       nonsmoothness  in  order  to  accumulate  enough  information  about
#       function curvature. Say, if you start right from the nonsmooth point,
#       optimizer simply won't get enough data to understand what  is  going
#       wrong before it terminates due to abrupt changes in the  derivative.
#       It is also  possible  that  &quot;unlucky&quot;  step  will  move  us  to  the
#       termination too quickly.
# 
#       Our current approach is to have less than 0.1%  false  negatives  in
#       our test examples  (measured  with  multiple  restarts  from  random
#       points), and to have exactly 0% false positives.
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.minbleicoptguardresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.optguardreport

</div></pre>
<a name='sub_minbleicoptguardsmoothness'></a><h3 class=pageheader><code>minbleicoptguardsmoothness</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  activates/deactivates nonsmoothness monitoring  option  of
# the  OptGuard  integrity  checker. Smoothness  monitor  silently  observes
# solution process and tries to detect ill-posed problems, i.e. ones with:
# a) discontinuous target function (non-C0)
# b) nonsmooth     target function (non-C1)
# 
# Smoothness monitoring does NOT interrupt optimization  even if it suspects
# that your problem is nonsmooth. It just sets corresponding  flags  in  the
# OptGuard report which can be retrieved after optimization is over.
# 
# Smoothness monitoring is a moderate overhead option which often adds  less
# than 1% to the optimizer running time. Thus, you can use it even for large
# scale problems.
# 
# NOTE: OptGuard does  NOT  guarantee  that  it  will  always  detect  C0/C1
#       continuity violations.
# 
#       First, minor errors are hard to  catch - say, a 0.0001 difference in
#       the model values at two sides of the gap may be due to discontinuity
#       of the model - or simply because the model has changed.
# 
#       Second, C1-violations  are  especially  difficult  to  detect  in  a
#       noninvasive way. The optimizer usually  performs  very  short  steps
#       near the nonsmoothness, and differentiation  usually   introduces  a
#       lot of numerical noise.  It  is  hard  to  tell  whether  some  tiny
#       discontinuity in the slope is due to real nonsmoothness or just  due
#       to numerical noise alone.
# 
#       Our top priority was to avoid false positives, so in some rare cases
#       minor errors may went unnoticed (however, in most cases they can  be
#       spotted with restart from different initial point).
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
#     level   -   monitoring level:
#                 * 0 - monitoring is disabled
#                 * 1 - noninvasive low-overhead monitoring; function values
#                       and/or gradients are recorded, but OptGuard does not
#                       try to perform additional evaluations  in  order  to
#                       get more information about suspicious locations.
# 
# === EXPLANATION ==========================================================
# 
# One major source of headache during optimization  is  the  possibility  of
# the coding errors in the target function/constraints (or their gradients).
# Such  errors   most   often   manifest   themselves  as  discontinuity  or
# nonsmoothness of the target/constraints.
# 
# Another frequent situation is when you try to optimize something involving
# lots of min() and max() operations, i.e. nonsmooth target. Although not  a
# coding error, it is nonsmoothness anyway - and smooth  optimizers  usually
# stop right after encountering nonsmoothness, well before reaching solution.
# 
# OptGuard integrity checker helps you to catch such situations: it monitors
# function values/gradients being passed  to  the  optimizer  and  tries  to
# errors. Upon discovering suspicious pair of points it  raises  appropriate
# flag (and allows you to continue optimization). When optimization is done,
# you can study OptGuard result.
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicoptguardsmoothness(state, level)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicoptguardsmoothness(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
          level:      int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbleicrequesttermination'></a><h3 class=pageheader><code>minbleicrequesttermination</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine submits request for termination of running  optimizer.  It
# should be called from user-supplied callback when user decides that it  is
# time to &quot;smoothly&quot; terminate optimization process.  As  result,  optimizer
# stops at point which was &quot;current accepted&quot; when termination  request  was
# submitted and returns error code 8 (successful termination).
# 
# INPUT PARAMETERS:
#     State   -   optimizer structure
# 
# NOTE: after  request  for  termination  optimizer  may   perform   several
#       additional calls to user-supplied callbacks. It does  NOT  guarantee
#       to stop immediately - it just guarantees that these additional calls
#       will be discarded later.
# 
# NOTE: calling this function on optimizer which is NOT running will have no
#       effect.
# 
# NOTE: multiple calls to this function are possible. First call is counted,
#       subsequent calls are silently ignored.
# 
#   -- ALGLIB --
#      Copyright 08.10.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicrequesttermination(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbleicrestartfrom'></a><h3 class=pageheader><code>minbleicrestartfrom</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine restarts algorithm from new point.
# All optimization parameters (including constraints) are left unchanged.
# 
# This  function  allows  to  solve multiple  optimization  problems  (which
# must have  same number of dimensions) without object reallocation penalty.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with MinBLEICCreate call.
#     X       -   new starting point.
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicrestartfrom(state, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbleicresults'></a><h3 class=pageheader><code>minbleicresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# BLEIC results
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     X       -   array[0..N-1], solution
#     Rep     -   optimization report. You should check Rep.TerminationType
#                 in  order  to  distinguish  successful  termination  from
#                 unsuccessful one:
#                 * -8    internal integrity control  detected  infinite or
#                         NAN   values   in   function/gradient.   Abnormal
#                         termination signalled.
#                 * -3   inconsistent constraints. Feasible point is
#                        either nonexistent or too hard to find. Try to
#                        restart optimizer with better initial approximation
#                 *  1   relative function improvement is no more than EpsF.
#                 *  2   scaled step is no more than EpsX.
#                 *  4   scaled gradient norm is no more than EpsG.
#                 *  5   MaxIts steps was taken
#                 *  8   terminated by user who called minbleicrequesttermination().
#                        X contains point which was &quot;current accepted&quot;  when
#                        termination request was submitted.
#                 More information about fields of this  structure  can  be
#                 found in the comments on MinBLEICReport datatype.
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.minbleicresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.minbleicreport

</div></pre>
<a name='sub_minbleicresultsbuf'></a><h3 class=pageheader><code>minbleicresultsbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# BLEIC results
# 
# Buffered implementation of MinBLEICResults() which uses pre-allocated buffer
# to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
# intended to be used in the inner cycles of performance critical algorithms
# where array reallocation penalty is too large to be ignored.
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.minbleicresultsbuf(state, x, rep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
          x:          1D array/list of float
          rep:        class xalglib.minbleicreport
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> rep
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float

</div></pre>
<a name='sub_minbleicsetbc'></a><h3 class=pageheader><code>minbleicsetbc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets boundary constraints for BLEIC optimizer.
# 
# Boundary constraints are inactive by default (after initial creation).
# They are preserved after algorithm restart with MinBLEICRestartFrom().
# 
# NOTE: if you have box-only constraints (no  general  linear  constraints),
#       then MinBC optimizer can be better option. It uses  special,  faster
#       constraint activation method, which performs better on problems with
#       multiple constraints active at the solution.
# 
#       On small-scale problems performance of MinBC is similar to  that  of
#       MinBLEIC, but on large-scale ones (hundreds and thousands of  active
#       constraints) it can be several times faster than MinBLEIC.
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     BndL    -   lower bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 very small number or -INF.
#     BndU    -   upper bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 very large number or +INF.
# 
# NOTE 1: it is possible to specify BndL[i]=BndU[i]. In this case I-th
# variable will be &quot;frozen&quot; at X[i]=BndL[i]=BndU[i].
# 
# NOTE 2: this solver has following useful properties:
# * bound constraints are always satisfied exactly
# * function is evaluated only INSIDE area specified by  bound  constraints,
#   even  when  numerical  differentiation is used (algorithm adjusts  nodes
#   according to boundary constraints)
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicsetbc(state, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
          bndl:       1D array/list of float
          bndu:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbleicsetcond'></a><h3 class=pageheader><code>minbleicsetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping conditions for the optimizer.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     EpsG    -   &gt;=0
#                 The  subroutine  finishes  its  work   if   the  condition
#                 |v|&lt;EpsG is satisfied, where:
#                 * |.| means Euclidian norm
#                 * v - scaled gradient vector, v[i]=g[i]*s[i]
#                 * g - gradient
#                 * s - scaling coefficients set by MinBLEICSetScale()
#     EpsF    -   &gt;=0
#                 The  subroutine  finishes  its work if on k+1-th iteration
#                 the  condition  |F(k+1)-F(k)|&lt;=EpsF*max{|F(k)|,|F(k+1)|,1}
#                 is satisfied.
#     EpsX    -   &gt;=0
#                 The subroutine finishes its work if  on  k+1-th  iteration
#                 the condition |v|&lt;=EpsX is fulfilled, where:
#                 * |.| means Euclidian norm
#                 * v - scaled step vector, v[i]=dx[i]/s[i]
#                 * dx - step vector, dx=X(k+1)-X(k)
#                 * s - scaling coefficients set by MinBLEICSetScale()
#     MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
#                 iterations is unlimited.
# 
# Passing EpsG=0, EpsF=0 and EpsX=0 and MaxIts=0 (simultaneously) will lead
# to automatic stopping criterion selection.
# 
# NOTE: when SetCond() called with non-zero MaxIts, BLEIC solver may perform
#       slightly more than MaxIts iterations. I.e., MaxIts  sets  non-strict
#       limit on iterations count.
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicsetcond(state, epsg, epsf, epsx, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
          epsg:       float
          epsf:       float
          epsx:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbleicsetlc'></a><h3 class=pageheader><code>minbleicsetlc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets linear constraints for BLEIC optimizer.
# 
# Linear constraints are inactive by default (after initial creation).
# They are preserved after algorithm restart with MinBLEICRestartFrom().
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with MinBLEICCreate call.
#     C       -   linear constraints, array[K,N+1].
#                 Each row of C represents one constraint, either equality
#                 or inequality (see below):
#                 * first N elements correspond to coefficients,
#                 * last element corresponds to the right part.
#                 All elements of C (including right part) must be finite.
#     CT      -   type of constraints, array[K]:
#                 * if CT[i]&gt;0, then I-th constraint is C[i,*]*x &gt;= C[i,n]
#                 * if CT[i]=0, then I-th constraint is C[i,*]*x  = C[i,n]
#                 * if CT[i]&lt;0, then I-th constraint is C[i,*]*x &lt;= C[i,n]
#     K       -   number of equality/inequality constraints, K&gt;=0:
#                 * if given, only leading K elements of C/CT are used
#                 * if not given, automatically determined from sizes of C/CT
# 
# NOTE 1: linear (non-bound) constraints are satisfied only approximately:
# * there always exists some minor violation (about Epsilon in magnitude)
#   due to rounding errors
# * numerical differentiation, if used, may  lead  to  function  evaluations
#   outside  of the feasible  area,   because   algorithm  does  NOT  change
#   numerical differentiation formula according to linear constraints.
# If you want constraints to be  satisfied  exactly, try to reformulate your
# problem  in  such  manner  that  all constraints will become boundary ones
# (this kind of constraints is always satisfied exactly, both in  the  final
# solution and in all intermediate points).
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicsetlc(state, c, ct, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicsetlc(state, c, ct)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
          c:          2D array/list of float
          ct:         1D array/list of int
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbleicsetprecdefault'></a><h3 class=pageheader><code>minbleicsetprecdefault</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modification of the preconditioner: preconditioning is turned off.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 13.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicsetprecdefault(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbleicsetprecdiag'></a><h3 class=pageheader><code>minbleicsetprecdiag</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modification  of  the  preconditioner:  diagonal of approximate Hessian is
# used.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     D       -   diagonal of the approximate Hessian, array[0..N-1],
#                 (if larger, only leading N elements are used).
# 
# NOTE 1: D[i] should be positive. Exception will be thrown otherwise.
# 
# NOTE 2: you should pass diagonal of approximate Hessian - NOT ITS INVERSE.
# 
#   -- ALGLIB --
#      Copyright 13.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicsetprecdiag(state, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
          d:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbleicsetprecscale'></a><h3 class=pageheader><code>minbleicsetprecscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modification of the preconditioner: scale-based diagonal preconditioning.
# 
# This preconditioning mode can be useful when you  don't  have  approximate
# diagonal of Hessian, but you know that your  variables  are  badly  scaled
# (for  example,  one  variable is in [1,10], and another in [1000,100000]),
# and most part of the ill-conditioning comes from different scales of vars.
# 
# In this case simple  scale-based  preconditioner,  with H[i] = 1/(s[i]^2),
# can greatly improve convergence.
# 
# IMPRTANT: you should set scale of your variables  with  MinBLEICSetScale()
# call  (before  or after MinBLEICSetPrecScale() call). Without knowledge of
# the scale of your variables scale-based preconditioner will be  just  unit
# matrix.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 13.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicsetprecscale(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbleicsetscale'></a><h3 class=pageheader><code>minbleicsetscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets scaling coefficients for BLEIC optimizer.
# 
# ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
# size and gradient are scaled before comparison with tolerances).  Scale of
# the I-th variable is a translation invariant measure of:
# a) &quot;how large&quot; the variable is
# b) how large the step should be to make significant changes in the function
# 
# Scaling is also used by finite difference variant of the optimizer  - step
# along I-th axis is equal to DiffStep*S[I].
# 
# In  most  optimizers  (and  in  the  BLEIC  too)  scaling is NOT a form of
# preconditioning. It just  affects  stopping  conditions.  You  should  set
# preconditioner  by  separate  call  to  one  of  the  MinBLEICSetPrec...()
# functions.
# 
# There is a special  preconditioning  mode, however,  which  uses   scaling
# coefficients to form diagonal preconditioning matrix. You  can  turn  this
# mode on, if you want.   But  you should understand that scaling is not the
# same thing as preconditioning - these are two different, although  related
# forms of tuning solver.
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     S       -   array[N], non-zero scaling coefficients
#                 S[i] may be negative, sign doesn't matter.
# 
#   -- ALGLIB --
#      Copyright 14.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicsetscale(state, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
          s:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbleicsetstpmax'></a><h3 class=pageheader><code>minbleicsetstpmax</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets maximum step length
# 
# IMPORTANT: this feature is hard to combine with preconditioning. You can't
# set upper limit on step length, when you solve optimization  problem  with
# linear (non-boundary) constraints AND preconditioner turned on.
# 
# When  non-boundary  constraints  are  present,  you  have to either a) use
# preconditioner, or b) use upper limit on step length.  YOU CAN'T USE BOTH!
# In this case algorithm will terminate with appropriate error code.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     StpMax  -   maximum step length, &gt;=0. Set StpMax to 0.0,  if you don't
#                 want to limit step length.
# 
# Use this subroutine when you optimize target function which contains exp()
# or  other  fast  growing  functions,  and optimization algorithm makes too
# large  steps  which  lead   to overflow. This function allows us to reject
# steps  that  are  too  large  (and  therefore  expose  us  to the possible
# overflow) without actually calculating function value at the x+stp*d.
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicsetstpmax(state, stpmax)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
          stpmax:     float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbleicsetxrep'></a><h3 class=pageheader><code>minbleicsetxrep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function turns on/off reporting.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     NeedXRep-   whether iteration reports are needed or not
# 
# If NeedXRep is True, algorithm will call rep() callback function if  it is
# provided to MinBLEICOptimize().
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicsetxrep(state, needxrep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
          needxrep:   bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_mincg></a><h2 class=pageheader><code>mincg</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_mincgcreate' class=toc>mincgcreate</a><br>
<a href='#sub_mincgcreatef' class=toc>mincgcreatef</a><br>
<a href='#sub_mincgoptguardgradient' class=toc>mincgoptguardgradient</a><br>
<a href='#sub_mincgoptguardnonc1test0results' class=toc>mincgoptguardnonc1test0results</a><br>
<a href='#sub_mincgoptguardnonc1test1results' class=toc>mincgoptguardnonc1test1results</a><br>
<a href='#sub_mincgoptguardresults' class=toc>mincgoptguardresults</a><br>
<a href='#sub_mincgoptguardsmoothness' class=toc>mincgoptguardsmoothness</a><br>
<a href='#sub_mincgrequesttermination' class=toc>mincgrequesttermination</a><br>
<a href='#sub_mincgrestartfrom' class=toc>mincgrestartfrom</a><br>
<a href='#sub_mincgresults' class=toc>mincgresults</a><br>
<a href='#sub_mincgresultsbuf' class=toc>mincgresultsbuf</a><br>
<a href='#sub_mincgsetcgtype' class=toc>mincgsetcgtype</a><br>
<a href='#sub_mincgsetcond' class=toc>mincgsetcond</a><br>
<a href='#sub_mincgsetprecdefault' class=toc>mincgsetprecdefault</a><br>
<a href='#sub_mincgsetprecdiag' class=toc>mincgsetprecdiag</a><br>
<a href='#sub_mincgsetprecscale' class=toc>mincgsetprecscale</a><br>
<a href='#sub_mincgsetscale' class=toc>mincgsetscale</a><br>
<a href='#sub_mincgsetstpmax' class=toc>mincgsetstpmax</a><br>
<a href='#sub_mincgsetxrep' class=toc>mincgsetxrep</a><br>
<a href='#sub_mincgsuggeststep' class=toc>mincgsuggeststep</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_mincgcreate'></a><h3 class=pageheader><code>mincgcreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
#         NONLINEAR CONJUGATE GRADIENT METHOD
# 
# DESCRIPTION:
# The subroutine minimizes function F(x) of N arguments by using one of  the
# nonlinear conjugate gradient methods.
# 
# These CG methods are globally convergent (even on non-convex functions) as
# long as grad(f) is Lipschitz continuous in  a  some  neighborhood  of  the
# L = { x : f(x)&lt;=f(x0) }.
# 
# 
# REQUIREMENTS:
# Algorithm will request following information during its operation:
# * function value F and its gradient G (simultaneously) at given point X
# 
# 
# USAGE:
# 1. User initializes algorithm state with MinCGCreate() call
# 2. User tunes solver parameters with MinCGSetCond(), MinCGSetStpMax() and
#    other functions
# 3. User calls MinCGOptimize() function which takes algorithm  state   and
#    pointer (delegate, etc.) to callback function which calculates F/G.
# 4. User calls MinCGResults() to get solution
# 5. Optionally, user may call MinCGRestartFrom() to solve another  problem
#    with same N but another starting point and/or another function.
#    MinCGRestartFrom() allows to reuse already initialized structure.
# 
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;0:
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from size of X
#     X       -   starting point, array[0..N-1].
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 25.03.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.mincgcreate(n, x)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.mincgcreate(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.mincgstate

</div></pre>
<a name='sub_mincgcreatef'></a><h3 class=pageheader><code>mincgcreatef</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# The subroutine is finite difference variant of MinCGCreate(). It uses
# finite differences in order to differentiate target function.
# 
# Description below contains information which is specific to this function
# only. We recommend to read comments on MinCGCreate() in order to get more
# information about creation of CG optimizer.
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;0:
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from size of X
#     X       -   starting point, array[0..N-1].
#     DiffStep-   differentiation step, &gt;0
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# NOTES:
# 1. algorithm uses 4-point central formula for differentiation.
# 2. differentiation step along I-th axis is equal to DiffStep*S[I] where
#    S[] is scaling vector which can be set by MinCGSetScale() call.
# 3. we recommend you to use moderate values of  differentiation  step.  Too
#    large step will result in too large truncation  errors, while too small
#    step will result in too large numerical  errors.  1.0E-6  can  be  good
#    value to start with.
# 4. Numerical  differentiation  is   very   inefficient  -   one   gradient
#    calculation needs 4*N function evaluations. This function will work for
#    any N - either small (1...10), moderate (10...100) or  large  (100...).
#    However, performance penalty will be too severe for any N's except  for
#    small ones.
#    We should also say that code which relies on numerical  differentiation
#    is  less  robust  and  precise.  L-BFGS  needs  exact  gradient values.
#    Imprecise  gradient may slow down  convergence,  especially  on  highly
#    nonlinear problems.
#    Thus  we  recommend to use this function for fast prototyping on small-
#    dimensional problems only, and to implement analytical gradient as soon
#    as possible.
# 
#   -- ALGLIB --
#      Copyright 16.05.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.mincgcreatef(n, x, diffstep)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.mincgcreatef(x, diffstep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          1D array/list of float
          diffstep:   float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.mincgstate

</div></pre>
<a name='sub_mincgoptguardgradient'></a><h3 class=pageheader><code>mincgoptguardgradient</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  activates/deactivates verification  of  the  user-supplied
# analytic gradient.
# 
# Upon  activation  of  this  option  OptGuard  integrity  checker  performs
# numerical differentiation of your target function  at  the  initial  point
# (note: future versions may also perform check  at  the  final  point)  and
# compares numerical gradient with analytic one provided by you.
# 
# If difference is too large, an error flag is set and optimization  session
# continues. After optimization session is over, you can retrieve the report
# which  stores  both  gradients  and  specific  components  highlighted  as
# suspicious by the OptGuard.
# 
# The primary OptGuard report can be retrieved with mincgoptguardresults().
# 
# IMPORTANT: gradient check is a high-overhead option which  will  cost  you
#            about 3*N additional function evaluations. In many cases it may
#            cost as much as the rest of the optimization session.
# 
#            YOU SHOULD NOT USE IT IN THE PRODUCTION CODE UNLESS YOU WANT TO
#            CHECK DERIVATIVES PROVIDED BY SOME THIRD PARTY.
# 
# NOTE: unlike previous incarnation of the gradient checking code,  OptGuard
#       does NOT interrupt optimization even if it discovers bad gradient.
# 
# INPUT PARAMETERS:
#     State       -   structure used to store algorithm state
#     TestStep    -   verification step used for numerical differentiation:
#                     * TestStep=0 turns verification off
#                     * TestStep&gt;0 activates verification
#                     You should carefully choose TestStep. Value  which  is
#                     too large (so large that  function  behavior  is  non-
#                     cubic at this scale) will lead  to  false  alarms. Too
#                     short step will result in rounding  errors  dominating
#                     numerical derivative.
# 
#                     You may use different step for different parameters by
#                     means of setting scale with mincgsetscale().
# 
# === EXPLANATION ==========================================================
# 
# In order to verify gradient algorithm performs following steps:
#   * two trial steps are made to X[i]-TestStep*S[i] and X[i]+TestStep*S[i],
#     where X[i] is i-th component of the initial point and S[i] is a  scale
#     of i-th parameter
#   * F(X) is evaluated at these trial points
#   * we perform one more evaluation in the middle point of the interval
#   * we  build  cubic  model using function values and derivatives at trial
#     points and we compare its prediction with actual value in  the  middle
#     point
# 
#   -- ALGLIB --
#      Copyright 15.06.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mincgoptguardgradient(state, teststep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
          teststep:   float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mincgoptguardnonc1test0results'></a><h3 class=pageheader><code>mincgoptguardnonc1test0results</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Detailed results of the OptGuard integrity check for nonsmoothness test #0
# 
# Nonsmoothness (non-C1) test #0 studies  function  values  (not  gradient!)
# obtained during line searches and monitors  behavior  of  the  directional
# derivative estimate.
# 
# This test is less powerful than test #1, but it does  not  depend  on  the
# gradient values and thus it is more robust against artifacts introduced by
# numerical differentiation.
# 
# Two reports are returned:
# * a &quot;strongest&quot; one, corresponding  to  line   search  which  had  highest
#   value of the nonsmoothness indicator
# * a &quot;longest&quot; one, corresponding to line search which  had  more  function
#   evaluations, and thus is more detailed
# 
# In both cases following fields are returned:
# 
# * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
#   did not notice anything (in the latter cases fields below are empty).
# * x0[], d[] - arrays of length N which store initial point  and  direction
#   for line search (d[] can be normalized, but does not have to)
# * stp[], f[] - arrays of length CNT which store step lengths and  function
#   values at these points; f[i] is evaluated in x0+stp[i]*d.
# * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
#   between steps #stpidxa and #stpidxb (usually we have  stpidxb=stpidxa+3,
#   with  most  likely  position  of  the  violation  between  stpidxa+1 and
#   stpidxa+2.
# 
# ==========================================================================
# = SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -  you  will
# =                   see where C1 continuity is violated.
# ==========================================================================
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     strrep  -   C1 test #0 &quot;strong&quot; report
#     lngrep  -   C1 test #0 &quot;long&quot; report
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   strrep, lngrep = xalglib.mincgoptguardnonc1test0results(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  strrep:     class xalglib.optguardnonc1test0report
          lngrep:     class xalglib.optguardnonc1test0report

</div></pre>
<a name='sub_mincgoptguardnonc1test1results'></a><h3 class=pageheader><code>mincgoptguardnonc1test1results</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Detailed results of the OptGuard integrity check for nonsmoothness test #1
# 
# Nonsmoothness (non-C1)  test  #1  studies  individual  components  of  the
# gradient computed during line search.
# 
# When precise analytic gradient is provided this test is more powerful than
# test #0  which  works  with  function  values  and  ignores  user-provided
# gradient.  However,  test  #0  becomes  more   powerful   when   numerical
# differentiation is employed (in such cases test #1 detects  higher  levels
# of numerical noise and becomes too conservative).
# 
# This test also tells specific components of the gradient which violate  C1
# continuity, which makes it more informative than #0, which just tells that
# continuity is violated.
# 
# Two reports are returned:
# * a &quot;strongest&quot; one, corresponding  to  line   search  which  had  highest
#   value of the nonsmoothness indicator
# * a &quot;longest&quot; one, corresponding to line search which  had  more  function
#   evaluations, and thus is more detailed
# 
# In both cases following fields are returned:
# 
# * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
#   did not notice anything (in the latter cases fields below are empty).
# * vidx - is an index of the variable in [0,N) with nonsmooth derivative
# * x0[], d[] - arrays of length N which store initial point  and  direction
#   for line search (d[] can be normalized, but does not have to)
# * stp[], g[] - arrays of length CNT which store step lengths and  gradient
#   values at these points; g[i] is evaluated in  x0+stp[i]*d  and  contains
#   vidx-th component of the gradient.
# * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
#   between steps #stpidxa and #stpidxb (usually we have  stpidxb=stpidxa+3,
#   with  most  likely  position  of  the  violation  between  stpidxa+1 and
#   stpidxa+2.
# 
# ==========================================================================
# = SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -  you  will
# =                   see where C1 continuity is violated.
# ==========================================================================
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     strrep  -   C1 test #1 &quot;strong&quot; report
#     lngrep  -   C1 test #1 &quot;long&quot; report
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   strrep, lngrep = xalglib.mincgoptguardnonc1test1results(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  strrep:     class xalglib.optguardnonc1test1report
          lngrep:     class xalglib.optguardnonc1test1report

</div></pre>
<a name='sub_mincgoptguardresults'></a><h3 class=pageheader><code>mincgoptguardresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Results of OptGuard integrity check, should be called  after  optimization
# session is over.
# 
# === PRIMARY REPORT =======================================================
# 
# OptGuard performs several checks which are intended to catch common errors
# in the implementation of nonlinear function/gradient:
# * incorrect analytic gradient
# * discontinuous (non-C0) target functions (constraints)
# * nonsmooth     (non-C1) target functions (constraints)
# 
# Each of these checks is activated with appropriate function:
# * mincgoptguardgradient() for gradient verification
# * mincgoptguardsmoothness() for C0/C1 checks
# 
# Following flags are set when these errors are suspected:
# * rep.badgradsuspected, and additionally:
#   * rep.badgradvidx for specific variable (gradient element) suspected
#   * rep.badgradxbase, a point where gradient is tested
#   * rep.badgraduser, user-provided gradient  (stored  as  2D  matrix  with
#     single row in order to make  report  structure  compatible  with  more
#     complex optimizers like MinNLC or MinLM)
#   * rep.badgradnum,   reference    gradient    obtained    via   numerical
#     differentiation (stored as  2D matrix with single row in order to make
#     report structure compatible with more complex optimizers  like  MinNLC
#     or MinLM)
# * rep.nonc0suspected
# * rep.nonc1suspected
# 
# === ADDITIONAL REPORTS/LOGS ==============================================
# 
# Several different tests are performed to catch C0/C1 errors, you can  find
# out specific test signaled error by looking to:
# * rep.nonc0test0positive, for non-C0 test #0
# * rep.nonc1test0positive, for non-C1 test #0
# * rep.nonc1test1positive, for non-C1 test #1
# 
# Additional information (including line search logs)  can  be  obtained  by
# means of:
# * mincgoptguardnonc1test0results()
# * mincgoptguardnonc1test1results()
# which return detailed error reports, specific points where discontinuities
# were found, and so on.
# 
# ==========================================================================
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     rep     -   generic OptGuard report;  more  detailed  reports  can  be
#                 retrieved with other functions.
# 
# NOTE: false negatives (nonsmooth problems are not identified as  nonsmooth
#       ones) are possible although unlikely.
# 
#       The reason  is  that  you  need  to  make several evaluations around
#       nonsmoothness  in  order  to  accumulate  enough  information  about
#       function curvature. Say, if you start right from the nonsmooth point,
#       optimizer simply won't get enough data to understand what  is  going
#       wrong before it terminates due to abrupt changes in the  derivative.
#       It is also  possible  that  &quot;unlucky&quot;  step  will  move  us  to  the
#       termination too quickly.
# 
#       Our current approach is to have less than 0.1%  false  negatives  in
#       our test examples  (measured  with  multiple  restarts  from  random
#       points), and to have exactly 0% false positives.
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.mincgoptguardresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.optguardreport

</div></pre>
<a name='sub_mincgoptguardsmoothness'></a><h3 class=pageheader><code>mincgoptguardsmoothness</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  activates/deactivates nonsmoothness monitoring  option  of
# the  OptGuard  integrity  checker. Smoothness  monitor  silently  observes
# solution process and tries to detect ill-posed problems, i.e. ones with:
# a) discontinuous target function (non-C0)
# b) nonsmooth     target function (non-C1)
# 
# Smoothness monitoring does NOT interrupt optimization  even if it suspects
# that your problem is nonsmooth. It just sets corresponding  flags  in  the
# OptGuard report which can be retrieved after optimization is over.
# 
# Smoothness monitoring is a moderate overhead option which often adds  less
# than 1% to the optimizer running time. Thus, you can use it even for large
# scale problems.
# 
# NOTE: OptGuard does  NOT  guarantee  that  it  will  always  detect  C0/C1
#       continuity violations.
# 
#       First, minor errors are hard to  catch - say, a 0.0001 difference in
#       the model values at two sides of the gap may be due to discontinuity
#       of the model - or simply because the model has changed.
# 
#       Second, C1-violations  are  especially  difficult  to  detect  in  a
#       noninvasive way. The optimizer usually  performs  very  short  steps
#       near the nonsmoothness, and differentiation  usually   introduces  a
#       lot of numerical noise.  It  is  hard  to  tell  whether  some  tiny
#       discontinuity in the slope is due to real nonsmoothness or just  due
#       to numerical noise alone.
# 
#       Our top priority was to avoid false positives, so in some rare cases
#       minor errors may went unnoticed (however, in most cases they can  be
#       spotted with restart from different initial point).
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
#     level   -   monitoring level:
#                 * 0 - monitoring is disabled
#                 * 1 - noninvasive low-overhead monitoring; function values
#                       and/or gradients are recorded, but OptGuard does not
#                       try to perform additional evaluations  in  order  to
#                       get more information about suspicious locations.
# 
# === EXPLANATION ==========================================================
# 
# One major source of headache during optimization  is  the  possibility  of
# the coding errors in the target function/constraints (or their gradients).
# Such  errors   most   often   manifest   themselves  as  discontinuity  or
# nonsmoothness of the target/constraints.
# 
# Another frequent situation is when you try to optimize something involving
# lots of min() and max() operations, i.e. nonsmooth target. Although not  a
# coding error, it is nonsmoothness anyway - and smooth  optimizers  usually
# stop right after encountering nonsmoothness, well before reaching solution.
# 
# OptGuard integrity checker helps you to catch such situations: it monitors
# function values/gradients being passed  to  the  optimizer  and  tries  to
# errors. Upon discovering suspicious pair of points it  raises  appropriate
# flag (and allows you to continue optimization). When optimization is done,
# you can study OptGuard result.
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mincgoptguardsmoothness(state, level)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mincgoptguardsmoothness(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
          level:      int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mincgrequesttermination'></a><h3 class=pageheader><code>mincgrequesttermination</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine submits request for termination of running  optimizer.  It
# should be called from user-supplied callback when user decides that it  is
# time to &quot;smoothly&quot; terminate optimization process.  As  result,  optimizer
# stops at point which was &quot;current accepted&quot; when termination  request  was
# submitted and returns error code 8 (successful termination).
# 
# INPUT PARAMETERS:
#     State   -   optimizer structure
# 
# NOTE: after  request  for  termination  optimizer  may   perform   several
#       additional calls to user-supplied callbacks. It does  NOT  guarantee
#       to stop immediately - it just guarantees that these additional calls
#       will be discarded later.
# 
# NOTE: calling this function on optimizer which is NOT running will have no
#       effect.
# 
# NOTE: multiple calls to this function are possible. First call is counted,
#       subsequent calls are silently ignored.
# 
#   -- ALGLIB --
#      Copyright 08.10.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mincgrequesttermination(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mincgrestartfrom'></a><h3 class=pageheader><code>mincgrestartfrom</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  subroutine  restarts  CG  algorithm from new point. All optimization
# parameters are left unchanged.
# 
# This  function  allows  to  solve multiple  optimization  problems  (which
# must have same number of dimensions) without object reallocation penalty.
# 
# INPUT PARAMETERS:
#     State   -   structure used to store algorithm state.
#     X       -   new starting point.
# 
#   -- ALGLIB --
#      Copyright 30.07.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mincgrestartfrom(state, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mincgresults'></a><h3 class=pageheader><code>mincgresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Conjugate gradient results
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     X       -   array[0..N-1], solution
#     Rep     -   optimization report:
#                 * Rep.TerminationType completetion code:
#                     * -8    internal integrity control  detected  infinite
#                             or NAN values in  function/gradient.  Abnormal
#                             termination signalled.
#                     * -7    gradient verification failed.
#                             See MinCGSetGradientCheck() for more information.
#                     *  1    relative function improvement is no more than
#                             EpsF.
#                     *  2    relative step is no more than EpsX.
#                     *  4    gradient norm is no more than EpsG
#                     *  5    MaxIts steps was taken
#                     *  7    stopping conditions are too stringent,
#                             further improvement is impossible,
#                             we return best X found so far
#                     *  8    terminated by user
#                 * Rep.IterationsCount contains iterations count
#                 * NFEV countains number of function calculations
# 
#   -- ALGLIB --
#      Copyright 20.04.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.mincgresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.mincgreport

</div></pre>
<a name='sub_mincgresultsbuf'></a><h3 class=pageheader><code>mincgresultsbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Conjugate gradient results
# 
# Buffered implementation of MinCGResults(), which uses pre-allocated buffer
# to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
# intended to be used in the inner cycles of performance critical algorithms
# where array reallocation penalty is too large to be ignored.
# 
#   -- ALGLIB --
#      Copyright 20.04.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.mincgresultsbuf(state, x, rep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
          x:          1D array/list of float
          rep:        class xalglib.mincgreport
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> rep
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float

</div></pre>
<a name='sub_mincgsetcgtype'></a><h3 class=pageheader><code>mincgsetcgtype</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets CG algorithm.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     CGType  -   algorithm type:
#                 * -1    automatic selection of the best algorithm
#                 * 0     DY (Dai and Yuan) algorithm
#                 * 1     Hybrid DY-HS algorithm
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mincgsetcgtype(state, cgtype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
          cgtype:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mincgsetcond'></a><h3 class=pageheader><code>mincgsetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping conditions for CG optimization algorithm.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     EpsG    -   &gt;=0
#                 The  subroutine  finishes  its  work   if   the  condition
#                 |v|&lt;EpsG is satisfied, where:
#                 * |.| means Euclidian norm
#                 * v - scaled gradient vector, v[i]=g[i]*s[i]
#                 * g - gradient
#                 * s - scaling coefficients set by MinCGSetScale()
#     EpsF    -   &gt;=0
#                 The  subroutine  finishes  its work if on k+1-th iteration
#                 the  condition  |F(k+1)-F(k)|&lt;=EpsF*max{|F(k)|,|F(k+1)|,1}
#                 is satisfied.
#     EpsX    -   &gt;=0
#                 The subroutine finishes its work if  on  k+1-th  iteration
#                 the condition |v|&lt;=EpsX is fulfilled, where:
#                 * |.| means Euclidian norm
#                 * v - scaled step vector, v[i]=dx[i]/s[i]
#                 * dx - ste pvector, dx=X(k+1)-X(k)
#                 * s - scaling coefficients set by MinCGSetScale()
#     MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
#                 iterations is unlimited.
# 
# Passing EpsG=0, EpsF=0, EpsX=0 and MaxIts=0 (simultaneously) will lead to
# automatic stopping criterion selection (small EpsX).
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mincgsetcond(state, epsg, epsf, epsx, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
          epsg:       float
          epsf:       float
          epsx:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mincgsetprecdefault'></a><h3 class=pageheader><code>mincgsetprecdefault</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modification of the preconditioner: preconditioning is turned off.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# NOTE:  you  can  change  preconditioner  &quot;on  the  fly&quot;,  during algorithm
# iterations.
# 
#   -- ALGLIB --
#      Copyright 13.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mincgsetprecdefault(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mincgsetprecdiag'></a><h3 class=pageheader><code>mincgsetprecdiag</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modification  of  the  preconditioner:  diagonal of approximate Hessian is
# used.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     D       -   diagonal of the approximate Hessian, array[0..N-1],
#                 (if larger, only leading N elements are used).
# 
# NOTE:  you  can  change  preconditioner  &quot;on  the  fly&quot;,  during algorithm
# iterations.
# 
# NOTE 2: D[i] should be positive. Exception will be thrown otherwise.
# 
# NOTE 3: you should pass diagonal of approximate Hessian - NOT ITS INVERSE.
# 
#   -- ALGLIB --
#      Copyright 13.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mincgsetprecdiag(state, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
          d:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mincgsetprecscale'></a><h3 class=pageheader><code>mincgsetprecscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modification of the preconditioner: scale-based diagonal preconditioning.
# 
# This preconditioning mode can be useful when you  don't  have  approximate
# diagonal of Hessian, but you know that your  variables  are  badly  scaled
# (for  example,  one  variable is in [1,10], and another in [1000,100000]),
# and most part of the ill-conditioning comes from different scales of vars.
# 
# In this case simple  scale-based  preconditioner,  with H[i] = 1/(s[i]^2),
# can greatly improve convergence.
# 
# IMPRTANT: you should set scale of your variables with MinCGSetScale() call
# (before or after MinCGSetPrecScale() call). Without knowledge of the scale
# of your variables scale-based preconditioner will be just unit matrix.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# NOTE:  you  can  change  preconditioner  &quot;on  the  fly&quot;,  during algorithm
# iterations.
# 
#   -- ALGLIB --
#      Copyright 13.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mincgsetprecscale(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mincgsetscale'></a><h3 class=pageheader><code>mincgsetscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets scaling coefficients for CG optimizer.
# 
# ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
# size and gradient are scaled before comparison with tolerances).  Scale of
# the I-th variable is a translation invariant measure of:
# a) &quot;how large&quot; the variable is
# b) how large the step should be to make significant changes in the function
# 
# Scaling is also used by finite difference variant of CG optimizer  -  step
# along I-th axis is equal to DiffStep*S[I].
# 
# In   most   optimizers  (and  in  the  CG  too)  scaling is NOT a form  of
# preconditioning. It just  affects  stopping  conditions.  You  should  set
# preconditioner by separate call to one of the MinCGSetPrec...() functions.
# 
# There  is  special  preconditioning  mode, however,  which  uses   scaling
# coefficients to form diagonal preconditioning matrix. You  can  turn  this
# mode on, if you want.   But  you should understand that scaling is not the
# same thing as preconditioning - these are two different, although  related
# forms of tuning solver.
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     S       -   array[N], non-zero scaling coefficients
#                 S[i] may be negative, sign doesn't matter.
# 
#   -- ALGLIB --
#      Copyright 14.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mincgsetscale(state, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
          s:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mincgsetstpmax'></a><h3 class=pageheader><code>mincgsetstpmax</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets maximum step length
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     StpMax  -   maximum step length, &gt;=0. Set StpMax to 0.0,  if you don't
#                 want to limit step length.
# 
# Use this subroutine when you optimize target function which contains exp()
# or  other  fast  growing  functions,  and optimization algorithm makes too
# large  steps  which  leads  to overflow. This function allows us to reject
# steps  that  are  too  large  (and  therefore  expose  us  to the possible
# overflow) without actually calculating function value at the x+stp*d.
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mincgsetstpmax(state, stpmax)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
          stpmax:     float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mincgsetxrep'></a><h3 class=pageheader><code>mincgsetxrep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function turns on/off reporting.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     NeedXRep-   whether iteration reports are needed or not
# 
# If NeedXRep is True, algorithm will call rep() callback function if  it is
# provided to MinCGOptimize().
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mincgsetxrep(state, needxrep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
          needxrep:   bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mincgsuggeststep'></a><h3 class=pageheader><code>mincgsuggeststep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function allows to suggest initial step length to the CG algorithm.
# 
# Suggested  step  length  is used as starting point for the line search. It
# can be useful when you have  badly  scaled  problem,  i.e.  when  ||grad||
# (which is used as initial estimate for the first step) is many  orders  of
# magnitude different from the desired step.
# 
# Line search  may  fail  on  such problems without good estimate of initial
# step length. Imagine, for example, problem with ||grad||=10^50 and desired
# step equal to 0.1 Line  search function will use 10^50  as  initial  step,
# then  it  will  decrease step length by 2 (up to 20 attempts) and will get
# 10^44, which is still too large.
# 
# This function allows us to tell than line search should  be  started  from
# some moderate step length, like 1.0, so algorithm will be able  to  detect
# desired step length in a several searches.
# 
# Default behavior (when no step is suggested) is to use preconditioner,  if
# it is available, to generate initial estimate of step length.
# 
# This function influences only first iteration of algorithm. It  should  be
# called between MinCGCreate/MinCGRestartFrom() call and MinCGOptimize call.
# Suggested step is ignored if you have preconditioner.
# 
# INPUT PARAMETERS:
#     State   -   structure used to store algorithm state.
#     Stp     -   initial estimate of the step length.
#                 Can be zero (no estimate).
# 
#   -- ALGLIB --
#      Copyright 30.07.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mincgsuggeststep(state, stp)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mincgstate
          stp:        float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_mincomp></a><h2 class=pageheader><code>mincomp</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_minasacreate' class=toc>minasacreate</a><br>
<a href='#sub_minasarestartfrom' class=toc>minasarestartfrom</a><br>
<a href='#sub_minasaresults' class=toc>minasaresults</a><br>
<a href='#sub_minasaresultsbuf' class=toc>minasaresultsbuf</a><br>
<a href='#sub_minasasetalgorithm' class=toc>minasasetalgorithm</a><br>
<a href='#sub_minasasetcond' class=toc>minasasetcond</a><br>
<a href='#sub_minasasetstpmax' class=toc>minasasetstpmax</a><br>
<a href='#sub_minasasetxrep' class=toc>minasasetxrep</a><br>
<a href='#sub_minbleicsetbarrierdecay' class=toc>minbleicsetbarrierdecay</a><br>
<a href='#sub_minbleicsetbarrierwidth' class=toc>minbleicsetbarrierwidth</a><br>
<a href='#sub_minlbfgssetcholeskypreconditioner' class=toc>minlbfgssetcholeskypreconditioner</a><br>
<a href='#sub_minlbfgssetdefaultpreconditioner' class=toc>minlbfgssetdefaultpreconditioner</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_minasacreate'></a><h3 class=pageheader><code>minasacreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Obsolete optimization algorithm.
# Was replaced by MinBLEIC subpackage.
# 
#   -- ALGLIB --
#      Copyright 25.03.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minasacreate(n, x, bndl, bndu)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minasacreate(x, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          1D array/list of float
          bndl:       1D array/list of float
          bndu:       1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minasastate

</div></pre>
<a name='sub_minasarestartfrom'></a><h3 class=pageheader><code>minasarestartfrom</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Obsolete optimization algorithm.
# Was replaced by MinBLEIC subpackage.
# 
#   -- ALGLIB --
#      Copyright 30.07.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minasarestartfrom(state, x, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minasastate
          x:          1D array/list of float
          bndl:       1D array/list of float
          bndu:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minasaresults'></a><h3 class=pageheader><code>minasaresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Obsolete optimization algorithm.
# Was replaced by MinBLEIC subpackage.
# 
#   -- ALGLIB --
#      Copyright 20.03.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.minasaresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minasastate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.minasareport

</div></pre>
<a name='sub_minasaresultsbuf'></a><h3 class=pageheader><code>minasaresultsbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Obsolete optimization algorithm.
# Was replaced by MinBLEIC subpackage.
# 
#   -- ALGLIB --
#      Copyright 20.03.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.minasaresultsbuf(state, x, rep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minasastate
          x:          1D array/list of float
          rep:        class xalglib.minasareport
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> rep
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float

</div></pre>
<a name='sub_minasasetalgorithm'></a><h3 class=pageheader><code>minasasetalgorithm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Obsolete optimization algorithm.
# Was replaced by MinBLEIC subpackage.
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minasasetalgorithm(state, algotype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minasastate
          algotype:   int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minasasetcond'></a><h3 class=pageheader><code>minasasetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Obsolete optimization algorithm.
# Was replaced by MinBLEIC subpackage.
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minasasetcond(state, epsg, epsf, epsx, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minasastate
          epsg:       float
          epsf:       float
          epsx:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minasasetstpmax'></a><h3 class=pageheader><code>minasasetstpmax</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Obsolete optimization algorithm.
# Was replaced by MinBLEIC subpackage.
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minasasetstpmax(state, stpmax)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minasastate
          stpmax:     float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minasasetxrep'></a><h3 class=pageheader><code>minasasetxrep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Obsolete optimization algorithm.
# Was replaced by MinBLEIC subpackage.
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minasasetxrep(state, needxrep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minasastate
          needxrep:   bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbleicsetbarrierdecay'></a><h3 class=pageheader><code>minbleicsetbarrierdecay</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is obsolete function which was used by previous version of the  BLEIC
# optimizer. It does nothing in the current version of BLEIC.
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicsetbarrierdecay(state, mudecay)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
          mudecay:    float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minbleicsetbarrierwidth'></a><h3 class=pageheader><code>minbleicsetbarrierwidth</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is obsolete function which was used by previous version of the  BLEIC
# optimizer. It does nothing in the current version of BLEIC.
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minbleicsetbarrierwidth(state, mu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minbleicstate
          mu:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlbfgssetcholeskypreconditioner'></a><h3 class=pageheader><code>minlbfgssetcholeskypreconditioner</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Obsolete function, use MinLBFGSSetCholeskyPreconditioner() instead.
# 
#   -- ALGLIB --
#      Copyright 13.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlbfgssetcholeskypreconditioner(state, p, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
          p:          2D array/list of float
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlbfgssetdefaultpreconditioner'></a><h3 class=pageheader><code>minlbfgssetdefaultpreconditioner</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Obsolete function, use MinLBFGSSetPrecDefault() instead.
# 
#   -- ALGLIB --
#      Copyright 13.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlbfgssetdefaultpreconditioner(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_mindf></a><h2 class=pageheader><code>mindf</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_mindfcreate' class=toc>mindfcreate</a><br>
<a href='#sub_mindfrequesttermination' class=toc>mindfrequesttermination</a><br>
<a href='#sub_mindfresults' class=toc>mindfresults</a><br>
<a href='#sub_mindfresultsbuf' class=toc>mindfresultsbuf</a><br>
<a href='#sub_mindfsetalgogdemo' class=toc>mindfsetalgogdemo</a><br>
<a href='#sub_mindfsetalgogdemofixed' class=toc>mindfsetalgogdemofixed</a><br>
<a href='#sub_mindfsetbc' class=toc>mindfsetbc</a><br>
<a href='#sub_mindfsetcondf' class=toc>mindfsetcondf</a><br>
<a href='#sub_mindfsetcondfx' class=toc>mindfsetcondfx</a><br>
<a href='#sub_mindfsetgdemopenalty' class=toc>mindfsetgdemopenalty</a><br>
<a href='#sub_mindfsetgdemoprofilequick' class=toc>mindfsetgdemoprofilequick</a><br>
<a href='#sub_mindfsetgdemoprofilerobust' class=toc>mindfsetgdemoprofilerobust</a><br>
<a href='#sub_mindfsetlc2dense' class=toc>mindfsetlc2dense</a><br>
<a href='#sub_mindfsetnlc2' class=toc>mindfsetnlc2</a><br>
<a href='#sub_mindfsetscale' class=toc>mindfsetscale</a><br>
<a href='#sub_mindfsetseed' class=toc>mindfsetseed</a><br>
<a href='#sub_mindfsetxrep' class=toc>mindfsetxrep</a><br>
<a href='#sub_mindfusetimers' class=toc>mindfusetimers</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_mindfcreate'></a><h3 class=pageheader><code>mindfcreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
#                           GLOBAL OPTIMIZATION
#                SUBJECT TO BOX/LINEAR/NONLINEAR CONSTRAINTS
# 
# The  subroutine  minimizes  function   F(x)  of N arguments subject to any
# combination of:
# * bound constraints
# * linear inequality constraints
# * linear equality constraints
# * nonlinear generalized inequality constraints Li&lt;=Ci(x)&lt;=Ui, with one  of
#   Li/Ui possibly being infinite
# 
# REQUIREMENTS:
# * F() and C()  do  NOT  have  to be differentiable, locally Lipschitz   or
#   continuous. Most solvers in this subpackage can deal with  nonsmoothness
#   or minor discontinuities, although obviously smoother problems  are  the
#   most easy ones.
# * generally, F() and C() must be computable at any point which is feasible
#   subject to box constraints
# 
# USAGE:
# 
# 1. User  initializes  algorithm  state   with   mindfcreate()   call   and
#    chooses specific solver to be used. There is some solver which is  used
#    by default, with default settings, but  you  should  NOT  rely  on  the
#    default choice. It may change in the future releases of ALGLIB  without
#    notice, and no one can guarantee that the new solver will be  able   to
#    solve your problem with default settings.
# 
# 2. User adds boundary and/or linear and/or nonlinear constraints by  means
#    of calling one of the following functions:
#    a) mindfsetbc() for boundary constraints
#    b) mindfsetlc2dense() for linear constraints
#    c) mindfsetnlc2() for nonlinear constraints
#    You may combine (a), (b) and (c) in one optimization problem.
# 
# 3. User sets scale of the variables with mindfsetscale() function.  It  is
#    VERY important to set  variable  scales  because  many  derivative-free
#    algorithms refuse to work when variables are badly scaled.
#    Scaling  helps  to seed initial  population,  control  convergence  and
#    enforce penalties for constraint violation.
# 
# 4. Finally, user calls mindfoptimize()  function which takes algorithm
#    state and pointer (delegate, etc) to callback function which calculates
#    F and G.
# 
# 5. User calls mindfresults() to get a solution
# 
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;0:
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from  size  of  X
#     X       -   starting point, array[N]. Some solvers can utilize  a good
#                 initial point to seed computations.
# 
#                 As of ALGLIB 4.04, the initial point is:
#                 * used by GDEMO
# 
#                 If the chosen solver does not need initial point, one  can
#                 supply zeros.
# 
# OUTPUT PARAMETERS:
#     State   -   structure stores algorithm state
# 
# 
# IMPORTANT: the  MINDF  optimizer   supports   parallel   model  evaluation
#            ('callback  parallelism'). This feature, which  is  present  in
#            commercial ALGLIB editions, greatly accelerates algorithms like
#            differential evolution which usually issue  batch  requests  to
#            user callbacks which can be efficiently parallelized.
# 
#            Callback parallelism  is  usually  beneficial  when  the  batch
#            evalution requires more than several milliseconds.
# 
#            See ALGLIB Reference Manual, 'Working with commercial  version'
#            section,  and  comments  on  mindfoptimize()  function for more
#            information.
# 
#   -- ALGLIB --
#      Copyright 24.07.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.mindfcreate(n, x)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.mindfcreate(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.mindfstate

</div></pre>
<a name='sub_mindfrequesttermination'></a><h3 class=pageheader><code>mindfrequesttermination</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine submits request for termination of a running optimizer. It
# should be called from a user-supplied callback when user decides  that  it
# is time to &quot;smoothly&quot; terminate optimization process.  As  a  result,  the
# optimizer  stops  at  the  point  which  was  &quot;current  accepted&quot; when the
# termination request was submitted and returns  error  code  8  (successful
# termination).
# 
# INPUT PARAMETERS:
#     State   -   optimizer structure
# 
# NOTE: after  request  for  termination  optimizer  may   perform   several
#       additional calls to user-supplied callbacks. It does  NOT  guarantee
#       to stop immediately - it just guarantees that these additional calls
#       will be discarded later.
# 
# NOTE: calling this function on an optimizer which is NOT running will have
#       no effect.
# 
# NOTE: multiple calls to this function are possible. First call is counted,
#       subsequent calls are silently ignored.
# 
#   -- ALGLIB --
#      Copyright 25.07.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfrequesttermination(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mindfstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mindfresults'></a><h3 class=pageheader><code>mindfresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# MinDF results
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     X       -   array[0..N-1], solution
#     Rep     -   optimization report:
# 
#                 rep.f stores objective value at the solution
# 
#                 You  should     check  rep.terminationtype  in   order  to
#                 distinguish successful termination from unsuccessful one:
#                 * -8   internal integrity control  detected  infinite  or
#                        NAN   values   in   function/gradient.    Abnormal
#                        termination signalled.
#                 * -3   box constraints are inconsistent
#                 * -1   inconsistent parameters were passed:
#                        * penalty parameter is zero, but we have nonlinear
#                          constraints set by MinDFsetnlc2()
#                 *  1   successful termination according to a solver-specific
#                        set of conditions
#                 *  8   User requested termination via minnsrequesttermination()
# 
#                 If you activated timers  with  mindfusetimers(),  you  can
#                 also find out how much time was spent in various code parts:
#                 * rep.timetotal    - for a total time in seconds
#                 * rep.timesolver   - for a time spent in the solver itself
#                 * rep.timecallback - for a time spent in user callbacks
#                 See comments on mindfreport structure for more information
#                 about timers and their accuracy.
# 
#   -- ALGLIB --
#      Copyright 25.07.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.mindfresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mindfstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.mindfreport

</div></pre>
<a name='sub_mindfresultsbuf'></a><h3 class=pageheader><code>mindfresultsbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 
# Buffered implementation of MinDFresults() which uses pre-allocated buffer
# to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
# intended to be used in the inner cycles of performance critical algorithms
# where array reallocation penalty is too large to be ignored.
# 
#   -- ALGLIB --
#      Copyright 25.07.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.mindfresultsbuf(state, x, rep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mindfstate
          x:          1D array/list of float
          rep:        class xalglib.mindfreport
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> rep
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float

</div></pre>
<a name='sub_mindfsetalgogdemo'></a><h3 class=pageheader><code>mindfsetalgogdemo</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine sets optimization algorithm to the differential  evolution
# solver GDEMO (Generalized Differential Evolution Multiobjective)  with  an
# automatic parameters selection.
# 
# NOTE: a version with manually tuned parameters can be activated by calling
#       the mindfsetalgogdemofixed() function.
# 
# The primary stopping condition for the solver is to stop after the specified
# number of iterations. You can also specify  additional  criteria  to  stop
# early:
# * stop when subpopulation target values (2N+1 best individuals) are within
#   EPS from the best one so far (function values seem to converge)
# * stop when both subpopulation target values  AND  subpopulation  variable
#   values are within EPS from the best one so far
# 
# The first condition is specified with mindfsetcondf(), the second  one  is
# activated with mindfsetcondfx().
# 
# Both conditions are heuristics which  may fail. Being 'within EPS from the
# best value so far'  in  practice  means  that  we  are  somewhere   within
# [0.1EPS,10EPS] from the true  solution;  however,  on  difficult  problems
# this condition may fire too early.
# 
# Imposing an additional requirement that variable values have clustered  too
# may prevent us from premature  stopping. However, on multi-extremal and/or
# noisy problems too many individuals may be trapped away from the  optimum,
# preventing this condition from activation.
# 
# ALGORITHM PROPERTIES:
# 
# * the solver uses a variant of  the  adaptive  parameter  tuning  strategy
#   called 'Success-History  Based  Parameter  Adaptation  for  Differential
#   Evolution Ensemble' (SHADE) by Ryoji Tanabe and Alex  Fukunaga.  You  do
#   not have to specify crossover probability and differential weight,   the
#   solver will automatically choose the most appropriate strategy.
# 
# * the solver can handle box, linear,  nonlinear  constraints.  Linear  and
#   nonlinear constraints are  handled  by  means  of an L1/L2  penalty. The
#   solver does not violate box constraints at any point,  but  may  violate
#   linear and nonlinear ones. Penalty coefficient can be changed with   the
#   mindfsetgdemopenalty() function.
# 
# * the solver heavily depends on variable scales being available (specified
#   by means of mindfsetscale() call) and on box constraints with both lower
#   and upper bounds being available which are used to determine the  search
#   region. It will work without box constraints  and  without  scales,  but
#   results are likely to be suboptimal.
# 
# * the solver is SIMD-optimized  and  parallelized  (in  commercial  ALGLIB
#   editions), with nearly linear scalability of parallel processing.
# 
# * this solver is intended for finding solutions  with up to several digits
#   of precision at best. Its primary purpose  is  to  find  at  least  some
#   solution to an otherwise intractable problem.
# 
# IMPORTANT: derivative-free optimization is inherently less robust than the
#            smooth nonlinear programming, especially when nonsmoothness and
#            discontinuities are present.
# 
#            Derivative-free  algorithms  have  less  convergence guarantees
#            than their smooth  counterparts.  It  is  considered  a  normal
#            (although, obviously, undesirable) situation when a derivative-
#            -free algorithm fails to converge with desired precision. Having
#            2 digits of accurasy is already a  good  result,  on  difficult
#            problems (high numerical noise, discontinuities) you  may  have
#            even less than that.
# 
# INPUT PARAMETERS:
#     State       -   solver
#     EpochsCnt   -   iterations count, &gt;0.  Usually   the  algorithm  needs
#                     hundreds of iterations to converge.
#     PopSize     -   population  size,  &gt;=0.  Zero  value  means  that  the
#                     default value (which is 10*N in the  current  version)
#                     will be chosen. Good values are  in  5*N...20*N,  with
#                     the smaller values being recommended for easy problems
#                     and the larger  values  for  difficult  multi-extremal
#                     and/or noisy tasks.
# 
#   -- ALGLIB --
#      Copyright 25.07.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfsetalgogdemo(state, epochscnt, popsize)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfsetalgogdemo(state, epochscnt)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mindfstate
          epochscnt:  int
          popsize:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mindfsetalgogdemofixed'></a><h3 class=pageheader><code>mindfsetalgogdemofixed</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine sets optimization algorithm to the differential  evolution
# solver GDEMO (Generalized Differential Evolution Multiobjective)  with the
# manual parameters selection.
# 
# Unlike DE with an automatic parameters selection  this  function  requires
# user to manually specify  algorithm  parameters. In the general  case  the
# full-auto GDEMO is better. However, it has to spend some time finding  out
# properties of a problem being solved; furthermore, it is  not  allowed  to
# try potentially dangerous values of  parameters  that  lead  to  premature
# stopping. Manually tuning the solver to the specific problem at  hand  can
# get 2x-3x better running time.
# 
# Aside from that, the algorithm is fully equivalent to automatic GDEMO, and
# we   recommend  you  reading  comments  on  mindfsetalgogdemo()  for  more
# information about algorithm properties and stopping criteria.
# 
# INPUT PARAMETERS:
#     State       -   solver
#     EpochsCnt   -   iterations count, &gt;0.  Usually   the  algorithm  needs
#                     hundreds of iterations to converge.
#     Strategy    -   specific DE strategy to use:
#                     * 0 for DE/rand/1
#                     * 1 for DE/best/2
#                     * 2 for DE/current-to-best/1
#     CrossoverProb-  crossover probability, 0&lt;CrossoverProb&lt;1
#     DifferentialWeight- weight, 0&lt;DifferentialWeight&lt;2
#     PopSize     -   population  size,  &gt;=0.  Zero  value  means  that  the
#                     default value (which is 10*N in the  current  version)
#                     will be chosen. Good values are  in  5*N...20*N,  with
#                     the smaller values being recommended for easy problems
#                     and the larger  values  for  difficult  multi-extremal
#                     and/or noisy tasks.
# 
#   -- ALGLIB --
#      Copyright 25.07.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfsetalgogdemofixed(state, epochscnt, strategy, crossoverprob, differentialweight, popsize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mindfstate
          epochscnt:  int
          strategy:   int
          crossoverprob: float
          differentialweight: float
          popsize:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mindfsetbc'></a><h3 class=pageheader><code>mindfsetbc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets box constraints.
# 
# Box constraints are inactive by default (after initial creation).
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     BndL    -   lower bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 very small number or -INF.
#     BndU    -   upper bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 very large number or +INF.
# 
#   -- ALGLIB --
#      Copyright 24.07.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfsetbc(state, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mindfstate
          bndl:       1D array/list of float
          bndu:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mindfsetcondf'></a><h3 class=pageheader><code>mindfsetcondf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping condition for the optimizer: function   values
# has converged to a neighborhood whose size is proportional to epsF.
# 
# Most derivarive-free solvers are heuristics, so the code used to implement
# this stopping condition is an heuristic too. Usually 'proportional to EPS'
# means that we are somewhere between Eps/10...Eps*10 away from the solution.
# However, there are no warranties that the solver  has  actually  converged
# to something, although in practice it works well.
# 
# The  specific  meaning  of  'converging'  is  algorithm-dependent.  It  is
# possible that some future ALGLIB optimizers will  ignore  this  condition,
# see comments on specific solvers for more info. This  condition  does  not
# work for multi-objective problems.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     EpsF    -   &gt;=0:
#                 * zero value means no condition for F
#                 * EpsF&gt;0 means stopping when the solver converged with
#                   an error estimate less than EpsF*max(|F|,1)
# 
#   -- ALGLIB --
#      Copyright 23.04.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfsetcondf(state, epsf)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mindfstate
          epsf:       float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mindfsetcondfx'></a><h3 class=pageheader><code>mindfsetcondfx</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping conditions for the optimizer.
# 
# This function sets a  combined   stopping  condition:  stopping  when  two
# criteria are met simultaneously:
# * function   values   has  converged  to  a  neighborhood  whose  size  is
#   proportional to epsF
# * variable   values   has  converged  to  a  neighborhood  whose  size  is
#   proportional to epsX
# It is possible to use only one condition by setting another EPS to zero.
# 
# Most derivarive-free solvers are heuristics, so the code used to implement
# this stopping condition is an heuristic too. Usually 'proportional to EPS'
# means that we are somewhere between Eps/10...Eps*10 away from the solution.
# However, there are no warranties that the solver  has  actually  converged
# to something, although in practice it works well.
# 
# The  specific  meaning  of  'converging'  is  algorithm-dependent.  It  is
# possible that some future ALGLIB optimizers will  ignore  this  condition,
# see comments on specific solvers for more info. This  condition  does  not
# work for multi-objective problems.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     EpsF    -   &gt;=0:
#                 * zero value means no condition for F
#                 * EpsF&gt;0 means stopping when the solver converged with
#                   an error estimate less than EpsF*max(|F|,1)
#     EpsX    -   &gt;=0:
#                 * zero value means no condition for X
#                 * EpsX&gt;0 means stopping when the solver converged with
#                   error in I-th variable less than EpsX*S[i], where S[i]
#                   is a variable scale
# 
#   -- ALGLIB --
#      Copyright 23.04.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfsetcondfx(state, epsf, epsx)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mindfstate
          epsf:       float
          epsx:       float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mindfsetgdemopenalty'></a><h3 class=pageheader><code>mindfsetgdemopenalty</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine tells GDEMO differential  evolution  optimizer  to  handle
# linear/nonlinear constraints by an L1/L2 penalty function.
# 
# IMPORTANT: this function does NOT change the  optimization  algorithm.  If
#            want to activate differential evolution solver, you still  have
#            to call a proper mindfsetalgo???() function.
# 
# INPUT PARAMETERS:
#     State       -   solver
#     Rho1, Rho2  -   penalty parameters for constraint violations:
#                     * Rho1 is a multiplier for L1 penalty
#                     * Rho2 is a multiplier for L2 penalty
#                     * Rho1,Rho2&gt;=0
#                     * having both of them at zero means that some  default
#                       value will be chosen.
#                     Ignored for problems with box-only constraints.
# 
#                     L1 penalty is usually better at enforcing constraints,
#                     but leads to slower convergence than L2 penalty. It is
#                     possible to combine both kinds of penalties together.
# 
#                     There is a compromise between constraint  satisfaction
#                     and  optimality:  high  values  of   Rho   mean   that
#                     constraints are satisfied with high accuracy  but that
#                     the target may  be  underoptimized  due  to  numerical
#                     difficulties.  Small  values  of  Rho  mean  that  the
#                     solution may  grossly  violate  constraints.  Choosing
#                     good Rho is usually a matter of trial and error.
# 
#   -- ALGLIB --
#      Copyright 25.07.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfsetgdemopenalty(state, rho1, rho2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mindfstate
          rho1:       float
          rho2:       float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mindfsetgdemoprofilequick'></a><h3 class=pageheader><code>mindfsetgdemoprofilequick</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine tells GDEMO differential  evolution  optimizer  to  use  a
# QUICK profile.
# 
# The QUICK profile is intended  to  facilitate accelerated  convergence  on
# medium-complexity problems at the cost  of  (sometimes)  having  premature
# convergence  on  difficult  and/or  multi-extremal  problems.  The  ROBUST
# profile can be selected if you favor convergence  warranties  over  speed.
# In most cases, the ROBUST profile is ~2x-3x slower than the QUICK one.
# 
# This function has effect only on adaptive GDEMO with automatic  parameters
# selection.  It  has  no  effect  on  fixed-parameters  GDEMO  or any other
# solvers.
# 
# IMPORTANT: this function does NOT change the  optimization  algorithm.  If
#            you want to activate differential evolution solver,  you  still
#            have to call a proper mindfsetalgo???() function.
# 
# INPUT PARAMETERS:
#     State       -   solver
# 
#   -- ALGLIB --
#      Copyright 25.04.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfsetgdemoprofilequick(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mindfstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mindfsetgdemoprofilerobust'></a><h3 class=pageheader><code>mindfsetgdemoprofilerobust</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine tells GDEMO differential  evolution  optimizer  to  use  a
# ROBUST profile (the default option).
# 
# The ROBUST profile is intended  to  facilitate  explorative  behavior  and
# robust convergence even on difficult multi-extremal problems. It comes  at
# the expense of increased running time  even  on  easy  problems. The QUICK
# profile can be chosen if your problem is relatively easy to handle and you
# prefer speed over robustness. In most cases, the QUICK profile  is  ~2x-3x
# faster than the robust one.
# 
# This function has effect only on adaptive GDEMO with automatic  parameters
# selection.  It  has  no  effect  on  fixed-parameters  GDEMO  or any other
# solvers.
# 
# IMPORTANT: this function does NOT change the  optimization  algorithm.  If
#            want to activate differential evolution solver, you still  have
#            to call a proper mindfsetalgo???() function.
# 
# INPUT PARAMETERS:
#     State       -   solver
# 
#   -- ALGLIB --
#      Copyright 25.04.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfsetgdemoprofilerobust(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mindfstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mindfsetlc2dense'></a><h3 class=pageheader><code>mindfsetlc2dense</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets two-sided linear constraints AL &lt;= A*x &lt;= AU with dense
# constraint matrix A.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with MinDFcreate() call.
#     A       -   linear constraints, array[K,N]. Each row of  A  represents
#                 one  constraint. One-sided  inequality   constraints, two-
#                 sided inequality  constraints,  equality  constraints  are
#                 supported (see below)
#     AL, AU  -   lower and upper bounds, array[K];
#                 * AL[i]=AU[i] =&gt; equality constraint Ai*x
#                 * AL[i]&lt;AU[i] =&gt; two-sided constraint AL[i]&lt;=Ai*x&lt;=AU[i]
#                 * AL[i]=-INF  =&gt; one-sided constraint Ai*x&lt;=AU[i]
#                 * AU[i]=+INF  =&gt; one-sided constraint AL[i]&lt;=Ai*x
#                 * AL[i]=-INF, AU[i]=+INF =&gt; constraint is ignored
#     K       -   number of equality/inequality constraints,  K&gt;=0;  if  not
#                 given, inferred from sizes of A, AL, AU.
# 
#   -- ALGLIB --
#      Copyright 25.07.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfsetlc2dense(state, a, al, au, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfsetlc2dense(state, a, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mindfstate
          a:          2D array/list of float
          al:         1D array/list of float
          au:         1D array/list of float
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mindfsetnlc2'></a><h3 class=pageheader><code>mindfsetnlc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets two-sided nonlinear constraints.
# 
# In fact, this function sets only  NUMBER  of  the  nonlinear  constraints.
# Constraints  themselves  (constraint  functions)   are   passed   to   the
# MinDFOptimize() method.
# 
# This method accepts user-defined vector function F[] where:
# * first component of F[] corresponds to the objective
# * subsequent NNLC components of F[] correspond to the two-sided  nonlinear
#   constraints NL&lt;=C(x)&lt;=NU, where
#   * NL[i]=NU[i] =&gt; I-th row is an equality constraint Ci(x)=NL
#   * NL[i]&lt;NU[i] =&gt; I-th tow is a  two-sided constraint NL[i]&lt;=Ci(x)&lt;=NU[i]
#   * NL[i]=-INF  =&gt; I-th row is an one-sided constraint Ci(x)&lt;=NU[i]
#   * NU[i]=+INF  =&gt; I-th row is an one-sided constraint NL[i]&lt;=Ci(x)
#   * NL[i]=-INF, NU[i]=+INF =&gt; constraint is ignored
# 
# NOTE: you may combine nonlinear constraints with linear/boundary ones.  If
#       your problem has mixed constraints, you  may explicitly specify some
#       of them as linear or box ones.
#       It helps optimizer to handle them more efficiently.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with MinDFCreate call.
#     NL      -   array[NNLC], lower bounds, can contain -INF
#     NU      -   array[NNLC], lower bounds, can contain +INF
#     NNLC    -   constraints count, NNLC&gt;=0
# 
# NOTE 1: nonlinear constraints are satisfied only  approximately!   It   is
#         possible   that  algorithm  will  evaluate  function  outside   of
#         feasible area!
# 
# NOTE 2: the algorithm scales variables according to the scale specified by
#         MinDFSetScale() function, so it can handle problems with badly
#         scaled variables (as long as we KNOW their scales).
# 
#         However,  there  is  no  way  to  automatically  scale   nonlinear
#         constraints. Inappropriate scaling  of nonlinear  constraints  may
#         ruin convergence. Solving problem with  constraint  &quot;1000*G0(x)=0&quot;
#         is NOT the same as solving it with constraint &quot;0.001*G0(x)=0&quot;.
# 
#         It means that YOU are  the  one who is responsible for the correct
#         scaling of the nonlinear constraints. We recommend  you  to  scale
#         nonlinear constraints in such  a  way  that  the  derivatives  (if
#         constraints are differentiable) have approximately unit  magnitude
#         (for problems  with  unit  variable  scales)  or  have  magnitudes
#         approximately equal to 1/S[i] (where S is a variable scale set  by
#         MinDFSetScale() function).
# 
#   -- ALGLIB --
#      Copyright 25.07.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfsetnlc2(state, nl, nu, nnlc)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfsetnlc2(state, nl, nu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mindfstate
          nl:         1D array/list of float
          nu:         1D array/list of float
          nnlc:       int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mindfsetscale'></a><h3 class=pageheader><code>mindfsetscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets variable scales.
# 
# ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
# size and gradient are scaled before comparison  with  tolerances)  and  to
# guide algorithm steps.
# 
# The scale of a variable is a translation invariant measure of:
# a) &quot;how large&quot; the variable is
# b) how large the step should be to make significant changes in the function
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     S       -   array[N], non-zero scaling coefficients
#                 S[i] may be negative, sign doesn't matter.
# 
#   -- ALGLIB --
#      Copyright 25.07.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfsetscale(state, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mindfstate
          s:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mindfsetseed'></a><h3 class=pageheader><code>mindfsetseed</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets seed used by internal RNG.
# 
# By default, a random seed is used, i.e. every time you run the solver,  we
# seed its generator with a new value obtained  from  the  system-wide  RNG.
# Thus, the solver returns non-deterministic results. You  can  change  such
# a behavior by specifying a fixed positive seed value.
# 
# INPUT PARAMETERS:
#     S           -   optimizer structure
#     SeedVal     -   seed value:
#                     * positive values are used for  seeding  RNG  with  a
#                       fixed  seed,  i.e.  subsequent  runs  on  the  same
#                       objective will return the same results
#                     * non-positive seed means that a random  seed is used
#                       for every run, i.e. subsequent  runs  on  the  same
#                       objective will return slightly different results
# 
#   -- ALGLIB --
#      Copyright 26.04.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfsetseed(s, seedval)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mindfstate
          seedval:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mindfsetxrep'></a><h3 class=pageheader><code>mindfsetxrep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function turns on/off reporting.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     NeedXRep-   whether iteration reports are needed or not
# 
# If NeedXRep is True, algorithm will call rep() callback function if  it is
# provided to MinDFOptimize().
# 
# NOTE: algorithm passes two parameters to rep() callback  - the best  point
#       so far and a function value at the point. For unconstrained problems
#       the function value is  non-increasing (the most recent best point is
#       always at least not worse than the previous best one).  However,  it
#       can increase between iterations when  solving  constrained  problems
#       (a  better  point  may  have  higher  objective  value  but  smaller
#       constraint violation).
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfsetxrep(state, needxrep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mindfstate
          needxrep:   bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mindfusetimers'></a><h3 class=pageheader><code>mindfusetimers</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function activates/deactivates internal timers  used  to  track  time
# spent in various parts of the solver (mostly, callbacks vs solver itself).
# 
# When activated with this function, the following timings are stored in the
# mindfreport structure fields:
# * total time spend in the optimization
# * time spent in the callback
# * time spent in the solver itself
# 
# See comments on mindfreport structure for more  information  about  timers
# and their accuracy.
# 
# Timers are an essential part of reports that helps to find out  where  the
# most time is spent and how to  optimize  the  code.  E.g.,  noticing  that
# significant amount of time is spent  in  numerical  differentiation  makes
# obvious that ALGLIB-provided parallel numerical differentiation is needed.
# 
# However, time measurements add noticeable  overhead,  about  50-100ns  per
# function call. In some applications it results in a significant  slowdown,
# that's why this option is inactive  by  default  and  should  be  manually
# activated.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     UseTimers-  true or false
# 
# NOTE: when tracing is turned on with alglib::trace_file(), some derivative
#       free  solvers   may  also  perform  internal,  more  detailed   time
#       measurements, which are printed to the log file.
# 
#   -- ALGLIB --
#      Copyright 23.04.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mindfusetimers(state, usetimers)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.mindfstate
          usetimers:  bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_minlbfgs></a><h2 class=pageheader><code>minlbfgs</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_minlbfgscreate' class=toc>minlbfgscreate</a><br>
<a href='#sub_minlbfgscreatef' class=toc>minlbfgscreatef</a><br>
<a href='#sub_minlbfgsoptguardgradient' class=toc>minlbfgsoptguardgradient</a><br>
<a href='#sub_minlbfgsoptguardnonc1test0results' class=toc>minlbfgsoptguardnonc1test0results</a><br>
<a href='#sub_minlbfgsoptguardnonc1test1results' class=toc>minlbfgsoptguardnonc1test1results</a><br>
<a href='#sub_minlbfgsoptguardresults' class=toc>minlbfgsoptguardresults</a><br>
<a href='#sub_minlbfgsoptguardsmoothness' class=toc>minlbfgsoptguardsmoothness</a><br>
<a href='#sub_minlbfgsrequesttermination' class=toc>minlbfgsrequesttermination</a><br>
<a href='#sub_minlbfgsrestartfrom' class=toc>minlbfgsrestartfrom</a><br>
<a href='#sub_minlbfgsresults' class=toc>minlbfgsresults</a><br>
<a href='#sub_minlbfgsresultsbuf' class=toc>minlbfgsresultsbuf</a><br>
<a href='#sub_minlbfgssetcond' class=toc>minlbfgssetcond</a><br>
<a href='#sub_minlbfgssetpreccholesky' class=toc>minlbfgssetpreccholesky</a><br>
<a href='#sub_minlbfgssetprecdefault' class=toc>minlbfgssetprecdefault</a><br>
<a href='#sub_minlbfgssetprecdiag' class=toc>minlbfgssetprecdiag</a><br>
<a href='#sub_minlbfgssetprecscale' class=toc>minlbfgssetprecscale</a><br>
<a href='#sub_minlbfgssetscale' class=toc>minlbfgssetscale</a><br>
<a href='#sub_minlbfgssetstpmax' class=toc>minlbfgssetstpmax</a><br>
<a href='#sub_minlbfgssetxrep' class=toc>minlbfgssetxrep</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_minlbfgscreate'></a><h3 class=pageheader><code>minlbfgscreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
#         LIMITED MEMORY BFGS METHOD FOR LARGE SCALE OPTIMIZATION
# 
# DESCRIPTION:
# The subroutine minimizes function F(x) of N arguments by  using  a  quasi-
# Newton method (LBFGS scheme) which is optimized to use  a  minimum  amount
# of memory.
# The subroutine generates the approximation of an inverse Hessian matrix by
# using information about the last M steps of the algorithm  (instead of N).
# It lessens a required amount of memory from a value  of  order  N^2  to  a
# value of order 2*N*M.
# 
# 
# REQUIREMENTS:
# Algorithm will request following information during its operation:
# * function value F and its gradient G (simultaneously) at given point X
# 
# 
# USAGE:
# 1. User initializes algorithm state with MinLBFGSCreate() call
# 2. User tunes solver parameters with MinLBFGSSetCond() MinLBFGSSetStpMax()
#    and other functions
# 3. User calls MinLBFGSOptimize() function which takes algorithm  state and
#    pointer (delegate, etc.) to callback function which calculates F/G.
# 4. User calls MinLBFGSResults() to get solution
# 5. Optionally user may call MinLBFGSRestartFrom() to solve another problem
#    with same N/M but another starting point and/or another function.
#    MinLBFGSRestartFrom() allows to reuse already initialized structure.
# 
# INPUT PARAMETERS:
#     N       -   problem dimension. N&gt;0
#     M       -   number of corrections in the BFGS scheme of Hessian
#                 approximation update. Recommended value:  3&lt;=M&lt;=7. The smaller
#                 value causes worse convergence, the bigger will  not  cause  a
#                 considerably better convergence, but will cause a fall in  the
#                 performance. M&lt;=N.
#     X       -   initial solution approximation, array[0..N-1].
# 
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# IMPORTANT: the   LBFGS  optimizer  supports  parallel  parallel  numerical
#            differentiation  ('callback    parallelism').   This   feature,
#            which  is  present  in  commercial   ALGLIB   editions  greatly
#            accelerates  optimization  with  numerical  differentiation  of
#            an expensive target functions.
# 
#            Callback parallelism is usually  beneficial  when  computing  a
#            numerical gradient requires  more  than  several  milliseconds.
# 
#            See ALGLIB Reference Manual, 'Working with commercial version'
#            section,  and  comments  on  minlbfgsoptimize() function for
#            more information.
# 
# NOTES:
# 1. you may tune stopping conditions with MinLBFGSSetCond() function
# 2. if target function contains exp() or other fast growing functions,  and
#    optimization algorithm makes too large steps which leads  to  overflow,
#    use MinLBFGSSetStpMax() function to bound algorithm's  steps.  However,
#    L-BFGS rarely needs such a tuning.
# 
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minlbfgscreate(n, m, x)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minlbfgscreate(m, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          m:          int
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minlbfgsstate

</div></pre>
<a name='sub_minlbfgscreatef'></a><h3 class=pageheader><code>minlbfgscreatef</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# The subroutine is finite difference variant of MinLBFGSCreate().  It  uses
# finite differences in order to differentiate target function.
# 
# Description below contains information which is specific to  this function
# only. We recommend to read comments on MinLBFGSCreate() in  order  to  get
# more information about creation of LBFGS optimizer.
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;0:
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from size of X
#     M       -   number of corrections in the BFGS scheme of Hessian
#                 approximation update. Recommended value:  3&lt;=M&lt;=7. The smaller
#                 value causes worse convergence, the bigger will  not  cause  a
#                 considerably better convergence, but will cause a fall in  the
#                 performance. M&lt;=N.
#     X       -   starting point, array[0..N-1].
#     DiffStep-   differentiation step, &gt;0
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# 
# IMPORTANT: the   LBFGS  optimizer  supports  parallel  parallel  numerical
#            differentiation  ('callback    parallelism').   This   feature,
#            which  is  present  in  commercial   ALGLIB   editions  greatly
#            accelerates  optimization  with  numerical  differentiation  of
#            an expensive target functions.
# 
#            Callback parallelism is usually  beneficial  when  computing  a
#            numerical gradient requires  more  than  several  milliseconds.
# 
#            See ALGLIB Reference Manual, 'Working with commercial version'
#            section,  and  comments  on  minlbfgsoptimize() function for
#            more information.
# 
# NOTES:
# 1. algorithm uses 4-point central formula for differentiation.
# 2. differentiation step along I-th axis is equal to DiffStep*S[I] where
#    S[] is scaling vector which can be set by MinLBFGSSetScale() call.
# 3. we recommend you to use moderate values of  differentiation  step.  Too
#    large step will result in too large truncation  errors, while too small
#    step will result in too large numerical  errors.  1.0E-6  can  be  good
#    value to start with.
# 4. Numerical  differentiation  is   very   inefficient  -   one   gradient
#    calculation needs 4*N function evaluations. This function will work for
#    any N - either small (1...10), moderate (10...100) or  large  (100...).
#    However, performance penalty will be too severe for any N's except  for
#    small ones.
#    We should also say that code which relies on numerical  differentiation
#    is   less  robust  and  precise.  LBFGS  needs  exact  gradient values.
#    Imprecise gradient may slow  down  convergence,  especially  on  highly
#    nonlinear problems.
#    Thus  we  recommend to use this function for fast prototyping on small-
#    dimensional problems only, and to implement analytical gradient as soon
#    as possible.
# 
#   -- ALGLIB --
#      Copyright 16.05.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minlbfgscreatef(n, m, x, diffstep)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minlbfgscreatef(m, x, diffstep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          m:          int
          x:          1D array/list of float
          diffstep:   float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minlbfgsstate

</div></pre>
<a name='sub_minlbfgsoptguardgradient'></a><h3 class=pageheader><code>minlbfgsoptguardgradient</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  activates/deactivates verification  of  the  user-supplied
# analytic gradient.
# 
# Upon  activation  of  this  option  OptGuard  integrity  checker  performs
# numerical differentiation of your target function  at  the  initial  point
# (note: future versions may also perform check  at  the  final  point)  and
# compares numerical gradient with analytic one provided by you.
# 
# If difference is too large, an error flag is set and optimization  session
# continues. After optimization session is over, you can retrieve the report
# which  stores  both  gradients  and  specific  components  highlighted  as
# suspicious by the OptGuard.
# 
# The primary OptGuard report can be retrieved with minlbfgsoptguardresults().
# 
# IMPORTANT: gradient check is a high-overhead option which  will  cost  you
#            about 3*N additional function evaluations. In many cases it may
#            cost as much as the rest of the optimization session.
# 
#            YOU SHOULD NOT USE IT IN THE PRODUCTION CODE UNLESS YOU WANT TO
#            CHECK DERIVATIVES PROVIDED BY SOME THIRD PARTY.
# 
# NOTE: unlike previous incarnation of the gradient checking code,  OptGuard
#       does NOT interrupt optimization even if it discovers bad gradient.
# 
# INPUT PARAMETERS:
#     State       -   structure used to store algorithm state
#     TestStep    -   verification step used for numerical differentiation:
#                     * TestStep=0 turns verification off
#                     * TestStep&gt;0 activates verification
#                     You should carefully choose TestStep. Value  which  is
#                     too large (so large that  function  behavior  is  non-
#                     cubic at this scale) will lead  to  false  alarms. Too
#                     short step will result in rounding  errors  dominating
#                     numerical derivative.
# 
#                     You may use different step for different parameters by
#                     means of setting scale with minlbfgssetscale().
# 
# === EXPLANATION ==========================================================
# 
# In order to verify gradient algorithm performs following steps:
#   * two trial steps are made to X[i]-TestStep*S[i] and X[i]+TestStep*S[i],
#     where X[i] is i-th component of the initial point and S[i] is a  scale
#     of i-th parameter
#   * F(X) is evaluated at these trial points
#   * we perform one more evaluation in the middle point of the interval
#   * we  build  cubic  model using function values and derivatives at trial
#     points and we compare its prediction with actual value in  the  middle
#     point
# 
#   -- ALGLIB --
#      Copyright 15.06.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlbfgsoptguardgradient(state, teststep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
          teststep:   float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlbfgsoptguardnonc1test0results'></a><h3 class=pageheader><code>minlbfgsoptguardnonc1test0results</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Detailed results of the OptGuard integrity check for nonsmoothness test #0
# 
# Nonsmoothness (non-C1) test #0 studies  function  values  (not  gradient!)
# obtained during line searches and monitors  behavior  of  the  directional
# derivative estimate.
# 
# This test is less powerful than test #1, but it does  not  depend  on  the
# gradient values and thus it is more robust against artifacts introduced by
# numerical differentiation.
# 
# Two reports are returned:
# * a &quot;strongest&quot; one, corresponding  to  line   search  which  had  highest
#   value of the nonsmoothness indicator
# * a &quot;longest&quot; one, corresponding to line search which  had  more  function
#   evaluations, and thus is more detailed
# 
# In both cases following fields are returned:
# 
# * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
#   did not notice anything (in the latter cases fields below are empty).
# * x0[], d[] - arrays of length N which store initial point  and  direction
#   for line search (d[] can be normalized, but does not have to)
# * stp[], f[] - arrays of length CNT which store step lengths and  function
#   values at these points; f[i] is evaluated in x0+stp[i]*d.
# * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
#   between steps #stpidxa and #stpidxb (usually we have  stpidxb=stpidxa+3,
#   with  most  likely  position  of  the  violation  between  stpidxa+1 and
#   stpidxa+2.
# 
# ==========================================================================
# = SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -  you  will
# =                   see where C1 continuity is violated.
# ==========================================================================
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     strrep  -   C1 test #0 &quot;strong&quot; report
#     lngrep  -   C1 test #0 &quot;long&quot; report
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   strrep, lngrep = xalglib.minlbfgsoptguardnonc1test0results(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  strrep:     class xalglib.optguardnonc1test0report
          lngrep:     class xalglib.optguardnonc1test0report

</div></pre>
<a name='sub_minlbfgsoptguardnonc1test1results'></a><h3 class=pageheader><code>minlbfgsoptguardnonc1test1results</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Detailed results of the OptGuard integrity check for nonsmoothness test #1
# 
# Nonsmoothness (non-C1)  test  #1  studies  individual  components  of  the
# gradient computed during line search.
# 
# When precise analytic gradient is provided this test is more powerful than
# test #0  which  works  with  function  values  and  ignores  user-provided
# gradient.  However,  test  #0  becomes  more   powerful   when   numerical
# differentiation is employed (in such cases test #1 detects  higher  levels
# of numerical noise and becomes too conservative).
# 
# This test also tells specific components of the gradient which violate  C1
# continuity, which makes it more informative than #0, which just tells that
# continuity is violated.
# 
# Two reports are returned:
# * a &quot;strongest&quot; one, corresponding  to  line   search  which  had  highest
#   value of the nonsmoothness indicator
# * a &quot;longest&quot; one, corresponding to line search which  had  more  function
#   evaluations, and thus is more detailed
# 
# In both cases following fields are returned:
# 
# * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
#   did not notice anything (in the latter cases fields below are empty).
# * vidx - is an index of the variable in [0,N) with nonsmooth derivative
# * x0[], d[] - arrays of length N which store initial point  and  direction
#   for line search (d[] can be normalized, but does not have to)
# * stp[], g[] - arrays of length CNT which store step lengths and  gradient
#   values at these points; g[i] is evaluated in  x0+stp[i]*d  and  contains
#   vidx-th component of the gradient.
# * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
#   between steps #stpidxa and #stpidxb (usually we have  stpidxb=stpidxa+3,
#   with  most  likely  position  of  the  violation  between  stpidxa+1 and
#   stpidxa+2.
# 
# ==========================================================================
# = SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -  you  will
# =                   see where C1 continuity is violated.
# ==========================================================================
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     strrep  -   C1 test #1 &quot;strong&quot; report
#     lngrep  -   C1 test #1 &quot;long&quot; report
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   strrep, lngrep = xalglib.minlbfgsoptguardnonc1test1results(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  strrep:     class xalglib.optguardnonc1test1report
          lngrep:     class xalglib.optguardnonc1test1report

</div></pre>
<a name='sub_minlbfgsoptguardresults'></a><h3 class=pageheader><code>minlbfgsoptguardresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Results of OptGuard integrity check, should be called  after  optimization
# session is over.
# 
# === PRIMARY REPORT =======================================================
# 
# OptGuard performs several checks which are intended to catch common errors
# in the implementation of nonlinear function/gradient:
# * incorrect analytic gradient
# * discontinuous (non-C0) target functions (constraints)
# * nonsmooth     (non-C1) target functions (constraints)
# 
# Each of these checks is activated with appropriate function:
# * minlbfgsoptguardgradient() for gradient verification
# * minlbfgsoptguardsmoothness() for C0/C1 checks
# 
# Following flags are set when these errors are suspected:
# * rep.badgradsuspected, and additionally:
#   * rep.badgradvidx for specific variable (gradient element) suspected
#   * rep.badgradxbase, a point where gradient is tested
#   * rep.badgraduser, user-provided gradient  (stored  as  2D  matrix  with
#     single row in order to make  report  structure  compatible  with  more
#     complex optimizers like MinNLC or MinLM)
#   * rep.badgradnum,   reference    gradient    obtained    via   numerical
#     differentiation (stored as  2D matrix with single row in order to make
#     report structure compatible with more complex optimizers  like  MinNLC
#     or MinLM)
# * rep.nonc0suspected
# * rep.nonc1suspected
# 
# === ADDITIONAL REPORTS/LOGS ==============================================
# 
# Several different tests are performed to catch C0/C1 errors, you can  find
# out specific test signaled error by looking to:
# * rep.nonc0test0positive, for non-C0 test #0
# * rep.nonc1test0positive, for non-C1 test #0
# * rep.nonc1test1positive, for non-C1 test #1
# 
# Additional information (including line search logs)  can  be  obtained  by
# means of:
# * minlbfgsoptguardnonc1test0results()
# * minlbfgsoptguardnonc1test1results()
# which return detailed error reports, specific points where discontinuities
# were found, and so on.
# 
# ==========================================================================
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     rep     -   generic OptGuard report;  more  detailed  reports  can  be
#                 retrieved with other functions.
# 
# NOTE: false negatives (nonsmooth problems are not identified as  nonsmooth
#       ones) are possible although unlikely.
# 
#       The reason  is  that  you  need  to  make several evaluations around
#       nonsmoothness  in  order  to  accumulate  enough  information  about
#       function curvature. Say, if you start right from the nonsmooth point,
#       optimizer simply won't get enough data to understand what  is  going
#       wrong before it terminates due to abrupt changes in the  derivative.
#       It is also  possible  that  &quot;unlucky&quot;  step  will  move  us  to  the
#       termination too quickly.
# 
#       Our current approach is to have less than 0.1%  false  negatives  in
#       our test examples  (measured  with  multiple  restarts  from  random
#       points), and to have exactly 0% false positives.
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.minlbfgsoptguardresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.optguardreport

</div></pre>
<a name='sub_minlbfgsoptguardsmoothness'></a><h3 class=pageheader><code>minlbfgsoptguardsmoothness</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  activates/deactivates nonsmoothness monitoring  option  of
# the  OptGuard  integrity  checker. Smoothness  monitor  silently  observes
# solution process and tries to detect ill-posed problems, i.e. ones with:
# a) discontinuous target function (non-C0)
# b) nonsmooth     target function (non-C1)
# 
# Smoothness monitoring does NOT interrupt optimization  even if it suspects
# that your problem is nonsmooth. It just sets corresponding  flags  in  the
# OptGuard report which can be retrieved after optimization is over.
# 
# Smoothness monitoring is a moderate overhead option which often adds  less
# than 1% to the optimizer running time. Thus, you can use it even for large
# scale problems.
# 
# NOTE: OptGuard does  NOT  guarantee  that  it  will  always  detect  C0/C1
#       continuity violations.
# 
#       First, minor errors are hard to  catch - say, a 0.0001 difference in
#       the model values at two sides of the gap may be due to discontinuity
#       of the model - or simply because the model has changed.
# 
#       Second, C1-violations  are  especially  difficult  to  detect  in  a
#       noninvasive way. The optimizer usually  performs  very  short  steps
#       near the nonsmoothness, and differentiation  usually   introduces  a
#       lot of numerical noise.  It  is  hard  to  tell  whether  some  tiny
#       discontinuity in the slope is due to real nonsmoothness or just  due
#       to numerical noise alone.
# 
#       Our top priority was to avoid false positives, so in some rare cases
#       minor errors may went unnoticed (however, in most cases they can  be
#       spotted with restart from different initial point).
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
#     level   -   monitoring level:
#                 * 0 - monitoring is disabled
#                 * 1 - noninvasive low-overhead monitoring; function values
#                       and/or gradients are recorded, but OptGuard does not
#                       try to perform additional evaluations  in  order  to
#                       get more information about suspicious locations.
# 
# === EXPLANATION ==========================================================
# 
# One major source of headache during optimization  is  the  possibility  of
# the coding errors in the target function/constraints (or their gradients).
# Such  errors   most   often   manifest   themselves  as  discontinuity  or
# nonsmoothness of the target/constraints.
# 
# Another frequent situation is when you try to optimize something involving
# lots of min() and max() operations, i.e. nonsmooth target. Although not  a
# coding error, it is nonsmoothness anyway - and smooth  optimizers  usually
# stop right after encountering nonsmoothness, well before reaching solution.
# 
# OptGuard integrity checker helps you to catch such situations: it monitors
# function values/gradients being passed  to  the  optimizer  and  tries  to
# errors. Upon discovering suspicious pair of points it  raises  appropriate
# flag (and allows you to continue optimization). When optimization is done,
# you can study OptGuard result.
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlbfgsoptguardsmoothness(state, level)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlbfgsoptguardsmoothness(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
          level:      int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlbfgsrequesttermination'></a><h3 class=pageheader><code>minlbfgsrequesttermination</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine submits request for termination of running  optimizer.  It
# should be called from user-supplied callback when user decides that it  is
# time to &quot;smoothly&quot; terminate optimization process.  As  result,  optimizer
# stops at point which was &quot;current accepted&quot; when termination  request  was
# submitted and returns error code 8 (successful termination).
# 
# INPUT PARAMETERS:
#     State   -   optimizer structure
# 
# NOTE: after  request  for  termination  optimizer  may   perform   several
#       additional calls to user-supplied callbacks. It does  NOT  guarantee
#       to stop immediately - it just guarantees that these additional calls
#       will be discarded later.
# 
# NOTE: calling this function on optimizer which is NOT running will have no
#       effect.
# 
# NOTE: multiple calls to this function are possible. First call is counted,
#       subsequent calls are silently ignored.
# 
#   -- ALGLIB --
#      Copyright 08.10.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlbfgsrequesttermination(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlbfgsrestartfrom'></a><h3 class=pageheader><code>minlbfgsrestartfrom</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  subroutine restarts LBFGS algorithm from new point. All optimization
# parameters are left unchanged.
# 
# This  function  allows  to  solve multiple  optimization  problems  (which
# must have same number of dimensions) without object reallocation penalty.
# 
# INPUT PARAMETERS:
#     State   -   structure used to store algorithm state
#     X       -   new starting point.
# 
#   -- ALGLIB --
#      Copyright 30.07.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlbfgsrestartfrom(state, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlbfgsresults'></a><h3 class=pageheader><code>minlbfgsresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# L-BFGS algorithm results
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     X       -   array[0..N-1], solution
#     Rep     -   optimization report:
#                 * Rep.TerminationType completetion code:
#                     * -8    internal integrity control  detected  infinite
#                             or NAN values in  function/gradient.  Abnormal
#                             termination signalled.
#                     * -2    rounding errors prevent further improvement.
#                             X contains best point found.
#                     * -1    incorrect parameters were specified
#                     *  1    relative function improvement is no more than
#                             EpsF.
#                     *  2    relative step is no more than EpsX.
#                     *  4    gradient norm is no more than EpsG
#                     *  5    MaxIts steps was taken
#                     *  7    stopping conditions are too stringent,
#                             further improvement is impossible
#                     *  8    terminated by user who called minlbfgsrequesttermination().
#                             X contains point which was &quot;current accepted&quot; when
#                             termination request was submitted.
#                 * Rep.IterationsCount contains iterations count
#                 * NFEV countains number of function calculations
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.minlbfgsresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.minlbfgsreport

</div></pre>
<a name='sub_minlbfgsresultsbuf'></a><h3 class=pageheader><code>minlbfgsresultsbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# L-BFGS algorithm results
# 
# Buffered implementation of MinLBFGSResults which uses pre-allocated buffer
# to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
# intended to be used in the inner cycles of performance critical algorithms
# where array reallocation penalty is too large to be ignored.
# 
#   -- ALGLIB --
#      Copyright 20.08.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.minlbfgsresultsbuf(state, x, rep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
          x:          1D array/list of float
          rep:        class xalglib.minlbfgsreport
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> rep
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float

</div></pre>
<a name='sub_minlbfgssetcond'></a><h3 class=pageheader><code>minlbfgssetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping conditions for L-BFGS optimization algorithm.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     EpsG    -   &gt;=0
#                 The  subroutine  finishes  its  work   if   the  condition
#                 |v|&lt;EpsG is satisfied, where:
#                 * |.| means Euclidian norm
#                 * v - scaled gradient vector, v[i]=g[i]*s[i]
#                 * g - gradient
#                 * s - scaling coefficients set by MinLBFGSSetScale()
#     EpsF    -   &gt;=0
#                 The  subroutine  finishes  its work if on k+1-th iteration
#                 the  condition  |F(k+1)-F(k)|&lt;=EpsF*max{|F(k)|,|F(k+1)|,1}
#                 is satisfied.
#     EpsX    -   &gt;=0
#                 The subroutine finishes its work if  on  k+1-th  iteration
#                 the condition |v|&lt;=EpsX is fulfilled, where:
#                 * |.| means Euclidian norm
#                 * v - scaled step vector, v[i]=dx[i]/s[i]
#                 * dx - ste pvector, dx=X(k+1)-X(k)
#                 * s - scaling coefficients set by MinLBFGSSetScale()
#     MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
#                 iterations is unlimited.
# 
# Passing EpsG=0, EpsF=0, EpsX=0 and MaxIts=0 (simultaneously) will lead to
# automatic stopping criterion selection (small EpsX).
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlbfgssetcond(state, epsg, epsf, epsx, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
          epsg:       float
          epsf:       float
          epsx:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlbfgssetpreccholesky'></a><h3 class=pageheader><code>minlbfgssetpreccholesky</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modification of the preconditioner: Cholesky factorization of  approximate
# Hessian is used.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     P       -   triangular preconditioner, Cholesky factorization of
#                 the approximate Hessian. array[0..N-1,0..N-1],
#                 (if larger, only leading N elements are used).
#     IsUpper -   whether upper or lower triangle of P is given
#                 (other triangle is not referenced)
# 
# After call to this function preconditioner is changed to P  (P  is  copied
# into the internal buffer).
# 
# NOTE:  you  can  change  preconditioner  &quot;on  the  fly&quot;,  during algorithm
# iterations.
# 
# NOTE 2:  P  should  be nonsingular. Exception will be thrown otherwise.
# 
#   -- ALGLIB --
#      Copyright 13.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlbfgssetpreccholesky(state, p, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
          p:          2D array/list of float
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlbfgssetprecdefault'></a><h3 class=pageheader><code>minlbfgssetprecdefault</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modification  of  the  preconditioner:  default  preconditioner    (simple
# scaling, same for all elements of X) is used.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# NOTE:  you  can  change  preconditioner  &quot;on  the  fly&quot;,  during algorithm
# iterations.
# 
#   -- ALGLIB --
#      Copyright 13.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlbfgssetprecdefault(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlbfgssetprecdiag'></a><h3 class=pageheader><code>minlbfgssetprecdiag</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modification  of  the  preconditioner:  diagonal of approximate Hessian is
# used.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     D       -   diagonal of the approximate Hessian, array[0..N-1],
#                 (if larger, only leading N elements are used).
# 
# NOTE:  you  can  change  preconditioner  &quot;on  the  fly&quot;,  during algorithm
# iterations.
# 
# NOTE 2: D[i] should be positive. Exception will be thrown otherwise.
# 
# NOTE 3: you should pass diagonal of approximate Hessian - NOT ITS INVERSE.
# 
#   -- ALGLIB --
#      Copyright 13.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlbfgssetprecdiag(state, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
          d:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlbfgssetprecscale'></a><h3 class=pageheader><code>minlbfgssetprecscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Modification of the preconditioner: scale-based diagonal preconditioning.
# 
# This preconditioning mode can be useful when you  don't  have  approximate
# diagonal of Hessian, but you know that your  variables  are  badly  scaled
# (for  example,  one  variable is in [1,10], and another in [1000,100000]),
# and most part of the ill-conditioning comes from different scales of vars.
# 
# In this case simple  scale-based  preconditioner,  with H[i] = 1/(s[i]^2),
# can greatly improve convergence.
# 
# IMPRTANT: you should set scale of your variables  with  MinLBFGSSetScale()
# call  (before  or after MinLBFGSSetPrecScale() call). Without knowledge of
# the scale of your variables scale-based preconditioner will be  just  unit
# matrix.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 13.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlbfgssetprecscale(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlbfgssetscale'></a><h3 class=pageheader><code>minlbfgssetscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets scaling coefficients for LBFGS optimizer.
# 
# ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
# size and gradient are scaled before comparison with tolerances).  Scale of
# the I-th variable is a translation invariant measure of:
# a) &quot;how large&quot; the variable is
# b) how large the step should be to make significant changes in the function
# 
# Scaling is also used by finite difference variant of the optimizer  - step
# along I-th axis is equal to DiffStep*S[I].
# 
# In  most  optimizers  (and  in  the  LBFGS  too)  scaling is NOT a form of
# preconditioning. It just  affects  stopping  conditions.  You  should  set
# preconditioner  by  separate  call  to  one  of  the  MinLBFGSSetPrec...()
# functions.
# 
# There  is  special  preconditioning  mode, however,  which  uses   scaling
# coefficients to form diagonal preconditioning matrix. You  can  turn  this
# mode on, if you want.   But  you should understand that scaling is not the
# same thing as preconditioning - these are two different, although  related
# forms of tuning solver.
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     S       -   array[N], non-zero scaling coefficients
#                 S[i] may be negative, sign doesn't matter.
# 
#   -- ALGLIB --
#      Copyright 14.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlbfgssetscale(state, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
          s:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlbfgssetstpmax'></a><h3 class=pageheader><code>minlbfgssetstpmax</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets maximum step length
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     StpMax  -   maximum step length, &gt;=0. Set StpMax to 0.0 (default),  if
#                 you don't want to limit step length.
# 
# Use this subroutine when you optimize target function which contains exp()
# or  other  fast  growing  functions,  and optimization algorithm makes too
# large  steps  which  leads  to overflow. This function allows us to reject
# steps  that  are  too  large  (and  therefore  expose  us  to the possible
# overflow) without actually calculating function value at the x+stp*d.
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlbfgssetstpmax(state, stpmax)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
          stpmax:     float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlbfgssetxrep'></a><h3 class=pageheader><code>minlbfgssetxrep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function turns on/off reporting.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     NeedXRep-   whether iteration reports are needed or not
# 
# If NeedXRep is True, algorithm will call rep() callback function if  it is
# provided to MinLBFGSOptimize().
# 
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlbfgssetxrep(state, needxrep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlbfgsstate
          needxrep:   bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_minlm></a><h2 class=pageheader><code>minlm</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_minlmcreatev' class=toc>minlmcreatev</a><br>
<a href='#sub_minlmcreatevj' class=toc>minlmcreatevj</a><br>
<a href='#sub_minlmoptguardgradient' class=toc>minlmoptguardgradient</a><br>
<a href='#sub_minlmoptguardresults' class=toc>minlmoptguardresults</a><br>
<a href='#sub_minlmrequesttermination' class=toc>minlmrequesttermination</a><br>
<a href='#sub_minlmrestartfrom' class=toc>minlmrestartfrom</a><br>
<a href='#sub_minlmresults' class=toc>minlmresults</a><br>
<a href='#sub_minlmresultsbuf' class=toc>minlmresultsbuf</a><br>
<a href='#sub_minlmsetacctype' class=toc>minlmsetacctype</a><br>
<a href='#sub_minlmsetbc' class=toc>minlmsetbc</a><br>
<a href='#sub_minlmsetcond' class=toc>minlmsetcond</a><br>
<a href='#sub_minlmsetlc' class=toc>minlmsetlc</a><br>
<a href='#sub_minlmsetnonmonotonicsteps' class=toc>minlmsetnonmonotonicsteps</a><br>
<a href='#sub_minlmsetnumdiff' class=toc>minlmsetnumdiff</a><br>
<a href='#sub_minlmsetscale' class=toc>minlmsetscale</a><br>
<a href='#sub_minlmsetstpmax' class=toc>minlmsetstpmax</a><br>
<a href='#sub_minlmsetxrep' class=toc>minlmsetxrep</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_minlmcreatev'></a><h3 class=pageheader><code>minlmcreatev</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
#                 IMPROVED LEVENBERG-MARQUARDT METHOD FOR
#                  NON-LINEAR LEAST SQUARES OPTIMIZATION
# 
# DESCRIPTION:
# This function is used to find minimum of function which is represented  as
# sum of squares:
#     F(x) = f[0]^2(x[0],...,x[n-1]) + ... + f[m-1]^2(x[0],...,x[n-1])
# using value of function vector f[] only. Finite differences  are  used  to
# calculate Jacobian.
# 
# 
# REQUIREMENTS:
# This algorithm will request following information during its operation:
# * function vector f[] at given point X
# 
# There are several overloaded versions of  MinLMOptimize()  function  which
# correspond  to  different LM-like optimization algorithms provided by this
# unit. You should choose version which accepts fvec() callback.
# 
# You can try to initialize MinLMState structure with VJ  function and  then
# use incorrect version  of  MinLMOptimize()  (for  example,  version  which
# works with general form function and does not accept function vector), but
# it will  lead  to  exception being thrown after first attempt to calculate
# Jacobian.
# 
# 
# USAGE:
# 1. User initializes algorithm state with MinLMCreateV() call
# 2. User tunes solver parameters with MinLMSetCond(),  MinLMSetStpMax() and
#    other functions
# 3. User calls MinLMOptimize() function which  takes algorithm  state   and
#    callback functions.
# 4. User calls MinLMResults() to get solution
# 5. Optionally, user may call MinLMRestartFrom() to solve  another  problem
#    with same N/M but another starting point and/or another function.
#    MinLMRestartFrom() allows to reuse already initialized structure.
# 
# 
# INPUT PARAMETERS:
#     N       -   dimension, N&gt;1
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from size of X
#     M       -   number of functions f[i]
#     X       -   initial solution, array[0..N-1]
#     DiffStep-   differentiation step, &gt;0. By  default,  symmetric  3-point
#                 formula which provides good accuracy is used.  It  can  be
#                 changed to a faster but  less  precise  2-point  one  with
#                 minlmsetnumdiff() function.
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# See also MinLMIteration, MinLMResults.
# 
# NOTES:
# 1. you may tune stopping conditions with MinLMSetCond() function
# 2. if target function contains exp() or other fast growing functions,  and
#    optimization algorithm makes too large steps which leads  to  overflow,
#    use MinLMSetStpMax() function to bound algorithm's steps.
# 
#   -- ALGLIB --
#      Copyright 30.03.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minlmcreatev(n, m, x, diffstep)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minlmcreatev(m, x, diffstep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          m:          int
          x:          1D array/list of float
          diffstep:   float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minlmstate

</div></pre>
<a name='sub_minlmcreatevj'></a><h3 class=pageheader><code>minlmcreatevj</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
#                 IMPROVED LEVENBERG-MARQUARDT METHOD FOR
#                  NON-LINEAR LEAST SQUARES OPTIMIZATION
# 
# DESCRIPTION:
# This function is used to find minimum of function which is represented  as
# sum of squares:
#     F(x) = f[0]^2(x[0],...,x[n-1]) + ... + f[m-1]^2(x[0],...,x[n-1])
# using value of function vector f[] and Jacobian of f[].
# 
# 
# REQUIREMENTS:
# This algorithm will request following information during its operation:
# 
# * function vector f[] at given point X
# * function vector f[] and Jacobian of f[] (simultaneously) at given point
# 
# There are several overloaded versions of  MinLMOptimize()  function  which
# correspond  to  different LM-like optimization algorithms provided by this
# unit. You should choose version which accepts fvec()  and jac() callbacks.
# First  one  is used to calculate f[] at given point, second one calculates
# f[] and Jacobian df[i]/dx[j].
# 
# You can try to initialize MinLMState structure with VJ  function and  then
# use incorrect version  of  MinLMOptimize()  (for  example,  version  which
# works  with  general  form function and does not provide Jacobian), but it
# will  lead  to  exception  being  thrown  after first attempt to calculate
# Jacobian.
# 
# 
# USAGE:
# 1. User initializes algorithm state with MinLMCreateVJ() call
# 2. User tunes solver parameters with MinLMSetCond(),  MinLMSetStpMax() and
#    other functions
# 3. User calls MinLMOptimize() function which  takes algorithm  state   and
#    callback functions.
# 4. User calls MinLMResults() to get solution
# 5. Optionally, user may call MinLMRestartFrom() to solve  another  problem
#    with same N/M but another starting point and/or another function.
#    MinLMRestartFrom() allows to reuse already initialized structure.
# 
# 
# INPUT PARAMETERS:
#     N       -   dimension, N&gt;1
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from size of X
#     M       -   number of functions f[i]
#     X       -   initial solution, array[0..N-1]
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# NOTES:
# 1. you may tune stopping conditions with MinLMSetCond() function
# 2. if target function contains exp() or other fast growing functions,  and
#    optimization algorithm makes too large steps which leads  to  overflow,
#    use MinLMSetStpMax() function to bound algorithm's steps.
# 
#   -- ALGLIB --
#      Copyright 30.03.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minlmcreatevj(n, m, x)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minlmcreatevj(m, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          m:          int
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minlmstate

</div></pre>
<a name='sub_minlmoptguardgradient'></a><h3 class=pageheader><code>minlmoptguardgradient</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  activates/deactivates verification  of  the  user-supplied
# analytic Jacobian.
# 
# Upon  activation  of  this  option  OptGuard  integrity  checker  performs
# numerical differentiation of your target function vector  at  the  initial
# point (note: future versions may also perform check  at  the final  point)
# and compares numerical Jacobian with analytic one provided by you.
# 
# If difference is too large, an error flag is set and optimization  session
# continues. After optimization session is over, you can retrieve the report
# which stores  both  Jacobians,  and  specific  components  highlighted  as
# suspicious by the OptGuard.
# 
# The OptGuard report can be retrieved with minlmoptguardresults().
# 
# IMPORTANT: gradient check is a high-overhead option which  will  cost  you
#            about 3*N additional function evaluations. In many cases it may
#            cost as much as the rest of the optimization session.
# 
#            YOU SHOULD NOT USE IT IN THE PRODUCTION CODE UNLESS YOU WANT TO
#            CHECK DERIVATIVES PROVIDED BY SOME THIRD PARTY.
# 
# NOTE: unlike previous incarnation of the gradient checking code,  OptGuard
#       does NOT interrupt optimization even if it discovers bad gradient.
# 
# INPUT PARAMETERS:
#     State       -   structure used to store algorithm state
#     TestStep    -   verification step used for numerical differentiation:
#                     * TestStep=0 turns verification off
#                     * TestStep&gt;0 activates verification
#                     You should carefully choose TestStep. Value  which  is
#                     too large (so large that  function  behavior  is  non-
#                     cubic at this scale) will lead  to  false  alarms. Too
#                     short step will result in rounding  errors  dominating
#                     numerical derivative.
# 
#                     You may use different step for different parameters by
#                     means of setting scale with minlmsetscale().
# 
# === EXPLANATION ==========================================================
# 
# In order to verify gradient algorithm performs following steps:
#   * two trial steps are made to X[i]-TestStep*S[i] and X[i]+TestStep*S[i],
#     where X[i] is i-th component of the initial point and S[i] is a  scale
#     of i-th parameter
#   * F(X) is evaluated at these trial points
#   * we perform one more evaluation in the middle point of the interval
#   * we  build  cubic  model using function values and derivatives at trial
#     points and we compare its prediction with actual value in  the  middle
#     point
# 
#   -- ALGLIB --
#      Copyright 15.06.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlmoptguardgradient(state, teststep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlmstate
          teststep:   float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlmoptguardresults'></a><h3 class=pageheader><code>minlmoptguardresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Results of OptGuard integrity check, should be called  after  optimization
# session is over.
# 
# OptGuard checks analytic Jacobian  against  reference  value  obtained  by
# numerical differentiation with user-specified step.
# 
# NOTE: other optimizers perform additional OptGuard checks for things  like
#       C0/C1-continuity violations. However, LM optimizer  can  check  only
#       for incorrect Jacobian.
# 
#       The reason is that unlike line search methods LM optimizer does  not
#       perform extensive evaluations along the line. Thus, we simply do not
#       have enough data to catch C0/C1-violations.
# 
# This check is activated with  minlmoptguardgradient() function.
# 
# Following flags are set when these errors are suspected:
# * rep.badgradsuspected, and additionally:
#   * rep.badgradfidx for specific function (Jacobian row) suspected
#   * rep.badgradvidx for specific variable (Jacobian column) suspected
#   * rep.badgradxbase, a point where gradient/Jacobian is tested
#   * rep.badgraduser, user-provided gradient/Jacobian
#   * rep.badgradnum, reference gradient/Jacobian obtained via numerical
#     differentiation
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     rep     -   OptGuard report
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.minlmoptguardresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlmstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.optguardreport

</div></pre>
<a name='sub_minlmrequesttermination'></a><h3 class=pageheader><code>minlmrequesttermination</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine submits request for termination of running  optimizer.  It
# should be called from user-supplied callback when user decides that it  is
# time to &quot;smoothly&quot; terminate optimization process.  As  result,  optimizer
# stops at point which was &quot;current accepted&quot; when termination  request  was
# submitted and returns error code 8 (successful termination).
# 
# INPUT PARAMETERS:
#     State   -   optimizer structure
# 
# NOTE: after  request  for  termination  optimizer  may   perform   several
#       additional calls to user-supplied callbacks. It does  NOT  guarantee
#       to stop immediately - it just guarantees that these additional calls
#       will be discarded later.
# 
# NOTE: calling this function on optimizer which is NOT running will have no
#       effect.
# 
# NOTE: multiple calls to this function are possible. First call is counted,
#       subsequent calls are silently ignored.
# 
#   -- ALGLIB --
#      Copyright 08.10.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlmrequesttermination(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlmstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlmrestartfrom'></a><h3 class=pageheader><code>minlmrestartfrom</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  subroutine  restarts  LM  algorithm from new point. All optimization
# parameters are left unchanged.
# 
# This  function  allows  to  solve multiple  optimization  problems  (which
# must have same number of dimensions) without object reallocation penalty.
# 
# INPUT PARAMETERS:
#     State   -   structure used for reverse communication previously
#                 allocated with MinLMCreateXXX call.
#     X       -   new starting point.
# 
#   -- ALGLIB --
#      Copyright 30.07.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlmrestartfrom(state, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlmstate
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlmresults'></a><h3 class=pageheader><code>minlmresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Levenberg-Marquardt algorithm results
# 
# NOTE: if you activated OptGuard integrity checking functionality and  want
#       to get OptGuard report,  it  can  be  retrieved  with  the  help  of
#       minlmoptguardresults() function.
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     X       -   array[0..N-1], solution
#     Rep     -   optimization  report;  includes  termination   codes   and
#                 additional information. Termination codes are listed below,
#                 see comments for this structure for more info.
# 
#                 Termination code is stored in rep.terminationtype field:
#                 * -8    optimizer detected NAN/INF values either in the
#                         function itself, or in its Jacobian
#                 * -3    constraints are inconsistent
#                 *  2    relative step is no more than EpsX.
#                 *  5    MaxIts steps was taken
#                 *  7    stopping conditions are too stringent,
#                         further improvement is impossible
#                 *  8    terminated by user who called minlmrequesttermination().
#                         X contains point which was &quot;current accepted&quot; when
#                         termination request was submitted.
# 
#                 rep.f contains SUM(f[i]^2) at X
# 
#   -- ALGLIB --
#      Copyright 10.03.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.minlmresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlmstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.minlmreport

</div></pre>
<a name='sub_minlmresultsbuf'></a><h3 class=pageheader><code>minlmresultsbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Levenberg-Marquardt algorithm results
# 
# Buffered implementation of MinLMResults(), which uses pre-allocated buffer
# to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
# intended to be used in the inner cycles of performance critical algorithms
# where array reallocation penalty is too large to be ignored.
# 
#   -- ALGLIB --
#      Copyright 10.03.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.minlmresultsbuf(state, x, rep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlmstate
          x:          1D array/list of float
          rep:        class xalglib.minlmreport
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> rep
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float

</div></pre>
<a name='sub_minlmsetacctype'></a><h3 class=pageheader><code>minlmsetacctype</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to change acceleration settings
# 
# You can choose between three acceleration strategies:
# * AccType=0, no acceleration.
# * AccType=1, secant updates are used to update quadratic model after  each
#   iteration. After fixed number of iterations (or after  model  breakdown)
#   we  recalculate  quadratic  model  using  analytic  Jacobian  or  finite
#   differences. Number of secant-based iterations depends  on  optimization
#   settings: about 3 iterations - when we have analytic Jacobian, up to 2*N
#   iterations - when we use finite differences to calculate Jacobian.
# 
# AccType=1 is recommended when Jacobian  calculation  cost is prohibitively
# high (several Mx1 function vector calculations  followed  by  several  NxN
# Cholesky factorizations are faster than calculation of one M*N  Jacobian).
# It should also be used when we have no Jacobian, because finite difference
# approximation takes too much time to compute.
# 
# Table below list  optimization  protocols  (XYZ  protocol  corresponds  to
# MinLMCreateXYZ) and acceleration types they support (and use by  default).
# 
# ACCELERATION TYPES SUPPORTED BY OPTIMIZATION PROTOCOLS:
# 
# protocol    0   1   comment
# V           +   +
# VJ          +   +
# FGH         +
# 
# DEFAULT VALUES:
# 
# protocol    0   1   comment
# V               x   without acceleration it is so slooooooooow
# VJ          x
# FGH         x
# 
# NOTE: this  function should be called before optimization. Attempt to call
# it during algorithm iterations may result in unexpected behavior.
# 
# NOTE: attempt to call this function with unsupported protocol/acceleration
# combination will result in exception being thrown.
# 
#   -- ALGLIB --
#      Copyright 14.10.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlmsetacctype(state, acctype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlmstate
          acctype:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlmsetbc'></a><h3 class=pageheader><code>minlmsetbc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets boundary constraints for LM optimizer
# 
# Boundary constraints are inactive by default (after initial creation).
# They are preserved until explicitly turned off with another SetBC() call.
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     BndL    -   lower bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 very small number or -INF (latter is recommended because
#                 it will allow solver to use better algorithm).
#     BndU    -   upper bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 very large number or +INF (latter is recommended because
#                 it will allow solver to use better algorithm).
# 
# NOTE 1: it is possible to specify BndL[i]=BndU[i]. In this case I-th
# variable will be &quot;frozen&quot; at X[i]=BndL[i]=BndU[i].
# 
# NOTE 2: this solver has following useful properties:
# * bound constraints are always satisfied exactly
# * function is evaluated only INSIDE area specified by bound constraints
#   or at its boundary
# 
#   -- ALGLIB --
#      Copyright 14.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlmsetbc(state, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlmstate
          bndl:       1D array/list of float
          bndu:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlmsetcond'></a><h3 class=pageheader><code>minlmsetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping conditions for Levenberg-Marquardt optimization
# algorithm.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     EpsX    -   &gt;=0
#                 The subroutine finishes its work if  on  k+1-th  iteration
#                 the condition |v|&lt;=EpsX is fulfilled, where:
#                 * |.| means Euclidian norm
#                 * v - scaled step vector, v[i]=dx[i]/s[i]
#                 * dx - ste pvector, dx=X(k+1)-X(k)
#                 * s - scaling coefficients set by MinLMSetScale()
#                 Recommended values: 1E-9 ... 1E-12.
#     MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
#                 iterations   is    unlimited.   Only   Levenberg-Marquardt
#                 iterations  are  counted  (L-BFGS/CG  iterations  are  NOT
#                 counted because their cost is very low compared to that of
#                 LM).
# 
# Passing  EpsX=0  and  MaxIts=0  (simultaneously)  will  lead  to automatic
# stopping criterion selection (small EpsX).
# 
# NOTE: it is not recommended to set large EpsX (say, 0.001). Because LM  is
#       a second-order method, it performs very precise steps anyway.
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlmsetcond(state, epsx, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlmstate
          epsx:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlmsetlc'></a><h3 class=pageheader><code>minlmsetlc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets general linear constraints for LM optimizer
# 
# Linear constraints are inactive by default (after initial creation).  They
# are preserved until explicitly turned off with another minlmsetlc() call.
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     C       -   linear constraints, array[K,N+1].
#                 Each row of C represents one constraint, either equality
#                 or inequality (see below):
#                 * first N elements correspond to coefficients,
#                 * last element corresponds to the right part.
#                 All elements of C (including right part) must be finite.
#     CT      -   type of constraints, array[K]:
#                 * if CT[i]&gt;0, then I-th constraint is C[i,*]*x &gt;= C[i,n+1]
#                 * if CT[i]=0, then I-th constraint is C[i,*]*x  = C[i,n+1]
#                 * if CT[i]&lt;0, then I-th constraint is C[i,*]*x &lt;= C[i,n+1]
#     K       -   number of equality/inequality constraints, K&gt;=0:
#                 * if given, only leading K elements of C/CT are used
#                 * if not given, automatically determined from sizes of C/CT
# 
# IMPORTANT: if you have linear constraints, it is strongly  recommended  to
#            set scale of variables with minlmsetscale(). QP solver which is
#            used to calculate linearly constrained steps heavily relies  on
#            good scaling of input problems.
# 
# IMPORTANT: solvers created with minlmcreatefgh()  do  not  support  linear
#            constraints.
# 
# NOTE: linear  (non-bound)  constraints are satisfied only approximately  -
#       there  always  exists some violation due  to  numerical  errors  and
#       algorithmic limitations.
# 
# NOTE: general linear constraints  add  significant  overhead  to  solution
#       process. Although solver performs roughly same amount of  iterations
#       (when compared  with  similar  box-only  constrained  problem), each
#       iteration   now    involves  solution  of  linearly  constrained  QP
#       subproblem, which requires ~3-5 times more Cholesky  decompositions.
#       Thus, if you can reformulate your problem in such way  this  it  has
#       only box constraints, it may be beneficial to do so.
# 
#   -- ALGLIB --
#      Copyright 14.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlmsetlc(state, c, ct, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlmsetlc(state, c, ct)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlmstate
          c:          2D array/list of float
          ct:         1D array/list of int
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlmsetnonmonotonicsteps'></a><h3 class=pageheader><code>minlmsetnonmonotonicsteps</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used  to  activate/deactivate  nonmonotonic  steps.  Such
# steps may improve  convergence  on  noisy  problems  or  ones  with  minor
# smoothness defects.
# 
# In its standard mode, LM solver compares value at the trial   point   f[1]
# with the value at the current point f[0]. Only steps that decrease f() are
# accepted.
# 
# When the nonmonotonic mode is activated, f[1]  is  compared  with  maximum
# over several previous  locations:  max(f[0],f[-1],...,f[-CNT]).  We  still
# accept only steps that decrease  f(),  however  our  reference  value  has
# changed. The net results is that f[1]&gt;f[0] are now allowed.
# 
# Nonmonotonic steps can help to handle minor defects in the objective (e.g.
# small  noise,  discontinuous  jumps  or  nonsmoothness).  However,  it  is
# important  that  the  overall  shape  of  the  problem  is  still  smooth.
# It  may  also  help  to  minimize  perfectly  smooth  targets with complex
# geometries by allowing to jump through curved valleys.
# 
# However, sometimes nonmonotonic steps degrade convergence by  allowing  an
# optimizer to wander too far away from the solution, so this feature should
# be used only after careful testing.
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     Cnt     -   nonmonotonic memory length, Cnt&gt;=0:
#                 * 0 for traditional monotonic steps
#                 * 2..3 is recommended for the nonmonotonic optimization
# 
#   -- ALGLIB --
#      Copyright 07.04.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlmsetnonmonotonicsteps(state, cnt)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlmstate
          cnt:        int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlmsetnumdiff'></a><h3 class=pageheader><code>minlmsetnumdiff</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets specific finite  difference  formula  to  be  used  for
# numerical differentiation.
# 
# It works only for optimizers created  with  minlmcreatev()  function;   in
# other cases it has no effect.
# 
# INPUT PARAMETERS:
#     State       -   structure previously allocated with MinLMCreateV() call.
#     FormulaType -   formula type:
#                     * 3 for a 3-point formula, which is also  known  as  a
#                       symmetric difference quotient (the formula  actually
#                       uses only two function values per variable:  at  x+h
#                       and x-h). A good choice for medium-accuracy  setups,
#                       a default option.
#                     * 2 for a forward (or backward, depending  on variable
#                       bounds)  finite   difference  (f(x+h)-f(x))/h.  This
#                       formula has the lowest accuracy. However, it  is  4x
#                       faster than the 5-point formula and 2x  faster  than
#                       the 3-point one because, in addition to the  central
#                       value f(x), it needs only  one  additional  function
#                       evaluation per variable.
# 
# 
#   -- ALGLIB --
#      Copyright 03.12.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlmsetnumdiff(state, formulatype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlmstate
          formulatype: int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlmsetscale'></a><h3 class=pageheader><code>minlmsetscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets scaling coefficients for LM optimizer.
# 
# ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
# size and gradient are scaled before comparison with tolerances).  Scale of
# the I-th variable is a translation invariant measure of:
# a) &quot;how large&quot; the variable is
# b) how large the step should be to make significant changes in the function
# 
# Generally, scale is NOT considered to be a form of preconditioner.  But LM
# optimizer is unique in that it uses scaling matrix both  in  the  stopping
# condition tests and as Marquardt damping factor.
# 
# Proper scaling is very important for the algorithm performance. It is less
# important for the quality of results, but still has some influence (it  is
# easier  to  converge  when  variables  are  properly  scaled, so premature
# stopping is possible when very badly scalled variables are  combined  with
# relaxed stopping conditions).
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     S       -   array[N], non-zero scaling coefficients
#                 S[i] may be negative, sign doesn't matter.
# 
#   -- ALGLIB --
#      Copyright 14.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlmsetscale(state, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlmstate
          s:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlmsetstpmax'></a><h3 class=pageheader><code>minlmsetstpmax</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets maximum step length
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     StpMax  -   maximum step length, &gt;=0. Set StpMax to 0.0,  if you don't
#                 want to limit step length.
# 
# Use this subroutine when you optimize target function which contains exp()
# or  other  fast  growing  functions,  and optimization algorithm makes too
# large  steps  which  leads  to overflow. This function allows us to reject
# steps  that  are  too  large  (and  therefore  expose  us  to the possible
# overflow) without actually calculating function value at the x+stp*d.
# 
# NOTE: non-zero StpMax leads to moderate  performance  degradation  because
# intermediate  step  of  preconditioned L-BFGS optimization is incompatible
# with limits on step size.
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlmsetstpmax(state, stpmax)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlmstate
          stpmax:     float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlmsetxrep'></a><h3 class=pageheader><code>minlmsetxrep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function turns on/off reporting.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     NeedXRep-   whether iteration reports are needed or not
# 
# If NeedXRep is True, algorithm will call rep() callback function if  it is
# provided to MinLMOptimize(). Both Levenberg-Marquardt and internal  L-BFGS
# iterations are reported.
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlmsetxrep(state, needxrep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlmstate
          needxrep:   bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_minlp></a><h2 class=pageheader><code>minlp</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_minlpaddlc2' class=toc>minlpaddlc2</a><br>
<a href='#sub_minlpaddlc2dense' class=toc>minlpaddlc2dense</a><br>
<a href='#sub_minlpcreate' class=toc>minlpcreate</a><br>
<a href='#sub_minlpoptimize' class=toc>minlpoptimize</a><br>
<a href='#sub_minlpresults' class=toc>minlpresults</a><br>
<a href='#sub_minlpresultsbuf' class=toc>minlpresultsbuf</a><br>
<a href='#sub_minlpsetalgodss' class=toc>minlpsetalgodss</a><br>
<a href='#sub_minlpsetalgoipm' class=toc>minlpsetalgoipm</a><br>
<a href='#sub_minlpsetbc' class=toc>minlpsetbc</a><br>
<a href='#sub_minlpsetbcall' class=toc>minlpsetbcall</a><br>
<a href='#sub_minlpsetbci' class=toc>minlpsetbci</a><br>
<a href='#sub_minlpsetcost' class=toc>minlpsetcost</a><br>
<a href='#sub_minlpsetlc' class=toc>minlpsetlc</a><br>
<a href='#sub_minlpsetlc2' class=toc>minlpsetlc2</a><br>
<a href='#sub_minlpsetlc2dense' class=toc>minlpsetlc2dense</a><br>
<a href='#sub_minlpsetscale' class=toc>minlpsetscale</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_minlpaddlc2'></a><h3 class=pageheader><code>minlpaddlc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends two-sided linear constraint  AL &lt;= A*x &lt;= AU  to the
# list of currently present constraints.
# 
# Constraint is passed in compressed format: as list of non-zero entries  of
# coefficient vector A. Such approach is more efficient than  dense  storage
# for highly sparse constraint vectors.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minlpcreate() call.
#     IdxA    -   array[NNZ], indexes of non-zero elements of A:
#                 * can be unsorted
#                 * can include duplicate indexes (corresponding entries  of
#                   ValA[] will be summed)
#     ValA    -   array[NNZ], values of non-zero elements of A
#     NNZ     -   number of non-zero coefficients in A
#     AL, AU  -   lower and upper bounds;
#                 * AL=AU    =&gt; equality constraint A*x
#                 * AL&lt;AU    =&gt; two-sided constraint AL&lt;=A*x&lt;=AU
#                 * AL=-INF  =&gt; one-sided constraint A*x&lt;=AU
#                 * AU=+INF  =&gt; one-sided constraint AL&lt;=A*x
#                 * AL=-INF, AU=+INF =&gt; constraint is ignored
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlpaddlc2(state, idxa, vala, nnz, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlpstate
          idxa:       1D array/list of int
          vala:       1D array/list of float
          nnz:        int
          al:         float
          au:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlpaddlc2dense'></a><h3 class=pageheader><code>minlpaddlc2dense</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends two-sided linear constraint  AL &lt;= A*x &lt;= AU  to the
# list of currently present constraints.
# 
# This version accepts dense constraint vector as input, but  sparsifies  it
# for internal storage and processing. Thus, time to add one  constraint  in
# is O(N) - we have to scan entire array of length N. Sparse version of this
# function is order of magnitude faster for  constraints  with  just  a  few
# nonzeros per row.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minlpcreate() call.
#     A       -   linear constraint coefficient, array[N], right side is NOT
#                 included.
#     AL, AU  -   lower and upper bounds;
#                 * AL=AU    =&gt; equality constraint Ai*x
#                 * AL&lt;AU    =&gt; two-sided constraint AL&lt;=A*x&lt;=AU
#                 * AL=-INF  =&gt; one-sided constraint Ai*x&lt;=AU
#                 * AU=+INF  =&gt; one-sided constraint AL&lt;=Ai*x
#                 * AL=-INF, AU=+INF =&gt; constraint is ignored
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlpaddlc2dense(state, a, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlpstate
          a:          1D array/list of float
          al:         float
          au:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlpcreate'></a><h3 class=pageheader><code>minlpcreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
#                             LINEAR PROGRAMMING
# 
# The subroutine creates LP  solver.  After  initial  creation  it  contains
# default optimization problem with zero cost vector and all variables being
# fixed to zero values and no constraints.
# 
# In order to actually solve something you should:
# * set cost vector with minlpsetcost()
# * set variable bounds with minlpsetbc() or minlpsetbcall()
# * specify constraint matrix with one of the following functions:
#   [*] minlpsetlc()        for dense one-sided constraints
#   [*] minlpsetlc2dense()  for dense two-sided constraints
#   [*] minlpsetlc2()       for sparse two-sided constraints
#   [*] minlpaddlc2dense()  to add one dense row to constraint matrix
#   [*] minlpaddlc2()       to add one row to constraint matrix (compressed format)
# * call minlpoptimize() to run the solver and  minlpresults()  to  get  the
#   solution vector and additional information.
# 
# By  default,  LP  solver uses best algorithm available. As of ALGLIB 3.17,
# sparse interior point (barrier) solver is used. Future releases of  ALGLIB
# may introduce other solvers.
# 
# User may choose specific LP algorithm by calling:
# * minlpsetalgodss() for revised dual simplex method with DSE  pricing  and
#   bounds flipping ratio test (aka long dual step).  Large-scale  sparse LU
#   solverwith  Forest-Tomlin update is used internally  as  linear  algebra
#   driver.
# * minlpsetalgoipm() for sparse interior point method
# 
# INPUT PARAMETERS:
#     N       -   problem size
# 
# OUTPUT PARAMETERS:
#     State   -   optimizer in the default state
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minlpcreate(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minlpstate

</div></pre>
<a name='sub_minlpoptimize'></a><h3 class=pageheader><code>minlpoptimize</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function solves LP problem.
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# You should use minlpresults() function to access results  after  calls  to
# this function.
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlpoptimize(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlpstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlpresults'></a><h3 class=pageheader><code>minlpresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# LP solver results
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     X       -   array[N], solution (on failure: last trial point)
#     Rep     -   optimization report. You should check Rep.TerminationType,
#                 which contains completion code, and you may check  another
#                 fields which contain another information  about  algorithm
#                 functioning.
# 
#                 Failure codes returned by algorithm are:
#                 * -4    LP problem is primal unbounded (dual infeasible)
#                 * -3    LP problem is primal infeasible (dual unbounded)
#                 * -2    IPM solver detected that problem is either
#                         infeasible or unbounded
# 
#                 Success codes:
#                 *  1..4 successful completion
#                 *  5    MaxIts steps was taken
# 
#   -- ALGLIB --
#      Copyright 11.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.minlpresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlpstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.minlpreport

</div></pre>
<a name='sub_minlpresultsbuf'></a><h3 class=pageheader><code>minlpresultsbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# LP results
# 
# Buffered implementation of MinLPResults() which uses pre-allocated  buffer
# to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
# intended to be used in the inner cycles of performance critical algorithms
# where array reallocation penalty is too large to be ignored.
# 
#   -- ALGLIB --
#      Copyright 11.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.minlpresultsbuf(state, x, rep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlpstate
          x:          1D array/list of float
          rep:        class xalglib.minlpreport
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> rep
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float

</div></pre>
<a name='sub_minlpsetalgodss'></a><h3 class=pageheader><code>minlpsetalgodss</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets LP algorithm to revised dual simplex method.
# 
# ALGLIB implementation of dual simplex method supports advanced performance
# and stability improvements like DSE pricing , bounds flipping  ratio  test
# (aka long dual step), Forest-Tomlin update, shifting.
# 
# INPUT PARAMETERS:
#     State   -   optimizer
#     Eps     -   stopping condition, Eps&gt;=0:
#                 * should be small number about 1E-6 or 1E-7.
#                 * zero value means that solver automatically selects good
#                   value (can be different in different ALGLIB versions)
#                 * default value is zero
#                 Algorithm stops when relative error is less than Eps.
# 
# ===== TRACING DSS SOLVER =================================================
# 
# DSS solver supports advanced tracing capabilities. You can trace algorithm
# output by specifying following trace symbols (case-insensitive)  by  means
# of trace_file() call:
# * 'DSS'         - for basic trace of algorithm  steps and decisions.  Only
#                   short scalars (function values and deltas) are  printed.
#                   N-dimensional quantities like search directions are  NOT
#                   printed.
# * 'DSS.DETAILED'- for output of points being visited and search directions
#                   This  symbol  also  implicitly  defines  'DSS'. You  can
#                   control output format by additionally specifying:
#                   * nothing     to output in  6-digit exponential format
#                   * 'PREC.E15'  to output in 15-digit exponential format
#                   * 'PREC.F6'   to output in  6-digit fixed-point format
# 
# By default trace is disabled and adds  no  overhead  to  the  optimization
# process. However, specifying any of the symbols adds some  formatting  and
# output-related overhead.
# 
# You may specify multiple symbols by separating them with commas:
# &gt;
# &gt; alglib::trace_file(&quot;DSS,PREC.F6&quot;, &quot;path/to/trace.log&quot;)
# &gt;
# 
#   -- ALGLIB --
#      Copyright 08.11.2020 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlpsetalgodss(state, eps)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlpstate
          eps:        float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlpsetalgoipm'></a><h3 class=pageheader><code>minlpsetalgoipm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets LP algorithm to sparse interior point method.
# 
# ALGORITHM INFORMATION:
# 
# * this  algorithm  is  our implementation  of  interior  point  method  as
#   formulated by  R.J.Vanderbei, with minor modifications to the  algorithm
#   (damped Newton directions are extensively used)
# * like all interior point methods, this algorithm  tends  to  converge  in
#   roughly same number of iterations (between 15 and 50) independently from
#   the problem dimensionality
# 
# INPUT PARAMETERS:
#     State   -   optimizer
#     Eps     -   stopping condition, Eps&gt;=0:
#                 * should be small number about 1E-6 or 1E-8.
#                 * zero value means that solver automatically selects good
#                   value (can be different in different ALGLIB versions)
#                 * default value is zero
#                 Algorithm  stops  when  primal  error  AND  dual error AND
#                 duality gap are less than Eps.
# 
# ===== TRACING IPM SOLVER =================================================
# 
# IPM solver supports advanced tracing capabilities. You can trace algorithm
# output by specifying following trace symbols (case-insensitive)  by  means
# of trace_file() call:
# * 'IPM'         - for basic trace of algorithm  steps and decisions.  Only
#                   short scalars (function values and deltas) are  printed.
#                   N-dimensional quantities like search directions are  NOT
#                   printed.
# * 'IPM.DETAILED'- for output of points being visited and search directions
#                   This  symbol  also  implicitly  defines  'IPM'. You  can
#                   control output format by additionally specifying:
#                   * nothing     to output in  6-digit exponential format
#                   * 'PREC.E15'  to output in 15-digit exponential format
#                   * 'PREC.F6'   to output in  6-digit fixed-point format
# 
# By default trace is disabled and adds  no  overhead  to  the  optimization
# process. However, specifying any of the symbols adds some  formatting  and
# output-related overhead.
# 
# You may specify multiple symbols by separating them with commas:
# &gt;
# &gt; alglib::trace_file(&quot;IPM,PREC.F6&quot;, &quot;path/to/trace.log&quot;)
# &gt;
# 
#   -- ALGLIB --
#      Copyright 08.11.2020 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlpsetalgoipm(state, eps)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlpsetalgoipm(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlpstate
          eps:        float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlpsetbc'></a><h3 class=pageheader><code>minlpsetbc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets box constraints for LP solver (all variables  at  once,
# different constraints for different variables).
# 
# The default state of constraints is to have all variables fixed  at  zero.
# You have to overwrite it by your own constraint vector. Constraint  status
# is preserved until constraints are  explicitly  overwritten  with  another
# minlpsetbc()  call,   overwritten   with  minlpsetbcall(),  or   partially
# overwritten with minlmsetbci() call.
# 
# Following types of constraints are supported:
# 
#     DESCRIPTION         CONSTRAINT              HOW TO SPECIFY
#     fixed variable      x[i]=Bnd[i]             BndL[i]=BndU[i]
#     lower bound         BndL[i]&lt;=x[i]           BndU[i]=+INF
#     upper bound         x[i]&lt;=BndU[i]           BndL[i]=-INF
#     range               BndL[i]&lt;=x[i]&lt;=BndU[i]  ...
#     free variable       -                       BndL[I]=-INF, BndU[I]+INF
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     BndL    -   lower bounds, array[N].
#     BndU    -   upper bounds, array[N].
# 
# NOTE: infinite values can be specified by means of Double.PositiveInfinity
#       and  Double.NegativeInfinity  (in  C#)  and  alglib::fp_posinf   and
#       alglib::fp_neginf (in C++).
# 
# NOTE: you may replace infinities by very small/very large values,  but  it
#       is not recommended because large numbers may introduce large numerical
#       errors in the algorithm.
# 
# NOTE: if constraints for all variables are same you may use minlpsetbcall()
#       which allows to specify constraints without using arrays.
# 
# NOTE: BndL&gt;BndU will result in LP problem being recognized as infeasible.
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlpsetbc(state, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlpstate
          bndl:       1D array/list of float
          bndu:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlpsetbcall'></a><h3 class=pageheader><code>minlpsetbcall</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets box constraints for LP solver (all variables  at  once,
# same constraints for all variables)
# 
# The default state of constraints is to have all variables fixed  at  zero.
# You have to overwrite it by your own constraint vector. Constraint  status
# is preserved until constraints are  explicitly  overwritten  with  another
# minlpsetbc() call or partially overwritten with minlpsetbcall().
# 
# Following types of constraints are supported:
# 
#     DESCRIPTION         CONSTRAINT              HOW TO SPECIFY
#     fixed variable      x[i]=Bnd[i]             BndL[i]=BndU[i]
#     lower bound         BndL[i]&lt;=x[i]           BndU[i]=+INF
#     upper bound         x[i]&lt;=BndU[i]           BndL[i]=-INF
#     range               BndL[i]&lt;=x[i]&lt;=BndU[i]  ...
#     free variable       -                       BndL[I]=-INF, BndU[I]+INF
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     BndL    -   lower bound, same for all variables
#     BndU    -   upper bound, same for all variables
# 
# NOTE: infinite values can be specified by means of Double.PositiveInfinity
#       and  Double.NegativeInfinity  (in  C#)  and  alglib::fp_posinf   and
#       alglib::fp_neginf (in C++).
# 
# NOTE: you may replace infinities by very small/very large values,  but  it
#       is not recommended because large numbers may introduce large numerical
#       errors in the algorithm.
# 
# NOTE: minlpsetbc() can  be  used  to  specify  different  constraints  for
#       different variables.
# 
# NOTE: BndL&gt;BndU will result in LP problem being recognized as infeasible.
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlpsetbcall(state, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlpstate
          bndl:       float
          bndu:       float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlpsetbci'></a><h3 class=pageheader><code>minlpsetbci</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets box constraints for I-th variable (other variables are
# not modified).
# 
# The default state of constraints is to have all variables fixed  at  zero.
# You have to overwrite it by your own constraint vector.
# 
# Following types of constraints are supported:
# 
#     DESCRIPTION         CONSTRAINT              HOW TO SPECIFY
#     fixed variable      x[i]=Bnd[i]             BndL[i]=BndU[i]
#     lower bound         BndL[i]&lt;=x[i]           BndU[i]=+INF
#     upper bound         x[i]&lt;=BndU[i]           BndL[i]=-INF
#     range               BndL[i]&lt;=x[i]&lt;=BndU[i]  ...
#     free variable       -                       BndL[I]=-INF, BndU[I]+INF
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     I       -   variable index, in [0,N)
#     BndL    -   lower bound for I-th variable
#     BndU    -   upper bound for I-th variable
# 
# NOTE: infinite values can be specified by means of Double.PositiveInfinity
#       and  Double.NegativeInfinity  (in  C#)  and  alglib::fp_posinf   and
#       alglib::fp_neginf (in C++).
# 
# NOTE: you may replace infinities by very small/very large values,  but  it
#       is not recommended because large numbers may introduce large numerical
#       errors in the algorithm.
# 
# NOTE: minlpsetbc() can  be  used  to  specify  different  constraints  for
#       different variables.
# 
# NOTE: BndL&gt;BndU will result in LP problem being recognized as infeasible.
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlpsetbci(state, i, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlpstate
          i:          int
          bndl:       float
          bndu:       float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlpsetcost'></a><h3 class=pageheader><code>minlpsetcost</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets cost term for LP solver.
# 
# By default, cost term is zero.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     C       -   cost term, array[N].
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlpsetcost(state, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlpstate
          c:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlpsetlc'></a><h3 class=pageheader><code>minlpsetlc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets one-sided linear constraints A*x ~ AU, where &quot;~&quot; can be
# a mix of &quot;&lt;=&quot;, &quot;=&quot; and &quot;&gt;=&quot;.
# 
# IMPORTANT: this function is provided here for compatibility with the  rest
#            of ALGLIB optimizers which accept constraints  in  format  like
#            this one. Many real-life problems feature two-sided constraints
#            like a0 &lt;= a*x &lt;= a1. It is really inefficient to add them as a
#            pair of one-sided constraints.
# 
#            Use minlpsetlc2dense(), minlpsetlc2(), minlpaddlc2()  (or   its
#            sparse version) wherever possible.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minlpcreate() call.
#     A       -   linear constraints, array[K,N+1]. Each row of A represents
#                 one constraint, with first N elements being linear coefficients,
#                 and last element being right side.
#     CT      -   constraint types, array[K]:
#                 * if CT[i]&gt;0, then I-th constraint is A[i,*]*x &gt;= A[i,n]
#                 * if CT[i]=0, then I-th constraint is A[i,*]*x  = A[i,n]
#                 * if CT[i]&lt;0, then I-th constraint is A[i,*]*x &lt;= A[i,n]
#     K       -   number of equality/inequality constraints,  K&gt;=0;  if  not
#                 given, inferred from sizes of A and CT.
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlpsetlc(state, a, ct, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlpsetlc(state, a, ct)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlpstate
          a:          2D array/list of float
          ct:         1D array/list of int
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlpsetlc2'></a><h3 class=pageheader><code>minlpsetlc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  sets  two-sided linear  constraints  AL &lt;= A*x &lt;= AU  with
# sparse constraining matrix A. Recommended for large-scale problems.
# 
# This  function  overwrites  linear  (non-box)  constraints set by previous
# calls (if such calls were made).
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minlpcreate() call.
#     A       -   sparse matrix with size [K,N] (exactly!).
#                 Each row of A represents one general linear constraint.
#                 A can be stored in any sparse storage format.
#     AL, AU  -   lower and upper bounds, array[K];
#                 * AL[i]=AU[i] =&gt; equality constraint Ai*x
#                 * AL[i]&lt;AU[i] =&gt; two-sided constraint AL[i]&lt;=Ai*x&lt;=AU[i]
#                 * AL[i]=-INF  =&gt; one-sided constraint Ai*x&lt;=AU[i]
#                 * AU[i]=+INF  =&gt; one-sided constraint AL[i]&lt;=Ai*x
#                 * AL[i]=-INF, AU[i]=+INF =&gt; constraint is ignored
#     K       -   number  of equality/inequality constraints, K&gt;=0.  If  K=0
#                 is specified, A, AL, AU are ignored.
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlpsetlc2(state, a, al, au, k)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlpstate
          a:          class xalglib.sparsematrix
          al:         1D array/list of float
          au:         1D array/list of float
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlpsetlc2dense'></a><h3 class=pageheader><code>minlpsetlc2dense</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets two-sided linear constraints AL &lt;= A*x &lt;= AU.
# 
# This version accepts dense matrix as  input;  internally  LP  solver  uses
# sparse storage  anyway  (most  LP  problems  are  sparse),  but  for  your
# convenience it may accept dense inputs. This  function  overwrites  linear
# constraints set by previous calls (if such calls were made).
# 
# We recommend you to use sparse version of this function unless  you  solve
# small-scale LP problem (less than few hundreds of variables).
# 
# NOTE: there also exist several versions of this function:
#       * one-sided dense version which  accepts  constraints  in  the  same
#         format as one used by QP and  NLP solvers
#       * two-sided sparse version which accepts sparse matrix
#       * two-sided dense  version which allows you to add constraints row by row
#       * two-sided sparse version which allows you to add constraints row by row
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minlpcreate() call.
#     A       -   linear constraints, array[K,N]. Each row of  A  represents
#                 one  constraint. One-sided  inequality   constraints, two-
#                 sided inequality  constraints,  equality  constraints  are
#                 supported (see below)
#     AL, AU  -   lower and upper bounds, array[K];
#                 * AL[i]=AU[i] =&gt; equality constraint Ai*x
#                 * AL[i]&lt;AU[i] =&gt; two-sided constraint AL[i]&lt;=Ai*x&lt;=AU[i]
#                 * AL[i]=-INF  =&gt; one-sided constraint Ai*x&lt;=AU[i]
#                 * AU[i]=+INF  =&gt; one-sided constraint AL[i]&lt;=Ai*x
#                 * AL[i]=-INF, AU[i]=+INF =&gt; constraint is ignored
#     K       -   number of equality/inequality constraints,  K&gt;=0;  if  not
#                 given, inferred from sizes of A, AL, AU.
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlpsetlc2dense(state, a, al, au, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlpsetlc2dense(state, a, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlpstate
          a:          2D array/list of float
          al:         1D array/list of float
          au:         1D array/list of float
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minlpsetscale'></a><h3 class=pageheader><code>minlpsetscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets scaling coefficients.
# 
# ALGLIB optimizers use scaling matrices to test stopping  conditions and as
# preconditioner.
# 
# Scale of the I-th variable is a translation invariant measure of:
# a) &quot;how large&quot; the variable is
# b) how large the step should be to make significant changes in the
#    function
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     S       -   array[N], non-zero scaling coefficients
#                 S[i] may be negative, sign doesn't matter.
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minlpsetscale(state, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minlpstate
          s:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_minmo></a><h2 class=pageheader><code>minmo</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_minmoaddlc2' class=toc>minmoaddlc2</a><br>
<a href='#sub_minmoaddlc2dense' class=toc>minmoaddlc2dense</a><br>
<a href='#sub_minmoaddlc2sparsefromdense' class=toc>minmoaddlc2sparsefromdense</a><br>
<a href='#sub_minmocreate' class=toc>minmocreate</a><br>
<a href='#sub_minmocreatef' class=toc>minmocreatef</a><br>
<a href='#sub_minmorequesttermination' class=toc>minmorequesttermination</a><br>
<a href='#sub_minmorestartfrom' class=toc>minmorestartfrom</a><br>
<a href='#sub_minmoresults' class=toc>minmoresults</a><br>
<a href='#sub_minmosetalgonbi' class=toc>minmosetalgonbi</a><br>
<a href='#sub_minmosetbc' class=toc>minmosetbc</a><br>
<a href='#sub_minmosetcond' class=toc>minmosetcond</a><br>
<a href='#sub_minmosetlc2' class=toc>minmosetlc2</a><br>
<a href='#sub_minmosetlc2dense' class=toc>minmosetlc2dense</a><br>
<a href='#sub_minmosetlc2mixed' class=toc>minmosetlc2mixed</a><br>
<a href='#sub_minmosetnlc2' class=toc>minmosetnlc2</a><br>
<a href='#sub_minmosetscale' class=toc>minmosetscale</a><br>
<a href='#sub_minmosetxrep' class=toc>minmosetxrep</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_minmoaddlc2'></a><h3 class=pageheader><code>minmoaddlc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends two-sided linear constraint  AL &lt;= A*x &lt;= AU  to the
# list of sparse constraints.
# 
# Constraint is passed in the compressed  format:  as  a  list  of  non-zero
# entries of the coefficient vector A. Such approach is more efficient  than
# the dense storage for highly sparse constraint vectors.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minmocreate() call.
#     IdxA    -   array[NNZ], indexes of non-zero elements of A:
#                 * can be unsorted
#                 * can include duplicate indexes (corresponding entries  of
#                   ValA[] will be summed)
#     ValA    -   array[NNZ], values of non-zero elements of A
#     NNZ     -   number of non-zero coefficients in A
#     AL, AU  -   lower and upper bounds;
#                 * AL=AU    =&gt; equality constraint A*x
#                 * AL&lt;AU    =&gt; two-sided constraint AL&lt;=A*x&lt;=AU
#                 * AL=-INF  =&gt; one-sided constraint A*x&lt;=AU
#                 * AU=+INF  =&gt; one-sided constraint AL&lt;=A*x
#                 * AL=-INF, AU=+INF =&gt; constraint is ignored
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minmoaddlc2(state, idxa, vala, nnz, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minmostate
          idxa:       1D array/list of int
          vala:       1D array/list of float
          nnz:        int
          al:         float
          au:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minmoaddlc2dense'></a><h3 class=pageheader><code>minmoaddlc2dense</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends two-sided linear  constraint  AL&lt;=A*x&lt;=AU  to  dense
# constraints list.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minmocreate() call.
#     A       -   linear constraint coefficient, array[N], right side is NOT
#                 included.
#     AL, AU  -   lower and upper bounds;
#                 * AL=AU    =&gt; equality constraint Ai*x
#                 * AL&lt;AU    =&gt; two-sided constraint AL&lt;=A*x&lt;=AU
#                 * AL=-INF  =&gt; one-sided constraint Ai*x&lt;=AU
#                 * AU=+INF  =&gt; one-sided constraint AL&lt;=Ai*x
#                 * AL=-INF, AU=+INF =&gt; constraint is ignored
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minmoaddlc2dense(state, a, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minmostate
          a:          1D array/list of float
          al:         float
          au:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minmoaddlc2sparsefromdense'></a><h3 class=pageheader><code>minmoaddlc2sparsefromdense</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends two-sided linear constraint  AL &lt;= A*x &lt;= AU  to the
# list of currently present sparse constraints.
# 
# Constraint vector A is  passed  as  a  dense  array  which  is  internally
# sparsified by this function.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minmocreate() call.
#     DA      -   array[N], constraint vector
#     AL, AU  -   lower and upper bounds;
#                 * AL=AU    =&gt; equality constraint A*x
#                 * AL&lt;AU    =&gt; two-sided constraint AL&lt;=A*x&lt;=AU
#                 * AL=-INF  =&gt; one-sided constraint A*x&lt;=AU
#                 * AU=+INF  =&gt; one-sided constraint AL&lt;=A*x
#                 * AL=-INF, AU=+INF =&gt; constraint is ignored
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minmoaddlc2sparsefromdense(state, da, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minmostate
          da:         1D array/list of float
          al:         float
          au:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minmocreate'></a><h3 class=pageheader><code>minmocreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
#                     MULTI-OBJECTIVE  OPTIMIZATION
# 
# DESCRIPTION:
# 
# The  solver  minimizes an M-dimensional vector function F(x) of N arguments
# subject to any combination of:
# * box constraints
# * two-sided linear equality/inequality constraints AL&lt;=A*x&lt;=AU, where some
#   of AL/AU can be infinite (i.e. missing)
# * two-sided nonlinear equality/inequality constraints NL&lt;=C(x)&lt;=NU,  where
#   some of NL/NU can be infinite (i.e. missing)
# 
# REQUIREMENTS:
# * F(), C() are continuously differentiable on the feasible set and on  its
#   neighborhood
# 
# USAGE:
# 
# 1. User initializes algorithm state using either:
#    * minmocreate()  to perform optimization with user-supplied Jacobian
#    * minmocreatef() to perform optimization with numerical differentiation
# 
# 2. User chooses which multi-objective solver to use. At the present moment
#    only NBI (Normal Boundary Intersection) solver is implemented, which is
#    activated by calling minmosetalgonbi().
# 
# 3. User adds boundary and/or linear and/or nonlinear constraints by  means
#    of calling one of the following functions:
#    a) minmosetbc() for boundary constraints
#    b) minmosetlc2()      for two-sided sparse linear constraints;
#       minmosetlc2dense() for two-sided dense  linear constraints;
#       minmosetlc2mixed() for two-sided mixed sparse/dense constraints
#    c) minmosetnlc2()     for two-sided nonlinear constraints
#    You may combine (a), (b) and (c) in one optimization problem.
# 
# 4. User sets scale of the variables with minmosetscale() function.  It  is
#    VERY important to set  scale  of  the  variables,  because  nonlinearly
#    constrained problems are hard to solve when variables are badly scaled.
# 
# 5. User sets  stopping  conditions  with  minmosetcond().
# 
# 6. Finally, user calls minmooptimize()   function  which  takes  algorithm
#    state  and  pointers  (delegate, etc.) to the callback functions  which
#    calculate F/C
# 
# 7. User calls  minmoresults()  to  get the solution
# 
# 8. Optionally user may call minmorestartfrom() to solve  another   problem
#    with same M,N but another starting point. minmorestartfrom() allows  to
#    reuse an already initialized optimizer structure.
# 
# 
# INPUT PARAMETERS:
#     N       -   variables count, N&gt;0:
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from the size of X
#     M       -   objectives count, M&gt;0.
#                 M=1 is possible, although makes little sense - it is better
#                 to use MinNLC directly.
#     X       -   starting point, array[N]:
#                 * it is better to set X to a feasible point
#                 * but X can be infeasible, in which case algorithm will try
#                   to reinforce feasibility during  initial  stages  of  the
#                   optimization
# 
# OUTPUT PARAMETERS:
#     State   -   structure that stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 01.03.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minmocreate(n, m, x)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minmocreate(m, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          m:          int
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minmostate

</div></pre>
<a name='sub_minmocreatef'></a><h3 class=pageheader><code>minmocreatef</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine is a finite  difference variant of minmocreate().  It uses
# finite differences in order to differentiate target function.
# 
# Description below contains information which is specific to this  function
# only. We recommend to read comments on minmocreate() too.
# 
# INPUT PARAMETERS:
#     N       -   variables count, N&gt;0:
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from the size of X
#     M       -   objectives count, M&gt;0.
#                 M=1 is possible, although makes little sense - it is better
#                 to use MinNLC directly.
#     X       -   starting point, array[N]:
#                 * it is better to set X to a feasible point
#                 * but X can be infeasible, in which case algorithm will try
#                   to reinforce feasibility during  initial  stages  of  the
#                   optimization
#     DiffStep-   differentiation step, &gt;0
# 
# OUTPUT PARAMETERS:
#     State   -   structure that stores algorithm state
# 
# NOTES:
# 1. algorithm uses 4-point central formula for differentiation.
# 2. differentiation step along I-th axis is equal to DiffStep*S[I] where
#    S[] is a scaling vector which can be set by minmosetscale() call.
# 3. we recommend you to use moderate values of  differentiation  step.  Too
#    large step means too large TRUNCATION errors,  whilst  too  small  step
#    means too large NUMERICAL errors.
#    1.0E-4 can be good value to start from for a unit-scaled problem.
# 4. Numerical  differentiation  is   very   inefficient  -   one   gradient
#    calculation needs 4*N function evaluations. This function will work for
#    any N - either small (1...10), moderate (10...100) or  large  (100...).
#    However, performance penalty will be too severe for any N's except  for
#    small ones.
#    We should also say that code which relies on numerical  differentiation
#    is  less   robust   and  precise.  Imprecise  gradient  may  slow  down
#    convergence, especially on highly nonlinear problems.
#    Thus  we  recommend to use this function for fast prototyping on small-
#    dimensional problems only, and to implement analytical gradient as soon
#    as possible.
# 
#   -- ALGLIB --
#      Copyright 01.03.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minmocreatef(n, m, x, diffstep)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minmocreatef(m, x, diffstep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          m:          int
          x:          1D array/list of float
          diffstep:   float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minmostate

</div></pre>
<a name='sub_minmorequesttermination'></a><h3 class=pageheader><code>minmorequesttermination</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine  submits  request  for  the  termination  of  the  running
# optimizer.
# 
# It should be called from the user-supplied callback when user decides that
# it is time to &quot;smoothly&quot; terminate optimization process, or from some other
# thread. As a result, optimizer stops  at  the  state  which  was  &quot;current
# accepted&quot; when termination request was submitted and returns error code  8
# (successful termination).
# 
# Usually it results in an incomplete Pareto front being returned.
# 
# INPUT PARAMETERS:
#     State   -   optimizer structure
# 
# NOTE: after  request  for  termination  optimizer  may   perform   several
#       additional calls to user-supplied callbacks. It does  NOT  guarantee
#       to stop immediately - it just guarantees that these additional calls
#       will be discarded later.
# 
# NOTE: calling this function on optimizer which is NOT running will have no
#       effect.
# 
# NOTE: multiple calls to this function are possible. First call is counted,
#       subsequent calls are silently ignored.
# 
#   -- ALGLIB --
#      Copyright 01.03.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minmorequesttermination(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minmostate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minmorestartfrom'></a><h3 class=pageheader><code>minmorestartfrom</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine restarts algorithm from the new point.
# All optimization parameters (including constraints) are left unchanged.
# 
# This  function  allows  to  solve multiple  optimization  problems  (which
# must have  same number of dimensions) without object reallocation penalty.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with MinMOCreate call.
#     X       -   new starting point.
# 
#   -- ALGLIB --
#      Copyright 01.03.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minmorestartfrom(state, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minmostate
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minmoresults'></a><h3 class=pageheader><code>minmoresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# MinMO results:  the  solution  found,  completion  codes  and   additional
# information.
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     ParetoFront-array[FrontSize,N+M], approximate Pareto front.
#                 Its columns have the following structure:
#                 * first N columns are variable values
#                 * next  M columns are objectives at these points
#                 Its rows have the following structure:
#                 * first M rows contain solutions to single-objective tasks
#                   with I-th row storing result for  I-th  objective  being
#                   minimized ignoring other ones.
#                   Thus, ParetoFront[I,N+I] for  0&lt;=I&lt;M  stores  so  called
#                   'ideal objective vector'.
#                 * subsequent FrontSize-M rows  store  variables/objectives
#                   at  various  randomly  and  nearly   uniformly   sampled
#                   locations of the Pareto front.
# 
#     FrontSize-  front size, &gt;=0.
#                 * no larger than the number passed to setalgo()
#                 * for  a  single-objective  task,  FrontSize=1  is  ALWAYS
#                   returned, no matter what was specified during setalgo()
#                   call.
#                 * if  the   solver   was   prematurely   terminated   with
#                   minnorequesttermination(), an  incomplete  Pareto  front
#                   will be returned (it may even have less than M rows)
#                 * if a  failure (negative completion code) was   signaled,
#                   FrontSize=0 will be returned
# 
#     Rep     -   optimization report, contains information about completion
#                 code, constraint violation at the solution and so on.
# 
#                 You   should   check   rep.terminationtype  in  order   to
#                 distinguish successful termination from unsuccessful one:
# 
#                 === FAILURE CODES ===
#                 * -8    internal  integrity control  detected  infinite or
#                         NAN   values    in   function/gradient.   Abnormal
#                         termination signalled.
#                 * -3    constraint bounds are  infeasible,  i.e.  we  have
#                         box/linear/nonlinear constraint  with  two  bounds
#                         present, and a lower one being  greater  than  the
#                         upper one.
#                         Note: less obvious infeasibilities of  constraints
#                               do NOT  trigger  emergency  completion;  you
#                               have to examine rep.bcerr/rep.lcerr/rep.nlcerr
#                               to detect possibly inconsistent constraints.
# 
#                 === SUCCESS CODES ===
#                 *  2   scaled step is no more than EpsX.
#                 *  5   MaxIts steps were taken.
#                 *  8   user   requested    algorithm    termination    via
#                        minmorequesttermination(), last accepted point   is
#                        returned.
# 
#                 More information about fields of this  structure  can  be
#                 found in the comments on minmoreport datatype.
# 
#   -- ALGLIB --
#      Copyright 01.03.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   paretofront, frontsize, rep = xalglib.minmoresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minmostate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  paretofront: 2D array/list of float
          frontsize:  int
          rep:        class xalglib.minmoreport

</div></pre>
<a name='sub_minmosetalgonbi'></a><h3 class=pageheader><code>minmosetalgonbi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Use the NBI (Normal Boundary Intersection)  algorithm  for  multiobjective
# optimization.
# 
# NBI is a simple yet powerful multiobjective  optimization  algorithm  that
# has the following attractive properties:
# * it generates nearly uniformly distributed Pareto points
# * it is applicable to problems with more than 2 objectives
# * it naturally supports a mix of box, linear and nonlinear constraints
# * it is less sensitive to the bad scaling of the targets
# 
# The only drawback of the algorithm is that for more than 2  objectives  it
# can miss some small parts of the Pareto front that are  located  near  its
# boundaries.
# 
# INPUT PARAMETERS:
#     State       -   structure which stores algorithm state
#     FrontSize   -   desired Pareto front size, FrontSize&gt;=M,
#                     where M is an objectives count
#     PolishSolutions-whether additional solution improving phase is needed
#                     or not:
#                     * if False, the original NBI as formulated  by Das and
#                       Dennis is used. It quickly produces  good solutions,
#                       but these solutions can be suboptimal (usually within
#                       0.1% of the optimal values).
#                       The reason is that the original NBI formulation does
#                       not account for  degeneracies that allow significant
#                       progress for one objective with no deterioration for
#                       other objectives.
#                     * if True,  the  original  NBI  is  followed  by   the
#                       additional solution  polishing  phase.  This  solver
#                       mode is several times slower than the original  NBI,
#                       but produces better solutions.
# 
#   -- ALGLIB --
#      Copyright 20.03.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minmosetalgonbi(state, frontsize, polishsolutions)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minmostate
          frontsize:  int
          polishsolutions: bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minmosetbc'></a><h3 class=pageheader><code>minmosetbc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets boundary constraints for the MO optimizer.
# 
# Boundary constraints are inactive by  default  (after  initial  creation).
# They are preserved after algorithm restart with MinMORestartFrom().
# 
# You may combine boundary constraints with  general  linear ones - and with
# nonlinear ones! Boundary constraints are  handled  more  efficiently  than
# other types.  Thus,  if  your  problem  has  mixed  constraints,  you  may
# explicitly specify some of them as boundary and save some time/space.
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     BndL    -   lower bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 a very small number or -INF.
#     BndU    -   upper bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 a very large number or +INF.
# 
# NOTE 1:  it is possible to specify  BndL[i]=BndU[i].  In  this  case  I-th
# variable will be &quot;frozen&quot; at X[i]=BndL[i]=BndU[i].
# 
#   -- ALGLIB --
#      Copyright 01.03.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minmosetbc(state, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minmostate
          bndl:       1D array/list of float
          bndu:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minmosetcond'></a><h3 class=pageheader><code>minmosetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping conditions for inner iterations of the optimizer.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     EpsX    -   &gt;=0
#                 The subroutine finishes its work if  on  k+1-th  iteration
#                 the condition |v|&lt;=EpsX is fulfilled, where:
#                 * |.| means Euclidian norm
#                 * v - scaled step vector, v[i]=dx[i]/s[i]
#                 * dx - step vector, dx=X(k+1)-X(k)
#                 * s - scaling coefficients set by MinMOSetScale()
#     MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
#                 iterations is unlimited.
# 
# Passing EpsX=0 and MaxIts=0 (simultaneously) will lead to an automatic
# selection of the stopping condition.
# 
#   -- ALGLIB --
#      Copyright 01.03.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minmosetcond(state, epsx, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minmostate
          epsx:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minmosetlc2'></a><h3 class=pageheader><code>minmosetlc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  sets  two-sided linear  constraints  AL &lt;= A*x &lt;= AU  with
# sparse constraining matrix A. Recommended for large-scale problems.
# 
# This  function  overwrites  linear  (non-box)  constraints set by previous
# calls (if such calls were made).
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minmocreate() call.
#     A       -   sparse matrix with size [K,N] (exactly!).
#                 Each row of A represents one general linear constraint.
#                 A can be stored in any sparse storage format.
#     AL, AU  -   lower and upper bounds, array[K];
#                 * AL[i]=AU[i] =&gt; equality constraint Ai*x
#                 * AL[i]&lt;AU[i] =&gt; two-sided constraint AL[i]&lt;=Ai*x&lt;=AU[i]
#                 * AL[i]=-INF  =&gt; one-sided constraint Ai*x&lt;=AU[i]
#                 * AU[i]=+INF  =&gt; one-sided constraint AL[i]&lt;=Ai*x
#                 * AL[i]=-INF, AU[i]=+INF =&gt; constraint is ignored
#     K       -   number  of equality/inequality constraints, K&gt;=0.  If  K=0
#                 is specified, A, AL, AU are ignored.
# 
#   -- ALGLIB --
#      Copyright 01.11.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minmosetlc2(state, a, al, au, k)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minmostate
          a:          class xalglib.sparsematrix
          al:         1D array/list of float
          au:         1D array/list of float
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minmosetlc2dense'></a><h3 class=pageheader><code>minmosetlc2dense</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets two-sided linear constraints AL &lt;= A*x &lt;= AU with dense
# constraint matrix A.
# 
# NOTE: knowing  that  constraint  matrix  is dense may help some MO solvers
#       to utilize efficient dense Level 3  BLAS  for  dense  parts  of  the
#       problem. If your problem has both dense and sparse constraints,  you
#       can use minmosetlc2mixed() function.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minmocreate() call.
#     A       -   linear constraints, array[K,N]. Each row of  A  represents
#                 one  constraint. One-sided  inequality   constraints, two-
#                 sided inequality  constraints,  equality  constraints  are
#                 supported (see below)
#     AL, AU  -   lower and upper bounds, array[K];
#                 * AL[i]=AU[i] =&gt; equality constraint Ai*x
#                 * AL[i]&lt;AU[i] =&gt; two-sided constraint AL[i]&lt;=Ai*x&lt;=AU[i]
#                 * AL[i]=-INF  =&gt; one-sided constraint Ai*x&lt;=AU[i]
#                 * AU[i]=+INF  =&gt; one-sided constraint AL[i]&lt;=Ai*x
#                 * AL[i]=-INF, AU[i]=+INF =&gt; constraint is ignored
#     K       -   number of equality/inequality constraints,  K&gt;=0;  if  not
#                 given, inferred from sizes of A, AL, AU.
# 
#   -- ALGLIB --
#      Copyright 01.03.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minmosetlc2dense(state, a, al, au, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minmosetlc2dense(state, a, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minmostate
          a:          2D array/list of float
          al:         1D array/list of float
          au:         1D array/list of float
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minmosetlc2mixed'></a><h3 class=pageheader><code>minmosetlc2mixed</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  sets  two-sided linear  constraints  AL &lt;= A*x &lt;= AU  with
# mixed constraining matrix A including sparse part (first SparseK rows) and
# dense part (last DenseK rows). Recommended for large-scale problems.
# 
# This  function  overwrites  linear  (non-box)  constraints set by previous
# calls (if such calls were made).
# 
# This function may be useful if constraint matrix includes large number  of
# both types of rows - dense and sparse. If you have just a few sparse rows,
# you  may  represent  them  in  dense  format  without losing  performance.
# Similarly, if you have just a few dense rows,  you  can  store them in the
# sparse format with almost same performance.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minmocreate() call.
#     SparseA -   sparse matrix with size [K,N] (exactly!).
#                 Each row of A represents one general linear constraint.
#                 A can be stored in any sparse storage format.
#     SparseK -   number of sparse constraints, SparseK&gt;=0
#     DenseA  -   linear constraints, array[K,N], set of dense constraints.
#                 Each row of A represents one general linear constraint.
#     DenseK  -   number of dense constraints, DenseK&gt;=0
#     AL, AU  -   lower and upper bounds, array[SparseK+DenseK], with former
#                 SparseK elements corresponding to sparse constraints,  and
#                 latter DenseK elements corresponding to dense constraints;
#                 * AL[i]=AU[i] =&gt; equality constraint Ai*x
#                 * AL[i]&lt;AU[i] =&gt; two-sided constraint AL[i]&lt;=Ai*x&lt;=AU[i]
#                 * AL[i]=-INF  =&gt; one-sided constraint Ai*x&lt;=AU[i]
#                 * AU[i]=+INF  =&gt; one-sided constraint AL[i]&lt;=Ai*x
#                 * AL[i]=-INF, AU[i]=+INF =&gt; constraint is ignored
#     K       -   number  of equality/inequality constraints, K&gt;=0.  If  K=0
#                 is specified, A, AL, AU are ignored.
# 
#   -- ALGLIB --
#      Copyright 01.11.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minmosetlc2mixed(state, sparsea, ksparse, densea, kdense, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minmostate
          sparsea:    class xalglib.sparsematrix
          ksparse:    int
          densea:     2D array/list of float
          kdense:     int
          al:         1D array/list of float
          au:         1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minmosetnlc2'></a><h3 class=pageheader><code>minmosetnlc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets two-sided nonlinear constraints for MinMO optimizer.
# 
# In fact, this function sets  only  constraints  COUNT  and  their  BOUNDS.
# Constraints  themselves  (constraint  functions)   are   passed   to   the
# MinMOOptimize() method as callbacks.
# 
# MinMOOptimize() method accepts a user-defined vector function F[]  and its
# Jacobian J[], where:
# * first M components of F[]  and  first  M rows  of  J[]   correspond   to
#   multiple objectives
# * subsequent NNLC components of F[] (and rows of J[]) correspond  to  two-
#   sided nonlinear constraints NL&lt;=C(x)&lt;=NU, where
#   * NL[i]=NU[i] =&gt; I-th row is an equality constraint Ci(x)=NL
#   * NL[i]&lt;NU[i] =&gt; I-th tow is a  two-sided constraint NL[i]&lt;=Ci(x)&lt;=NU[i]
#   * NL[i]=-INF  =&gt; I-th row is an one-sided constraint Ci(x)&lt;=NU[i]
#   * NU[i]=+INF  =&gt; I-th row is an one-sided constraint NL[i]&lt;=Ci(x)
#   * NL[i]=-INF, NU[i]=+INF =&gt; constraint is ignored
# 
# NOTE: you may combine nonlinear constraints with linear/boundary ones.  If
#       your problem has mixed constraints, you  may explicitly specify some
#       of them as linear or box ones.
#       It helps optimizer to handle them more efficiently.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with MinMOCreate call.
#     NL      -   array[NNLC], lower bounds, can contain -INF
#     NU      -   array[NNLC], lower bounds, can contain +INF
#     NNLC    -   constraints count, NNLC&gt;=0
# 
# NOTE 1: nonlinear constraints are satisfied only  approximately!   It   is
#         possible that the algorithm will evaluate the function  outside of
#         the feasible area!
# 
# NOTE 2: algorithm scales variables  according  to the scale  specified by
#         MinMOSetScale()  function,  so  it can handle problems with badly
#         scaled variables (as long as we KNOW their scales).
# 
#         However,  there  is  no  way  to  automatically  scale   nonlinear
#         constraints. Inappropriate scaling  of nonlinear  constraints  may
#         ruin convergence. Solving problem with  constraint  &quot;1000*G0(x)=0&quot;
#         is NOT the same as solving it with constraint &quot;0.001*G0(x)=0&quot;.
# 
#         It means that YOU are  the  one who is responsible for the correct
#         scaling of the nonlinear constraints Gi(x) and Hi(x). We recommend
#         you to scale nonlinear constraints in such a way that the Jacobian
#         rows have approximately unit magnitude  (for  problems  with  unit
#         scale) or have magnitude approximately equal to 1/S[i] (where S is
#         a scale set by MinMOSetScale() function).
# 
#   -- ALGLIB --
#      Copyright 01.03.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minmosetnlc2(state, nl, nu, nnlc)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minmostate
          nl:         1D array/list of float
          nu:         1D array/list of float
          nnlc:       int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minmosetscale'></a><h3 class=pageheader><code>minmosetscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets scaling coefficients for the MO optimizer.
# 
# ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
# size and gradient are scaled before comparison with tolerances).  Scale of
# the I-th variable is a translation invariant measure of:
# a) &quot;how large&quot; the variable is
# b) how large the step should be to make significant changes in the function
# 
# Scaling is also used by finite difference variant of the optimizer  - step
# along I-th axis is equal to DiffStep*S[I].
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     S       -   array[N], non-zero scaling coefficients
#                 S[i] may be negative, sign doesn't matter.
# 
#   -- ALGLIB --
#      Copyright 01.03.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minmosetscale(state, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minmostate
          s:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minmosetxrep'></a><h3 class=pageheader><code>minmosetxrep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function turns on/off reporting of the Pareto front points.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     NeedXRep-   whether iteration reports are needed or not
# 
# If NeedXRep is True, algorithm will call rep() callback  function  (if  it
# was provided to MinMOOptimize) every time we find a Pareto front point.
# 
# NOTE: according to the communication protocol used by ALGLIB,  the  solver
#       passes two parameters to the rep() callback - a current point and  a
#       target value at the current point.
#       However, because  we solve a  multi-objective  problem,  the  target
#       parameter is not used and set to zero.
# 
#   -- ALGLIB --
#      Copyright 01.03.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minmosetxrep(state, needxrep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minmostate
          needxrep:   bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_minnlc></a><h2 class=pageheader><code>minnlc</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_minnlcaddlc2' class=toc>minnlcaddlc2</a><br>
<a href='#sub_minnlcaddlc2dense' class=toc>minnlcaddlc2dense</a><br>
<a href='#sub_minnlcaddlc2sparsefromdense' class=toc>minnlcaddlc2sparsefromdense</a><br>
<a href='#sub_minnlccreate' class=toc>minnlccreate</a><br>
<a href='#sub_minnlccreatebuf' class=toc>minnlccreatebuf</a><br>
<a href='#sub_minnlccreatef' class=toc>minnlccreatef</a><br>
<a href='#sub_minnlccreatefbuf' class=toc>minnlccreatefbuf</a><br>
<a href='#sub_minnlcoptguardgradient' class=toc>minnlcoptguardgradient</a><br>
<a href='#sub_minnlcoptguardnonc1test0results' class=toc>minnlcoptguardnonc1test0results</a><br>
<a href='#sub_minnlcoptguardnonc1test1results' class=toc>minnlcoptguardnonc1test1results</a><br>
<a href='#sub_minnlcoptguardresults' class=toc>minnlcoptguardresults</a><br>
<a href='#sub_minnlcoptguardsmoothness' class=toc>minnlcoptguardsmoothness</a><br>
<a href='#sub_minnlcrequesttermination' class=toc>minnlcrequesttermination</a><br>
<a href='#sub_minnlcrestartfrom' class=toc>minnlcrestartfrom</a><br>
<a href='#sub_minnlcresults' class=toc>minnlcresults</a><br>
<a href='#sub_minnlcresultsbuf' class=toc>minnlcresultsbuf</a><br>
<a href='#sub_minnlcsetalgoaul2' class=toc>minnlcsetalgoaul2</a><br>
<a href='#sub_minnlcsetalgoorbit' class=toc>minnlcsetalgoorbit</a><br>
<a href='#sub_minnlcsetalgosl1qp' class=toc>minnlcsetalgosl1qp</a><br>
<a href='#sub_minnlcsetalgosl1qpbfgs' class=toc>minnlcsetalgosl1qpbfgs</a><br>
<a href='#sub_minnlcsetalgosqp' class=toc>minnlcsetalgosqp</a><br>
<a href='#sub_minnlcsetalgosqpbfgs' class=toc>minnlcsetalgosqpbfgs</a><br>
<a href='#sub_minnlcsetbc' class=toc>minnlcsetbc</a><br>
<a href='#sub_minnlcsetcond' class=toc>minnlcsetcond</a><br>
<a href='#sub_minnlcsetcond3' class=toc>minnlcsetcond3</a><br>
<a href='#sub_minnlcsetlc' class=toc>minnlcsetlc</a><br>
<a href='#sub_minnlcsetlc2' class=toc>minnlcsetlc2</a><br>
<a href='#sub_minnlcsetlc2dense' class=toc>minnlcsetlc2dense</a><br>
<a href='#sub_minnlcsetlc2mixed' class=toc>minnlcsetlc2mixed</a><br>
<a href='#sub_minnlcsetnlc' class=toc>minnlcsetnlc</a><br>
<a href='#sub_minnlcsetnlc2' class=toc>minnlcsetnlc2</a><br>
<a href='#sub_minnlcsetnumdiff' class=toc>minnlcsetnumdiff</a><br>
<a href='#sub_minnlcsetscale' class=toc>minnlcsetscale</a><br>
<a href='#sub_minnlcsetstpmax' class=toc>minnlcsetstpmax</a><br>
<a href='#sub_minnlcsetxrep' class=toc>minnlcsetxrep</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_minnlcaddlc2'></a><h3 class=pageheader><code>minnlcaddlc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends two-sided linear constraint  AL &lt;= A*x &lt;= AU  to the
# list of currently present sparse constraints.
# 
# Constraint is passed in compressed format: as list of non-zero entries  of
# coefficient vector A. Such approach is more efficient than  dense  storage
# for highly sparse constraint vectors.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minnlccreate() call.
#     IdxA    -   array[NNZ], indexes of non-zero elements of A:
#                 * can be unsorted
#                 * can include duplicate indexes (corresponding entries  of
#                   ValA[] will be summed)
#     ValA    -   array[NNZ], values of non-zero elements of A
#     NNZ     -   number of non-zero coefficients in A
#     AL, AU  -   lower and upper bounds;
#                 * AL=AU    =&gt; equality constraint A*x
#                 * AL&lt;AU    =&gt; two-sided constraint AL&lt;=A*x&lt;=AU
#                 * AL=-INF  =&gt; one-sided constraint A*x&lt;=AU
#                 * AU=+INF  =&gt; one-sided constraint AL&lt;=A*x
#                 * AL=-INF, AU=+INF =&gt; constraint is ignored
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcaddlc2(state, idxa, vala, nnz, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          idxa:       1D array/list of int
          vala:       1D array/list of float
          nnz:        int
          al:         float
          au:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcaddlc2dense'></a><h3 class=pageheader><code>minnlcaddlc2dense</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends a two-sided linear constraint AL &lt;= A*x &lt;= AU to the
# matrix of dense constraints.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minnlccreate() call.
#     A       -   linear constraint coefficient, array[N], right side is NOT
#                 included.
#     AL, AU  -   lower and upper bounds;
#                 * AL=AU    =&gt; equality constraint Ai*x
#                 * AL&lt;AU    =&gt; two-sided constraint AL&lt;=A*x&lt;=AU
#                 * AL=-INF  =&gt; one-sided constraint Ai*x&lt;=AU
#                 * AU=+INF  =&gt; one-sided constraint AL&lt;=Ai*x
#                 * AL=-INF, AU=+INF =&gt; constraint is ignored
# 
#   -- ALGLIB --
#      Copyright 15.04.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcaddlc2dense(state, a, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          a:          1D array/list of float
          al:         float
          au:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcaddlc2sparsefromdense'></a><h3 class=pageheader><code>minnlcaddlc2sparsefromdense</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends two-sided linear constraint  AL &lt;= A*x &lt;= AU  to the
# list of currently present sparse constraints.
# 
# Constraint vector A is  passed  as  a  dense  array  which  is  internally
# sparsified by this function.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minnlccreate() call.
#     DA      -   array[N], constraint vector
#     AL, AU  -   lower and upper bounds;
#                 * AL=AU    =&gt; equality constraint A*x
#                 * AL&lt;AU    =&gt; two-sided constraint AL&lt;=A*x&lt;=AU
#                 * AL=-INF  =&gt; one-sided constraint A*x&lt;=AU
#                 * AU=+INF  =&gt; one-sided constraint AL&lt;=A*x
#                 * AL=-INF, AU=+INF =&gt; constraint is ignored
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcaddlc2sparsefromdense(state, da, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          da:         1D array/list of float
          al:         float
          au:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlccreate'></a><h3 class=pageheader><code>minnlccreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
#                   NONLINEARLY  CONSTRAINED  OPTIMIZATION
# 
# DESCRIPTION:
# The  subroutine  minimizes a function  F(x)  of N arguments subject to the
# any combination of the:
# * bound constraints
# * linear inequality constraints
# * linear equality constraints
# * nonlinear equality constraints Gi(x)=0
# * nonlinear inequality constraints Hi(x)&lt;=0
# 
# REQUIREMENTS:
# * the user must provide callback calculating F(), H(), G()  -  either both
#   value and gradient, or merely a value (numerical differentiation will be
#   used)
# * F(), G(), H() are continuously differentiable on the  feasible  set  and
#   its neighborhood
# * starting point X0, which can be infeasible
# 
# USAGE:
# 
# Here we give the very brief outline  of  the MinNLC optimizer. We strongly
# recommend you to study examples in the ALGLIB Reference Manual and to read
# ALGLIB User Guide: https://www.alglib.net/nonlinear-programming/
# 
# 1. The user initializes the solver with minnlccreate() or  minnlccreatef()
#    (the latter is used for numerical  differentiation)  call  and  chooses
#    which NLC solver to use.
# 
#    In the current release the following solvers can be used:
# 
#    * sparse large-scale filter-based SQP solver, recommended  for problems
#      of any size (from several variables to thousands  of  variables).
#      Activated with minnlcsetalgosqp() function.
# 
#    * dense SQP-BFGS solver, recommended  for small-scale problems  (up  to
#      several hundreds of variables) with a very expensive target function.
#      Requires less function  evaluations than SQP, but has more  expensive
#      iteration. Activated with minnlcsetalgosqpbfgs() function.
# 
#    * ORBIT, a model-based derivative  free  solver  that  uses  local  RBF
#      models to optimize expensive objectives.  This  solver  is  activated
#      with minnlcsetalgoorbit() function.
# 
#    * several other solvers, including legacy ones
# 
# 2. [optional] user activates OptGuard  integrity checker  which  tries  to
#    detect possible errors in the user-supplied callbacks:
#    * discontinuity/nonsmoothness of the target/nonlinear constraints
#    * errors in the analytic gradient provided by user
#    This feature is essential for early prototyping stages because it helps
#    to catch common coding and problem statement errors.
#    OptGuard can be activated with following functions (one per each  check
#    performed):
#    * minnlcoptguardsmoothness()
#    * minnlcoptguardgradient()
# 
# 3. User adds boundary and/or linear and/or nonlinear constraints by  means
#    of calling one of the following functions:
#    a) minnlcsetbc() for boundary constraints
#    b) minnlcsetlc2() for sparse two-sided linear constraints,
#       minnlcsetlc2dense() for dense two-sided linear constraints,
#       minnlcsetlc2mixed() for mixed sparse/dense two-sided linear constraints
#     * minqpaddlc2dense()  to add one dense row to the dense constraint submatrix
#     * minqpaddlc2()       to add one sparse row to the sparse constraint submatrix
#     * minqpaddlc2sparsefromdense() to add one sparse row (passed as a dense array) to the sparse constraint submatrix
#    c) minnlcsetnlc2() for nonlinear constraints
#    You may combine (a), (b) and (c) in one optimization problem.
# 
# 4. User sets scale of the variables with minnlcsetscale() function. It  is
#    VERY important to set  scale  of  the  variables,  because  nonlinearly
#    constrained problems are hard to solve when variables are badly scaled.
#    Knowing  variable   scales   helps   to  check  stopping  criteria  and
#    precondition the solver.
# 
# 5. User sets stopping conditions with minnlcsetcond3() or minnlcsetcond().
#    If NLC solver uses inner/outer  iteration  layout,  this  function sets
#    stopping conditions for INNER iterations.
# 
# 6. Finally, user calls minnlcoptimize()  function  which  takes  algorithm
#    state and pointer (delegate, etc.) to callback function which calculates
#    F/G/H.
# 
# 7. User calls  minnlcresults()  to  get  solution;  additionally  you  can
#    retrieve OptGuard report with minnlcoptguardresults(), and get detailed
#    report about purported errors in the target function with:
#    * minnlcoptguardnonc1test0results()
#    * minnlcoptguardnonc1test1results()
# 
# 8. Optionally user may call minnlcrestartfrom() to solve  another  problem
#    with same N but another starting point. minnlcrestartfrom()  allows  to
#    reuse already initialized structure.
# 
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;0:
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from size ofX
#     X       -   starting point, array[N]:
#                 * it is better to set X to a feasible point
#                 * but X can be infeasible, in which case algorithm will try
#                   to find feasible point first, using X as initial
#                   approximation.
# 
# OUTPUT PARAMETERS:
#     State   -   structure stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 06.06.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minnlccreate(n, x)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minnlccreate(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minnlcstate

</div></pre>
<a name='sub_minnlccreatebuf'></a><h3 class=pageheader><code>minnlccreatebuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Buffered version of minnlccreate() which reuses already  allocated  memory
# as much as possible.
# 
#   -- ALGLIB --
#      Copyright 06.10.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlccreatebuf(n, x, state)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlccreatebuf(x, state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          1D array/list of float
          state:      class xalglib.minnlcstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlccreatef'></a><h3 class=pageheader><code>minnlccreatef</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine is a finite  difference variant of MinNLCCreate(). It uses
# finite differences in order to differentiate target function.
# 
# Description below contains information which is specific to this  function
# only. We recommend to read comments on MinNLCCreate() in order to get more
# information about creation of the NLC optimizer.
# 
# CALLBACK PARALLELISM
# 
# The MINNLC optimizer supports parallel parallel  numerical differentiation
# ('callback parallelism'). This feature, which  is  present  in  commercial
# ALGLIB  editions,  greatly   accelerates   optimization   with   numerical
# differentiation of an expensive target functions.
# 
# Callback parallelism is usually  beneficial  when  computing  a  numerical
# gradient requires more than several  milliseconds.  In this case  the  job
# of computing individual gradient components can be split between  multiple
# threads. Even inexpensive targets can benefit  from  parallelism,  if  you
# have many variables.
# 
# ALGLIB Reference Manual, 'Working with commercial  version' section, tells
# how to activate callback parallelism for your programming language.
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;0:
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from size ofX
#     X       -   starting point, array[N]:
#                 * it is better to set X to a feasible point
#                 * but X can be infeasible, in which case algorithm will try
#                   to find feasible point first, using X as initial
#                   approximation.
#     DiffStep-   differentiation step, &gt;0.
#                 By default, a 5-point formula is used  (actually,  only  4
#                 function values per variable are used because  the central
#                 one has zero coefficient due to symmetry; that's why  this
#                 formula is often called a 4-point one). It can be  changed
#                 with minnlcsetnumdiff() function.
# 
# OUTPUT PARAMETERS:
#     State   -   structure stores algorithm state
# 
# NOTES:
# 
# 1. the differentiation step along I-th axis is equal to DiffStep*S[I] where
#    S[] is scaling vector which can be set by MinNLCSetScale() call.
# 
# 2. we recommend you to use moderate values of  differentiation  step.  Too
#    large step will result in too large TRUNCATION  errors, while too small
#    step will result in too large NUMERICAL  errors.  1.0E-4  can  be  good
#    value to start from.
# 
# 3. Numerical  differentiation  is   very   inefficient  -   one   gradient
#    calculation needs ~N function evaluations. This function will work  for
#    any N - either small (1...10), moderate (10...100) or  large  (100...).
#    However, performance penalty will be too severe for any N's except  for
#    small ones.
# 
#    We should also say that code which relies on numerical  differentiation
#    is  less   robust   and  precise.  Imprecise  gradient  may  slow  down
#    convergence, especially  on  highly  nonlinear  problems  or  near  the
#    solution.
# 
#    Thus  we  recommend to use this function for fast prototyping on small-
#    dimensional problems only, and to implement analytical gradient as soon
#    as possible.
# 
#   -- ALGLIB --
#      Copyright 06.06.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minnlccreatef(n, x, diffstep)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minnlccreatef(x, diffstep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          1D array/list of float
          diffstep:   float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minnlcstate

</div></pre>
<a name='sub_minnlccreatefbuf'></a><h3 class=pageheader><code>minnlccreatefbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Buffered version of minnlccreatef() which reuses already allocated memory
# as much as possible.
# 
#   -- ALGLIB --
#      Copyright 06.06.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlccreatefbuf(n, x, diffstep, state)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlccreatefbuf(x, diffstep, state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          1D array/list of float
          diffstep:   float
          state:      class xalglib.minnlcstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcoptguardgradient'></a><h3 class=pageheader><code>minnlcoptguardgradient</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  activates/deactivates verification  of  the  user-supplied
# analytic gradient/Jacobian.
# 
# Upon  activation  of  this  option  OptGuard  integrity  checker  performs
# numerical differentiation of your target  function  (constraints)  at  the
# initial point (note: future versions may also perform check  at  the final
# point) and compares numerical gradient/Jacobian with analytic one provided
# by you.
# 
# If difference is too large, an error flag is set and optimization  session
# continues. After optimization session is over, you can retrieve the report
# which stores both gradients/Jacobians, and specific components highlighted
# as suspicious by the OptGuard.
# 
# The primary OptGuard report can be retrieved with minnlcoptguardresults().
# 
# IMPORTANT: gradient check is a high-overhead option which  will  cost  you
#            about 3*N additional function evaluations. In many cases it may
#            cost as much as the rest of the optimization session.
# 
#            YOU SHOULD NOT USE IT IN THE PRODUCTION CODE UNLESS YOU WANT TO
#            CHECK DERIVATIVES PROVIDED BY SOME THIRD PARTY.
# 
# NOTE: unlike previous incarnation of the gradient checking code,  OptGuard
#       does NOT interrupt optimization even if it discovers bad gradient.
# 
# INPUT PARAMETERS:
#     State       -   structure used to store algorithm state
#     TestStep    -   verification step used for numerical differentiation:
#                     * TestStep=0 turns verification off
#                     * TestStep&gt;0 activates verification
#                     You should carefully choose TestStep. Value  which  is
#                     too large (so large that  function  behavior  is  non-
#                     cubic at this scale) will lead  to  false  alarms. Too
#                     short step will result in rounding  errors  dominating
#                     numerical derivative.
# 
#                     You may use different step for different parameters by
#                     means of setting scale with minnlcsetscale().
# 
# === EXPLANATION ==========================================================
# 
# In order to verify gradient algorithm performs following steps:
#   * two trial steps are made to X[i]-TestStep*S[i] and X[i]+TestStep*S[i],
#     where X[i] is i-th component of the initial point and S[i] is a  scale
#     of i-th parameter
#   * F(X) is evaluated at these trial points
#   * we perform one more evaluation in the middle point of the interval
#   * we  build  cubic  model using function values and derivatives at trial
#     points and we compare its prediction with actual value in  the  middle
#     point
# 
#   -- ALGLIB --
#      Copyright 15.06.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcoptguardgradient(state, teststep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          teststep:   float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcoptguardnonc1test0results'></a><h3 class=pageheader><code>minnlcoptguardnonc1test0results</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Detailed results of the OptGuard integrity check for nonsmoothness test #0
# 
# Nonsmoothness (non-C1) test #0 studies  function  values  (not  gradient!)
# obtained during line searches and monitors  behavior  of  the  directional
# derivative estimate.
# 
# This test is less powerful than test #1, but it does  not  depend  on  the
# gradient values and thus it is more robust against artifacts introduced by
# numerical differentiation.
# 
# Two reports are returned:
# * a &quot;strongest&quot; one, corresponding  to  line   search  which  had  highest
#   value of the nonsmoothness indicator
# * a &quot;longest&quot; one, corresponding to line search which  had  more  function
#   evaluations, and thus is more detailed
# 
# In both cases following fields are returned:
# 
# * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
#   did not notice anything (in the latter cases fields below are empty).
# * fidx - is an index of the function (0 for  target  function, 1 or higher
#   for nonlinear constraints) which is suspected of being &quot;non-C1&quot;
# * x0[], d[] - arrays of length N which store initial point  and  direction
#   for line search (d[] can be normalized, but does not have to)
# * stp[], f[] - arrays of length CNT which store step lengths and  function
#   values at these points; f[i] is evaluated in x0+stp[i]*d.
# * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
#   between steps #stpidxa and #stpidxb (usually we have  stpidxb=stpidxa+3,
#   with  most  likely  position  of  the  violation  between  stpidxa+1 and
#   stpidxa+2.
# 
# ==========================================================================
# = SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -  you  will
# =                   see where C1 continuity is violated.
# ==========================================================================
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     strrep  -   C1 test #0 &quot;strong&quot; report
#     lngrep  -   C1 test #0 &quot;long&quot; report
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   strrep, lngrep = xalglib.minnlcoptguardnonc1test0results(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  strrep:     class xalglib.optguardnonc1test0report
          lngrep:     class xalglib.optguardnonc1test0report

</div></pre>
<a name='sub_minnlcoptguardnonc1test1results'></a><h3 class=pageheader><code>minnlcoptguardnonc1test1results</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Detailed results of the OptGuard integrity check for nonsmoothness test #1
# 
# Nonsmoothness (non-C1)  test  #1  studies  individual  components  of  the
# gradient computed during line search.
# 
# When precise analytic gradient is provided this test is more powerful than
# test #0  which  works  with  function  values  and  ignores  user-provided
# gradient.  However,  test  #0  becomes  more   powerful   when   numerical
# differentiation is employed (in such cases test #1 detects  higher  levels
# of numerical noise and becomes too conservative).
# 
# This test also tells specific components of the gradient which violate  C1
# continuity, which makes it more informative than #0, which just tells that
# continuity is violated.
# 
# Two reports are returned:
# * a &quot;strongest&quot; one, corresponding  to  line   search  which  had  highest
#   value of the nonsmoothness indicator
# * a &quot;longest&quot; one, corresponding to line search which  had  more  function
#   evaluations, and thus is more detailed
# 
# In both cases following fields are returned:
# 
# * positive - is TRUE  when test flagged suspicious point;  FALSE  if  test
#   did not notice anything (in the latter cases fields below are empty).
# * fidx - is an index of the function (0 for  target  function, 1 or higher
#   for nonlinear constraints) which is suspected of being &quot;non-C1&quot;
# * vidx - is an index of the variable in [0,N) with nonsmooth derivative
# * x0[], d[] - arrays of length N which store initial point  and  direction
#   for line search (d[] can be normalized, but does not have to)
# * stp[], g[] - arrays of length CNT which store step lengths and  gradient
#   values at these points; g[i] is evaluated in  x0+stp[i]*d  and  contains
#   vidx-th component of the gradient.
# * stpidxa, stpidxb - we  suspect  that  function  violates  C1  continuity
#   between steps #stpidxa and #stpidxb (usually we have  stpidxb=stpidxa+3,
#   with  most  likely  position  of  the  violation  between  stpidxa+1 and
#   stpidxa+2.
# 
# ==========================================================================
# = SHORTLY SPEAKING: build a 2D plot of (stp,f) and look at it -  you  will
# =                   see where C1 continuity is violated.
# ==========================================================================
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     strrep  -   C1 test #1 &quot;strong&quot; report
#     lngrep  -   C1 test #1 &quot;long&quot; report
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   strrep, lngrep = xalglib.minnlcoptguardnonc1test1results(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  strrep:     class xalglib.optguardnonc1test1report
          lngrep:     class xalglib.optguardnonc1test1report

</div></pre>
<a name='sub_minnlcoptguardresults'></a><h3 class=pageheader><code>minnlcoptguardresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Results of OptGuard integrity check, should be called  after  optimization
# session is over.
# 
# === PRIMARY REPORT =======================================================
# 
# OptGuard performs several checks which are intended to catch common errors
# in the implementation of nonlinear function/gradient:
# * incorrect analytic gradient
# * discontinuous (non-C0) target functions (constraints)
# * nonsmooth     (non-C1) target functions (constraints)
# 
# Each of these checks is activated with appropriate function:
# * minnlcoptguardgradient() for gradient verification
# * minnlcoptguardsmoothness() for C0/C1 checks
# 
# Following flags are set when these errors are suspected:
# * rep.badgradsuspected, and additionally:
#   * rep.badgradfidx for specific function (Jacobian row) suspected
#   * rep.badgradvidx for specific variable (Jacobian column) suspected
#   * rep.badgradxbase, a point where gradient/Jacobian is tested
#   * rep.badgraduser, user-provided gradient/Jacobian
#   * rep.badgradnum, reference gradient/Jacobian obtained via numerical
#     differentiation
# * rep.nonc0suspected, and additionally:
#   * rep.nonc0fidx - an index of specific function violating C0 continuity
# * rep.nonc1suspected, and additionally
#   * rep.nonc1fidx - an index of specific function violating C1 continuity
# Here function index 0 means  target function, index 1  or  higher  denotes
# nonlinear constraints.
# 
# === ADDITIONAL REPORTS/LOGS ==============================================
# 
# Several different tests are performed to catch C0/C1 errors, you can  find
# out specific test signaled error by looking to:
# * rep.nonc0test0positive, for non-C0 test #0
# * rep.nonc1test0positive, for non-C1 test #0
# * rep.nonc1test1positive, for non-C1 test #1
# 
# Additional information (including line search logs)  can  be  obtained  by
# means of:
# * minnlcoptguardnonc1test0results()
# * minnlcoptguardnonc1test1results()
# which return detailed error reports, specific points where discontinuities
# were found, and so on.
# 
# ==========================================================================
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     rep     -   generic OptGuard report;  more  detailed  reports  can  be
#                 retrieved with other functions.
# 
# NOTE: false negatives (nonsmooth problems are not identified as  nonsmooth
#       ones) are possible although unlikely.
# 
#       The reason  is  that  you  need  to  make several evaluations around
#       nonsmoothness  in  order  to  accumulate  enough  information  about
#       function curvature. Say, if you start right from the nonsmooth point,
#       optimizer simply won't get enough data to understand what  is  going
#       wrong before it terminates due to abrupt changes in the  derivative.
#       It is also  possible  that  &quot;unlucky&quot;  step  will  move  us  to  the
#       termination too quickly.
# 
#       Our current approach is to have less than 0.1%  false  negatives  in
#       our test examples  (measured  with  multiple  restarts  from  random
#       points), and to have exactly 0% false positives.
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.minnlcoptguardresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.optguardreport

</div></pre>
<a name='sub_minnlcoptguardsmoothness'></a><h3 class=pageheader><code>minnlcoptguardsmoothness</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  activates/deactivates nonsmoothness monitoring  option  of
# the  OptGuard  integrity  checker. Smoothness  monitor  silently  observes
# solution process and tries to detect ill-posed problems, i.e. ones with:
# a) discontinuous target function (non-C0) and/or constraints
# b) nonsmooth     target function (non-C1) and/or constraints
# 
# Smoothness monitoring does NOT interrupt optimization  even if it suspects
# that your problem is nonsmooth. It just sets corresponding  flags  in  the
# OptGuard report which can be retrieved after optimization is over.
# 
# Smoothness monitoring is a moderate overhead option which often adds  less
# than 1% to the optimizer running time. Thus, you can use it even for large
# scale problems.
# 
# NOTE: OptGuard does  NOT  guarantee  that  it  will  always  detect  C0/C1
#       continuity violations.
# 
#       First, minor errors are hard to  catch - say, a 0.0001 difference in
#       the model values at two sides of the gap may be due to discontinuity
#       of the model - or simply because the model has changed.
# 
#       Second, C1-violations  are  especially  difficult  to  detect  in  a
#       noninvasive way. The optimizer usually  performs  very  short  steps
#       near the nonsmoothness, and differentiation  usually   introduces  a
#       lot of numerical noise.  It  is  hard  to  tell  whether  some  tiny
#       discontinuity in the slope is due to real nonsmoothness or just  due
#       to numerical noise alone.
# 
#       Our top priority was to avoid false positives, so in some rare cases
#       minor errors may went unnoticed (however, in most cases they can  be
#       spotted with restart from different initial point).
# 
# INPUT PARAMETERS:
#     state   -   algorithm state
#     level   -   monitoring level:
#                 * 0 - monitoring is disabled
#                 * 1 - noninvasive low-overhead monitoring; function values
#                       and/or gradients are recorded, but OptGuard does not
#                       try to perform additional evaluations  in  order  to
#                       get more information about suspicious locations.
#                       This kind of monitoring does not work well with  SQP
#                       because SQP solver needs just 1-2 function evaluations
#                       per step, which is not enough for OptGuard  to  make
#                       any conclusions.
# 
# === EXPLANATION ==========================================================
# 
# One major source of headache during optimization  is  the  possibility  of
# the coding errors in the target function/constraints (or their gradients).
# Such  errors   most   often   manifest   themselves  as  discontinuity  or
# nonsmoothness of the target/constraints.
# 
# Another frequent situation is when you try to optimize something involving
# lots of min() and max() operations, i.e. nonsmooth target. Although not  a
# coding error, it is nonsmoothness anyway - and smooth  optimizers  usually
# stop right after encountering nonsmoothness, well before reaching solution.
# 
# OptGuard integrity checker helps you to catch such situations: it monitors
# function values/gradients being passed  to  the  optimizer  and  tries  to
# errors. Upon discovering suspicious pair of points it  raises  appropriate
# flag (and allows you to continue optimization). When optimization is done,
# you can study OptGuard result.
# 
#   -- ALGLIB --
#      Copyright 21.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcoptguardsmoothness(state, level)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcoptguardsmoothness(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          level:      int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcrequesttermination'></a><h3 class=pageheader><code>minnlcrequesttermination</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine submits request for termination of running  optimizer.  It
# should be called from user-supplied callback when user decides that it  is
# time to &quot;smoothly&quot; terminate optimization process.  As  result,  optimizer
# stops at point which was &quot;current accepted&quot; when termination  request  was
# submitted and returns error code 8 (successful termination).
# 
# INPUT PARAMETERS:
#     State   -   optimizer structure
# 
# NOTE: after  request  for  termination  optimizer  may   perform   several
#       additional calls to user-supplied callbacks. It does  NOT  guarantee
#       to stop immediately - it just guarantees that these additional calls
#       will be discarded later.
# 
# NOTE: calling this function on optimizer which is NOT running will have no
#       effect.
# 
# NOTE: multiple calls to this function are possible. First call is counted,
#       subsequent calls are silently ignored.
# 
#   -- ALGLIB --
#      Copyright 08.10.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcrequesttermination(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcrestartfrom'></a><h3 class=pageheader><code>minnlcrestartfrom</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine restarts algorithm from new point.
# All optimization parameters (including constraints) are left unchanged.
# 
# This  function  allows  to  solve multiple  optimization  problems  (which
# must have  same number of dimensions) without object reallocation penalty.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with MinNLCCreate call.
#     X       -   new starting point.
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcrestartfrom(state, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcresults'></a><h3 class=pageheader><code>minnlcresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# MinNLC results:  the  solution  found,  completion  codes  and  additional
# information.
# 
# If you activated OptGuard integrity checking functionality and want to get
# OptGuard report, it can be retrieved with:
# * minnlcoptguardresults() - for a primary report about (a) suspected C0/C1
#   continuity violations and (b) errors in the analytic gradient.
# * minnlcoptguardnonc1test0results() - for C1 continuity violation test #0,
#   detailed line search log
# * minnlcoptguardnonc1test1results() - for C1 continuity violation test #1,
#   detailed line search log
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     X       -   array[0..N-1], solution
#     Rep     -   optimization report, contains information about completion
#                 code, constraint violation at the solution and so on.
# 
#                 rep.f contains objective value at the solution.
# 
#                 You   should   check   rep.terminationtype  in  order   to
#                 distinguish successful termination from unsuccessful one:
# 
#                 === FAILURE CODES ===
#                 * -8    internal  integrity control  detected  infinite or
#                         NAN  values  in  function/gradient,  recovery  was
#                         impossible. Abnormal termination signalled.
#                 * -3    box  constraints are infeasible.
#                         Note: infeasibility of  non-box  constraints  does
#                               NOT trigger emergency completion;  you  have
#                               to examine rep.bcerr/rep.lcerr/rep.nlcerr to
#                               detect possibly inconsistent constraints.
# 
#                 === SUCCESS CODES ===
#                 *  2   scaled step is no more than EpsX.
#                 *  5   MaxIts steps were taken.
#                 *  8   user   requested    algorithm    termination    via
#                        minnlcrequesttermination(), last accepted point  is
#                        returned.
# 
#                 === ADDITIONAL CODES ===
#                 * +800      if   during  algorithm  execution  the  solver
#                             encountered NAN/INF values in  the  target  or
#                             constraints but managed to recover by reducing
#                             trust region radius, the  solver  returns  one
#                             of SUCCESS codes but adds +800 to the code.
# 
#                 Some solvers (as of ALGLIB 4.02, only SQP) return Lagrange
#                 multipliers in rep.lagbc/lagbcnz, laglc, lagnlc fields.
# 
#                 More information about fields of this  structure  can  be
#                 found in the comments on the minnlcreport datatype.
# 
#   -- ALGLIB --
#      Copyright 18.01.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.minnlcresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.minnlcreport

</div></pre>
<a name='sub_minnlcresultsbuf'></a><h3 class=pageheader><code>minnlcresultsbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# NLC results
# 
# Buffered implementation of MinNLCResults() which uses pre-allocated buffer
# to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
# intended to be used in the inner cycles of performance critical algorithms
# where array reallocation penalty is too large to be ignored.
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.minnlcresultsbuf(state, x, rep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          x:          1D array/list of float
          rep:        class xalglib.minnlcreport
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> rep
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float

</div></pre>
<a name='sub_minnlcsetalgoaul2'></a><h3 class=pageheader><code>minnlcsetalgoaul2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function tells MinNLC unit to use the large-scale augmented Lagrangian
# algorithm for nonlinearly constrained optimization.
# 
# This  algorithm  is  a  significant  refactoring  of  one  described in &quot;A
# Modified Barrier-Augmented  Lagrangian Method for Constrained Minimization
# (1999)&quot; by D.GOLDFARB,  R.POLYAK,  K. SCHEINBERG,  I.YUZEFOVICH  with  the
# following additions:
# * improved sparsity support
# * improved handling of large-scale problems with the low rank  LBFGS-based
#   sparse preconditioner
# * automatic selection of the penalty parameter Rho
# 
# AUL solver can be significantly faster than SQP on easy  problems  due  to
# cheaper iterations, although it needs more function evaluations. On large-
# scale sparse problems one iteration of the AUL solver usually  costs  tens
# times less than one iteration of the SQP solver.
# 
# However, the SQP solver is more robust than the AUL. In particular, it  is
# much better at constraint enforcement and will  never escape feasible area
# after constraints were successfully enforced.  It  also  needs  much  less
# target function evaluations.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     MaxOuterIts-upper limit on outer iterations count:
#                 * MaxOuterIts=0 means that the solver  will  automatically
#                   choose an upper limit. Recommended value.
#                 * MaxOuterIts&gt;1 means that the AUL solver will performs at
#                   most specified number of outer iterations
# 
#   -- ALGLIB --
#      Copyright 22.09.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetalgoaul2(state, maxouterits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          maxouterits: int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetalgoorbit'></a><h3 class=pageheader><code>minnlcsetalgoorbit</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function selects ORBIT solver, a model-based  derivative-free  solver
# for minimization of expensive derivative-free functions.
# 
# The ORBIT algorithm by Wild and Shoemaker (2013) is an algorithm that uses
# objective function values to build a smooth  RBF  model  (f=r^3)  that  is
# minimized over a trust region in order to  identify  step  direction.  The
# algorithm saves and reuses function values at all previously known points.
# 
# ALGLIB added to the original algorithm the following modifications:
# * box, linear and nonlinear constraints
# * improved tolerance to noise in the objective/constraints
# 
# Its  intended  area  of  application  is  a  low-accuracy  minimization of
# expensive objectives with no  gradient  available.  It  is  expected  that
# additional overhead of building and minimizing an RBF model is  negligible
# when compared with the objective evaluation cost. Iteration overhead grows
# as O(N^3), so this solver is recommended for problems with N below 100.
# 
# This algorithm has the following nice properties:
# * no parameters to tune
# * no convexity requirements for target function or constraints
# * the initial point can be infeasible
# * the algorithm respects box constraints in all  intermediate  points  (it
#   does not even evaluate the target outside of the box constrained area)
# * once linear and nonlinear constraints are enforced, the  algorithm  will
#   try to respect them as much as possible.
# 
# When compared with SQP solver, ORBIT:
# * is much faster than the finite-difference  based  serial  SQP  at  early
#   stages of optimization, being able to achieve 0.1-0.01 relative accuracy
#   about 4x-10x faster than SQP solver
# * has slower asymptotic convergence on ill-conditioned problems, sometimes
#   being unable to reduce error in objective or constraints below  1E-5  in
#   a reasonable amount of time
# * has  no  obvious  benefits  over  SQP  with  analytic gradient or highly
#   parallelized (more than 10 cores) finite-difference SQP
# 
# NOTE: whilst technically this algorithm supports callback parallelism,  in
#       practice it can't efficiently utilize parallel resources because  it
#       issues requests for objective/constraints in  an  inherently  serial
#       manner.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#     Rad0    -   initial  sampling   radius  (multiplied  by   per-variable
#                 scales),  Rad0&gt;=0,  zero  value  means  automatic   radius
#                 selection.
#                 An ideal  value  is  large  enough  to  allow  significant
#                 progress by making a Rad0-sized step, but  not  too  large
#                 (so  that  initial  linear  model  well  approximates  the
#                 objective).
#                 Recommended values: 0.1 or 1  (assuming  properly   chosen
#                 variable scales.
#                 The solver can tolerate inappropriately  chosen  Rad0,  at
#                 the expense of additional function evaluations  needed  to
#                 adjust it.
# 
#     MaxNFEV -   MaxNFEV&gt;=0,  with   zero  value  meaning  no  limit.  This
#                 parameter allows to control computational budget (measured
#                 in  function  evaluations).
# 
#                 It provides somewhat finer control than  MaxIts  parameter
#                 of minnlcsetcond(), which controls the maximum  amount  of
#                 iterations performed by the algorithm, with  one iteration
#                 usually needing more than one function evaluation.
# 
#                 The  solver  does  not  stop  immediately  after  reaching
#                 MaxNFEV evaluations, but  will  stop  shortly  after  that
#                 (usually within N+1 evaluations, often within 1-2).
# 
#   -- ALGLIB --
#      Copyright 02.10.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetalgoorbit(state, rad0, maxnfev)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          rad0:       float
          maxnfev:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetalgosl1qp'></a><h3 class=pageheader><code>minnlcsetalgosl1qp</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function selects a legacy solver: an L1 merit function based SQP with
# the sparse l-BFGS update.
# 
# It is recommended to use either SQP or SQP-BFGS solvers  instead  of  this
# one.  These  solvers  use  filters  to  provide  much  faster  and  robust
# convergence.
# &gt;
# 
#   -- ALGLIB --
#      Copyright 02.12.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetalgosl1qp(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetalgosl1qpbfgs'></a><h3 class=pageheader><code>minnlcsetalgosl1qpbfgs</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function selects a legacy solver: an L1 merit function based SQP with
# the dense BFGS update.
# 
# It is recommended to use either SQP or SQP-BFGS solvers  instead  of  this
# one.  These  solvers  use  filters  to  provide  much  faster  and  robust
# convergence.
# 
#   -- ALGLIB --
#      Copyright 02.12.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetalgosl1qpbfgs(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetalgosqp'></a><h3 class=pageheader><code>minnlcsetalgosqp</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function selects large-scale  sparse  filter-based  SQP  solver,  the
# most robust solver in ALGLIB, a recommended option.
# 
# This algorithm is scalable to problems with tens of thousands of variables
# and can efficiently handle sparsity of constraints.
# 
# The convergence is proved for the following case:
# * function and constraints are continuously differentiable (C1 class)
# 
# This algorithm has the following nice properties:
# * no parameters to tune
# * no convexity requirements for target function or constraints
# * the initial point can be infeasible
# * the algorithm respects box constraints in all  intermediate  points  (it
#   does not even evaluate the target outside of the box constrained area)
# * once linear constraints are enforced, the algorithm will not violate them
# * no such guarantees can be provided for nonlinear constraints,  but  once
#   nonlinear  constraints  are  enforced,  the algorithm will try to respect
#   them as much as possible
# * numerical differentiation does  not  violate  box  constraints  (although
#   general linear and nonlinear ones can be violated during differentiation)
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# ===== TRACING SQP SOLVER =================================================
# 
# SQP solver supports advanced tracing capabilities. You can trace algorithm
# output by specifying following trace symbols (case-insensitive)  by  means
# of trace_file() call:
# * 'SQP'         - for basic trace of algorithm  steps and decisions.  Only
#                   short scalars (function values and deltas) are  printed.
#                   N-dimensional quantities like search directions are  NOT
#                   printed.
#                   It also prints OptGuard  integrity  checker  report when
#                   nonsmoothness of target/constraints is suspected.
# * 'SQP.DETAILED'- for output of points being visited and search directions
#                   This  symbol  also  implicitly  defines  'SQP'. You  can
#                   control output format by additionally specifying:
#                   * nothing     to output in  6-digit exponential format
#                   * 'PREC.E15'  to output in 15-digit exponential format
#                   * 'PREC.F6'   to output in  6-digit fixed-point format
# * 'SQP.PROBING' - to let algorithm insert additional function  evaluations
#                   before line search  in  order  to  build  human-readable
#                   chart of the raw  Lagrangian  (~40  additional  function
#                   evaluations is performed for  each  line  search).  This
#                   symbol  also  implicitly  defines  'SQP'  and  activates
#                   OptGuard integrity checker which detects continuity  and
#                   smoothness violations. An OptGuard log is printed at the
#                   end of the file.
# 
# By default trace is disabled and adds  no  overhead  to  the  optimization
# process. However, specifying any of the symbols adds some  formatting  and
# output-related   overhead.  Specifying  'SQP.PROBING'  adds   even  larger
# overhead due to additional function evaluations being performed.
# 
# You may specify multiple symbols by separating them with commas:
# &gt;
# &gt; alglib::trace_file(&quot;SQP,SQP.PROBING,PREC.F6&quot;, &quot;path/to/trace.log&quot;)
# &gt;
# 
#   -- ALGLIB --
#      Copyright 02.12.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetalgosqp(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetalgosqpbfgs'></a><h3 class=pageheader><code>minnlcsetalgosqpbfgs</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function selects a special solver for low-dimensional  problems  with
# expensive target function - the dense filer-based SQP-BFGS solver.
# 
# This algorithm uses a dense quadratic model of the  target  and  solves  a
# dense QP subproblem at each step. Thus, it has difficulties scaling beyond
# several hundreds of variables.  However,  it  usually  needs  the smallest
# number of the target evaluations - sometimes  up  to  30%  less  than  the
# sparse large-scale filter-based SQP.
# 
# The convergence is proved for the following case:
# * function and constraints are continuously differentiable (C1 class)
# 
# This algorithm has the following nice properties:
# * no parameters to tune
# * no convexity requirements for target function or constraints
# * the initial point can be infeasible
# * the algorithm respects box constraints in all  intermediate  points  (it
#   does not even evaluate the target outside of the box constrained area)
# * once linear constraints are enforced, the algorithm will not violate them
# * no such guarantees can be provided for nonlinear constraints,  but  once
#   nonlinear  constraints  are  enforced,  the algorithm will try to respect
#   them as much as possible
# * numerical differentiation does  not  violate  box  constraints  (although
#   general linear and nonlinear ones can be violated during differentiation)
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# ===== TRACING SQP SOLVER =================================================
# 
# SQP solver supports advanced tracing capabilities. You can trace algorithm
# output by specifying following trace symbols (case-insensitive)  by  means
# of trace_file() call:
# * 'SQP'         - for basic trace of algorithm  steps and decisions.  Only
#                   short scalars (function values and deltas) are  printed.
#                   N-dimensional quantities like search directions are  NOT
#                   printed.
#                   It also prints OptGuard  integrity  checker  report when
#                   nonsmoothness of target/constraints is suspected.
# * 'SQP.DETAILED'- for output of points being visited and search directions
#                   This  symbol  also  implicitly  defines  'SQP'. You  can
#                   control output format by additionally specifying:
#                   * nothing     to output in  6-digit exponential format
#                   * 'PREC.E15'  to output in 15-digit exponential format
#                   * 'PREC.F6'   to output in  6-digit fixed-point format
# * 'SQP.PROBING' - to let algorithm insert additional function  evaluations
#                   before line search  in  order  to  build  human-readable
#                   chart of the raw  Lagrangian  (~40  additional  function
#                   evaluations is performed for  each  line  search).  This
#                   symbol  also  implicitly  defines  'SQP'  and  activates
#                   OptGuard integrity checker which detects continuity  and
#                   smoothness violations. An OptGuard log is printed at the
#                   end of the file.
# 
# By default trace is disabled and adds  no  overhead  to  the  optimization
# process. However, specifying any of the symbols adds some  formatting  and
# output-related   overhead.  Specifying  'SQP.PROBING'  adds   even  larger
# overhead due to additional function evaluations being performed.
# 
# You may specify multiple symbols by separating them with commas:
# &gt;
# &gt; alglib::trace_file(&quot;SQP,SQP.PROBING,PREC.F6&quot;, &quot;path/to/trace.log&quot;)
# &gt;
# 
#   -- ALGLIB --
#      Copyright 02.12.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetalgosqpbfgs(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetbc'></a><h3 class=pageheader><code>minnlcsetbc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets boundary constraints for NLC optimizer.
# 
# Boundary constraints are inactive by  default  (after  initial  creation).
# They are preserved after algorithm restart with  MinNLCRestartFrom().
# 
# You may combine boundary constraints with  general  linear ones - and with
# nonlinear ones! Boundary constraints are  handled  more  efficiently  than
# other types.  Thus,  if  your  problem  has  mixed  constraints,  you  may
# explicitly specify some of them as boundary and save some time/space.
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     BndL    -   lower bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 very small number or -INF.
#     BndU    -   upper bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 very large number or +INF.
# 
# NOTE 1:  it is possible to specify  BndL[i]=BndU[i].  In  this  case  I-th
# variable will be &quot;frozen&quot; at X[i]=BndL[i]=BndU[i].
# 
# NOTE 2:  when you solve your problem  with  augmented  Lagrangian  solver,
#          boundary constraints are  satisfied  only  approximately!  It  is
#          possible   that  algorithm  will  evaluate  function  outside  of
#          feasible area!
# 
#   -- ALGLIB --
#      Copyright 06.06.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetbc(state, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          bndl:       1D array/list of float
          bndu:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetcond'></a><h3 class=pageheader><code>minnlcsetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping conditions for the optimizer.
# 
# This  function allows to set  iterations  limit  and  step-based  stopping
# conditions. If you want the solver to stop upon having a small  change  in
# the target, use minnlcsetcond3() function.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     EpsX    -   &gt;=0
#                 The subroutine finishes its work if  on  k+1-th  iteration
#                 the condition |v|&lt;=EpsX is fulfilled, where:
#                 * |.| means Euclidian norm
#                 * v - scaled step vector, v[i]=dx[i]/s[i]
#                 * dx - step vector, dx=X(k+1)-X(k)
#                 * s - scaling coefficients set by MinNLCSetScale()
#     MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
#                 iterations is unlimited.
# 
# Passing EpsX=0 and MaxIts=0 (simultaneously) will lead to automatic
# selection of the stopping condition.
# 
#   -- ALGLIB --
#      Copyright 06.06.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetcond(state, epsx, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          epsx:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetcond3'></a><h3 class=pageheader><code>minnlcsetcond3</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping conditions for the optimizer.
# 
# This function allows to set three types of stopping conditions:
# * iterations limit
# * stopping upon performing a short step (depending on the specific  solver
#   being used  it may stop as soon as the first short step was made, or
#   only after performing several sequential short steps)
# * stopping upon having a small change in  the  target  (depending  on  the
#   specific solver being used it may stop as soon as the  first  step  with
#   small change in the target was made, or only  after  performing  several
#   sequential steps)
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     EpsF    -   &gt;=0
#                 The optimizer will stop as soon as the following condition
#                 is met:
# 
#                     |f_scl(k+1)-f_scl(k)| &lt;= max(|f_scl(k+1)|,|f_scl(k)|,1)
# 
#                 where f_scl is an internally used by the optimizer rescaled
#                 target (ALGLIB optimizers usually apply rescaling in order
#                 to normalize target and constraints).
#     EpsX    -   &gt;=0
#                 The subroutine finishes its work if  on  k+1-th  iteration
#                 the condition |v|&lt;=EpsX is fulfilled, where:
#                 * |.| means Euclidian norm
#                 * v - scaled step vector, v[i]=dx[i]/s[i]
#                 * dx - step vector, dx=X(k+1)-X(k)
#                 * s - scaling coefficients set by MinNLCSetScale()
#     MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
#                 iterations is unlimited.
# 
# Passing EpsF, EpsX=0 and MaxIts=0 (simultaneously) will lead to the
# automatic selection of the stopping condition.
# 
#   -- ALGLIB --
#      Copyright 21.09.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetcond3(state, epsf, epsx, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          epsf:       float
          epsx:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetlc'></a><h3 class=pageheader><code>minnlcsetlc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets linear constraints for MinNLC optimizer.
# 
# Linear constraints are inactive by default (after initial creation).  They
# are preserved after algorithm restart with MinNLCRestartFrom().
# 
# You may combine linear constraints with boundary ones - and with nonlinear
# ones! If your problem has mixed constraints, you  may  explicitly  specify
# some of them as linear. It  may  help  optimizer   to   handle  them  more
# efficiently.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with MinNLCCreate call.
#     C       -   linear constraints, array[K,N+1].
#                 Each row of C represents one constraint, either equality
#                 or inequality (see below):
#                 * first N elements correspond to coefficients,
#                 * last element corresponds to the right part.
#                 All elements of C (including right part) must be finite.
#     CT      -   type of constraints, array[K]:
#                 * if CT[i]&gt;0, then I-th constraint is C[i,*]*x &gt;= C[i,n+1]
#                 * if CT[i]=0, then I-th constraint is C[i,*]*x  = C[i,n+1]
#                 * if CT[i]&lt;0, then I-th constraint is C[i,*]*x &lt;= C[i,n+1]
#     K       -   number of equality/inequality constraints, K&gt;=0:
#                 * if given, only leading K elements of C/CT are used
#                 * if not given, automatically determined from sizes of C/CT
# 
# NOTE 1: when you solve your problem  with  augmented  Lagrangian   solver,
#         linear constraints are  satisfied  only   approximately!   It   is
#         possible   that  algorithm  will  evaluate  function  outside   of
#         feasible area!
# 
#   -- ALGLIB --
#      Copyright 06.06.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetlc(state, c, ct, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetlc(state, c, ct)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          c:          2D array/list of float
          ct:         1D array/list of int
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetlc2'></a><h3 class=pageheader><code>minnlcsetlc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  sets  two-sided linear  constraints  AL &lt;= A*x &lt;= AU  with
# a sparse constraining matrix A. Recommended for large-scale problems.
# 
# This  function  overwrites  linear  (non-box)  constraints set by previous
# calls (if such calls were made).
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minnlccreate() call.
#     A       -   sparse matrix with size [K,N] (exactly!).
#                 Each row of A represents one general linear constraint.
#                 A can be stored in any sparse storage format.
#     AL, AU  -   lower and upper bounds, array[K];
#                 * AL[i]=AU[i] =&gt; equality constraint Ai*x
#                 * AL[i]&lt;AU[i] =&gt; two-sided constraint AL[i]&lt;=Ai*x&lt;=AU[i]
#                 * AL[i]=-INF  =&gt; one-sided constraint Ai*x&lt;=AU[i]
#                 * AU[i]=+INF  =&gt; one-sided constraint AL[i]&lt;=Ai*x
#                 * AL[i]=-INF, AU[i]=+INF =&gt; constraint is ignored
#     K       -   number  of equality/inequality constraints, K&gt;=0.  If  K=0
#                 is specified, A, AL, AU are ignored.
# 
#   -- ALGLIB --
#      Copyright 15.04.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetlc2(state, a, al, au, k)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          a:          class xalglib.sparsematrix
          al:         1D array/list of float
          au:         1D array/list of float
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetlc2dense'></a><h3 class=pageheader><code>minnlcsetlc2dense</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets two-sided linear constraints AL &lt;= A*x &lt;= AU with dense
# constraint matrix A.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minnlccreate() call.
#     A       -   linear constraints, array[K,N]. Each row of  A  represents
#                 one  constraint. One-sided  inequality   constraints, two-
#                 sided inequality  constraints,  equality  constraints  are
#                 supported (see below)
#     AL, AU  -   lower and upper bounds, array[K];
#                 * AL[i]=AU[i] =&gt; equality constraint Ai*x
#                 * AL[i]&lt;AU[i] =&gt; two-sided constraint AL[i]&lt;=Ai*x&lt;=AU[i]
#                 * AL[i]=-INF  =&gt; one-sided constraint Ai*x&lt;=AU[i]
#                 * AU[i]=+INF  =&gt; one-sided constraint AL[i]&lt;=Ai*x
#                 * AL[i]=-INF, AU[i]=+INF =&gt; constraint is ignored
#     K       -   number of equality/inequality constraints,  K&gt;=0;  if  not
#                 given, inferred from sizes of A, AL, AU.
# 
#   -- ALGLIB --
#      Copyright 15.04.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetlc2dense(state, a, al, au, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetlc2dense(state, a, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          a:          2D array/list of float
          al:         1D array/list of float
          au:         1D array/list of float
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetlc2mixed'></a><h3 class=pageheader><code>minnlcsetlc2mixed</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  sets  two-sided linear  constraints  AL &lt;= A*x &lt;= AU  with
# a mixed constraining matrix A including a sparse part (first SparseK rows)
# and a dense part (last DenseK rows). Recommended for large-scale problems.
# 
# This  function  overwrites  linear  (non-box)  constraints set by previous
# calls (if such calls were made).
# 
# This function may be useful if constraint matrix includes large number  of
# both types of rows - dense and sparse. If you have just a few sparse rows,
# you  may  represent  them  in  dense  format  without losing  performance.
# Similarly, if you have just a few dense rows, you may store them in sparse
# format with almost same performance.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minnlccreate() call.
#     SparseA -   sparse matrix with size [K,N] (exactly!).
#                 Each row of A represents one general linear constraint.
#                 A can be stored in any sparse storage format.
#     SparseK -   number of sparse constraints, SparseK&gt;=0
#     DenseA  -   linear constraints, array[K,N], set of dense constraints.
#                 Each row of A represents one general linear constraint.
#     DenseK  -   number of dense constraints, DenseK&gt;=0
#     AL, AU  -   lower and upper bounds, array[SparseK+DenseK], with former
#                 SparseK elements corresponding to sparse constraints,  and
#                 latter DenseK elements corresponding to dense constraints;
#                 * AL[i]=AU[i] =&gt; equality constraint Ai*x
#                 * AL[i]&lt;AU[i] =&gt; two-sided constraint AL[i]&lt;=Ai*x&lt;=AU[i]
#                 * AL[i]=-INF  =&gt; one-sided constraint Ai*x&lt;=AU[i]
#                 * AU[i]=+INF  =&gt; one-sided constraint AL[i]&lt;=Ai*x
#                 * AL[i]=-INF, AU[i]=+INF =&gt; constraint is ignored
#     K       -   number  of equality/inequality constraints, K&gt;=0.  If  K=0
#                 is specified, A, AL, AU are ignored.
# 
#   -- ALGLIB --
#      Copyright 15.04.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetlc2mixed(state, sparsea, ksparse, densea, kdense, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          sparsea:    class xalglib.sparsematrix
          ksparse:    int
          densea:     2D array/list of float
          kdense:     int
          al:         1D array/list of float
          au:         1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetnlc'></a><h3 class=pageheader><code>minnlcsetnlc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets nonlinear constraints for MinNLC optimizer.
# 
# It sets constraints of the form
# 
#     Ci(x)=0 for i=0..NLEC-1
#     Ci(x)&lt;=0 for i=NLEC..NLEC+NLIC-1
# 
# See MinNLCSetNLC2() for a modern function which allows greater flexibility
# in the constraint specification.
# 
#   -- ALGLIB --
#      Copyright 06.06.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetnlc(state, nlec, nlic)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          nlec:       int
          nlic:       int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetnlc2'></a><h3 class=pageheader><code>minnlcsetnlc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets two-sided nonlinear constraints for MinNLC optimizer.
# 
# In fact, this function sets  only  constraints  COUNT  and  their  BOUNDS.
# Constraints  themselves  (constraint  functions)   are   passed   to   the
# MinNLCOptimize() method as callbacks.
# 
# MinNLCOptimize() method accepts a user-defined vector function F[] and its
# Jacobian J[], where:
# * first element of F[] and first row of J[] correspond to the target
# * subsequent NNLC components of F[] (and rows of J[]) correspond  to  two-
#   sided nonlinear constraints NL&lt;=C(x)&lt;=NU, where
#   * NL[i]=NU[i] =&gt; I-th row is an equality constraint Ci(x)=NL
#   * NL[i]&lt;NU[i] =&gt; I-th tow is a  two-sided constraint NL[i]&lt;=Ci(x)&lt;=NU[i]
#   * NL[i]=-INF  =&gt; I-th row is an one-sided constraint Ci(x)&lt;=NU[i]
#   * NU[i]=+INF  =&gt; I-th row is an one-sided constraint NL[i]&lt;=Ci(x)
#   * NL[i]=-INF, NU[i]=+INF =&gt; constraint is ignored
# 
# NOTE: you may combine nonlinear constraints with linear/boundary ones.  If
#       your problem has mixed constraints, you  may explicitly specify some
#       of them as linear or box ones.
#       It helps optimizer to handle them more efficiently.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with MinNLCCreate call.
#     NL      -   array[NNLC], lower bounds, can contain -INF
#     NU      -   array[NNLC], lower bounds, can contain +INF
#     NNLC    -   constraints count, NNLC&gt;=0
# 
# NOTE 1: nonlinear constraints are satisfied only  approximately!   It   is
#         possible that the algorithm will evaluate the function  outside of
#         the feasible area!
# 
# NOTE 2: algorithm scales variables  according  to the scale  specified by
#         MinNLCSetScale()  function,  so it can handle problems with badly
#         scaled variables (as long as we KNOW their scales).
# 
#         However,  there  is  no  way  to  automatically  scale   nonlinear
#         constraints. Inappropriate scaling  of nonlinear  constraints  may
#         ruin convergence. Solving problem with  constraint  &quot;1000*G0(x)=0&quot;
#         is NOT the same as solving it with constraint &quot;0.001*G0(x)=0&quot;.
# 
#         It means that YOU are  the  one who is responsible for the correct
#         scaling of the nonlinear constraints Gi(x) and Hi(x). We recommend
#         you to scale nonlinear constraints in such a way that the Jacobian
#         rows have approximately unit magnitude  (for  problems  with  unit
#         scale) or have magnitude approximately equal to 1/S[i] (where S is
#         a scale set by MinNLCSetScale() function).
# 
#   -- ALGLIB --
#      Copyright 23.09.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetnlc2(state, nl, nu, nnlc)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetnlc2(state, nl, nu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          nl:         1D array/list of float
          nu:         1D array/list of float
          nnlc:       int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetnumdiff'></a><h3 class=pageheader><code>minnlcsetnumdiff</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets specific finite  difference  formula  to  be  used  for
# numerical differentiation.
# 
# It works only for optimizers created  with  minnlccreatef()  function;  in
# other cases it has no effect.
# 
# INPUT PARAMETERS:
#     State       -   structure previously allocated with MinNLCCreateF call.
#     FormulaType -   formula type:
#                     * 5 for a 5-point formula (actually, only 4 values per
#                       variable  are  used, ones at x+h, x+h/2,  x-h/2  and
#                       x-h; the central  one has  zero  multiplier  due  to
#                       symmetry). The most precise and the  most  expensive
#                       option, chosen by default
#                     * 3 for a 3-point formula, which is also  known  as  a
#                       symmetric difference quotient (the formula  actually
#                       uses only two function values per variable:  at  x+h
#                       and x-h). A   good  compromise  for  medium-accuracy
#                       setups
#                     * 2 for a forward (or backward, depending  on variable
#                       bounds)  finite   difference  (f(x+h)-f(x))/h.  This
#                       formula has the lowest accuracy. However, it  is  4x
#                       faster than the 5-point formula and 2x  faster  than
#                       the 3-point one because, in addition to the  central
#                       value f(x), it needs only  one  additional  function
#                       evaluation per variable.
# 
# 
#   -- ALGLIB --
#      Copyright 03.12.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetnumdiff(state, formulatype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          formulatype: int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetscale'></a><h3 class=pageheader><code>minnlcsetscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets scaling coefficients for NLC optimizer.
# 
# ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
# size and gradient are scaled before comparison  with  tolerances).  Scales
# are also used by the finite difference variant of the optimizer - the step
# along I-th axis is equal to DiffStep*S[I]. Finally,  variable  scales  are
# used for preconditioning (i.e. to speed up the solver).
# 
# The scale of the I-th variable is a translation invariant measure of:
# a) &quot;how large&quot; the variable is
# b) how large the step should be to make significant changes in the function
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     S       -   array[N], non-zero scaling coefficients
#                 S[i] may be negative, sign doesn't matter.
# 
#   -- ALGLIB --
#      Copyright 06.06.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetscale(state, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          s:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetstpmax'></a><h3 class=pageheader><code>minnlcsetstpmax</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets maximum step length (after scaling of step vector  with
# respect to variable scales specified by minnlcsetscale() call).
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     StpMax  -   maximum step length, &gt;=0. Set StpMax to 0.0 (default),  if
#                 you don't want to limit step length.
# 
# Use this subroutine when you optimize target function which contains exp()
# or  other  fast  growing  functions,  and optimization algorithm makes too
# large  steps  which  leads  to overflow. This function allows us to reject
# steps  that  are  too  large  (and  therefore  expose  us  to the possible
# overflow) without actually calculating function value at the x+stp*d.
# 
# NOTE: different solvers employed by MinNLC  optimizer  may  use  different
#       norms for the step.
# 
#   -- ALGLIB --
#      Copyright 02.04.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetstpmax(state, stpmax)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          stpmax:     float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnlcsetxrep'></a><h3 class=pageheader><code>minnlcsetxrep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function turns on/off reporting.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     NeedXRep-   whether iteration reports are needed or not
# 
# If NeedXRep is True, algorithm will call rep() callback function if  it is
# provided to MinNLCOptimize().
# 
# NOTE: algorithm passes two parameters to rep() callback  -  current  point
#       and penalized function value at current point. Important -  function
#       value which is returned is NOT function being minimized. It  is  sum
#       of the value of the function being minimized - and penalty term.
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnlcsetxrep(state, needxrep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnlcstate
          needxrep:   bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_minns></a><h2 class=pageheader><code>minns</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_minnscreate' class=toc>minnscreate</a><br>
<a href='#sub_minnscreatef' class=toc>minnscreatef</a><br>
<a href='#sub_minnsrequesttermination' class=toc>minnsrequesttermination</a><br>
<a href='#sub_minnsrestartfrom' class=toc>minnsrestartfrom</a><br>
<a href='#sub_minnsresults' class=toc>minnsresults</a><br>
<a href='#sub_minnsresultsbuf' class=toc>minnsresultsbuf</a><br>
<a href='#sub_minnssetalgoags' class=toc>minnssetalgoags</a><br>
<a href='#sub_minnssetbc' class=toc>minnssetbc</a><br>
<a href='#sub_minnssetcond' class=toc>minnssetcond</a><br>
<a href='#sub_minnssetlc' class=toc>minnssetlc</a><br>
<a href='#sub_minnssetnlc' class=toc>minnssetnlc</a><br>
<a href='#sub_minnssetscale' class=toc>minnssetscale</a><br>
<a href='#sub_minnssetxrep' class=toc>minnssetxrep</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_minnscreate'></a><h3 class=pageheader><code>minnscreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
#                   NONSMOOTH NONCONVEX OPTIMIZATION
#             SUBJECT TO BOX/LINEAR/NONLINEAR-NONSMOOTH CONSTRAINTS
# 
# DESCRIPTION:
# 
# The  subroutine  minimizes  function   F(x)  of N arguments subject to any
# combination of:
# * bound constraints
# * linear inequality constraints
# * linear equality constraints
# * nonlinear equality constraints Gi(x)=0
# * nonlinear inequality constraints Hi(x)&lt;=0
# 
# IMPORTANT: see MinNSSetAlgoAGS for important  information  on  performance
#            restrictions of AGS solver.
# 
# REQUIREMENTS:
# * starting point X0 must be feasible or not too far away from the feasible
#   set
# * F(), G(), H() are continuous, locally Lipschitz  and  continuously  (but
#   not necessarily twice) differentiable in an open dense  subset  of  R^N.
#   Functions F(), G() and H() may be nonsmooth and non-convex.
#   Informally speaking, it means  that  functions  are  composed  of  large
#   differentiable &quot;patches&quot; with nonsmoothness having  place  only  at  the
#   boundaries between these &quot;patches&quot;.
#   Most real-life nonsmooth  functions  satisfy  these  requirements.  Say,
#   anything which involves finite number of abs(), min() and max() is  very
#   likely to pass the test.
#   Say, it is possible to optimize anything of the following:
#   * f=abs(x0)+2*abs(x1)
#   * f=max(x0,x1)
#   * f=sin(max(x0,x1)+abs(x2))
# * for nonlinearly constrained problems: F()  must  be  bounded from  below
#   without nonlinear constraints (this requirement is due to the fact that,
#   contrary to box and linear constraints, nonlinear ones  require  special
#   handling).
# * user must provide function value and gradient for F(), H(), G()  at  all
#   points where function/gradient can be calculated. If optimizer  requires
#   value exactly at the boundary between &quot;patches&quot; (say, at x=0 for f=abs(x)),
#   where gradient is not defined, user may resolve tie arbitrarily (in  our
#   case - return +1 or -1 at its discretion).
# * NS solver supports numerical differentiation, i.e. it may  differentiate
#   your function for you,  but  it  results  in  2N  increase  of  function
#   evaluations. Not recommended unless you solve really small problems. See
#   minnscreatef() for more information on this functionality.
# 
# USAGE:
# 
# 1. User initializes algorithm state with MinNSCreate() call  and   chooses
#    what NLC solver to use. There is some solver which is used by  default,
#    with default settings, but you should NOT rely on  default  choice.  It
#    may change in future releases of ALGLIB without notice, and no one  can
#    guarantee that new solver will be  able  to  solve  your  problem  with
#    default settings.
# 
#    From the other side, if you choose solver explicitly, you can be pretty
#    sure that it will work with new ALGLIB releases.
# 
#    In the current release following solvers can be used:
#    * AGS solver (activated with MinNSSetAlgoAGS() function)
# 
# 2. User adds boundary and/or linear and/or nonlinear constraints by  means
#    of calling one of the following functions:
#    a) MinNSSetBC() for boundary constraints
#    b) MinNSSetLC() for linear constraints
#    c) MinNSSetNLC() for nonlinear constraints
#    You may combine (a), (b) and (c) in one optimization problem.
# 
# 3. User sets scale of the variables with MinNSSetScale() function. It   is
#    VERY important to set  scale  of  the  variables,  because  nonlinearly
#    constrained problems are hard to solve when variables are badly scaled.
# 
# 4. User sets stopping conditions with MinNSSetCond().
# 
# 5. Finally, user calls MinNSOptimize()  function  which  takes   algorithm
#    state and pointer (delegate, etc) to callback function which calculates
#    F/G/H.
# 
# 7. User calls MinNSResults() to get solution
# 
# 8. Optionally user may call MinNSRestartFrom() to solve   another  problem
#    with same N but another starting point. MinNSRestartFrom()  allows   to
#    reuse already initialized structure.
# 
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;0:
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from size of X
#     X       -   starting point, array[N]:
#                 * it is better to set X to a feasible point
#                 * but X can be infeasible, in which case algorithm will try
#                   to find feasible point first, using X as initial
#                   approximation.
# 
# OUTPUT PARAMETERS:
#     State   -   structure stores algorithm state
# 
# NOTE: minnscreatef() function may be used if  you  do  not  have  analytic
#       gradient.   This   function  creates  solver  which  uses  numerical
#       differentiation with user-specified step.
# 
#   -- ALGLIB --
#      Copyright 18.05.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minnscreate(n, x)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minnscreate(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minnsstate

</div></pre>
<a name='sub_minnscreatef'></a><h3 class=pageheader><code>minnscreatef</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Version of minnscreatef() which uses numerical differentiation. I.e.,  you
# do not have to calculate derivatives yourself. However, this version needs
# 2N times more function evaluations.
# 
# 2-point differentiation formula is  used,  because  more  precise  4-point
# formula is unstable when used on non-smooth functions.
# 
# INPUT PARAMETERS:
#     N       -   problem dimension, N&gt;0:
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from size of X
#     X       -   starting point, array[N]:
#                 * it is better to set X to a feasible point
#                 * but X can be infeasible, in which case algorithm will try
#                   to find feasible point first, using X as initial
#                   approximation.
#     DiffStep-   differentiation  step,  DiffStep&gt;0.   Algorithm   performs
#                 numerical differentiation  with  step  for  I-th  variable
#                 being equal to DiffStep*S[I] (here S[] is a  scale vector,
#                 set by minnssetscale() function).
#                 Do not use  too  small  steps,  because  it  may  lead  to
#                 catastrophic cancellation during intermediate calculations.
# 
# OUTPUT PARAMETERS:
#     State   -   structure stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 18.05.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minnscreatef(n, x, diffstep)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minnscreatef(x, diffstep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          x:          1D array/list of float
          diffstep:   float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minnsstate

</div></pre>
<a name='sub_minnsrequesttermination'></a><h3 class=pageheader><code>minnsrequesttermination</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine submits request for termination of running  optimizer.  It
# should be called from user-supplied callback when user decides that it  is
# time to &quot;smoothly&quot; terminate optimization process.  As  result,  optimizer
# stops at point which was &quot;current accepted&quot; when termination  request  was
# submitted and returns error code 8 (successful termination).
# 
# INPUT PARAMETERS:
#     State   -   optimizer structure
# 
# NOTE: after  request  for  termination  optimizer  may   perform   several
#       additional calls to user-supplied callbacks. It does  NOT  guarantee
#       to stop immediately - it just guarantees that these additional calls
#       will be discarded later.
# 
# NOTE: calling this function on optimizer which is NOT running will have no
#       effect.
# 
# NOTE: multiple calls to this function are possible. First call is counted,
#       subsequent calls are silently ignored.
# 
#   -- ALGLIB --
#      Copyright 18.05.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnsrequesttermination(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnsstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnsrestartfrom'></a><h3 class=pageheader><code>minnsrestartfrom</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine restarts algorithm from new point.
# All optimization parameters (including constraints) are left unchanged.
# 
# This  function  allows  to  solve multiple  optimization  problems  (which
# must have  same number of dimensions) without object reallocation penalty.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minnscreate() call.
#     X       -   new starting point.
# 
#   -- ALGLIB --
#      Copyright 18.05.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnsrestartfrom(state, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnsstate
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnsresults'></a><h3 class=pageheader><code>minnsresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# MinNS results
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     X       -   array[0..N-1], solution
#     Rep     -   optimization report. You should check Rep.TerminationType
#                 in  order  to  distinguish  successful  termination  from
#                 unsuccessful one:
#                 * -8   internal integrity control  detected  infinite  or
#                        NAN   values   in   function/gradient.    Abnormal
#                        termination signalled.
#                 * -3   box constraints are inconsistent
#                 * -1   inconsistent parameters were passed:
#                        * penalty parameter for minnssetalgoags() is zero,
#                          but we have nonlinear constraints set by minnssetnlc()
#                 *  2   sampling radius decreased below epsx
#                 *  7    stopping conditions are too stringent,
#                         further improvement is impossible,
#                         X contains best point found so far.
#                 *  8    User requested termination via minnsrequesttermination()
# 
#   -- ALGLIB --
#      Copyright 18.05.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.minnsresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnsstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.minnsreport

</div></pre>
<a name='sub_minnsresultsbuf'></a><h3 class=pageheader><code>minnsresultsbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 
# Buffered implementation of minnsresults() which uses pre-allocated  buffer
# to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
# intended to be used in the inner cycles of performance critical algorithms
# where array reallocation penalty is too large to be ignored.
# 
#   -- ALGLIB --
#      Copyright 18.05.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.minnsresultsbuf(state, x, rep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnsstate
          x:          1D array/list of float
          rep:        class xalglib.minnsreport
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> rep
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float

</div></pre>
<a name='sub_minnssetalgoags'></a><h3 class=pageheader><code>minnssetalgoags</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function tells MinNS unit to use  AGS  (adaptive  gradient  sampling)
# algorithm for nonsmooth constrained  optimization.  This  algorithm  is  a
# slight modification of one described in  &quot;An  Adaptive  Gradient  Sampling
# Algorithm for Nonsmooth Optimization&quot; by Frank E. Curtisy and Xiaocun Quez.
# 
# This optimizer has following benefits and drawbacks:
# + robustness; it can be used with nonsmooth and nonconvex functions.
# + relatively easy tuning; most of the metaparameters are easy to select.
# - it has convergence of steepest descent, slower than CG/LBFGS.
# - each iteration involves evaluation of ~2N gradient values  and  solution
#   of 2Nx2N quadratic programming problem, which  limits  applicability  of
#   algorithm by small-scale problems (up to 50-100).
# 
# IMPORTANT: this  algorithm  has  convergence  guarantees,   i.e.  it  will
#            steadily move towards some stationary point of the function.
# 
#            However, &quot;stationary point&quot; does not  always  mean  &quot;solution&quot;.
#            Nonsmooth problems often have &quot;flat spots&quot;,  i.e.  areas  where
#            function do not change at all. Such &quot;flat spots&quot; are stationary
#            points by definition, and algorithm may be caught here.
# 
#            Nonsmooth CONVEX tasks are not prone to  this  problem. Say, if
#            your function has form f()=MAX(f0,f1,...), and f_i are  convex,
#            then f() is convex too and you have guaranteed  convergence  to
#            solution.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     Radius  -   initial sampling radius, &gt;=0.
# 
#                 Internally multiplied  by  vector of  per-variable  scales
#                 specified by minnssetscale()).
# 
#                 You should select relatively large sampling radius, roughly
#                 proportional to scaled length of the first  steps  of  the
#                 algorithm. Something close to 0.1 in magnitude  should  be
#                 good for most problems.
# 
#                 AGS solver can automatically decrease radius, so too large
#                 radius is  not a problem (assuming that you  won't  choose
#                 so large radius that algorithm  will  sample  function  in
#                 too far away points, where gradient value is irrelevant).
# 
#                 Too small radius won't cause algorithm to fail, but it may
#                 slow down algorithm (it may  have  to  perform  too  short
#                 steps).
#     Penalty -   penalty coefficient for nonlinear constraints:
#                 * for problem with nonlinear constraints  should  be  some
#                   problem-specific  positive   value,  large  enough  that
#                   penalty term changes shape of the function.
#                   Starting  from  some  problem-specific   value   penalty
#                   coefficient becomes  large  enough  to  exactly  enforce
#                   nonlinear constraints;  larger  values  do  not  improve
#                   precision.
#                   Increasing it too much may slow down convergence, so you
#                   should choose it carefully.
#                 * can be zero for problems WITHOUT  nonlinear  constraints
#                   (i.e. for unconstrained ones or ones with  just  box  or
#                   linear constraints)
#                 * if you specify zero value for problem with at least  one
#                   nonlinear  constraint,  algorithm  will  terminate  with
#                   error code -1.
# 
# ALGORITHM OUTLINE
# 
# The very basic outline of unconstrained AGS algorithm is given below:
# 
# 0. If sampling radius is below EpsX  or  we  performed  more  then  MaxIts
#    iterations - STOP.
# 1. sample O(N) gradient values at random locations  around  current point;
#    informally speaking, this sample is an implicit piecewise  linear model
#    of the function, although algorithm formulation does  not  mention that
#    explicitly
# 2. solve quadratic programming problem in order to find descent direction
# 3. if QP solver tells us that we  are  near  solution,  decrease  sampling
#    radius and move to (0)
# 4. perform backtracking line search
# 5. after moving to new point, goto (0)
# 
# Constraint handling details:
# * box constraints are handled exactly by algorithm
# * linear/nonlinear constraints are handled by adding L1  penalty.  Because
#   our solver can handle nonsmoothness, we can  use  L1  penalty  function,
#   which is an exact one  (i.e.  exact  solution  is  returned  under  such
#   penalty).
# * penalty coefficient for  linear  constraints  is  chosen  automatically;
#   however, penalty coefficient for nonlinear constraints must be specified
#   by user.
# 
# ===== TRACING AGS SOLVER =================================================
# 
# AGS solver supports advanced tracing capabilities. You can trace algorithm
# output by specifying following trace symbols (case-insensitive)  by  means
# of trace_file() call:
# * 'AGS'         - for basic trace of algorithm  steps and decisions.  Only
#                   short scalars (function values and deltas) are  printed.
#                   N-dimensional quantities like search directions are  NOT
#                   printed.
# * 'AGS.DETAILED'- for output of points being visited and search directions
#                   This  symbol  also  implicitly  defines  'AGS'. You  can
#                   control output format by additionally specifying:
#                   * nothing     to output in  6-digit exponential format
#                   * 'PREC.E15'  to output in 15-digit exponential format
#                   * 'PREC.F6'   to output in  6-digit fixed-point format
# * 'AGS.DETAILED.SAMPLE'-
#                   for output of points being visited ,  search  directions
#                   and gradient sample. May take a LOT of  space ,  do  not
#                   use it on problems with more that several tens of vars.
#                   This  symbol   also    implicitly   defines   'AGS'  and
#                   'AGS.DETAILED'.
# 
# By default trace is disabled and adds  no  overhead  to  the  optimization
# process. However, specifying any of the symbols adds some  formatting  and
# output-related overhead.
# 
# You may specify multiple symbols by separating them with commas:
# &gt;
# &gt; alglib::trace_file(&quot;AGS,PREC.F6&quot;, &quot;path/to/trace.log&quot;)
# &gt;
# 
# 
#   -- ALGLIB --
#      Copyright 18.05.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnssetalgoags(state, radius, penalty)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnsstate
          radius:     float
          penalty:    float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnssetbc'></a><h3 class=pageheader><code>minnssetbc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets boundary constraints.
# 
# Boundary constraints are inactive by default (after initial creation).
# They are preserved after algorithm restart with minnsrestartfrom().
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     BndL    -   lower bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 very small number or -INF.
#     BndU    -   upper bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 very large number or +INF.
# 
# NOTE 1: it is possible to specify BndL[i]=BndU[i]. In this case I-th
# variable will be &quot;frozen&quot; at X[i]=BndL[i]=BndU[i].
# 
# NOTE 2: AGS solver has following useful properties:
# * bound constraints are always satisfied exactly
# * function is evaluated only INSIDE area specified by  bound  constraints,
#   even  when  numerical  differentiation is used (algorithm adjusts  nodes
#   according to boundary constraints)
# 
#   -- ALGLIB --
#      Copyright 18.05.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnssetbc(state, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnsstate
          bndl:       1D array/list of float
          bndu:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnssetcond'></a><h3 class=pageheader><code>minnssetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping conditions for iterations of optimizer.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     EpsX    -   &gt;=0
#                 The AGS solver finishes its work if  on  k+1-th  iteration
#                 sampling radius decreases below EpsX.
#     MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
#                 iterations is unlimited.
# 
# Passing EpsX=0  and  MaxIts=0  (simultaneously)  will  lead  to  automatic
# stopping criterion selection. We do not recommend you to rely  on  default
# choice in production code.
# 
#   -- ALGLIB --
#      Copyright 18.05.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnssetcond(state, epsx, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnsstate
          epsx:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnssetlc'></a><h3 class=pageheader><code>minnssetlc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets linear constraints.
# 
# Linear constraints are inactive by default (after initial creation).
# They are preserved after algorithm restart with minnsrestartfrom().
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minnscreate() call.
#     C       -   linear constraints, array[K,N+1].
#                 Each row of C represents one constraint, either equality
#                 or inequality (see below):
#                 * first N elements correspond to coefficients,
#                 * last element corresponds to the right part.
#                 All elements of C (including right part) must be finite.
#     CT      -   type of constraints, array[K]:
#                 * if CT[i]&gt;0, then I-th constraint is C[i,*]*x &gt;= C[i,n+1]
#                 * if CT[i]=0, then I-th constraint is C[i,*]*x  = C[i,n+1]
#                 * if CT[i]&lt;0, then I-th constraint is C[i,*]*x &lt;= C[i,n+1]
#     K       -   number of equality/inequality constraints, K&gt;=0:
#                 * if given, only leading K elements of C/CT are used
#                 * if not given, automatically determined from sizes of C/CT
# 
# NOTE: linear (non-bound) constraints are satisfied only approximately:
# 
# * there always exists some minor violation (about current sampling  radius
#   in magnitude during optimization, about EpsX in the solution) due to use
#   of penalty method to handle constraints.
# * numerical differentiation, if used, may  lead  to  function  evaluations
#   outside  of the feasible  area,   because   algorithm  does  NOT  change
#   numerical differentiation formula according to linear constraints.
# 
# If you want constraints to be  satisfied  exactly, try to reformulate your
# problem  in  such  manner  that  all constraints will become boundary ones
# (this kind of constraints is always satisfied exactly, both in  the  final
# solution and in all intermediate points).
# 
#   -- ALGLIB --
#      Copyright 18.05.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnssetlc(state, c, ct, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnssetlc(state, c, ct)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnsstate
          c:          2D array/list of float
          ct:         1D array/list of int
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnssetnlc'></a><h3 class=pageheader><code>minnssetnlc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets nonlinear constraints.
# 
# In fact, this function sets NUMBER of nonlinear  constraints.  Constraints
# itself (constraint functions) are passed to minnsoptimize() method.   This
# method requires user-defined vector function F[]  and  its  Jacobian  J[],
# where:
# * first component of F[] and first row  of  Jacobian  J[]  correspond   to
#   function being minimized
# * next NLEC components of F[] (and rows  of  J)  correspond  to  nonlinear
#   equality constraints G_i(x)=0
# * next NLIC components of F[] (and rows  of  J)  correspond  to  nonlinear
#   inequality constraints H_i(x)&lt;=0
# 
# NOTE: you may combine nonlinear constraints with linear/boundary ones.  If
#       your problem has mixed constraints, you  may explicitly specify some
#       of them as linear ones. It may help optimizer to  handle  them  more
#       efficiently.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minnscreate() call.
#     NLEC    -   number of Non-Linear Equality Constraints (NLEC), &gt;=0
#     NLIC    -   number of Non-Linear Inquality Constraints (NLIC), &gt;=0
# 
# NOTE 1: nonlinear constraints are satisfied only  approximately!   It   is
#         possible   that  algorithm  will  evaluate  function  outside   of
#         the feasible area!
# 
# NOTE 2: algorithm scales variables  according  to   scale   specified   by
#         minnssetscale()  function,  so  it can handle problems with  badly
#         scaled variables (as long as we KNOW their scales).
# 
#         However,  there  is  no  way  to  automatically  scale   nonlinear
#         constraints Gi(x) and Hi(x). Inappropriate scaling  of  Gi/Hi  may
#         ruin convergence. Solving problem with  constraint  &quot;1000*G0(x)=0&quot;
#         is NOT same as solving it with constraint &quot;0.001*G0(x)=0&quot;.
# 
#         It  means  that  YOU  are  the  one who is responsible for correct
#         scaling of nonlinear constraints Gi(x) and Hi(x). We recommend you
#         to scale nonlinear constraints in such way that I-th component  of
#         dG/dX (or dH/dx) has approximately unit  magnitude  (for  problems
#         with unit scale)  or  has  magnitude approximately equal to 1/S[i]
#         (where S is a scale set by minnssetscale() function).
# 
# NOTE 3: nonlinear constraints are always hard to handle,  no  matter  what
#         algorithm you try to use. Even basic box/linear constraints modify
#         function  curvature   by  adding   valleys  and  ridges.  However,
#         nonlinear constraints add valleys which are very  hard  to  follow
#         due to their &quot;curved&quot; nature.
# 
#         It means that optimization with single nonlinear constraint may be
#         significantly slower than optimization with multiple linear  ones.
#         It is normal situation, and we recommend you to  carefully  choose
#         Rho parameter of minnssetalgoags(), because too  large  value  may
#         slow down convergence.
# 
# 
#   -- ALGLIB --
#      Copyright 18.05.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnssetnlc(state, nlec, nlic)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnsstate
          nlec:       int
          nlic:       int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnssetscale'></a><h3 class=pageheader><code>minnssetscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets scaling coefficients for NLC optimizer.
# 
# ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
# size and gradient are scaled before comparison with tolerances).  Scale of
# the I-th variable is a translation invariant measure of:
# a) &quot;how large&quot; the variable is
# b) how large the step should be to make significant changes in the function
# 
# Scaling is also used by finite difference variant of the optimizer  - step
# along I-th axis is equal to DiffStep*S[I].
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     S       -   array[N], non-zero scaling coefficients
#                 S[i] may be negative, sign doesn't matter.
# 
#   -- ALGLIB --
#      Copyright 18.05.2015 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnssetscale(state, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnsstate
          s:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minnssetxrep'></a><h3 class=pageheader><code>minnssetxrep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function turns on/off reporting.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     NeedXRep-   whether iteration reports are needed or not
# 
# If NeedXRep is True, algorithm will call rep() callback function if  it is
# provided to minnsoptimize().
# 
#   -- ALGLIB --
#      Copyright 28.11.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minnssetxrep(state, needxrep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minnsstate
          needxrep:   bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_minqp></a><h2 class=pageheader><code>minqp</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_minqpaddlc2' class=toc>minqpaddlc2</a><br>
<a href='#sub_minqpaddlc2dense' class=toc>minqpaddlc2dense</a><br>
<a href='#sub_minqpaddlc2sparsefromdense' class=toc>minqpaddlc2sparsefromdense</a><br>
<a href='#sub_minqpaddpowccorthogonal' class=toc>minqpaddpowccorthogonal</a><br>
<a href='#sub_minqpaddpowccprimitive' class=toc>minqpaddpowccprimitive</a><br>
<a href='#sub_minqpaddqc2' class=toc>minqpaddqc2</a><br>
<a href='#sub_minqpaddqc2dense' class=toc>minqpaddqc2dense</a><br>
<a href='#sub_minqpaddqc2list' class=toc>minqpaddqc2list</a><br>
<a href='#sub_minqpaddsoccorthogonal' class=toc>minqpaddsoccorthogonal</a><br>
<a href='#sub_minqpaddsoccprimitive' class=toc>minqpaddsoccprimitive</a><br>
<a href='#sub_minqpclearcc' class=toc>minqpclearcc</a><br>
<a href='#sub_minqpclearqc' class=toc>minqpclearqc</a><br>
<a href='#sub_minqpcreate' class=toc>minqpcreate</a><br>
<a href='#sub_minqpexport' class=toc>minqpexport</a><br>
<a href='#sub_minqpimport' class=toc>minqpimport</a><br>
<a href='#sub_minqpoptimize' class=toc>minqpoptimize</a><br>
<a href='#sub_minqpresults' class=toc>minqpresults</a><br>
<a href='#sub_minqpresultsbuf' class=toc>minqpresultsbuf</a><br>
<a href='#sub_minqpsetalgodenseaul' class=toc>minqpsetalgodenseaul</a><br>
<a href='#sub_minqpsetalgodensegenipm' class=toc>minqpsetalgodensegenipm</a><br>
<a href='#sub_minqpsetalgodenseipm' class=toc>minqpsetalgodenseipm</a><br>
<a href='#sub_minqpsetalgoquickqp' class=toc>minqpsetalgoquickqp</a><br>
<a href='#sub_minqpsetalgosparseecqp' class=toc>minqpsetalgosparseecqp</a><br>
<a href='#sub_minqpsetalgosparsegenipm' class=toc>minqpsetalgosparsegenipm</a><br>
<a href='#sub_minqpsetalgosparseipm' class=toc>minqpsetalgosparseipm</a><br>
<a href='#sub_minqpsetbc' class=toc>minqpsetbc</a><br>
<a href='#sub_minqpsetbcall' class=toc>minqpsetbcall</a><br>
<a href='#sub_minqpsetbci' class=toc>minqpsetbci</a><br>
<a href='#sub_minqpsetlc' class=toc>minqpsetlc</a><br>
<a href='#sub_minqpsetlc2' class=toc>minqpsetlc2</a><br>
<a href='#sub_minqpsetlc2dense' class=toc>minqpsetlc2dense</a><br>
<a href='#sub_minqpsetlc2mixed' class=toc>minqpsetlc2mixed</a><br>
<a href='#sub_minqpsetlcmixed' class=toc>minqpsetlcmixed</a><br>
<a href='#sub_minqpsetlcmixedlegacy' class=toc>minqpsetlcmixedlegacy</a><br>
<a href='#sub_minqpsetlcsparse' class=toc>minqpsetlcsparse</a><br>
<a href='#sub_minqpsetlinearterm' class=toc>minqpsetlinearterm</a><br>
<a href='#sub_minqpsetorigin' class=toc>minqpsetorigin</a><br>
<a href='#sub_minqpsetquadraticterm' class=toc>minqpsetquadraticterm</a><br>
<a href='#sub_minqpsetquadratictermsparse' class=toc>minqpsetquadratictermsparse</a><br>
<a href='#sub_minqpsetscale' class=toc>minqpsetscale</a><br>
<a href='#sub_minqpsetscaleautodiag' class=toc>minqpsetscaleautodiag</a><br>
<a href='#sub_minqpsetstartingpoint' class=toc>minqpsetstartingpoint</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_minqpaddlc2'></a><h3 class=pageheader><code>minqpaddlc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends two-sided linear constraint  AL &lt;= A*x &lt;= AU  to the
# list of currently present sparse constraints.
# 
# Constraint is passed in compressed format: as list of non-zero entries  of
# coefficient vector A. Such approach is more efficient than  dense  storage
# for highly sparse constraint vectors.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minqpcreate() call.
#     IdxA    -   array[NNZ], indexes of non-zero elements of A:
#                 * can be unsorted
#                 * can include duplicate indexes (corresponding entries  of
#                   ValA[] will be summed)
#     ValA    -   array[NNZ], values of non-zero elements of A
#     NNZ     -   number of non-zero coefficients in A
#     AL, AU  -   lower and upper bounds;
#                 * AL=AU    =&gt; equality constraint A*x
#                 * AL&lt;AU    =&gt; two-sided constraint AL&lt;=A*x&lt;=AU
#                 * AL=-INF  =&gt; one-sided constraint A*x&lt;=AU
#                 * AU=+INF  =&gt; one-sided constraint AL&lt;=A*x
#                 * AL=-INF, AU=+INF =&gt; constraint is ignored
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpaddlc2(state, idxa, vala, nnz, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          idxa:       1D array/list of int
          vala:       1D array/list of float
          nnz:        int
          al:         float
          au:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpaddlc2dense'></a><h3 class=pageheader><code>minqpaddlc2dense</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends two-sided linear constraint  AL &lt;= A*x &lt;= AU  to the
# matrix of currently present dense constraints.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minqpcreate() call.
#     A       -   linear constraint coefficient, array[N], right side is NOT
#                 included.
#     AL, AU  -   lower and upper bounds;
#                 * AL=AU    =&gt; equality constraint Ai*x
#                 * AL&lt;AU    =&gt; two-sided constraint AL&lt;=A*x&lt;=AU
#                 * AL=-INF  =&gt; one-sided constraint Ai*x&lt;=AU
#                 * AU=+INF  =&gt; one-sided constraint AL&lt;=Ai*x
#                 * AL=-INF, AU=+INF =&gt; constraint is ignored
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpaddlc2dense(state, a, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          a:          1D array/list of float
          al:         float
          au:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpaddlc2sparsefromdense'></a><h3 class=pageheader><code>minqpaddlc2sparsefromdense</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends two-sided linear constraint  AL &lt;= A*x &lt;= AU  to the
# list of currently present sparse constraints.
# 
# Constraint vector A is  passed  as  a  dense  array  which  is  internally
# sparsified by this function.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minqpcreate() call.
#     DA      -   array[N], constraint vector
#     AL, AU  -   lower and upper bounds;
#                 * AL=AU    =&gt; equality constraint A*x
#                 * AL&lt;AU    =&gt; two-sided constraint AL&lt;=A*x&lt;=AU
#                 * AL=-INF  =&gt; one-sided constraint A*x&lt;=AU
#                 * AU=+INF  =&gt; one-sided constraint AL&lt;=A*x
#                 * AL=-INF, AU=+INF =&gt; constraint is ignored
# 
#   -- ALGLIB --
#      Copyright 19.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpaddlc2sparsefromdense(state, da, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          da:         1D array/list of float
          al:         float
          au:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpaddpowccorthogonal'></a><h3 class=pageheader><code>minqpaddpowccorthogonal</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends an axis-orthogonal power cone constraint of the form
# 
#          (          k-kp-1      )     k-1
#     sqrt ( theta^2 + SUM y[i]^2 ) &lt;=  MUL y[i]^alpha[i]
#          (           i=0        )    i=k-kp
# 
# where
# 
#     y[i] = a[i]*x[idx[i]]+c[i], y[i]&gt;=0
# 
#     0&lt;alpha[i]&lt;1, with SUM(alpha[i])&lt;=1
# 
#     1&lt;=kp&lt;=k, with kp=k meaning that we have MUL(y[i]^alpha[i])&gt;=|theta|
# 
# Alternatively, if ApplyOrigin parameter  is  True,  x[i]  is  replaced  by
# x[i]-origin[i] (applies to all variables).
# 
# Unlike many other conic solvers, ALGLIB provides a flexible conic API that
# allows alpha[] to sum up to any positive value less than  or  equal  to  1
# (e.g. it is possible to formulate |x|&lt;z^0.33 without  using  slack  vars).
# Furthermore, ALGLIB allows conic constraints to overlap, i.e. it allows  a
# variable to be a part of multiple conic constraints, or to appear multiple
# times in the same constraint.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated  with  minqpcreate()  call.
#     Idx     -   array[K] (or larger, only leading  K  elements  are  used)
#                 storing variable indexes. Indexes can be  unsorted  and/or
#                 non-distinct.
#     A       -   array[K]  (or larger, only leading  K  elements are used),
#                 variable multipliers. Can contain zero values.
#     C       -   array[K] (or larger, only leading  K  elements  are used),
#                 variable shifts.
#     K       -   cone dimensionality, K&gt;=1. It is possible to have K&gt;N.
#     Theta   -   additional constant term, can be zero
#     AlphaV  -   array[KPow], power coefficients:
#                 * 0&lt;AlphaV[i]&lt;=1
#                 * 0&lt;SUM(AlphaV[])&lt;=1
#     KPow    -   1&lt;=KPow&lt;=K, with KPow=K being correctly handled.
# 
# RESULT:
#     constraint index in a conic constraints list, starting from 0
# 
# NOTE: power cone constraints are always  convex,  so having them preserves
#       convexity of the QP problem.
# 
# NOTE: A starting point that is strictly feasible with respect to both  box
#       and conic constraints greatly helps the solver to power up; however,
#       it will work even without such a point,  albeit  at  somewhat  lower
#       performance.
# 
# NOTE: a power cone with alpha&lt;1 is sensitive to numerical errors near  the
#       origin.  Suppose,  for  example,  that  we  have a constraint of the
#       form |y|&lt;=x^alpha with alpha=0.25 and that x is zero at the solution
#       Furthermore, suppose that we perturbed x by as little  as  eps=1E-8.
#       Because of alpha=0.25 the constraint is  perturbed  by  as  much  as
#       eps^(1/4)=0.01!
# 
#       Such great sensitivity is  explained  by  the  non-differentiability
#       of x^alpha for alpha&lt;1 near x=0.  It  does  not  prevent  the  conic
#       solver  from  converging  to   the precise solution, it merely makes
#       constraints  extremely  sensitive  to  small   errors,   e.g.   ones
#       introduced during the presolve/postsolve, like discussed below.
# 
#       The conic solver sometimes has to insert slack variables, most often
#       because of constraints referring the same right-hand  side  variable
#       twice.   For   example,  for  sqrt(x0^2+x1^2)&lt;=(y0-1)^0.5*(y0+1)^0.5
#       it will automatically add t=y0+1 (a linear equality constraint)  and
#       will rewrite the  constraint  as  sqrt(x0^2+x1^2)&lt;=(y0-1)^0.5*t^0.5.
#       The solver will have no  difficulty  solving  the  problem,  even if
#       the optimal t is close to zero. However, the equality y0=t-1 will be
#       satisfied only approximately, and even a tiny error will be  greatly
#       magnified when evaluating the constraint violation.
# 
#       Thus,   one  has  to  be  very  careful  when  evaluating constraint
#       violation errors  for  power  cones.  Having  high  error  does  not
#       necessarily mean that the solver has failed.
# 
#   -- ALGLIB --
#      Copyright 09.09.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.minqpaddpowccorthogonal(state, idx, a, c, k, theta, alphav, kpow, applyorigin)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          idx:        1D array/list of int
          a:          1D array/list of float
          c:          1D array/list of float
          k:          int
          theta:      float
          alphav:     1D array/list of float
          kpow:       int
          applyorigin: bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_minqpaddpowccprimitive'></a><h3 class=pageheader><code>minqpaddpowccprimitive</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends a primitive power cone constraint of the form
# 
#         (                                                  )
#     sqrt(x[range0]^2 + x[range0+1]^2 + ... + x[range1-1]^2 ) &lt;= x[axisidx]^alpha
#         (                                                  )
# 
# or, written in another form,
# 
#     (    (                                                  ))^(1/alpha)
#     (sqrt(x[range0]^2 + x[range0+1]^2 + ... + x[range1-1]^2 ))           &lt;= x[axisidx]
#     (    (                                                  ))
# 
# where
# 
#     0&lt;alpha&lt;=1
# 
# with 'primitive' meaning that there are no per-variable  scales  and  that
# variables under the square root have sequential indexes. More general form
# of power cone constraints can be specified with minqpaddpowccorthogonal().
# 
# Alternatively, if ApplyOrigin parameter  is  True,  x[i]  is  replaced  by
# x[i]-origin[i] (applies to all variables).
# 
# Unlike many other conic solvers, ALGLIB provides a flexible conic API that
# allows alpha to be any positive value less than or equal to 1 (e.g.  it is
# possible to formulate |x|&lt;z^0.33 without using  slack vars that are  fixed
# at 1.0). Furthermore, ALGLIB allows conic constraints to overlap, i.e.  it
# allows a variable to be a part of multiple conic constraints.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minqpcreate() call.
#     Range0,
#     Range1  -   0&lt;=range0&lt;=range1&lt;=N, variable range for the LHS;
#                 * squared variables x[range0]...x[range1-1] are summed up
#                   under the square root.
#                 * range0=range1 means that the constraint is interpreted
#                   as x[AxisIdx]&gt;=0.
#     AxisIdx -   RHS variable index:
#                 * 0&lt;=AxisIdx&lt;N
#                 * either AxisIdx&lt;range0 or AxisAdx&gt;=Range1.
#     Alpha   -   power parameter, 0&lt;alpha&lt;=1
# 
# RESULT:
#     constraint index in a conic constraints list, starting from 0
# 
# NOTE: power cone constraints are always  convex,  so having them preserves
#       convexity of the QP problem.
# 
# NOTE: A starting point that is strictly feasible with respect to both  box
#       and conic constraints greatly helps the solver to power up; however,
#       it will work even without such a point,  albeit  at  somewhat  lower
#       performance.
# 
# NOTE: a power cone with alpha&lt;1 is sensitive to numerical errors near  the
#       origin.  Suppose,  for  example,  that  we  have a constraint of the
#       form |y|&lt;=x^alpha with alpha=0.25 and that x is zero at the solution
#       Furthermore, suppose that we perturbed x by as little  as  eps=1E-8.
#       Because of alpha=0.25 the constraint is  perturbed  by  as  much  as
#       eps^(1/4)=0.01!
# 
#       Such great sensitivity is  explained  by  the  non-differentiability
#       of x^alpha for alpha&lt;1 near x=0.  It  does  not  prevent  the  conic
#       solver  from  converging  to   the precise solution, it merely makes
#       constraints  extremely  sensitive  to  small   errors,   e.g.   ones
#       introduced during the presolve/postsolve, like discussed below.
# 
#       The conic solver sometimes has to insert slack variables, most often
#       because of constraints referring the same right-hand  side  variable
#       twice.   For   example,  for  sqrt(x0^2+x1^2)&lt;=(y0-1)^0.5*(y0+1)^0.5
#       it will automatically add t=y0+1 (a linear equality constraint)  and
#       will rewrite the  constraint  as  sqrt(x0^2+x1^2)&lt;=(y0-1)^0.5*t^0.5.
#       The solver will have no  difficulty  solving  the  problem,  even if
#       the optimal t is close to zero. However, the equality y0=t-1 will be
#       satisfied only approximately, and even a tiny error will be  greatly
#       magnified when evaluating the constraint violation.
# 
#       Thus,   one  has  to  be  very  careful  when  evaluating constraint
#       violation errors  for  power  cones.  Having  high  error  does  not
#       necessarily mean that the solver has failed.
# 
#   -- ALGLIB --
#      Copyright 19.11.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.minqpaddpowccprimitive(state, range0, range1, axisidx, alpha, applyorigin)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          range0:     int
          range1:     int
          axisidx:    int
          alpha:      float
          applyorigin: bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_minqpaddqc2'></a><h3 class=pageheader><code>minqpaddqc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends a two-sided quadratic constraint of the form
# 
#     CL &lt;= b'x + 0.5*x'*Q*x &lt;= CU
# 
# or (depending on the ApplyOrigin parameter)
# 
#     CL &lt;= b'(x-origin) + 0.5*(x-origin)'*Q*(x-origin) &lt;= CU
# 
# to the set of currently present constraints. The linear term is  given  by
# a dense array, the quadratic term is given by a sparse array.
# 
# Here CL can be finite or -INF (absense of constraint), CU can be finite or
# +INF (absense of constraint), CL&lt;=CU, with  CL=CU  denoting   an  equality
# constraint. Q is an arbitrary (including indefinite) symmetric matrix.
# 
# The  function  has  O(max(N,NNZ)) memory and time requirements  because  a
# dense array is used to store linear term and because  most  sparse  matrix
# storage formats supported by ALGLIB need at least O(N) memory even for  an
# empty quadratic constraint matrix.
# 
# Use minqpaddqc2list() if you have to add many constraints with  much  less
# than N nonzero elements.
# 
# IMPORTANT: ALGLIB  supports  arbitrary  quadratic  constraints,  including
#            nonconvex ones. However, only convex constraints (combined with
#            the convex objective) result in guaranteed convergence  to  the
#            global minimizer. In all other cases, only local convergence to
#            a local minimum is guaranteed.
# 
#            A convex constraint is a  constraint  of  the  following  form:
#            b'*(x-origin) + 0.5(x-origin)'*Q*(x-origin) &lt;=CU, with Q  being
#            a semidefinite matrix. All other modifications  are  nonconvex:
#            * -x0^2&lt;=1 is nonconvex
#            *  x0^2&gt;=1 is nonconvex (despite Q=1 being positive definite)
#            *  x0^2 =1 is nonconvex
# 
#            The latter case is notable because it effectively converts a QP
#            problem into a mixed integer QP program. Smooth interior  point
#            solver can not efficiently handle such programs, converging  to
#            a randomly chosen x0 (either +1 or -1) and  keeping  its  value
#            fixed during the optimization.
# 
#            It is also  notable  that  larger  equality  constraints  (e.g.
#            x0^2+x1^2=1) are much less difficult  to  handle  because  they
#            form large connected regions within the parameters space.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minqpcreate() call.
#     Q       -   symmetric matrix Q in a sparse matrix storage format:
#                 * if IsUpper=True, then the upper triangle  is  given, and
#                   the lower triangle is ignored
#                 * if IsUpper=False, then the lower triangle is  given, and
#                   the upper triangle is ignored
#                 * any sparse matrix storage format present in ALGLIB is
#                   supported
#                 * the matrix must be exactly NxN
#     IsUpper -   whether upper or lower triangle of Q is used
#     B       -   array[N], linear term
#     CL, CU  -   lower and upper bounds:
#                 * CL can be finite or -INF (absence of a bound)
#                 * CU can be finite or +INF (absence of a bound)
#                 * CL&lt;=CU, with CL=CU meaning an equality constraint
#                 * CL=-INF, CU=+INF =&gt; constraint is ignored
#     ApplyOrigin-whether origin (as specified by minqpsetorigin) is applied
#                 to the constraint or not. If no origin was specified, this
#                 parameter has no effect.
# 
# RESULT:
#     constraint index, starting from 0
# 
#   -- ALGLIB --
#      Copyright 19.07.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.minqpaddqc2(state, q, isupper, b, cl, cu, applyorigin)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          q:          class xalglib.sparsematrix
          isupper:    bool
          b:          1D array/list of float
          cl:         float
          cu:         float
          applyorigin: bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_minqpaddqc2dense'></a><h3 class=pageheader><code>minqpaddqc2dense</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends a two-sided quadratic constraint of the form
# 
#     CL &lt;= b'x + 0.5*x'*Q*x &lt;= CU
# 
# or (depending on the ApplyOrigin parameter)
# 
#     CL &lt;= b'(x-origin) + 0.5*(x-origin)'*Q*(x-origin) &lt;= CU
# 
# to the set of currently present constraints. The linear and quadratic terms
# are given by dense arrays.
# 
# Here CL can be finite or -INF (absense of constraint), CU can be finite or
# +INF (absense of constraint), CL&lt;=CU, with  CL=CU  denoting   an  equality
# constraint. Q is an arbitrary (including indefinite) symmetric matrix.
# 
# This function trades convenience of using dense arrays for the efficiency.
# Because dense NxN storage is used, merely calling this function has O(N^2)
# complexity, no matter how sparse the Q is.
# 
# Use minqpaddqc2() or minqpaddqc2list() if you have sparse  Q  and/or  many
# constraints to handle.
# 
# IMPORTANT: ALGLIB  supports  arbitrary  quadratic  constraints,  including
#            nonconvex ones. However, only convex constraints (combined with
#            the convex objective) result in guaranteed convergence  to  the
#            global minimizer. In all other cases, only local convergence to
#            a local minimum is guaranteed.
# 
#            A convex constraint is a  constraint  of  the  following  form:
#            b'*(x-origin) + 0.5(x-origin)'*Q*(x-origin) &lt;=CU, with Q  being
#            a semidefinite matrix. All other modifications  are  nonconvex:
#            * -x0^2&lt;=1 is nonconvex
#            *  x0^2&gt;=1 is nonconvex (despite Q=1 being positive definite)
#            *  x0^2 =1 is nonconvex
# 
#            The latter case is notable because it effectively converts a QP
#            problem into a mixed integer QP program. Smooth interior  point
#            solver can not efficiently handle such programs, converging  to
#            a randomly chosen x0 (either +1 or -1) and  keeping  its  value
#            fixed during the optimization.
# 
#            It is also  notable  that  larger  equality  constraints  (e.g.
#            x0^2+x1^2=1) are much less difficult  to  handle  because  they
#            form large connected regions within the parameters space.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minqpcreate() call.
#     Q       -   array[N,N], symmetric matrix Q:
#                 * if IsUpper=True, then the upper triangle  is  given, and
#                   the lower triangle is ignored
#                 * if IsUpper=False, then the lower triangle is  given, and
#                   the upper triangle is ignored
#                 * if more than N rows/cols are present, only leading N
#                   elements are used
#     IsUpper -   whether upper or lower triangle of Q is used
#     B       -   array[N], linear term
#     CL, CU  -   lower and upper bounds:
#                 * CL can be finite or -INF (absence of a bound)
#                 * CU can be finite or +INF (absence of a bound)
#                 * CL&lt;=CU, with CL=CU meaning an equality constraint
#                 * CL=-INF, CU=+INF =&gt; constraint is ignored
#     ApplyOrigin-whether origin (as specified by minqpsetorigin) is applied
#                 to the constraint or not. If no origin was specified, this
#                 parameter has no effect.
# 
# RESULT:
#     constraint index, starting from 0
# 
#   -- ALGLIB --
#      Copyright 19.06.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.minqpaddqc2dense(state, q, isupper, b, cl, cu, applyorigin)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          q:          2D array/list of float
          isupper:    bool
          b:          1D array/list of float
          cl:         float
          cu:         float
          applyorigin: bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_minqpaddqc2list'></a><h3 class=pageheader><code>minqpaddqc2list</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends a two-sided quadratic constraint of the form
# 
#     CL &lt;= b'x + 0.5*x'*Q*x &lt;= CU
# 
# or (depending on the ApplyOrigin parameter)
# 
#     CL &lt;= b'(x-origin) + 0.5*(x-origin)'*Q*(x-origin) &lt;= CU
# 
# to the set of currently present constraints.  Both  linear  and  quadratic
# terms are given as lists of non-zero entries.
# 
# Here CL can be finite or -INF (absense of constraint), CU can be finite or
# +INF (absense of constraint), CL&lt;=CU, with  CL=CU  denoting   an  equality
# constraint. Q is an arbitrary (including indefinite) symmetric matrix.
# 
# The function needs O(NNZ) memory for temporaries and  O(NNZ*logNNZ)  time,
# where NNZ is a  total  number  of  non-zeros  in  both  lists.  For  small
# constraints it can be orders of magnitude faster than  minqpaddqc2()  with
# its  O(max(N,NNZ)) temporary memory or minqpaddqc2dense() with its  O(N^2)
# temporaries. Thus, it is recommended if you have many small constraints.
# 
# NOTE: in  the  end,  all  quadratic  constraints  are  stored  in the same
#       memory-efficient compressed format. However, you have to allocate an
#       NxN  temporary  dense  matrix  when  you  pass  a  constraint  using
#       minqpaddqc2dense(). Similarly, data structures used as a part of the
#       API  provided  by   minqpaddqc2()   have   O(N)   temporary   memory
#       requirements.
# 
# IMPORTANT: ALGLIB  supports  arbitrary  quadratic  constraints,  including
#            nonconvex ones. However, only convex constraints (combined with
#            the convex objective) result in guaranteed convergence  to  the
#            global minimizer. In all other cases, only local convergence to
#            a local minimum is guaranteed.
# 
#            A convex constraint is a  constraint  of  the  following  form:
#            b'*(x-origin) + 0.5(x-origin)'*Q*(x-origin) &lt;=CU, with Q  being
#            a semidefinite matrix. All other modifications  are  nonconvex:
#            * -x0^2&lt;=1 is nonconvex
#            *  x0^2&gt;=1 is nonconvex (despite Q=1 being positive definite)
#            *  x0^2 =1 is nonconvex
# 
#            The latter case is notable because it effectively converts a QP
#            problem into a mixed integer QP program. Smooth interior  point
#            solver can not efficiently handle such programs, converging  to
#            a randomly chosen x0 (either +1 or -1) and  keeping  its  value
#            fixed during the optimization.
# 
#            It is also  notable  that  larger  equality  constraints  (e.g.
#            x0^2+x1^2=1) are much less difficult  to  handle  because  they
#            form large connected regions within the parameters space.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minqpcreate() call.
#     QRIdx   -   array[QNNZ], stores row indexes of QNNZ  nonzero  elements
#                 of a symmetric matrix Q
#     QCIdx   -   array[QNNZ], stores col indexes of QNNZ  nonzero  elements
#                 of a symmetric matrix Q
#     QVals   -   array[QNNZ], stores values of QNNZ  nonzero  elements of a
#                 symmetric matrix Q
#     QNNZ    -   number of non-zero elements in Q, QNNZ&gt;=0
#     IsUpper -   whether upper or lower triangle of Q is used:
#                 * if IsUpper=True, then only elements with QRIdx[I]&lt;=QCIdx[I]
#                   are used and the rest is ignored
#                 * if IsUpper=False, then only elements with QRIdx[I]&gt;=QCIdx[I]
#                   are used and the rest is ignored
#     BIdx    -   array[BNNZ], indexes of BNNZ nonzero elements of a linear term
#     BVals   -   array[BNNZ], values of BNNZ nonzero elements of a linear term
#     BNNZ    -   number of nonzero elements in B, BNNZ&gt;=0
#     CL, CU  -   lower and upper bounds:
#                 * CL can be finite or -INF (absence of a bound)
#                 * CU can be finite or +INF (absence of a bound)
#                 * CL&lt;=CU, with CL=CU meaning an equality constraint
#                 * CL=-INF, CU=+INF =&gt; constraint is ignored
#     ApplyOrigin-whether origin (as specified by minqpsetorigin) is applied
#                 to the constraint or not. If no origin was specified, this
#                 parameter has no effect.
# 
# RESULT:
#     constraint index, starting from 0
# 
#   -- ALGLIB --
#      Copyright 19.07.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.minqpaddqc2list(state, qridx, qcidx, qvals, qnnz, isupper, bidx, bvals, bnnz, cl, cu, applyorigin)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          qridx:      1D array/list of int
          qcidx:      1D array/list of int
          qvals:      1D array/list of float
          qnnz:       int
          isupper:    bool
          bidx:       1D array/list of int
          bvals:      1D array/list of float
          bnnz:       int
          cl:         float
          cu:         float
          applyorigin: bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_minqpaddsoccorthogonal'></a><h3 class=pageheader><code>minqpaddsoccorthogonal</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends an axis-orthogonal second-order  conic constraint of
# the form
# 
#          ( k-2 (                     )^2          )
#     sqrt ( SUM ( a[i]*x[idx[i]]+c[i] )  + theta^2 ) &lt;= a[k-1]*x[idx[k-1]]+c[k-1]
#          ( i=0 (                     )            )
# 
# Alternatively, if ApplyOrigin parameter  is  True,  x[i]  is  replaced  by
# x[i]-origin[i] (applies to all variables).
# 
# Unlike many other conic solvers, ALGLIB provides a flexible conic API that
# allows a[] to have zero elements at arbitrary positions (e.g.,  |x|&lt;=const
# can be handled just as easy as |x|&lt;=y). Furthermore, ALGLIB  allows  conic
# constraints to overlap, i.e. it allows a variable to be a part of multiple
# conic constraints, or to appear multiple times in the same constraint.
# 
# NOTE: second-order conic constraints are always  convex,  so  having  them
#       preserves convexity of the QP problem.
# 
# NOTE: A starting point that is strictly feasible with respect to both  box
#       and conic constraints greatly helps the solver to power up; however,
#       it will work even without such a point,  albeit  at  somewhat  lower
#       performance.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated  with  minqpcreate()  call.
#     Idx     -   array[K] (or larger, only leading  K  elements  are  used)
#                 storing variable indexes. Indexes can be  unsorted  and/or
#                 non-distinct.
#     A       -   array[K]  (or larger, only leading  K  elements are used),
#                 variable multipliers. Can contain zero values.
#     C       -   array[K] (or larger, only leading  K  elements  are used),
#                 variable shifts.
#     K       -   cone dimensionality, K&gt;=1. It is possible to have K&gt;N.
#     Theta   -   additional constant term, can be zero
# 
# RESULT:
#     constraint index in a conic constraints list, starting from 0
# 
#   -- ALGLIB --
#      Copyright 09.09.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.minqpaddsoccorthogonal(state, idx, a, c, k, theta, applyorigin)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          idx:        1D array/list of int
          a:          1D array/list of float
          c:          1D array/list of float
          k:          int
          theta:      float
          applyorigin: bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_minqpaddsoccprimitive'></a><h3 class=pageheader><code>minqpaddsoccprimitive</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends a primitive second-order  conic  constraint  of  the
# form
# 
#         (                                                  )
#     sqrt(x[range0]^2 + x[range0+1]^2 + ... + x[range1-1]^2 ) &lt;= x[axisidx]
#         (                                                  )
# 
# with 'primitive' meaning that there are no per-variable  scales  and  that
# variables under the square root have sequential indexes. More general form
# of conic constraints can be specified with minqpaddsoccorthogonal().
# 
# Alternatively, if ApplyOrigin parameter  is  True,  x[i]  is  replaced  by
# x[i]-origin[i] (applies to all variables).
# 
# Unlike  many  other  conic  solvers,  ALGLIB  allows  conic constraints to
# overlap, i.e. it allows  a  variable  to  be  a  part  of  multiple  conic
# constraints.
# 
# NOTE: second-order conic constraints are always  convex,  so  having  them
#       preserves convexity of the QP problem.
# 
# NOTE: A starting point that is strictly feasible with respect to both  box
#       and conic constraints greatly helps the solver to power up; however,
#       it will work even without such a point,  albeit  at  somewhat  lower
#       performance.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minqpcreate() call.
#     Range0,
#     Range1  -   0&lt;=range0&lt;=range1&lt;=N, variable range for the LHS;
#                 * squared variables x[range0]...x[range1-1] are summed up
#                   under the square root.
#                 * range0=range1 means that the constraint is interpreted
#                   as x[AxisIdx]&gt;=0.
#     AxisIdx -   RHS variable index:
#                 * 0&lt;=AxisIdx&lt;N
#                 * either AxisIdx&lt;range0 or AxisAdx&gt;=Range1.
# 
# RESULT:
#     constraint index in a conic constraints list, starting from 0
# 
#   -- ALGLIB --
#      Copyright 09.09.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.minqpaddsoccprimitive(state, range0, range1, axisidx, applyorigin)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          range0:     int
          range1:     int
          axisidx:    int
          applyorigin: bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_minqpclearcc'></a><h3 class=pageheader><code>minqpclearcc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function clears the list of conic constraints. Other  constraints are
# not modified.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minqpcreate() call.
# 
#   -- ALGLIB --
#      Copyright 19.06.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpclearcc(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpclearqc'></a><h3 class=pageheader><code>minqpclearqc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function clears the list of quadratic constraints. Other  constraints
# are not modified.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minqpcreate() call.
# 
#   -- ALGLIB --
#      Copyright 19.06.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpclearqc(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpcreate'></a><h3 class=pageheader><code>minqpcreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
#                     CONSTRAINED QUADRATIC PROGRAMMING
# 
# The subroutine creates QP optimizer. After initial creation,  it  contains
# default optimization problem with zero quadratic and linear terms  and  no
# constraints.
# 
# In order to actually solve something you should:
# 
# specify objective:
# * set linear term with minqpsetlinearterm()
# * set quadratic term with minqpsetquadraticterm() or
#   minqpsetquadratictermsparse()
# 
# specify constraints:
# * set variable bounds with minqpsetbc() or minqpsetbcall()
# * specify linear constraint matrix with one of the following functions:
#   * modern API:
#     * minqpsetlc2()       for sparse two-sided constraints AL &lt;= A*x &lt;= AU
#     * minqpsetlc2dense()  for dense  two-sided constraints AL &lt;= A*x &lt;= AU
#     * minqpsetlc2mixed()  for mixed  two-sided constraints AL &lt;= A*x &lt;= AU
#     * minqpaddlc2dense()  to add one dense row to the dense constraint submatrix
#     * minqpaddlc2()       to add one sparse row to the sparse constraint submatrix
#     * minqpaddlc2sparsefromdense() to add one sparse row (passed as a dense array) to the sparse constraint submatrix
#   * legacy API:
#     * minqpsetlc()        for dense one-sided equality/inequality constraints
#     * minqpsetlcsparse()  for sparse one-sided equality/inequality constraints
#     * minqpsetlcmixed()   for mixed dense/sparse one-sided equality/inequality constraints
# * add two-sided quadratic constraint(s) of the form CL &lt;= b'x+0.5*x'Qx &lt;= CU
#   with one of the following functions:
#   * minqpaddqc2()         for a quadratic constraint given by a sparse
#                           matrix structure; has O(max(N,NNZ)) memory and
#                           running time requirements.
#   * minqpaddqc2dense()    for a quadratic constraint given by a dense
#                           matrix; has O(N^2) memory and running time requirements.
#   * minqpaddqc2list()     for a sparse quadratic constraint given by
#                           a list of non-zero  entries;  has  O(NNZ) memory
#                           and O(NNZ*logNNZ)  running   time  requirements,
#                           ideal for constraints  with  much  less  than  N
#                           nonzero elements.
# * add second order cone constraints with:
#   * minqpaddsoccprimitive()     for a primitive second order cone constraint
#   * minqpaddsoccorthogonal()    for an axis-orthogonal second order cone constraint
# * add power cone constraints with:
#   * minqpaddpowccprimitive()    for a primitive power cone constraint
#   * minqpaddpowccorthogonal()   for an axis-orthogonal power cone constraint
# 
# configure and run QP solver:
# * choose appropriate QP solver and set it  and  its stopping  criteria  by
#   means of minqpsetalgo??????() function
# * call minqpoptimize() to run the solver and  minqpresults()  to  get  the
#   solution vector and additional information.
# 
# Following solvers are recommended for  convex  and  semidefinite  problems
# with box and linear constraints:
# * QuickQP for dense problems with box-only constraints (or no constraints
#   at all)
# * DENSE-IPM-QP for  convex  or  semidefinite  problems  with   medium  (up
#   to several thousands) variable count, dense/sparse  quadratic  term  and
#   any number  (up  to  many  thousands)  of  dense/sparse  general  linear
#   constraints
# * SPARSE-IPM-QP for convex  or  semidefinite  problems  with   large (many
#   thousands) variable count, sparse quadratic term AND linear constraints.
# * SPARSE-ECQP for convex having only  linear  equality  constraints.  This
#   specialized solver can be orders of magnitude faster than IPM.
# 
# If your problem happens to be nonconvex or has nonlinear constraints, then
# you can use:
# * DENSE-GENIPM or SPARSE-GENIPM  solver  which  supports  convex/nonconvex
#   QP   problems  with  box,  linear,  quadratic  equality/inequality   and
#   conic constraints.
# * QuickQP for small dense nonconvex problems with box-only constraints
# 
# INPUT PARAMETERS:
#     N       -   problem size
# 
# OUTPUT PARAMETERS:
#     State   -   optimizer with zero quadratic/linear terms
#                 and no constraints
# 
#   -- ALGLIB --
#      Copyright 11.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.minqpcreate(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minqpstate

</div></pre>
<a name='sub_minqpexport'></a><h3 class=pageheader><code>minqpexport</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Export current QP problem stored in the solver into  QPXProblem  instance.
# This  instance  can  be  serialized  into   ALGLIB-specific   format   and
# unserialized from several widely acnowledged formats.
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     P       -   QPXProblem instance storing current objective and
#                 constraints.
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.minqpexport(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          class xalglib.qpxproblem

</div></pre>
<a name='sub_minqpimport'></a><h3 class=pageheader><code>minqpimport</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Imports QP problem, as defined by QPXProblem instance, creating a QP solver
# with objective/constraints/scales/origin set to that stored in the instance.
# 
# INPUT PARAMETERS:
#     P       -   QPXProblem instance storing current objective and
#                 constraints.
# 
# OUTPUT PARAMETERS:
#     State   -   newly created solver
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.minqpimport(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.minqpstate

</div></pre>
<a name='sub_minqpoptimize'></a><h3 class=pageheader><code>minqpoptimize</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function solves quadratic programming problem.
# 
# Prior to calling this function you should choose solver by means of one of
# the following functions:
# 
# * minqpsetalgoquickqp()     - for QuickQP solver
# * minqpsetalgodenseaul()    - for Dense-AUL-QP solver
# * minqpsetalgodenseipm()    - for convex Dense-IPM-QP solver
# * minqpsetalgosparseipm()   - for convex Sparse-IPM-QP solver
# * minqpsetalgodensegenipm() - for convex/nonconvex Dense-IPM-QP solver with conic constraints
# * minqpsetalgosparsegenipm()- for convex/nonconvex Sparse-IPM-QP solver with conic constraints
# 
# These functions also allow you to control stopping criteria of the solver.
# If you did not set solver,  MinQP  subpackage  will  automatically  select
# solver for your problem and will run it with default stopping criteria.
# 
# However, it is better to set explicitly solver and its stopping criteria.
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# You should use MinQPResults() function to access results after calls
# to this function.
# 
#   -- ALGLIB --
#      Copyright 2011-2024 by Bochkanov Sergey.
#      Special thanks to Elvira Illarionova  for  important  suggestions  on
#      the linearly constrained QP algorithm.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpoptimize(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpresults'></a><h3 class=pageheader><code>minqpresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# QP solver results
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     X       -   array[0..N-1], solution (on failure - the best point found
#                 so far).
#     Rep     -   optimization report, contains:
#                 * completion code in Rep.TerminationType (positive  values
#                   denote some kind of success, negative - failures)
#                 * Lagrange multipliers - for QP solvers which support them
#                 * other statistics
#                 See comments on minqpreport structure for more information
# 
# Following completion codes are returned in Rep.TerminationType:
# * -9    failure of the automatic scale evaluation:  one  of  the  diagonal
#         elements of the quadratic term is non-positive.  Specify  variable
#         scales manually!
# * -5    inappropriate solver was used:
#         * QuickQP solver for problem with general linear constraints
#         * QuickQP/DENSE-AUL/DENSE-IPM/SPARSE-IPM for a problem with
#           quadratic/conic constraints
# * -4    the function is unbounded from below even under constraints,
#         no meaningful minimum can be found.
# * -3    inconsistent constraints (or, maybe, feasible point is too hard to
#         find).
# * -2    IPM solver has difficulty finding primal/dual feasible point.
#         It is likely that the problem is either infeasible or unbounded,
#         but it is difficult to determine exact reason for termination.
#         X contains best point found so far.
# *  &gt;0   success
# *  7    stopping conditions are too stringent,
#         further improvement is impossible,
#         X contains best point found so far.
# 
#   -- ALGLIB --
#      Copyright 11.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.minqpresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.minqpreport

</div></pre>
<a name='sub_minqpresultsbuf'></a><h3 class=pageheader><code>minqpresultsbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# QP results
# 
# Buffered implementation of MinQPResults() which uses pre-allocated  buffer
# to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
# intended to be used in the inner cycles of performance critical algorithms
# where array reallocation penalty is too large to be ignored.
# 
#   -- ALGLIB --
#      Copyright 11.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.minqpresultsbuf(state, x, rep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          x:          1D array/list of float
          rep:        class xalglib.minqpreport
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> rep
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float

</div></pre>
<a name='sub_minqpsetalgodenseaul'></a><h3 class=pageheader><code>minqpsetalgodenseaul</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function tells QP solver to use DENSE-AUL algorithm and sets stopping
# criteria for the algorithm.
# 
# This  algorithm  is  intended  for  non-convex problems with moderate  (up
# to several thousands) variable count and arbitrary number  of  constraints
# which are either (a) effectively convexified under constraints or (b) have
# unique solution even with nonconvex target.
# 
# IMPORTANT: when DENSE-IPM solver is applicable, its performance is usually
#            much better than that of DENSE-AUL.
#            We recommend  you to use DENSE-AUL only when other solvers  can
#            not be used.
# 
# ALGORITHM FEATURES:
# 
# * supports  box  and  dense/sparse  general   linear   equality/inequality
#   constraints
# * convergence is theoretically proved for positive-definite  (convex)   QP
#   problems. Semidefinite and non-convex problems can be solved as long  as
#   they  are   bounded  from  below  under  constraints,  although  without
#   theoretical guarantees.
# 
# ALGORITHM OUTLINE:
# 
# * this  algorithm   is   an   augmented   Lagrangian   method  with  dense
#   preconditioner (hence  its  name).
# * it performs several outer iterations in order to refine  values  of  the
#   Lagrange multipliers. Single outer  iteration  is  a  solution  of  some
#   unconstrained optimization problem: first  it  performs  dense  Cholesky
#   factorization of the Hessian in order to build preconditioner  (adaptive
#   regularization is applied to enforce positive  definiteness),  and  then
#   it uses L-BFGS optimizer to solve optimization problem.
# * typically you need about 5-10 outer iterations to converge to solution
# 
# ALGORITHM LIMITATIONS:
# 
# * because dense Cholesky driver is used, this algorithm has O(N^2)  memory
#   requirements and O(OuterIterations*N^3) minimum running time.  From  the
#   practical  point  of  view,  it  limits  its  applicability  by  several
#   thousands of variables.
#   From  the  other  side,  variables  count  is  the most limiting factor,
#   and dependence on constraint count is  much  more  lower. Assuming  that
#   constraint matrix is sparse, it may handle tens of thousands  of general
#   linear constraints.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     EpsX    -   &gt;=0, stopping criteria for inner optimizer.
#                 Inner  iterations  are  stopped  when  step  length  (with
#                 variable scaling being applied) is less than EpsX.
#                 See  minqpsetscale()  for  more  information  on  variable
#                 scaling.
#     Rho     -   penalty coefficient, Rho&gt;0:
#                 * large enough  that  algorithm  converges  with   desired
#                   precision.
#                 * not TOO large to prevent ill-conditioning
#                 * recommended values are 100, 1000 or 10000
#     ItsCnt  -   number of outer iterations:
#                 * recommended values: 10-15 (although  in  most  cases  it
#                   converges within 5 iterations, you may need a  few  more
#                   to be sure).
#                 * ItsCnt=0 means that small number of outer iterations  is
#                   automatically chosen (10 iterations in current version).
#                 * ItsCnt=1 means that AUL algorithm performs just as usual
#                   penalty method.
#                 * ItsCnt&gt;1 means that  AUL  algorithm  performs  specified
#                   number of outer iterations
# 
# IT IS VERY IMPORTANT TO CALL minqpsetscale() WHEN YOU USE THIS  ALGORITHM
# BECAUSE ITS CONVERGENCE PROPERTIES AND STOPPING CRITERIA ARE SCALE-DEPENDENT!
# 
# NOTE: Passing  EpsX=0  will  lead  to  automatic  step  length  selection
#       (specific step length chosen may change in the future  versions  of
#       ALGLIB, so it is better to specify step length explicitly).
# 
#   -- ALGLIB --
#      Copyright 20.08.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetalgodenseaul(state, epsx, rho, itscnt)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          epsx:       float
          rho:        float
          itscnt:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetalgodensegenipm'></a><h3 class=pageheader><code>minqpsetalgodensegenipm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function tells QP solver to  use  DENSE-GENIPM  QP algorithm and sets
# stopping criteria for the algorithm.
# 
# This  algorithm  is  intended  for convex/nonconvex box/linearly/conically
# constrained QP problems with moderate (up to several thousands)  variables
# count and arbitrary number  of  constraints.  Use  SPARSE-GENIPM  if  your
# problem is sparse.
# 
# The algorithm is a generalization of DENSE-IPM solver, capable of handling
# more general constraints as well as nonconvexity of  the  target.  In  the
# latter case, a local solution is found.
# 
# IMPORTANT: the commercial edition of ALGLIB can parallelize this function.
#            See the ALGLIB Reference Manual for more information on how  to
#            activate parallelism support.
# 
# ALGORITHM FEATURES:
# 
# * supports box, linear equality/inequality and conic constraints
# * for convex problems returns the global (and the only) solution
# * can handle non-convex  problem  (only  a  locally  optimal  solution  is
#   returned in this case)
# 
# ALGORITHM LIMITATIONS:
# 
# * because a dense Cholesky driver is used, for  N-dimensional problem with
#   M dense constaints this algorithm has O(N^2+N*M) memory requirements and
#   O(N^3+M*N^2) running time.
#   Having sparse constraints with Z nonzeros per row  relaxes  storage  and
#   running time down to O(N^2+M*Z) and O(N^3+M*Z^2)
#   From the practical  point  of  view,  it  limits  its  applicability  by
#   several thousands of variables.
#   From  the  other  side,  variables  count  is  the most limiting factor,
#   and dependence on constraint count is  much  more  lower. Assuming  that
#   the constraint matrix is sparse, it may  handle  tens  of  thousands  of
#   general linear constraints.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     Eps     -   &gt;=0, stopping criteria. The algorithm stops  when   primal
#                 and dual infeasiblities as well as complementarity gap are
#                 less than Eps.
# 
# IT IS VERY IMPORTANT TO CALL minqpsetscale() WHEN YOU USE THIS  ALGORITHM
# BECAUSE ITS CONVERGENCE PROPERTIES AND STOPPING CRITERIA ARE SCALE-DEPENDENT!
# 
# NOTE: Passing EpsX=0 will lead to automatic selection of small epsilon.
# 
# ===== TRACING GENIPM SOLVER ==============================================
# 
# GENIPM solver supports advanced tracing capabilities. You can log algorithm
# output by specifying following trace symbols (case-insensitive)  by  means
# of trace_file() call:
# * 'GENIPM'      - for basic trace of algorithm  steps and decisions.  Only
#                   short scalars (function values and deltas) are  printed.
#                   N-dimensional quantities like search directions are  NOT
#                   printed.
# * 'GENIPM.DETAILED'- for output of points being visited and search directions
#                   This  symbol  also  implicitly  defines  'GENIPM'. You  can
#                   control output format by additionally specifying:
#                   * nothing     to output in  6-digit exponential format
#                   * 'PREC.E15'  to output in 15-digit exponential format
#                   * 'PREC.F6'   to output in  6-digit fixed-point format
# 
# By default trace is disabled and adds  no  overhead  to  the  optimization
# process. However, specifying any of the symbols adds some  formatting  and
# output-related overhead.
# 
# You may specify multiple symbols by separating them with commas:
# &gt;
# &gt; alglib::trace_file(&quot;GENIPM,PREC.F6&quot;, &quot;path/to/trace.log&quot;)
# &gt;
# 
#   -- ALGLIB --
#      Copyright 01.05.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetalgodensegenipm(state, eps)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          eps:        float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetalgodenseipm'></a><h3 class=pageheader><code>minqpsetalgodenseipm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function tells QP solver to  use  DENSE-IPM  QP  algorithm  and  sets
# stopping criteria for the algorithm.
# 
# This  algorithm  is  intended for convex and semidefinite QP (but not QCQP
# or conic) problems with moderate (up to several thousands) variable  count
# and arbitrary number of linear constraints. Quadratic and conic constraints
# are supported by another solver (DENSE-GENIPM).
# 
# IMPORTANT: the commercial edition of ALGLIB can parallelize this function.
#            See the ALGLIB Reference Manual for more information on how  to
#            activate parallelism support.
# 
# IMPORTANT: this  algorithm  is  likely  to  fail  on  nonconvex  problems,
#            furthermore, sometimes it fails without a notice. If you try to
#            run DENSE-IPM on a problem  with  indefinite  matrix (a  matrix
#            having  at least one negative eigenvalue) then depending on the
#            circumstances it may either (a) stall at some  arbitrary point,
#            or (b) throw an exception due to the failure  of  the  Cholesky
#            decomposition.
# 
#            Use GENIPM algorithm if  your  problem  is  nonconvex  or has a
#            potential of becoming  nonconvex.  The GENIPM solver  can  also
#            handle problems with quadratic and conic constraints.
# 
# ALGORITHM FEATURES:
# 
# * supports  box  and  dense/sparse  general   linear   equality/inequality
#   constraints
# 
# ALGORITHM OUTLINE:
# 
# * this  algorithm  is  our implementation  of  interior  point  method  as
#   formulated by  R.J.Vanderbei, with minor modifications to the  algorithm
#   (damped Newton directions are extensively used)
# * like all interior point methods, this algorithm  tends  to  converge  in
#   roughly same number of iterations (between 15 and 50) independently from
#   the problem dimensionality
# 
# ALGORITHM LIMITATIONS:
# 
# * because a dense Cholesky driver is used, for  N-dimensional problem with
#   M dense constaints this algorithm has O(N^2+N*M) memory requirements and
#   O(N^3+M*N^2) running time.
#   Having sparse constraints with Z nonzeros per row  relaxes  storage  and
#   running time down to O(N^2+M*Z) and O(N^3+M*Z^2)
#   From the practical  point  of  view,  it  limits  its  applicability  by
#   several thousands of variables.
#   From  the  other  side,  variables  count  is  the most limiting factor,
#   and dependence on constraint count is  much  more  lower. Assuming  that
#   the constraint matrix is sparse, it may  handle  tens  of  thousands  of
#   general linear constraints.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     Eps     -   &gt;=0, stopping criteria. The algorithm stops  when   primal
#                 and dual infeasiblities as well as complementarity gap are
#                 less than Eps.
# 
# IT IS VERY IMPORTANT TO CALL minqpsetscale() WHEN YOU USE THIS  ALGORITHM
# BECAUSE ITS CONVERGENCE PROPERTIES AND STOPPING CRITERIA ARE SCALE-DEPENDENT!
# 
# NOTE: Passing EpsX=0 will lead to automatic selection of small epsilon.
# 
# ===== TRACING IPM SOLVER =================================================
# 
# IPM solver supports advanced tracing capabilities. You can trace algorithm
# output by specifying following trace symbols (case-insensitive)  by  means
# of trace_file() call:
# * 'IPM'         - for basic trace of algorithm  steps and decisions.  Only
#                   short scalars (function values and deltas) are  printed.
#                   N-dimensional quantities like search directions are  NOT
#                   printed.
# * 'IPM.DETAILED'- for output of points being visited and search directions
#                   This  symbol  also  implicitly  defines  'IPM'. You  can
#                   control output format by additionally specifying:
#                   * nothing     to output in  6-digit exponential format
#                   * 'PREC.E15'  to output in 15-digit exponential format
#                   * 'PREC.F6'   to output in  6-digit fixed-point format
# 
# By default trace is disabled and adds  no  overhead  to  the  optimization
# process. However, specifying any of the symbols adds some  formatting  and
# output-related overhead.
# 
# You may specify multiple symbols by separating them with commas:
# &gt;
# &gt; alglib::trace_file(&quot;IPM,PREC.F6&quot;, &quot;path/to/trace.log&quot;)
# &gt;
# 
#   -- ALGLIB --
#      Copyright 01.11.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetalgodenseipm(state, eps)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          eps:        float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetalgoquickqp'></a><h3 class=pageheader><code>minqpsetalgoquickqp</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function tells solver to use QuickQP  algorithm:  special  extra-fast
# algorithm for problems with box-only constrants. It may  solve  non-convex
# problems as long as they are bounded from below under constraints.
# 
# ALGORITHM FEATURES:
# * several times faster than DENSE-IPM when running on box-only problem
# * utilizes accelerated methods for activation of constraints.
# * supports dense and sparse QP problems
# * supports ONLY box constraints; general linear constraints are NOT
#   supported by this solver
# * can solve all types of problems  (convex,  semidefinite,  nonconvex)  as
#   long as they are bounded from below under constraints.
#   Say, it is possible to solve &quot;min{-x^2} subject to -1&lt;=x&lt;=+1&quot;.
#   In convex/semidefinite case global minimum  is  returned,  in  nonconvex
#   case - algorithm returns one of the local minimums.
# 
# ALGORITHM OUTLINE:
# 
# * algorithm  performs  two kinds of iterations: constrained CG  iterations
#   and constrained Newton iterations
# * initially it performs small number of constrained CG  iterations,  which
#   can efficiently activate/deactivate multiple constraints
# * after CG phase algorithm tries to calculate Cholesky  decomposition  and
#   to perform several constrained Newton steps. If  Cholesky  decomposition
#   failed (matrix is indefinite even under constraints),  we  perform  more
#   CG iterations until we converge to such set of constraints  that  system
#   matrix becomes  positive  definite.  Constrained  Newton  steps  greatly
#   increase convergence speed and precision.
# * algorithm interleaves CG and Newton iterations which  allows  to  handle
#   indefinite matrices (CG phase) and quickly converge after final  set  of
#   constraints is found (Newton phase). Combination of CG and Newton phases
#   is called &quot;outer iteration&quot;.
# * it is possible to turn off Newton  phase  (beneficial  for  semidefinite
#   problems - Cholesky decomposition will fail too often)
# 
# ALGORITHM LIMITATIONS:
# 
# * algorithm does not support general  linear  constraints;  only  box ones
#   are supported
# * Cholesky decomposition for sparse problems  is  performed  with  Skyline
#   Cholesky solver, which is intended for low-profile matrices. No profile-
#   reducing reordering of variables is performed in this version of ALGLIB.
# * problems with near-zero negative eigenvalues (or exacty zero  ones)  may
#   experience about 2-3x performance penalty. The reason is  that  Cholesky
#   decomposition can not be performed until we identify directions of  zero
#   and negative curvature and activate corresponding boundary constraints -
#   but we need a lot of trial and errors because these directions  are hard
#   to notice in the matrix spectrum.
#   In this case you may turn off Newton phase of algorithm.
#   Large negative eigenvalues  are  not  an  issue,  so  highly  non-convex
#   problems can be solved very efficiently.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     EpsG    -   &gt;=0
#                 The  subroutine  finishes  its  work   if   the  condition
#                 |v|&lt;EpsG is satisfied, where:
#                 * |.| means Euclidian norm
#                 * v - scaled constrained gradient vector, v[i]=g[i]*s[i]
#                 * g - gradient
#                 * s - scaling coefficients set by MinQPSetScale()
#     EpsF    -   &gt;=0
#                 The  subroutine  finishes its work if exploratory steepest
#                 descent  step  on  k+1-th iteration  satisfies   following
#                 condition:  |F(k+1)-F(k)|&lt;=EpsF*max{|F(k)|,|F(k+1)|,1}
#     EpsX    -   &gt;=0
#                 The  subroutine  finishes its work if exploratory steepest
#                 descent  step  on  k+1-th iteration  satisfies   following
#                 condition:
#                 * |.| means Euclidian norm
#                 * v - scaled step vector, v[i]=dx[i]/s[i]
#                 * dx - step vector, dx=X(k+1)-X(k)
#                 * s - scaling coefficients set by MinQPSetScale()
#     MaxOuterIts-maximum number of OUTER iterations.  One  outer  iteration
#                 includes some amount of CG iterations (from 5 to  ~N)  and
#                 one or several (usually small amount) Newton steps.  Thus,
#                 one outer iteration has high cost, but can greatly  reduce
#                 funcation value.
#                 Use 0 if you do not want to limit number of outer iterations.
#     UseNewton-  use Newton phase or not:
#                 * Newton phase improves performance of  positive  definite
#                   dense problems (about 2 times improvement can be observed)
#                 * can result in some performance penalty  on  semidefinite
#                   or slightly negative definite  problems  -  each  Newton
#                   phase will bring no improvement (Cholesky failure),  but
#                   still will require computational time.
#                 * if you doubt, you can turn off this  phase  -  optimizer
#                   will retain its most of its high speed.
# 
# IT IS VERY IMPORTANT TO CALL MinQPSetScale() WHEN YOU USE THIS  ALGORITHM
# BECAUSE ITS STOPPING CRITERIA ARE SCALE-DEPENDENT!
# 
# Passing EpsG=0, EpsF=0 and EpsX=0 and MaxIts=0 (simultaneously) will lead
# to automatic stopping criterion selection (presently it is  small    step
# length, but it may change in the future versions of ALGLIB).
# 
#   -- ALGLIB --
#      Copyright 22.05.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetalgoquickqp(state, epsg, epsf, epsx, maxouterits, usenewton)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          epsg:       float
          epsf:       float
          epsx:       float
          maxouterits: int
          usenewton:  bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetalgosparseecqp'></a><h3 class=pageheader><code>minqpsetalgosparseecqp</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function tells QP solver to use an ECQP algorithm.
# 
# This  algorithm  is  intended  for sparse convex problems with only linear
# equality constraints. It can handle millions of variables and constraints,
# assuming that the problem is sufficiently  sparse.  However,  it  can  NOT
# deal with nonlinear equality constraints or inequality constraints of  any
# type (including box ones), nor it can deal with nonconvex problems.
# 
# When applicable, it outperforms SPARSE-IPM by  tens  of  times.  It  is  a
# regularized direct linear algebra solver that performs several  rounds  of
# iterative  refinement  in  order to improve a solution. Thus, due  to  its
# direct nature, it does not need stopping criteria and performs much faster
# than interior point methods.
# 
# IMPORTANT: the commercial edition of ALGLIB can parallelize this function.
#            Specific speed-up due  to  parallelism  heavily  depends  on  a
#            sparsity pattern of quadratic term and constraints.
#            See the ALGLIB Reference Manual for more information on how  to
#            activate parallelism support.
# 
# IMPORTANT: internally this solver performs large  and  sparse  (N+M)x(N+M)
#            triangular factorization. So it expects both quadratic term and
#            constraints to be highly sparse. However, its  running  time is
#            influenced by BOTH fill factor and sparsity pattern.
# 
#            Generally we expect that no more than few nonzero  elements per
#            row are present. However different sparsity patterns may result
#            in completely different running  times  even  given  same  fill
#            factor.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     Eps     -   &gt;=0, stopping criteria. The algorithm stops  when   primal
#                 and dual infeasiblities are less than Eps.
# 
# IT IS VERY IMPORTANT TO CALL minqpsetscale() WHEN YOU USE THIS  ALGORITHM
# BECAUSE ITS CONVERGENCE PROPERTIES AND STOPPING CRITERIA ARE SCALE-DEPENDENT!
# 
# NOTE: Passing EpsX=0 will lead to automatic selection of small epsilon.
# 
#   -- ALGLIB --
#      Copyright 01.07.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetalgosparseecqp(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetalgosparsegenipm'></a><h3 class=pageheader><code>minqpsetalgosparsegenipm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function tells QP solver to  use SPARSE-GENIPM  QP algorithm and sets
# stopping criteria for the algorithm.
# 
# This   algorithm  is intended for convex/nonconvex box/linearly/conically/
# quadratically constrained QP  problems  with  sparse  quadratic  term  and
# constraints. It can handle millions of variables and constraints, assuming
# that the problem is sufficiently sparse. If your problem is small (several
# thousands vars at most) and dense, consider using DENSE-GENIPM  as  a more
# efficient alternative.
# 
# The  algorithm  is  a  generalization of the SPARSE-IPM solver, capable of
# handling more general constraints as well as nonconvexity of  the  target.
# In the latter case, a local solution is found.
# 
# IMPORTANT: the commercial edition of ALGLIB can parallelize this function.
#            Specific speed-up due  to  parallelism  heavily  depends  on  a
#            sparsity pattern of quadratic term and constraints.
#            See the ALGLIB Reference Manual for more information on how  to
#            activate parallelism support.
# 
# IMPORTANT: internally this solver performs large  and  sparse  (N+M)x(N+M)
#            triangular factorization. So it expects both quadratic term and
#            constraints to be highly sparse. However, its  running  time is
#            influenced by BOTH fill factor and sparsity pattern.
# 
#            Generally we expect that no more than few nonzero  elements per
#            row are present. However different sparsity patterns may result
#            in completely different running  times  even  given  same  fill
#            factor.
# 
#            In many cases this algorithm outperforms DENSE-IPM by order  of
#            magnitude. However, in some cases you may  get  better  results
#            with DENSE-IPM even when solving sparse task.
# 
# ALGORITHM FEATURES:
# 
# 
# * supports box, linear equality/inequality constraints
# * for convex problems returns the global (and the only) solution
# * can handle non-convex  problem  (only  a  locally  optimal  solution  is
#   returned in this case)
# * specializes on large-scale sparse problems
# 
# ALGORITHM LIMITATIONS:
# 
# * this algorithm may handle moderate number  of dense constraints, usually
#   no more than a thousand of dense ones without losing its efficiency.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     Eps     -   &gt;=0, stopping criteria. The algorithm stops  when   primal
#                 and dual infeasiblities as well as complementarity gap are
#                 less than Eps.
# 
# IT IS VERY IMPORTANT TO CALL minqpsetscale() WHEN YOU USE THIS  ALGORITHM
# BECAUSE ITS CONVERGENCE PROPERTIES AND STOPPING CRITERIA ARE SCALE-DEPENDENT!
# 
# NOTE: Passing EpsX=0 will lead to automatic selection of small epsilon.
# 
# ===== TRACING GENIPM SOLVER ==============================================
# 
# GENIPM solver supports advanced tracing capabilities. You can log algorithm
# output by specifying following trace symbols (case-insensitive)  by  means
# of trace_file() call:
# * 'GENIPM'      - for basic trace of algorithm  steps and decisions.  Only
#                   short scalars (function values and deltas) are  printed.
#                   N-dimensional quantities like search directions are  NOT
#                   printed.
# * 'GENIPM.DETAILED'- for output of points being visited and search directions
#                   This  symbol  also  implicitly  defines  'IPM'. You  can
#                   control output format by additionally specifying:
#                   * nothing     to output in  6-digit exponential format
#                   * 'PREC.E15'  to output in 15-digit exponential format
#                   * 'PREC.F6'   to output in  6-digit fixed-point format
# 
# By default trace is disabled and adds  no  overhead  to  the  optimization
# process. However, specifying any of the symbols adds some  formatting  and
# output-related overhead.
# 
# You may specify multiple symbols by separating them with commas:
# &gt;
# &gt; alglib::trace_file(&quot;GENIPM,PREC.F6&quot;, &quot;path/to/trace.log&quot;)
# &gt;
# 
#   -- ALGLIB --
#      Copyright 01.05.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetalgosparsegenipm(state, eps)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          eps:        float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetalgosparseipm'></a><h3 class=pageheader><code>minqpsetalgosparseipm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function tells QP solver to  use  SPARSE-IPM  QP algorithm  and  sets
# stopping criteria for the algorithm.
# 
# This  algorithm  is  intended for convex and semidefinite QP (but not QCQP
# or conic) problems with large  variable  and  constraint  count and sparse
# quadratic term and sparse linear constraints. It was successfully used for
# problems with millions of variables and constraints. Quadratic  and  conic
# constraints are supported by another solver (SPARSE-GENIPM).
# 
# It is possible to have some limited set of dense linear constraints - they
# will be handled separately  by  the  dense  BLAS  -  but  the  more  dense
# constraints you have, the more time solver needs.
# 
# IMPORTANT: the commercial edition of ALGLIB can parallelize this function.
#            Specific speed-up due  to  parallelism  heavily  depends  on  a
#            sparsity pattern of quadratic term and constraints.
#            See the ALGLIB Reference Manual for more information on how  to
#            activate parallelism support.
# 
# IMPORTANT: internally this solver performs large  and  sparse  (N+M)x(N+M)
#            triangular factorization. So it expects both quadratic term and
#            constraints to be highly sparse. However, its  running  time is
#            influenced by BOTH fill factor and sparsity pattern.
# 
#            Generally we expect that no more than few nonzero  elements per
#            row are present. However different sparsity patterns may result
#            in completely different running  times  even  given  same  fill
#            factor.
# 
#            In many cases this algorithm outperforms DENSE-IPM by order  of
#            magnitude. However, in some cases you may  get  better  results
#            with DENSE-IPM even when solving sparse task.
# 
# IMPORTANT: this algorithm won't work for nonconvex problems. If you try to
#            run SPARSE-IPM  on a problem with indefinite quadratic term  (a
#            matrix having at least one negative eigenvalue) then  depending
#            on the circumstances it may either (a) stall  at some arbitrary
#            point, or (b) throw an exception due  to  the  failure  of  the
#            Cholesky decomposition.
# 
#            Use GENIPM algorithm if  your  problem  is  nonconvex  or has a
#            potential of becoming  nonconvex.  The  GENIPM  solver can also
#            handle problems with quadratic and conic constraints.
# 
# ALGORITHM FEATURES:
# 
# * supports  box  and  dense/sparse  general   linear   equality/inequality
#   constraints
# * specializes on large-scale sparse problems
# 
# ALGORITHM OUTLINE:
# 
# * this  algorithm  is  our implementation  of  interior  point  method  as
#   formulated by  R.J.Vanderbei, with minor modifications to the  algorithm
#   (damped Newton directions are extensively used)
# * like all interior point methods, this algorithm  tends  to  converge  in
#   roughly same number of iterations (between 15 and 50) independently from
#   the problem dimensionality
# 
# ALGORITHM LIMITATIONS:
# 
# * this algorithm may handle moderate number  of dense constraints, usually
#   no more than a thousand of dense ones without losing its efficiency.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     Eps     -   &gt;=0, stopping criteria. The algorithm stops  when   primal
#                 and dual infeasiblities as well as complementarity gap are
#                 less than Eps.
# 
# IT IS VERY IMPORTANT TO CALL minqpsetscale() WHEN YOU USE THIS  ALGORITHM
# BECAUSE ITS CONVERGENCE PROPERTIES AND STOPPING CRITERIA ARE SCALE-DEPENDENT!
# 
# NOTE: Passing EpsX=0 will lead to automatic selection of small epsilon.
# 
# ===== TRACING IPM SOLVER =================================================
# 
# IPM solver supports advanced tracing capabilities. You can trace algorithm
# output by specifying following trace symbols (case-insensitive)  by  means
# of trace_file() call:
# * 'IPM'         - for basic trace of algorithm  steps and decisions.  Only
#                   short scalars (function values and deltas) are  printed.
#                   N-dimensional quantities like search directions are  NOT
#                   printed.
# * 'IPM.DETAILED'- for output of points being visited and search directions
#                   This  symbol  also  implicitly  defines  'IPM'. You  can
#                   control output format by additionally specifying:
#                   * nothing     to output in  6-digit exponential format
#                   * 'PREC.E15'  to output in 15-digit exponential format
#                   * 'PREC.F6'   to output in  6-digit fixed-point format
# 
# By default trace is disabled and adds  no  overhead  to  the  optimization
# process. However, specifying any of the symbols adds some  formatting  and
# output-related overhead.
# 
# You may specify multiple symbols by separating them with commas:
# &gt;
# &gt; alglib::trace_file(&quot;IPM,PREC.F6&quot;, &quot;path/to/trace.log&quot;)
# &gt;
# 
#   -- ALGLIB --
#      Copyright 01.11.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetalgosparseipm(state, eps)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          eps:        float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetbc'></a><h3 class=pageheader><code>minqpsetbc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets box constraints for QP solver
# 
# Box constraints are inactive by default (after  initial  creation).  After
# being  set,  they are  preserved until explicitly overwritten with another
# minqpsetbc()  or  minqpsetbcall()  call,  or  partially  overwritten  with
# minqpsetbci() call.
# 
# Following types of constraints are supported:
# 
#     DESCRIPTION         CONSTRAINT              HOW TO SPECIFY
#     fixed variable      x[i]=Bnd[i]             BndL[i]=BndU[i]
#     lower bound         BndL[i]&lt;=x[i]           BndU[i]=+INF
#     upper bound         x[i]&lt;=BndU[i]           BndL[i]=-INF
#     range               BndL[i]&lt;=x[i]&lt;=BndU[i]  ...
#     free variable       -                       BndL[I]=-INF, BndU[I]+INF
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     BndL    -   lower bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 very small number or -INF (latter is recommended because
#                 it will allow solver to use better algorithm).
#     BndU    -   upper bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 very large number or +INF (latter is recommended because
#                 it will allow solver to use better algorithm).
# 
# NOTE: infinite values can be specified by means of Double.PositiveInfinity
#       and  Double.NegativeInfinity  (in  C#)  and  alglib::fp_posinf   and
#       alglib::fp_neginf (in C++).
# 
# NOTE: you may replace infinities by very small/very large values,  but  it
#       is not recommended because large numbers may introduce large numerical
#       errors in the algorithm.
# 
# NOTE: if constraints for all variables are same you may use minqpsetbcall()
#       which allows to specify constraints without using arrays.
# 
# NOTE: BndL&gt;BndU will result in QP problem being recognized as infeasible.
# 
#   -- ALGLIB --
#      Copyright 11.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetbc(state, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          bndl:       1D array/list of float
          bndu:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetbcall'></a><h3 class=pageheader><code>minqpsetbcall</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets box constraints for QP solver (all variables  at  once,
# same constraints for all variables)
# 
# Box constraints are inactive by default (after  initial  creation).  After
# being  set,  they are  preserved until explicitly overwritten with another
# minqpsetbc()  or  minqpsetbcall()  call,  or  partially  overwritten  with
# minqpsetbci() call.
# 
# Following types of constraints are supported:
# 
#     DESCRIPTION         CONSTRAINT              HOW TO SPECIFY
#     fixed variable      x[i]=Bnd                BndL=BndU
#     lower bound         BndL&lt;=x[i]              BndU=+INF
#     upper bound         x[i]&lt;=BndU              BndL=-INF
#     range               BndL&lt;=x[i]&lt;=BndU        ...
#     free variable       -                       BndL=-INF, BndU+INF
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     BndL    -   lower bound, same for all variables
#     BndU    -   upper bound, same for all variables
# 
# NOTE: infinite values can be specified by means of Double.PositiveInfinity
#       and  Double.NegativeInfinity  (in  C#)  and  alglib::fp_posinf   and
#       alglib::fp_neginf (in C++).
# 
# NOTE: you may replace infinities by very small/very large values,  but  it
#       is not recommended because large numbers may introduce large numerical
#       errors in the algorithm.
# 
# NOTE: BndL&gt;BndU will result in QP problem being recognized as infeasible.
# 
#   -- ALGLIB --
#      Copyright 11.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetbcall(state, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          bndl:       float
          bndu:       float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetbci'></a><h3 class=pageheader><code>minqpsetbci</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets box constraints for I-th variable (other variables are
# not modified).
# 
# Following types of constraints are supported:
# 
#     DESCRIPTION         CONSTRAINT              HOW TO SPECIFY
#     fixed variable      x[i]=Bnd                BndL=BndU
#     lower bound         BndL&lt;=x[i]              BndU=+INF
#     upper bound         x[i]&lt;=BndU              BndL=-INF
#     range               BndL&lt;=x[i]&lt;=BndU        ...
#     free variable       -                       BndL=-INF, BndU+INF
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     BndL    -   lower bound
#     BndU    -   upper bound
# 
# NOTE: infinite values can be specified by means of Double.PositiveInfinity
#       and  Double.NegativeInfinity  (in  C#)  and  alglib::fp_posinf   and
#       alglib::fp_neginf (in C++).
# 
# NOTE: you may replace infinities by very small/very large values,  but  it
#       is not recommended because large numbers may introduce large numerical
#       errors in the algorithm.
# 
# NOTE: BndL&gt;BndU will result in QP problem being recognized as infeasible.
# 
#   -- ALGLIB --
#      Copyright 11.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetbci(state, i, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          i:          int
          bndl:       float
          bndu:       float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetlc'></a><h3 class=pageheader><code>minqpsetlc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets dense linear constraints for QP optimizer.
# 
# This  function  overrides  results  of  previous  calls  to  minqpsetlc(),
# minqpsetlcsparse() and minqpsetlcmixed().  After  call  to  this  function
# all non-box constraints are dropped, and you have only  those  constraints
# which were specified in the present call.
# 
# If you want  to  specify  mixed  (with  dense  and  sparse  terms)  linear
# constraints, you should call minqpsetlcmixed().
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with MinQPCreate call.
#     C       -   linear constraints, array[K,N+1].
#                 Each row of C represents one constraint, either equality
#                 or inequality (see below):
#                 * first N elements correspond to coefficients,
#                 * last element corresponds to the right part.
#                 All elements of C (including right part) must be finite.
#     CT      -   type of constraints, array[K]:
#                 * if CT[i]&gt;0, then I-th constraint is C[i,*]*x &gt;= C[i,n+1]
#                 * if CT[i]=0, then I-th constraint is C[i,*]*x  = C[i,n+1]
#                 * if CT[i]&lt;0, then I-th constraint is C[i,*]*x &lt;= C[i,n+1]
#     K       -   number of equality/inequality constraints, K&gt;=0:
#                 * if given, only leading K elements of C/CT are used
#                 * if not given, automatically determined from sizes of C/CT
# 
# NOTE 1: linear (non-bound) constraints are satisfied only approximately  -
#         there always exists some violation due  to  numerical  errors  and
#         algorithmic limitations.
# 
#   -- ALGLIB --
#      Copyright 19.06.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetlc(state, c, ct, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetlc(state, c, ct)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          c:          2D array/list of float
          ct:         1D array/list of int
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetlc2'></a><h3 class=pageheader><code>minqpsetlc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  sets  two-sided linear  constraints  AL &lt;= A*x &lt;= AU  with
# sparse constraining matrix A. Recommended for large-scale problems.
# 
# This  function  overwrites  linear  (non-box)  constraints set by previous
# calls (if such calls were made).
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minqpcreate() call.
#     A       -   sparse matrix with size [K,N] (exactly!).
#                 Each row of A represents one general linear constraint.
#                 A can be stored in any sparse storage format.
#     AL, AU  -   lower and upper bounds, array[K];
#                 * AL[i]=AU[i] =&gt; equality constraint Ai*x
#                 * AL[i]&lt;AU[i] =&gt; two-sided constraint AL[i]&lt;=Ai*x&lt;=AU[i]
#                 * AL[i]=-INF  =&gt; one-sided constraint Ai*x&lt;=AU[i]
#                 * AU[i]=+INF  =&gt; one-sided constraint AL[i]&lt;=Ai*x
#                 * AL[i]=-INF, AU[i]=+INF =&gt; constraint is ignored
#     K       -   number  of equality/inequality constraints, K&gt;=0.  If  K=0
#                 is specified, A, AL, AU are ignored.
# 
#   -- ALGLIB --
#      Copyright 01.11.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetlc2(state, a, al, au, k)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          a:          class xalglib.sparsematrix
          al:         1D array/list of float
          au:         1D array/list of float
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetlc2dense'></a><h3 class=pageheader><code>minqpsetlc2dense</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets two-sided linear constraints AL &lt;= A*x &lt;= AU with dense
# constraint matrix A.
# 
# NOTE: knowing  that  constraint  matrix  is  dense  helps  some QP solvers
#       (especially modern IPM method) to utilize efficient  dense  Level  3
#       BLAS for dense parts of the problem. If your problem has both  dense
#       and sparse constraints, you  can  use  minqpsetlc2mixed()  function,
#       which will result in dense algebra being applied to dense terms, and
#       sparse sparse linear algebra applied to sparse terms.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minqpcreate() call.
#     A       -   linear constraints, array[K,N]. Each row of  A  represents
#                 one  constraint. One-sided  inequality   constraints, two-
#                 sided inequality  constraints,  equality  constraints  are
#                 supported (see below)
#     AL, AU  -   lower and upper bounds, array[K];
#                 * AL[i]=AU[i] =&gt; equality constraint Ai*x
#                 * AL[i]&lt;AU[i] =&gt; two-sided constraint AL[i]&lt;=Ai*x&lt;=AU[i]
#                 * AL[i]=-INF  =&gt; one-sided constraint Ai*x&lt;=AU[i]
#                 * AU[i]=+INF  =&gt; one-sided constraint AL[i]&lt;=Ai*x
#                 * AL[i]=-INF, AU[i]=+INF =&gt; constraint is ignored
#     K       -   number of equality/inequality constraints,  K&gt;=0;  if  not
#                 given, inferred from sizes of A, AL, AU.
# 
#   -- ALGLIB --
#      Copyright 01.11.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetlc2dense(state, a, al, au, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetlc2dense(state, a, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          a:          2D array/list of float
          al:         1D array/list of float
          au:         1D array/list of float
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetlc2mixed'></a><h3 class=pageheader><code>minqpsetlc2mixed</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  sets  two-sided linear  constraints  AL &lt;= A*x &lt;= AU  with
# mixed constraining matrix A including sparse part (first SparseK rows) and
# dense part (last DenseK rows). Recommended for large-scale problems.
# 
# This  function  overwrites  linear  (non-box)  constraints set by previous
# calls (if such calls were made).
# 
# This function may be useful if constraint matrix includes large number  of
# both types of rows - dense and sparse. If you have just a few sparse rows,
# you  may  represent  them  in  dense  format  without losing  performance.
# Similarly, if you have just a few dense rows, you may store them in sparse
# format with almost same performance.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with minqpcreate() call.
#     SparseA -   sparse matrix with size [K,N] (exactly!).
#                 Each row of A represents one general linear constraint.
#                 A can be stored in any sparse storage format.
#     SparseK -   number of sparse constraints, SparseK&gt;=0
#     DenseA  -   linear constraints, array[K,N], set of dense constraints.
#                 Each row of A represents one general linear constraint.
#     DenseK  -   number of dense constraints, DenseK&gt;=0
#     AL, AU  -   lower and upper bounds, array[SparseK+DenseK], with former
#                 SparseK elements corresponding to sparse constraints,  and
#                 latter DenseK elements corresponding to dense constraints;
#                 * AL[i]=AU[i] =&gt; equality constraint Ai*x
#                 * AL[i]&lt;AU[i] =&gt; two-sided constraint AL[i]&lt;=Ai*x&lt;=AU[i]
#                 * AL[i]=-INF  =&gt; one-sided constraint Ai*x&lt;=AU[i]
#                 * AU[i]=+INF  =&gt; one-sided constraint AL[i]&lt;=Ai*x
#                 * AL[i]=-INF, AU[i]=+INF =&gt; constraint is ignored
#     K       -   number  of equality/inequality constraints, K&gt;=0.  If  K=0
#                 is specified, A, AL, AU are ignored.
# 
#   -- ALGLIB --
#      Copyright 01.11.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetlc2mixed(state, sparsea, ksparse, densea, kdense, al, au)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          sparsea:    class xalglib.sparsematrix
          ksparse:    int
          densea:     2D array/list of float
          kdense:     int
          al:         1D array/list of float
          au:         1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetlcmixed'></a><h3 class=pageheader><code>minqpsetlcmixed</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets mixed linear constraints, which include a set of  dense
# rows, and a set of sparse rows.
# 
# This  function  overrides  results  of  previous  calls  to  minqpsetlc(),
# minqpsetlcsparse() and minqpsetlcmixed().
# 
# This function may be useful if constraint matrix includes large number  of
# both types of rows - dense and sparse. If you have just a few sparse rows,
# you  may  represent  them  in  dense  format  without losing  performance.
# Similarly, if you have just a few dense rows, you may store them in sparse
# format with almost same performance.
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with MinQPCreate call.
#     SparseC -   linear constraints, sparse  matrix with dimensions EXACTLY
#                 EQUAL TO [SparseK,N+1].  Each  row  of  C  represents  one
#                 constraint, either equality or inequality (see below):
#                 * first N elements correspond to coefficients,
#                 * last element corresponds to the right part.
#                 All elements of C (including right part) must be finite.
#     SparseCT-   type of sparse constraints, array[K]:
#                 * if SparseCT[i]&gt;0, then I-th constraint is SparseC[i,*]*x &gt;= SparseC[i,n+1]
#                 * if SparseCT[i]=0, then I-th constraint is SparseC[i,*]*x  = SparseC[i,n+1]
#                 * if SparseCT[i]&lt;0, then I-th constraint is SparseC[i,*]*x &lt;= SparseC[i,n+1]
#     SparseK -   number of sparse equality/inequality constraints, K&gt;=0
#     DenseC  -   dense linear constraints, array[K,N+1].
#                 Each row of DenseC represents one constraint, either equality
#                 or inequality (see below):
#                 * first N elements correspond to coefficients,
#                 * last element corresponds to the right part.
#                 All elements of DenseC (including right part) must be finite.
#     DenseCT -   type of constraints, array[K]:
#                 * if DenseCT[i]&gt;0, then I-th constraint is DenseC[i,*]*x &gt;= DenseC[i,n+1]
#                 * if DenseCT[i]=0, then I-th constraint is DenseC[i,*]*x  = DenseC[i,n+1]
#                 * if DenseCT[i]&lt;0, then I-th constraint is DenseC[i,*]*x &lt;= DenseC[i,n+1]
#     DenseK  -   number of equality/inequality constraints, DenseK&gt;=0
# 
# NOTE 1: linear (non-box) constraints  are  satisfied only approximately  -
#         there always exists some violation due  to  numerical  errors  and
#         algorithmic limitations.
# 
# NOTE 2: due to backward compatibility reasons SparseC can be  larger  than
#         [SparseK,N+1]. In this case only leading  [SparseK,N+1]  submatrix
#         will be  used.  However,  the  rest  of  ALGLIB  has  more  strict
#         requirements on the input size, so we recommend you to pass sparse
#         term whose size exactly matches algorithm expectations.
# 
#   -- ALGLIB --
#      Copyright 22.08.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetlcmixed(state, sparsec, sparsect, sparsek, densec, densect, densek)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          sparsec:    class xalglib.sparsematrix
          sparsect:   1D array/list of int
          sparsek:    int
          densec:     2D array/list of float
          densect:    1D array/list of int
          densek:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetlcmixedlegacy'></a><h3 class=pageheader><code>minqpsetlcmixedlegacy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function provides legacy API for specification of mixed  dense/sparse
# linear constraints.
# 
# New conventions used by ALGLIB since release  3.16.0  state  that  set  of
# sparse constraints comes first,  followed  by  set  of  dense  ones.  This
# convention is essential when you talk about things like order of  Lagrange
# multipliers.
# 
# However, legacy API accepted mixed  constraints  in  reverse  order.  This
# function is here to simplify situation with code relying on legacy API. It
# simply accepts constraints in one order (old) and passes them to new  API,
# now in correct order.
# 
#   -- ALGLIB --
#      Copyright 01.11.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetlcmixedlegacy(state, densec, densect, densek, sparsec, sparsect, sparsek)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          densec:     2D array/list of float
          densect:    1D array/list of int
          densek:     int
          sparsec:    class xalglib.sparsematrix
          sparsect:   1D array/list of int
          sparsek:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetlcsparse'></a><h3 class=pageheader><code>minqpsetlcsparse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets sparse linear constraints for QP optimizer.
# 
# This  function  overrides  results  of  previous  calls  to  minqpsetlc(),
# minqpsetlcsparse() and minqpsetlcmixed().  After  call  to  this  function
# all non-box constraints are dropped, and you have only  those  constraints
# which were specified in the present call.
# 
# If you want  to  specify  mixed  (with  dense  and  sparse  terms)  linear
# constraints, you should call minqpsetlcmixed().
# 
# INPUT PARAMETERS:
#     State   -   structure previously allocated with MinQPCreate call.
#     C       -   linear  constraints,  sparse  matrix  with  dimensions  at
#                 least [K,N+1]. If matrix has  larger  size,  only  leading
#                 Kx(N+1) rectangle is used.
#                 Each row of C represents one constraint, either equality
#                 or inequality (see below):
#                 * first N elements correspond to coefficients,
#                 * last element corresponds to the right part.
#                 All elements of C (including right part) must be finite.
#     CT      -   type of constraints, array[K]:
#                 * if CT[i]&gt;0, then I-th constraint is C[i,*]*x &gt;= C[i,n+1]
#                 * if CT[i]=0, then I-th constraint is C[i,*]*x  = C[i,n+1]
#                 * if CT[i]&lt;0, then I-th constraint is C[i,*]*x &lt;= C[i,n+1]
#     K       -   number of equality/inequality constraints, K&gt;=0
# 
# NOTE 1: linear (non-bound) constraints are satisfied only approximately  -
#         there always exists some violation due  to  numerical  errors  and
#         algorithmic limitations.
# 
#   -- ALGLIB --
#      Copyright 22.08.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetlcsparse(state, c, ct, k)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          c:          class xalglib.sparsematrix
          ct:         1D array/list of int
          k:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetlinearterm'></a><h3 class=pageheader><code>minqpsetlinearterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets linear term for QP solver.
# 
# By default, linear term is zero.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     B       -   linear term, array[N].
# 
#   -- ALGLIB --
#      Copyright 11.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetlinearterm(state, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          b:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetorigin'></a><h3 class=pageheader><code>minqpsetorigin</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function sets origin for QP solver. By default, following QP program
# is solved:
# 
#     min(0.5*x'*A*x+b'*x)
# 
# This function allows to solve a different problem:
# 
#     min(0.5*(x-x_origin)'*A*(x-x_origin)+b'*(x-x_origin))
# 
# Specification of non-zero origin  affects  function  being  minimized  and
# quadratic/conic constraints, but not box and linear constraints which  are
# still calculated without origin.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     XOrigin -   origin, array[N].
# 
#   -- ALGLIB --
#      Copyright 11.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetorigin(state, xorigin)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          xorigin:    1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetquadraticterm'></a><h3 class=pageheader><code>minqpsetquadraticterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  sets  dense  quadratic  term  for  QP solver. By  default,
# quadratic term is zero.
# 
# IMPORTANT:
# 
# This solver minimizes following  function:
#     f(x) = 0.5*x'*A*x + b'*x.
# Note that quadratic term has 0.5 before it. So if  you  want  to  minimize
#     f(x) = x^2 + x
# you should rewrite your problem as follows:
#     f(x) = 0.5*(2*x^2) + x
# and your matrix A will be equal to [[2.0]], not to [[1.0]]
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     A       -   matrix, array[N,N]
#     IsUpper -   storage type:
#                 * if True, symmetric matrix  A  is  given  by  its  upper
#                   triangle, and the lower triangle isn't used
#                 * if False, symmetric matrix  A  is  given  by  its lower
#                   triangle, and the upper triangle isn't used
# 
#   -- ALGLIB --
#      Copyright 11.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetquadraticterm(state, a, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          a:          2D array/list of float
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetquadratictermsparse'></a><h3 class=pageheader><code>minqpsetquadratictermsparse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  sets  sparse  quadratic  term  for  QP solver. By default,
# quadratic  term  is  zero.  This  function  overrides  previous  calls  to
# minqpsetquadraticterm() or minqpsetquadratictermsparse().
# 
# NOTE: dense solvers like DENSE-AUL-QP or DENSE-IPM-QP  will  convert  this
#       matrix to dense storage anyway.
# 
# IMPORTANT:
# 
# This solver minimizes following  function:
#     f(x) = 0.5*x'*A*x + b'*x.
# Note that quadratic term has 0.5 before it. So if  you  want  to  minimize
#     f(x) = x^2 + x
# you should rewrite your problem as follows:
#     f(x) = 0.5*(2*x^2) + x
# and your matrix A will be equal to [[2.0]], not to [[1.0]]
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     A       -   matrix, array[N,N]
#     IsUpper -   (optional) storage type:
#                 * if True, symmetric matrix  A  is  given  by  its  upper
#                   triangle, and the lower triangle isn't used
#                 * if False, symmetric matrix  A  is  given  by  its lower
#                   triangle, and the upper triangle isn't used
#                 * if not given, both lower and upper  triangles  must  be
#                   filled.
# 
#   -- ALGLIB --
#      Copyright 11.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetquadratictermsparse(state, a, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          a:          class xalglib.sparsematrix
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetscale'></a><h3 class=pageheader><code>minqpsetscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets scaling coefficients.
# 
# ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
# size and gradient are scaled before comparison  with  tolerances)  and  as
# preconditioner.
# 
# Scale of the I-th variable is a translation invariant measure of:
# a) &quot;how large&quot; the variable is
# b) how large the step should be to make significant changes in the
#    function
# 
# If you do not know how to choose scales of your variables, you can:
# * read www.alglib.net/optimization/scaling.php article
# * use minqpsetscaleautodiag(), which calculates scale  using  diagonal  of
#   the  quadratic  term:  S  is  set to 1/sqrt(diag(A)), which works well
#   sometimes.
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     S       -   array[N], non-zero scaling coefficients
#                 S[i] may be negative, sign doesn't matter.
# 
#   -- ALGLIB --
#      Copyright 14.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetscale(state, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          s:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetscaleautodiag'></a><h3 class=pageheader><code>minqpsetscaleautodiag</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets automatic evaluation of variable scaling.
# 
# IMPORTANT: this function works only for  matrices  with positive  diagonal
#            elements! Zero or negative elements will  result  in  -9  error
#            code  being  returned.  Specify  scale  vector  manually   with
#            minqpsetscale() in such cases.
# 
# ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
# size and gradient are scaled before comparison  with  tolerances)  and  as
# preconditioner.
# 
# The  best  way  to  set  scaling  is  to manually specify variable scales.
# However, sometimes you just need quick-and-dirty solution  -  either  when
# you perform fast prototyping, or when you know your problem well  and  you
# are 100% sure that this quick solution is robust enough in your case.
# 
# One such solution is to evaluate scale of I-th variable as 1/Sqrt(A[i,i]),
# where A[i,i] is an I-th diagonal element of the quadratic term.
# 
# Such approach works well sometimes, but you have to be careful here.
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 26.12.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetscaleautodiag(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_minqpsetstartingpoint'></a><h3 class=pageheader><code>minqpsetstartingpoint</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets starting point for QP solver. It is useful to have good
# initial approximation to the solution, because it will increase  speed  of
# convergence and identification of active constraints.
# 
# NOTE: interior point solvers ignore initial point provided by user.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     X       -   starting point, array[N].
# 
#   -- ALGLIB --
#      Copyright 11.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.minqpsetstartingpoint(state, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.minqpstate
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_mlpbase></a><h2 class=pageheader><code>mlpbase</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_mlpactivationfunction' class=toc>mlpactivationfunction</a><br>
<a href='#sub_mlpallerrorssparsesubset' class=toc>mlpallerrorssparsesubset</a><br>
<a href='#sub_mlpallerrorssubset' class=toc>mlpallerrorssubset</a><br>
<a href='#sub_mlpavgce' class=toc>mlpavgce</a><br>
<a href='#sub_mlpavgcesparse' class=toc>mlpavgcesparse</a><br>
<a href='#sub_mlpavgerror' class=toc>mlpavgerror</a><br>
<a href='#sub_mlpavgerrorsparse' class=toc>mlpavgerrorsparse</a><br>
<a href='#sub_mlpavgrelerror' class=toc>mlpavgrelerror</a><br>
<a href='#sub_mlpavgrelerrorsparse' class=toc>mlpavgrelerrorsparse</a><br>
<a href='#sub_mlpclserror' class=toc>mlpclserror</a><br>
<a href='#sub_mlpcopy' class=toc>mlpcopy</a><br>
<a href='#sub_mlpcopytunableparameters' class=toc>mlpcopytunableparameters</a><br>
<a href='#sub_mlpcreate0' class=toc>mlpcreate0</a><br>
<a href='#sub_mlpcreate1' class=toc>mlpcreate1</a><br>
<a href='#sub_mlpcreate2' class=toc>mlpcreate2</a><br>
<a href='#sub_mlpcreateb0' class=toc>mlpcreateb0</a><br>
<a href='#sub_mlpcreateb1' class=toc>mlpcreateb1</a><br>
<a href='#sub_mlpcreateb2' class=toc>mlpcreateb2</a><br>
<a href='#sub_mlpcreatec0' class=toc>mlpcreatec0</a><br>
<a href='#sub_mlpcreatec1' class=toc>mlpcreatec1</a><br>
<a href='#sub_mlpcreatec2' class=toc>mlpcreatec2</a><br>
<a href='#sub_mlpcreater0' class=toc>mlpcreater0</a><br>
<a href='#sub_mlpcreater1' class=toc>mlpcreater1</a><br>
<a href='#sub_mlpcreater2' class=toc>mlpcreater2</a><br>
<a href='#sub_mlperror' class=toc>mlperror</a><br>
<a href='#sub_mlperrorn' class=toc>mlperrorn</a><br>
<a href='#sub_mlperrorsparse' class=toc>mlperrorsparse</a><br>
<a href='#sub_mlperrorsparsesubset' class=toc>mlperrorsparsesubset</a><br>
<a href='#sub_mlperrorsubset' class=toc>mlperrorsubset</a><br>
<a href='#sub_mlpgetinputscaling' class=toc>mlpgetinputscaling</a><br>
<a href='#sub_mlpgetinputscount' class=toc>mlpgetinputscount</a><br>
<a href='#sub_mlpgetlayerscount' class=toc>mlpgetlayerscount</a><br>
<a href='#sub_mlpgetlayersize' class=toc>mlpgetlayersize</a><br>
<a href='#sub_mlpgetneuroninfo' class=toc>mlpgetneuroninfo</a><br>
<a href='#sub_mlpgetoutputscaling' class=toc>mlpgetoutputscaling</a><br>
<a href='#sub_mlpgetoutputscount' class=toc>mlpgetoutputscount</a><br>
<a href='#sub_mlpgetweight' class=toc>mlpgetweight</a><br>
<a href='#sub_mlpgetweightscount' class=toc>mlpgetweightscount</a><br>
<a href='#sub_mlpgrad' class=toc>mlpgrad</a><br>
<a href='#sub_mlpgradbatch' class=toc>mlpgradbatch</a><br>
<a href='#sub_mlpgradbatchsparse' class=toc>mlpgradbatchsparse</a><br>
<a href='#sub_mlpgradbatchsparsesubset' class=toc>mlpgradbatchsparsesubset</a><br>
<a href='#sub_mlpgradbatchsubset' class=toc>mlpgradbatchsubset</a><br>
<a href='#sub_mlpgradn' class=toc>mlpgradn</a><br>
<a href='#sub_mlpgradnbatch' class=toc>mlpgradnbatch</a><br>
<a href='#sub_mlphessianbatch' class=toc>mlphessianbatch</a><br>
<a href='#sub_mlphessiannbatch' class=toc>mlphessiannbatch</a><br>
<a href='#sub_mlpinitpreprocessor' class=toc>mlpinitpreprocessor</a><br>
<a href='#sub_mlpissoftmax' class=toc>mlpissoftmax</a><br>
<a href='#sub_mlpprocess' class=toc>mlpprocess</a><br>
<a href='#sub_mlpprocessi' class=toc>mlpprocessi</a><br>
<a href='#sub_mlpproperties' class=toc>mlpproperties</a><br>
<a href='#sub_mlprandomize' class=toc>mlprandomize</a><br>
<a href='#sub_mlprandomizefull' class=toc>mlprandomizefull</a><br>
<a href='#sub_mlprelclserror' class=toc>mlprelclserror</a><br>
<a href='#sub_mlprelclserrorsparse' class=toc>mlprelclserrorsparse</a><br>
<a href='#sub_mlprmserror' class=toc>mlprmserror</a><br>
<a href='#sub_mlprmserrorsparse' class=toc>mlprmserrorsparse</a><br>
<a href='#sub_mlpsetinputscaling' class=toc>mlpsetinputscaling</a><br>
<a href='#sub_mlpsetneuroninfo' class=toc>mlpsetneuroninfo</a><br>
<a href='#sub_mlpsetoutputscaling' class=toc>mlpsetoutputscaling</a><br>
<a href='#sub_mlpsetweight' class=toc>mlpsetweight</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_mlpactivationfunction'></a><h3 class=pageheader><code>mlpactivationfunction</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Neural network activation function
# 
# INPUT PARAMETERS:
#     NET         -   neuron input
#     K           -   function index (zero for linear function)
# 
# OUTPUT PARAMETERS:
#     F           -   function
#     DF          -   its derivative
#     D2F         -   its second derivative
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   f, df, d2f = xalglib.mlpactivationfunction(net, k)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     net:        float
          k:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  f:          float
          df:         float
          d2f:        float

</div></pre>
<a name='sub_mlpallerrorssparsesubset'></a><h3 class=pageheader><code>mlpallerrorssparsesubset</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Calculation of all types of errors on subset of dataset.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network -   network initialized with one of the network creation funcs
#     XY      -   original dataset given by sparse matrix;
#                 one sample = one row;
#                 first NIn columns contain inputs,
#                 next NOut columns - desired outputs.
#     SetSize -   real size of XY, SetSize&gt;=0;
#     Subset  -   subset of SubsetSize elements, array[SubsetSize];
#     SubsetSize- number of elements in Subset[] array:
#                 * if SubsetSize&gt;0, rows of XY with indices Subset[0]...
#                   ...Subset[SubsetSize-1] are processed
#                 * if SubsetSize=0, zeros are returned
#                 * if SubsetSize&lt;0, entire dataset is  processed;  Subset[]
#                   array is ignored in this case.
# 
# OUTPUT PARAMETERS:
#     Rep     -   it contains all type of errors.
# 
# 
#   -- ALGLIB --
#      Copyright 04.09.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.mlpallerrorssparsesubset(network, xy, setsize, subset, subsetsize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         class xalglib.sparsematrix
          setsize:    int
          subset:     1D array/list of int
          subsetsize: int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.modelerrors

</div></pre>
<a name='sub_mlpallerrorssubset'></a><h3 class=pageheader><code>mlpallerrorssubset</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Calculation of all types of errors on subset of dataset.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network -   network initialized with one of the network creation funcs
#     XY      -   original dataset; one sample = one row;
#                 first NIn columns contain inputs,
#                 next NOut columns - desired outputs.
#     SetSize -   real size of XY, SetSize&gt;=0;
#     Subset  -   subset of SubsetSize elements, array[SubsetSize];
#     SubsetSize- number of elements in Subset[] array:
#                 * if SubsetSize&gt;0, rows of XY with indices Subset[0]...
#                   ...Subset[SubsetSize-1] are processed
#                 * if SubsetSize=0, zeros are returned
#                 * if SubsetSize&lt;0, entire dataset is  processed;  Subset[]
#                   array is ignored in this case.
# 
# OUTPUT PARAMETERS:
#     Rep     -   it contains all type of errors.
# 
#   -- ALGLIB --
#      Copyright 04.09.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.mlpallerrorssubset(network, xy, setsize, subset, subsetsize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          setsize:    int
          subset:     1D array/list of int
          subsetsize: int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.modelerrors

</div></pre>
<a name='sub_mlpavgce'></a><h3 class=pageheader><code>mlpavgce</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average cross-entropy  (in bits  per element) on the test set.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network     -   neural network;
#     XY          -   training  set,  see  below  for  information  on   the
#                     training set format;
#     NPoints     -   points count.
# 
# RESULT:
# CrossEntropy/(NPoints*LN(2)).
# Zero if network solves regression task.
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# dataset format is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 08.01.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpavgce(network, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlpavgcesparse'></a><h3 class=pageheader><code>mlpavgcesparse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average  cross-entropy  (in bits  per element)  on the  test set  given by
# sparse matrix.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network     -   neural network;
#     XY          -   training  set,  see  below  for  information  on   the
#                     training set format. This function checks  correctness
#                     of  the  dataset  (no  NANs/INFs,  class  numbers  are
#                     correct) and throws exception when  incorrect  dataset
#                     is passed.  Sparse  matrix  must  use  CRS  format for
#                     storage.
#     NPoints     -   points count, &gt;=0.
# 
# RESULT:
# CrossEntropy/(NPoints*LN(2)).
# Zero if network solves regression task.
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# dataset format is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 9.08.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpavgcesparse(network, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         class xalglib.sparsematrix
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlpavgerror'></a><h3 class=pageheader><code>mlpavgerror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average absolute error on the test set.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network     -   neural network;
#     XY          -   training  set,  see  below  for  information  on   the
#                     training set format;
#     NPoints     -   points count.
# 
# RESULT:
# Its meaning for regression task is obvious. As for classification task, it
# means average error when estimating posterior probabilities.
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# dataset format is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 11.03.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpavgerror(network, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlpavgerrorsparse'></a><h3 class=pageheader><code>mlpavgerrorsparse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average absolute error on the test set given by sparse matrix.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network     -   neural network;
#     XY          -   training  set,  see  below  for  information  on   the
#                     training set format. This function checks  correctness
#                     of  the  dataset  (no  NANs/INFs,  class  numbers  are
#                     correct) and throws exception when  incorrect  dataset
#                     is passed.  Sparse  matrix  must  use  CRS  format for
#                     storage.
#     NPoints     -   points count, &gt;=0.
# 
# RESULT:
# Its meaning for regression task is obvious. As for classification task, it
# means average error when estimating posterior probabilities.
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# dataset format is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 09.08.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpavgerrorsparse(network, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         class xalglib.sparsematrix
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlpavgrelerror'></a><h3 class=pageheader><code>mlpavgrelerror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average relative error on the test set.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network     -   neural network;
#     XY          -   training  set,  see  below  for  information  on   the
#                     training set format;
#     NPoints     -   points count.
# 
# RESULT:
# Its meaning for regression task is obvious. As for classification task, it
# means  average  relative  error  when  estimating posterior probability of
# belonging to the correct class.
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# dataset format is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 11.03.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpavgrelerror(network, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlpavgrelerrorsparse'></a><h3 class=pageheader><code>mlpavgrelerrorsparse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average relative error on the test set given by sparse matrix.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network     -   neural network;
#     XY          -   training  set,  see  below  for  information  on   the
#                     training set format. This function checks  correctness
#                     of  the  dataset  (no  NANs/INFs,  class  numbers  are
#                     correct) and throws exception when  incorrect  dataset
#                     is passed.  Sparse  matrix  must  use  CRS  format for
#                     storage.
#     NPoints     -   points count, &gt;=0.
# 
# RESULT:
# Its meaning for regression task is obvious. As for classification task, it
# means  average  relative  error  when  estimating posterior probability of
# belonging to the correct class.
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# dataset format is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 09.08.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpavgrelerrorsparse(network, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         class xalglib.sparsematrix
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlpclserror'></a><h3 class=pageheader><code>mlpclserror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Classification error of the neural network on dataset.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network     -   neural network;
#     XY          -   training  set,  see  below  for  information  on   the
#                     training set format;
#     NPoints     -   points count.
# 
# RESULT:
#     classification error (number of misclassified cases)
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# dataset format is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpclserror(network, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_mlpcopy'></a><h3 class=pageheader><code>mlpcopy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Copying of neural network
# 
# INPUT PARAMETERS:
#     Network1 -   original
# 
# OUTPUT PARAMETERS:
#     Network2 -   copy
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   network2 = xalglib.mlpcopy(network1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network1:   class xalglib.multilayerperceptron
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  network2:   class xalglib.multilayerperceptron

</div></pre>
<a name='sub_mlpcopytunableparameters'></a><h3 class=pageheader><code>mlpcopytunableparameters</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function copies tunable  parameters (weights/means/sigmas)  from  one
# network to another with same architecture. It  performs  some  rudimentary
# checks that architectures are same, and throws exception if check fails.
# 
# It is intended for fast copying of states between two  network  which  are
# known to have same geometry.
# 
# INPUT PARAMETERS:
#     Network1 -   source, must be correctly initialized
#     Network2 -   target, must have same architecture
# 
# OUTPUT PARAMETERS:
#     Network2 -   network state is copied from source to target
# 
#   -- ALGLIB --
#      Copyright 20.06.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mlpcopytunableparameters(network1, network2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network1:   class xalglib.multilayerperceptron
          network2:   class xalglib.multilayerperceptron
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network2
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mlpcreate0'></a><h3 class=pageheader><code>mlpcreate0</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Creates  neural  network  with  NIn  inputs,  NOut outputs, without hidden
# layers, with linear output layer. Network weights are  filled  with  small
# random values.
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   network = xalglib.mlpcreate0(nin, nout)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nout:       int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  network:    class xalglib.multilayerperceptron

</div></pre>
<a name='sub_mlpcreate1'></a><h3 class=pageheader><code>mlpcreate1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Same  as  MLPCreate0,  but  with  one  hidden  layer  (NHid  neurons) with
# non-linear activation function. Output layer is linear.
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   network = xalglib.mlpcreate1(nin, nhid, nout)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nhid:       int
          nout:       int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  network:    class xalglib.multilayerperceptron

</div></pre>
<a name='sub_mlpcreate2'></a><h3 class=pageheader><code>mlpcreate2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Same as MLPCreate0, but with two hidden layers (NHid1 and  NHid2  neurons)
# with non-linear activation function. Output layer is linear.
#  $ALL
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   network = xalglib.mlpcreate2(nin, nhid1, nhid2, nout)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nhid1:      int
          nhid2:      int
          nout:       int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  network:    class xalglib.multilayerperceptron

</div></pre>
<a name='sub_mlpcreateb0'></a><h3 class=pageheader><code>mlpcreateb0</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Creates  neural  network  with  NIn  inputs,  NOut outputs, without hidden
# layers with non-linear output layer. Network weights are filled with small
# random values.
# 
# Activation function of the output layer takes values:
# 
#     (B, +INF), if D&gt;=0
# 
# or
# 
#     (-INF, B), if D&lt;0.
# 
# 
#   -- ALGLIB --
#      Copyright 30.03.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   network = xalglib.mlpcreateb0(nin, nout, b, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nout:       int
          b:          float
          d:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  network:    class xalglib.multilayerperceptron

</div></pre>
<a name='sub_mlpcreateb1'></a><h3 class=pageheader><code>mlpcreateb1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Same as MLPCreateB0 but with non-linear hidden layer.
# 
#   -- ALGLIB --
#      Copyright 30.03.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   network = xalglib.mlpcreateb1(nin, nhid, nout, b, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nhid:       int
          nout:       int
          b:          float
          d:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  network:    class xalglib.multilayerperceptron

</div></pre>
<a name='sub_mlpcreateb2'></a><h3 class=pageheader><code>mlpcreateb2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Same as MLPCreateB0 but with two non-linear hidden layers.
# 
#   -- ALGLIB --
#      Copyright 30.03.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   network = xalglib.mlpcreateb2(nin, nhid1, nhid2, nout, b, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nhid1:      int
          nhid2:      int
          nout:       int
          b:          float
          d:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  network:    class xalglib.multilayerperceptron

</div></pre>
<a name='sub_mlpcreatec0'></a><h3 class=pageheader><code>mlpcreatec0</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Creates classifier network with NIn  inputs  and  NOut  possible  classes.
# Network contains no hidden layers and linear output  layer  with  SOFTMAX-
# normalization  (so  outputs  sums  up  to  1.0  and  converge to posterior
# probabilities).
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   network = xalglib.mlpcreatec0(nin, nout)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nout:       int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  network:    class xalglib.multilayerperceptron

</div></pre>
<a name='sub_mlpcreatec1'></a><h3 class=pageheader><code>mlpcreatec1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Same as MLPCreateC0, but with one non-linear hidden layer.
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   network = xalglib.mlpcreatec1(nin, nhid, nout)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nhid:       int
          nout:       int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  network:    class xalglib.multilayerperceptron

</div></pre>
<a name='sub_mlpcreatec2'></a><h3 class=pageheader><code>mlpcreatec2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Same as MLPCreateC0, but with two non-linear hidden layers.
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   network = xalglib.mlpcreatec2(nin, nhid1, nhid2, nout)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nhid1:      int
          nhid2:      int
          nout:       int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  network:    class xalglib.multilayerperceptron

</div></pre>
<a name='sub_mlpcreater0'></a><h3 class=pageheader><code>mlpcreater0</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Creates  neural  network  with  NIn  inputs,  NOut outputs, without hidden
# layers with non-linear output layer. Network weights are filled with small
# random values. Activation function of the output layer takes values [A,B].
# 
#   -- ALGLIB --
#      Copyright 30.03.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   network = xalglib.mlpcreater0(nin, nout, a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nout:       int
          a:          float
          b:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  network:    class xalglib.multilayerperceptron

</div></pre>
<a name='sub_mlpcreater1'></a><h3 class=pageheader><code>mlpcreater1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Same as MLPCreateR0, but with non-linear hidden layer.
# 
#   -- ALGLIB --
#      Copyright 30.03.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   network = xalglib.mlpcreater1(nin, nhid, nout, a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nhid:       int
          nout:       int
          a:          float
          b:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  network:    class xalglib.multilayerperceptron

</div></pre>
<a name='sub_mlpcreater2'></a><h3 class=pageheader><code>mlpcreater2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Same as MLPCreateR0, but with two non-linear hidden layers.
# 
#   -- ALGLIB --
#      Copyright 30.03.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   network = xalglib.mlpcreater2(nin, nhid1, nhid2, nout, a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nhid1:      int
          nhid2:      int
          nout:       int
          a:          float
          b:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  network:    class xalglib.multilayerperceptron

</div></pre>
<a name='sub_mlperror'></a><h3 class=pageheader><code>mlperror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Error of the neural network on dataset.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network     -   neural network;
#     XY          -   training  set,  see  below  for  information  on   the
#                     training set format;
#     NPoints     -   points count.
# 
# RESULT:
#     sum-of-squares error, SUM(sqr(y[i]-desired_y[i])/2)
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# dataset format is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlperror(network, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlperrorn'></a><h3 class=pageheader><code>mlperrorn</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Natural error function for neural network, internal subroutine.
# 
# NOTE: this function is single-threaded. Unlike other  error  function,  it
# receives no speed-up from being executed in SMP mode.
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlperrorn(network, xy, ssize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          ssize:      int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlperrorsparse'></a><h3 class=pageheader><code>mlperrorsparse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Error of the neural network on dataset given by sparse matrix.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network     -   neural network
#     XY          -   training  set,  see  below  for  information  on   the
#                     training set format. This function checks  correctness
#                     of  the  dataset  (no  NANs/INFs,  class  numbers  are
#                     correct) and throws exception when  incorrect  dataset
#                     is passed.  Sparse  matrix  must  use  CRS  format for
#                     storage.
#     NPoints     -   points count, &gt;=0
# 
# RESULT:
#     sum-of-squares error, SUM(sqr(y[i]-desired_y[i])/2)
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# dataset format is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 23.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlperrorsparse(network, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         class xalglib.sparsematrix
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlperrorsparsesubset'></a><h3 class=pageheader><code>mlperrorsparsesubset</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Error of the neural network on subset of sparse dataset.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network   -     neural network;
#     XY        -     training  set,  see  below  for  information  on   the
#                     training set format. This function checks  correctness
#                     of  the  dataset  (no  NANs/INFs,  class  numbers  are
#                     correct) and throws exception when  incorrect  dataset
#                     is passed.  Sparse  matrix  must  use  CRS  format for
#                     storage.
#     SetSize   -     real size of XY, SetSize&gt;=0;
#                     it is used when SubsetSize&lt;0;
#     Subset    -     subset of SubsetSize elements, array[SubsetSize];
#     SubsetSize-     number of elements in Subset[] array:
#                     * if SubsetSize&gt;0, rows of XY with indices Subset[0]...
#                       ...Subset[SubsetSize-1] are processed
#                     * if SubsetSize=0, zeros are returned
#                     * if SubsetSize&lt;0, entire dataset is  processed;  Subset[]
#                       array is ignored in this case.
# 
# RESULT:
#     sum-of-squares error, SUM(sqr(y[i]-desired_y[i])/2)
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# dataset format is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 04.09.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlperrorsparsesubset(network, xy, setsize, subset, subsetsize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         class xalglib.sparsematrix
          setsize:    int
          subset:     1D array/list of int
          subsetsize: int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlperrorsubset'></a><h3 class=pageheader><code>mlperrorsubset</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Error of the neural network on subset of dataset.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network   -     neural network;
#     XY        -     training  set,  see  below  for  information  on   the
#                     training set format;
#     SetSize   -     real size of XY, SetSize&gt;=0;
#     Subset    -     subset of SubsetSize elements, array[SubsetSize];
#     SubsetSize-     number of elements in Subset[] array:
#                     * if SubsetSize&gt;0, rows of XY with indices Subset[0]...
#                       ...Subset[SubsetSize-1] are processed
#                     * if SubsetSize=0, zeros are returned
#                     * if SubsetSize&lt;0, entire dataset is  processed;  Subset[]
#                       array is ignored in this case.
# 
# RESULT:
#     sum-of-squares error, SUM(sqr(y[i]-desired_y[i])/2)
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# dataset format is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 04.09.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlperrorsubset(network, xy, setsize, subset, subsetsize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          setsize:    int
          subset:     1D array/list of int
          subsetsize: int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlpgetinputscaling'></a><h3 class=pageheader><code>mlpgetinputscaling</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns offset/scaling coefficients for I-th input of the
# network.
# 
# INPUT PARAMETERS:
#     Network     -   network
#     I           -   input index
# 
# OUTPUT PARAMETERS:
#     Mean        -   mean term
#     Sigma       -   sigma term, guaranteed to be nonzero.
# 
# I-th input is passed through linear transformation
#     IN[i] = (IN[i]-Mean)/Sigma
# before feeding to the network
# 
#   -- ALGLIB --
#      Copyright 25.03.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   mean, sigma = xalglib.mlpgetinputscaling(network, i)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          i:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  mean:       float
          sigma:      float

</div></pre>
<a name='sub_mlpgetinputscount'></a><h3 class=pageheader><code>mlpgetinputscount</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Returns number of inputs.
# 
#   -- ALGLIB --
#      Copyright 19.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpgetinputscount(network)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_mlpgetlayerscount'></a><h3 class=pageheader><code>mlpgetlayerscount</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns total number of layers (including input, hidden and
# output layers).
# 
#   -- ALGLIB --
#      Copyright 25.03.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpgetlayerscount(network)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_mlpgetlayersize'></a><h3 class=pageheader><code>mlpgetlayersize</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns size of K-th layer.
# 
# K=0 corresponds to input layer, K=CNT-1 corresponds to output layer.
# 
# Size of the output layer is always equal to the number of outputs, although
# when we have softmax-normalized network, last neuron doesn't have any
# connections - it is just zero.
# 
#   -- ALGLIB --
#      Copyright 25.03.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpgetlayersize(network, k)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          k:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_mlpgetneuroninfo'></a><h3 class=pageheader><code>mlpgetneuroninfo</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns information about Ith neuron of Kth layer
# 
# INPUT PARAMETERS:
#     Network     -   network
#     K           -   layer index
#     I           -   neuron index (within layer)
# 
# OUTPUT PARAMETERS:
#     FKind       -   activation function type (used by MLPActivationFunction())
#                     this value is zero for input or linear neurons
#     Threshold   -   also called offset, bias
#                     zero for input neurons
# 
# NOTE: this function throws exception if layer or neuron with  given  index
# do not exists.
# 
#   -- ALGLIB --
#      Copyright 25.03.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   fkind, threshold = xalglib.mlpgetneuroninfo(network, k, i)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          k:          int
          i:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  fkind:      int
          threshold:  float

</div></pre>
<a name='sub_mlpgetoutputscaling'></a><h3 class=pageheader><code>mlpgetoutputscaling</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns offset/scaling coefficients for I-th output of the
# network.
# 
# INPUT PARAMETERS:
#     Network     -   network
#     I           -   input index
# 
# OUTPUT PARAMETERS:
#     Mean        -   mean term
#     Sigma       -   sigma term, guaranteed to be nonzero.
# 
# I-th output is passed through linear transformation
#     OUT[i] = OUT[i]*Sigma+Mean
# before returning it to user. In case we have SOFTMAX-normalized network,
# we return (Mean,Sigma)=(0.0,1.0).
# 
#   -- ALGLIB --
#      Copyright 25.03.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   mean, sigma = xalglib.mlpgetoutputscaling(network, i)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          i:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  mean:       float
          sigma:      float

</div></pre>
<a name='sub_mlpgetoutputscount'></a><h3 class=pageheader><code>mlpgetoutputscount</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Returns number of outputs.
# 
#   -- ALGLIB --
#      Copyright 19.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpgetoutputscount(network)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_mlpgetweight'></a><h3 class=pageheader><code>mlpgetweight</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns information about connection from I0-th neuron of
# K0-th layer to I1-th neuron of K1-th layer.
# 
# INPUT PARAMETERS:
#     Network     -   network
#     K0          -   layer index
#     I0          -   neuron index (within layer)
#     K1          -   layer index
#     I1          -   neuron index (within layer)
# 
# RESULT:
#     connection weight (zero for non-existent connections)
# 
# This function:
# 1. throws exception if layer or neuron with given index do not exists.
# 2. returns zero if neurons exist, but there is no connection between them
# 
#   -- ALGLIB --
#      Copyright 25.03.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpgetweight(network, k0, i0, k1, i1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          k0:         int
          i0:         int
          k1:         int
          i1:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlpgetweightscount'></a><h3 class=pageheader><code>mlpgetweightscount</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Returns number of weights.
# 
#   -- ALGLIB --
#      Copyright 19.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpgetweightscount(network)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_mlpgrad'></a><h3 class=pageheader><code>mlpgrad</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Gradient calculation
# 
# INPUT PARAMETERS:
#     Network -   network initialized with one of the network creation funcs
#     X       -   input vector, length of array must be at least NIn
#     DesiredY-   desired outputs, length of array must be at least NOut
#     Grad    -   possibly preallocated array. If size of array is smaller
#                 than WCount, it will be reallocated. It is recommended to
#                 reuse previously allocated array to reduce allocation
#                 overhead.
# 
# OUTPUT PARAMETERS:
#     E       -   error function, SUM(sqr(y[i]-desiredy[i])/2,i)
#     Grad    -   gradient of E with respect to weights of network, array[WCount]
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   e, grad = xalglib.mlpgrad(network, x, desiredy, grad)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          x:          1D array/list of float
          desiredy:   1D array/list of float
          grad:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  e:          float
          grad:       1D array/list of float

</div></pre>
<a name='sub_mlpgradbatch'></a><h3 class=pageheader><code>mlpgradbatch</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Batch gradient calculation for a set of inputs/outputs
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network -   network initialized with one of the network creation funcs
#     XY      -   original dataset in dense format; one sample = one row:
#                 * first NIn columns contain inputs,
#                 * for regression problem, next NOut columns store
#                   desired outputs.
#                 * for classification problem, next column (just one!)
#                   stores class number.
#     SSize   -   number of elements in XY
#     Grad    -   possibly preallocated array. If size of array is smaller
#                 than WCount, it will be reallocated. It is recommended to
#                 reuse previously allocated array to reduce allocation
#                 overhead.
# 
# OUTPUT PARAMETERS:
#     E       -   error function, SUM(sqr(y[i]-desiredy[i])/2,i)
#     Grad    -   gradient of E with respect to weights of network, array[WCount]
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   e, grad = xalglib.mlpgradbatch(network, xy, ssize, grad)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          ssize:      int
          grad:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  e:          float
          grad:       1D array/list of float

</div></pre>
<a name='sub_mlpgradbatchsparse'></a><h3 class=pageheader><code>mlpgradbatchsparse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Batch gradient calculation for a set  of inputs/outputs  given  by  sparse
# matrices
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network -   network initialized with one of the network creation funcs
#     XY      -   original dataset in sparse format; one sample = one row:
#                 * MATRIX MUST BE STORED IN CRS FORMAT
#                 * first NIn columns contain inputs.
#                 * for regression problem, next NOut columns store
#                   desired outputs.
#                 * for classification problem, next column (just one!)
#                   stores class number.
#     SSize   -   number of elements in XY
#     Grad    -   possibly preallocated array. If size of array is smaller
#                 than WCount, it will be reallocated. It is recommended to
#                 reuse previously allocated array to reduce allocation
#                 overhead.
# 
# OUTPUT PARAMETERS:
#     E       -   error function, SUM(sqr(y[i]-desiredy[i])/2,i)
#     Grad    -   gradient of E with respect to weights of network, array[WCount]
# 
#   -- ALGLIB --
#      Copyright 26.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   e, grad = xalglib.mlpgradbatchsparse(network, xy, ssize, grad)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         class xalglib.sparsematrix
          ssize:      int
          grad:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  e:          float
          grad:       1D array/list of float

</div></pre>
<a name='sub_mlpgradbatchsparsesubset'></a><h3 class=pageheader><code>mlpgradbatchsparsesubset</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Batch gradient calculation for a set of inputs/outputs  for  a  subset  of
# dataset given by set of indexes.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network -   network initialized with one of the network creation funcs
#     XY      -   original dataset in sparse format; one sample = one row:
#                 * MATRIX MUST BE STORED IN CRS FORMAT
#                 * first NIn columns contain inputs,
#                 * for regression problem, next NOut columns store
#                   desired outputs.
#                 * for classification problem, next column (just one!)
#                   stores class number.
#     SetSize -   real size of XY, SetSize&gt;=0;
#     Idx     -   subset of SubsetSize elements, array[SubsetSize]:
#                 * Idx[I] stores row index in the original dataset which is
#                   given by XY. Gradient is calculated with respect to rows
#                   whose indexes are stored in Idx[].
#                 * Idx[]  must store correct indexes; this function  throws
#                   an  exception  in  case  incorrect index (less than 0 or
#                   larger than rows(XY)) is given
#                 * Idx[]  may  store  indexes  in  any  order and even with
#                   repetitions.
#     SubsetSize- number of elements in Idx[] array:
#                 * positive value means that subset given by Idx[] is processed
#                 * zero value results in zero gradient
#                 * negative value means that full dataset is processed
#     Grad      - possibly  preallocated array. If size of array is  smaller
#                 than WCount, it will be reallocated. It is  recommended to
#                 reuse  previously  allocated  array  to  reduce allocation
#                 overhead.
# 
# OUTPUT PARAMETERS:
#     E       -   error function, SUM(sqr(y[i]-desiredy[i])/2,i)
#     Grad    -   gradient  of  E  with  respect   to  weights  of  network,
#                 array[WCount]
# 
# NOTE: when  SubsetSize&lt;0 is used full dataset by call MLPGradBatchSparse
#       function.
# 
#   -- ALGLIB --
#      Copyright 26.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   e, grad = xalglib.mlpgradbatchsparsesubset(network, xy, setsize, idx, subsetsize, grad)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         class xalglib.sparsematrix
          setsize:    int
          idx:        1D array/list of int
          subsetsize: int
          grad:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  e:          float
          grad:       1D array/list of float

</div></pre>
<a name='sub_mlpgradbatchsubset'></a><h3 class=pageheader><code>mlpgradbatchsubset</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Batch gradient calculation for a subset of dataset
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network -   network initialized with one of the network creation funcs
#     XY      -   original dataset in dense format; one sample = one row:
#                 * first NIn columns contain inputs,
#                 * for regression problem, next NOut columns store
#                   desired outputs.
#                 * for classification problem, next column (just one!)
#                   stores class number.
#     SetSize -   real size of XY, SetSize&gt;=0;
#     Idx     -   subset of SubsetSize elements, array[SubsetSize]:
#                 * Idx[I] stores row index in the original dataset which is
#                   given by XY. Gradient is calculated with respect to rows
#                   whose indexes are stored in Idx[].
#                 * Idx[]  must store correct indexes; this function  throws
#                   an  exception  in  case  incorrect index (less than 0 or
#                   larger than rows(XY)) is given
#                 * Idx[]  may  store  indexes  in  any  order and even with
#                   repetitions.
#     SubsetSize- number of elements in Idx[] array:
#                 * positive value means that subset given by Idx[] is processed
#                 * zero value results in zero gradient
#                 * negative value means that full dataset is processed
#     Grad      - possibly  preallocated array. If size of array is  smaller
#                 than WCount, it will be reallocated. It is  recommended to
#                 reuse  previously  allocated  array  to  reduce allocation
#                 overhead.
# 
# OUTPUT PARAMETERS:
#     E         - error function, SUM(sqr(y[i]-desiredy[i])/2,i)
#     Grad      - gradient  of  E  with  respect   to  weights  of  network,
#                 array[WCount]
# 
#   -- ALGLIB --
#      Copyright 26.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   e, grad = xalglib.mlpgradbatchsubset(network, xy, setsize, idx, subsetsize, grad)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          setsize:    int
          idx:        1D array/list of int
          subsetsize: int
          grad:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  e:          float
          grad:       1D array/list of float

</div></pre>
<a name='sub_mlpgradn'></a><h3 class=pageheader><code>mlpgradn</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Gradient calculation (natural error function is used)
# 
# INPUT PARAMETERS:
#     Network -   network initialized with one of the network creation funcs
#     X       -   input vector, length of array must be at least NIn
#     DesiredY-   desired outputs, length of array must be at least NOut
#     Grad    -   possibly preallocated array. If size of array is smaller
#                 than WCount, it will be reallocated. It is recommended to
#                 reuse previously allocated array to reduce allocation
#                 overhead.
# 
# OUTPUT PARAMETERS:
#     E       -   error function, sum-of-squares for regression networks,
#                 cross-entropy for classification networks.
#     Grad    -   gradient of E with respect to weights of network, array[WCount]
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   e, grad = xalglib.mlpgradn(network, x, desiredy, grad)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          x:          1D array/list of float
          desiredy:   1D array/list of float
          grad:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  e:          float
          grad:       1D array/list of float

</div></pre>
<a name='sub_mlpgradnbatch'></a><h3 class=pageheader><code>mlpgradnbatch</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Batch gradient calculation for a set of inputs/outputs
# (natural error function is used)
# 
# INPUT PARAMETERS:
#     Network -   network initialized with one of the network creation funcs
#     XY      -   set of inputs/outputs; one sample = one row;
#                 first NIn columns contain inputs,
#                 next NOut columns - desired outputs.
#     SSize   -   number of elements in XY
#     Grad    -   possibly preallocated array. If size of array is smaller
#                 than WCount, it will be reallocated. It is recommended to
#                 reuse previously allocated array to reduce allocation
#                 overhead.
# 
# OUTPUT PARAMETERS:
#     E       -   error function, sum-of-squares for regression networks,
#                 cross-entropy for classification networks.
#     Grad    -   gradient of E with respect to weights of network, array[WCount]
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   e, grad = xalglib.mlpgradnbatch(network, xy, ssize, grad)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          ssize:      int
          grad:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  e:          float
          grad:       1D array/list of float

</div></pre>
<a name='sub_mlphessianbatch'></a><h3 class=pageheader><code>mlphessianbatch</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Batch Hessian calculation using R-algorithm.
# Internal subroutine.
# 
#   -- ALGLIB --
#      Copyright 26.01.2008 by Bochkanov Sergey.
# 
#      Hessian calculation based on R-algorithm described in
#      &quot;Fast Exact Multiplication by the Hessian&quot;,
#      B. A. Pearlmutter,
#      Neural Computation, 1994.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   e, grad, h = xalglib.mlphessianbatch(network, xy, ssize, grad, h)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          ssize:      int
          grad:       1D array/list of float
          h:          2D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  e:          float
          grad:       1D array/list of float
          h:          2D array/list of float

</div></pre>
<a name='sub_mlphessiannbatch'></a><h3 class=pageheader><code>mlphessiannbatch</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Batch Hessian calculation (natural error function) using R-algorithm.
# Internal subroutine.
# 
#   -- ALGLIB --
#      Copyright 26.01.2008 by Bochkanov Sergey.
# 
#      Hessian calculation based on R-algorithm described in
#      &quot;Fast Exact Multiplication by the Hessian&quot;,
#      B. A. Pearlmutter,
#      Neural Computation, 1994.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   e, grad, h = xalglib.mlphessiannbatch(network, xy, ssize, grad, h)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          ssize:      int
          grad:       1D array/list of float
          h:          2D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  e:          float
          grad:       1D array/list of float
          h:          2D array/list of float

</div></pre>
<a name='sub_mlpinitpreprocessor'></a><h3 class=pageheader><code>mlpinitpreprocessor</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Internal subroutine.
# 
#   -- ALGLIB --
#      Copyright 30.03.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mlpinitpreprocessor(network, xy, ssize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          ssize:      int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mlpissoftmax'></a><h3 class=pageheader><code>mlpissoftmax</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Tells whether network is SOFTMAX-normalized (i.e. classifier) or not.
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpissoftmax(network)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_mlpprocess'></a><h3 class=pageheader><code>mlpprocess</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Procesing
# 
# INPUT PARAMETERS:
#     Network -   neural network
#     X       -   input vector,  array[0..NIn-1].
# 
# OUTPUT PARAMETERS:
#     Y       -   result. Regression estimate when solving regression  task,
#                 vector of posterior probabilities for classification task.
# 
# See also MLPProcessI
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.mlpprocess(network, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          x:          1D array/list of float
          y:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_mlpprocessi'></a><h3 class=pageheader><code>mlpprocessi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 'interactive'  variant  of  MLPProcess  for  languages  like  Python which
# support constructs like &quot;Y = MLPProcess(NN,X)&quot; and interactive mode of the
# interpreter
# 
# This function allocates new array on each call,  so  it  is  significantly
# slower than its 'non-interactive' counterpart, but it is  more  convenient
# when you call it from command line.
# 
#   -- ALGLIB --
#      Copyright 21.09.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.mlpprocessi(network, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_mlpproperties'></a><h3 class=pageheader><code>mlpproperties</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Returns information about initialized network: number of inputs, outputs,
# weights.
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   nin, nout, wcount = xalglib.mlpproperties(network)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  nin:        int
          nout:       int
          wcount:     int

</div></pre>
<a name='sub_mlprandomize'></a><h3 class=pageheader><code>mlprandomize</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Randomization of neural network weights
# 
#   -- ALGLIB --
#      Copyright 06.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mlprandomize(network)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mlprandomizefull'></a><h3 class=pageheader><code>mlprandomizefull</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Randomization of neural network weights and standartisator
# 
#   -- ALGLIB --
#      Copyright 10.03.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mlprandomizefull(network)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mlprelclserror'></a><h3 class=pageheader><code>mlprelclserror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Relative classification error on the test set.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network     -   neural network;
#     XY          -   training  set,  see  below  for  information  on   the
#                     training set format;
#     NPoints     -   points count.
# 
# RESULT:
# Percent   of incorrectly   classified  cases.  Works  both  for classifier
# networks and general purpose networks used as classifiers.
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# dataset format is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 25.12.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlprelclserror(network, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlprelclserrorsparse'></a><h3 class=pageheader><code>mlprelclserrorsparse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Relative classification error on the test set given by sparse matrix.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network     -   neural network;
#     XY          -   training  set,  see  below  for  information  on   the
#                     training set format. Sparse matrix must use CRS format
#                     for storage.
#     NPoints     -   points count, &gt;=0.
# 
# RESULT:
# Percent   of incorrectly   classified  cases.  Works  both  for classifier
# networks and general purpose networks used as classifiers.
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# dataset format is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 09.08.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlprelclserrorsparse(network, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         class xalglib.sparsematrix
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlprmserror'></a><h3 class=pageheader><code>mlprmserror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# RMS error on the test set given.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network     -   neural network;
#     XY          -   training  set,  see  below  for  information  on   the
#                     training set format;
#     NPoints     -   points count.
# 
# RESULT:
# Root mean  square error. Its meaning for regression task is obvious. As for
# classification  task,  RMS  error  means  error  when estimating  posterior
# probabilities.
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# dataset format is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 04.11.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlprmserror(network, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlprmserrorsparse'></a><h3 class=pageheader><code>mlprmserrorsparse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# RMS error on the test set given by sparse matrix.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     Network     -   neural network;
#     XY          -   training  set,  see  below  for  information  on   the
#                     training set format. This function checks  correctness
#                     of  the  dataset  (no  NANs/INFs,  class  numbers  are
#                     correct) and throws exception when  incorrect  dataset
#                     is passed.  Sparse  matrix  must  use  CRS  format for
#                     storage.
#     NPoints     -   points count, &gt;=0.
# 
# RESULT:
# Root mean  square error. Its meaning for regression task is obvious. As for
# classification  task,  RMS  error  means  error  when estimating  posterior
# probabilities.
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# dataset format is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 09.08.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlprmserrorsparse(network, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         class xalglib.sparsematrix
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlpsetinputscaling'></a><h3 class=pageheader><code>mlpsetinputscaling</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets offset/scaling coefficients for I-th input of the
# network.
# 
# INPUT PARAMETERS:
#     Network     -   network
#     I           -   input index
#     Mean        -   mean term
#     Sigma       -   sigma term (if zero, will be replaced by 1.0)
# 
# NTE: I-th input is passed through linear transformation
#     IN[i] = (IN[i]-Mean)/Sigma
# before feeding to the network. This function sets Mean and Sigma.
# 
#   -- ALGLIB --
#      Copyright 25.03.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mlpsetinputscaling(network, i, mean, sigma)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          i:          int
          mean:       float
          sigma:      float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mlpsetneuroninfo'></a><h3 class=pageheader><code>mlpsetneuroninfo</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function modifies information about Ith neuron of Kth layer
# 
# INPUT PARAMETERS:
#     Network     -   network
#     K           -   layer index
#     I           -   neuron index (within layer)
#     FKind       -   activation function type (used by MLPActivationFunction())
#                     this value must be zero for input neurons
#                     (you can not set activation function for input neurons)
#     Threshold   -   also called offset, bias
#                     this value must be zero for input neurons
#                     (you can not set threshold for input neurons)
# 
# NOTES:
# 1. this function throws exception if layer or neuron with given index do
#    not exists.
# 2. this function also throws exception when you try to set non-linear
#    activation function for input neurons (any kind of network) or for output
#    neurons of classifier network.
# 3. this function throws exception when you try to set non-zero threshold for
#    input neurons (any kind of network).
# 
#   -- ALGLIB --
#      Copyright 25.03.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mlpsetneuroninfo(network, k, i, fkind, threshold)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          k:          int
          i:          int
          fkind:      int
          threshold:  float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mlpsetoutputscaling'></a><h3 class=pageheader><code>mlpsetoutputscaling</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets offset/scaling coefficients for I-th output of the
# network.
# 
# INPUT PARAMETERS:
#     Network     -   network
#     I           -   input index
#     Mean        -   mean term
#     Sigma       -   sigma term (if zero, will be replaced by 1.0)
# 
# OUTPUT PARAMETERS:
# 
# NOTE: I-th output is passed through linear transformation
#     OUT[i] = OUT[i]*Sigma+Mean
# before returning it to user. This function sets Sigma/Mean. In case we
# have SOFTMAX-normalized network, you can not set (Sigma,Mean) to anything
# other than(0.0,1.0) - this function will throw exception.
# 
#   -- ALGLIB --
#      Copyright 25.03.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mlpsetoutputscaling(network, i, mean, sigma)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          i:          int
          mean:       float
          sigma:      float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mlpsetweight'></a><h3 class=pageheader><code>mlpsetweight</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function modifies information about connection from I0-th neuron of
# K0-th layer to I1-th neuron of K1-th layer.
# 
# INPUT PARAMETERS:
#     Network     -   network
#     K0          -   layer index
#     I0          -   neuron index (within layer)
#     K1          -   layer index
#     I1          -   neuron index (within layer)
#     W           -   connection weight (must be zero for non-existent
#                     connections)
# 
# This function:
# 1. throws exception if layer or neuron with given index do not exists.
# 2. throws exception if you try to set non-zero weight for non-existent
#    connection
# 
#   -- ALGLIB --
#      Copyright 25.03.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mlpsetweight(network, k0, i0, k1, i1, w)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          k0:         int
          i0:         int
          k1:         int
          i1:         int
          w:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_mlpe></a><h2 class=pageheader><code>mlpe</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_mlpeavgce' class=toc>mlpeavgce</a><br>
<a href='#sub_mlpeavgerror' class=toc>mlpeavgerror</a><br>
<a href='#sub_mlpeavgrelerror' class=toc>mlpeavgrelerror</a><br>
<a href='#sub_mlpecreate0' class=toc>mlpecreate0</a><br>
<a href='#sub_mlpecreate1' class=toc>mlpecreate1</a><br>
<a href='#sub_mlpecreate2' class=toc>mlpecreate2</a><br>
<a href='#sub_mlpecreateb0' class=toc>mlpecreateb0</a><br>
<a href='#sub_mlpecreateb1' class=toc>mlpecreateb1</a><br>
<a href='#sub_mlpecreateb2' class=toc>mlpecreateb2</a><br>
<a href='#sub_mlpecreatec0' class=toc>mlpecreatec0</a><br>
<a href='#sub_mlpecreatec1' class=toc>mlpecreatec1</a><br>
<a href='#sub_mlpecreatec2' class=toc>mlpecreatec2</a><br>
<a href='#sub_mlpecreatefromnetwork' class=toc>mlpecreatefromnetwork</a><br>
<a href='#sub_mlpecreater0' class=toc>mlpecreater0</a><br>
<a href='#sub_mlpecreater1' class=toc>mlpecreater1</a><br>
<a href='#sub_mlpecreater2' class=toc>mlpecreater2</a><br>
<a href='#sub_mlpeissoftmax' class=toc>mlpeissoftmax</a><br>
<a href='#sub_mlpeprocess' class=toc>mlpeprocess</a><br>
<a href='#sub_mlpeprocessi' class=toc>mlpeprocessi</a><br>
<a href='#sub_mlpeproperties' class=toc>mlpeproperties</a><br>
<a href='#sub_mlperandomize' class=toc>mlperandomize</a><br>
<a href='#sub_mlperelclserror' class=toc>mlperelclserror</a><br>
<a href='#sub_mlpermserror' class=toc>mlpermserror</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_mlpeavgce'></a><h3 class=pageheader><code>mlpeavgce</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average cross-entropy (in bits per element) on the test set
# 
# INPUT PARAMETERS:
#     Ensemble-   ensemble
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     CrossEntropy/(NPoints*LN(2)).
#     Zero if ensemble solves regression task.
# 
#   -- ALGLIB --
#      Copyright 17.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpeavgce(ensemble, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     ensemble:   class xalglib.mlpensemble
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> ensemble
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlpeavgerror'></a><h3 class=pageheader><code>mlpeavgerror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average error on the test set
# 
# INPUT PARAMETERS:
#     Ensemble-   ensemble
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     Its meaning for regression task is obvious. As for classification task
# it means average error when estimating posterior probabilities.
# 
#   -- ALGLIB --
#      Copyright 17.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpeavgerror(ensemble, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     ensemble:   class xalglib.mlpensemble
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> ensemble
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlpeavgrelerror'></a><h3 class=pageheader><code>mlpeavgrelerror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Average relative error on the test set
# 
# INPUT PARAMETERS:
#     Ensemble-   ensemble
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     Its meaning for regression task is obvious. As for classification task
# it means average relative error when estimating posterior probabilities.
# 
#   -- ALGLIB --
#      Copyright 17.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpeavgrelerror(ensemble, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     ensemble:   class xalglib.mlpensemble
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> ensemble
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlpecreate0'></a><h3 class=pageheader><code>mlpecreate0</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Like MLPCreate0, but for ensembles.
# 
#   -- ALGLIB --
#      Copyright 18.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   ensemble = xalglib.mlpecreate0(nin, nout, ensemblesize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nout:       int
          ensemblesize: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  ensemble:   class xalglib.mlpensemble

</div></pre>
<a name='sub_mlpecreate1'></a><h3 class=pageheader><code>mlpecreate1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Like MLPCreate1, but for ensembles.
# 
#   -- ALGLIB --
#      Copyright 18.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   ensemble = xalglib.mlpecreate1(nin, nhid, nout, ensemblesize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nhid:       int
          nout:       int
          ensemblesize: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  ensemble:   class xalglib.mlpensemble

</div></pre>
<a name='sub_mlpecreate2'></a><h3 class=pageheader><code>mlpecreate2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Like MLPCreate2, but for ensembles.
# 
#   -- ALGLIB --
#      Copyright 18.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   ensemble = xalglib.mlpecreate2(nin, nhid1, nhid2, nout, ensemblesize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nhid1:      int
          nhid2:      int
          nout:       int
          ensemblesize: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  ensemble:   class xalglib.mlpensemble

</div></pre>
<a name='sub_mlpecreateb0'></a><h3 class=pageheader><code>mlpecreateb0</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Like MLPCreateB0, but for ensembles.
# 
#   -- ALGLIB --
#      Copyright 18.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   ensemble = xalglib.mlpecreateb0(nin, nout, b, d, ensemblesize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nout:       int
          b:          float
          d:          float
          ensemblesize: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  ensemble:   class xalglib.mlpensemble

</div></pre>
<a name='sub_mlpecreateb1'></a><h3 class=pageheader><code>mlpecreateb1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Like MLPCreateB1, but for ensembles.
# 
#   -- ALGLIB --
#      Copyright 18.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   ensemble = xalglib.mlpecreateb1(nin, nhid, nout, b, d, ensemblesize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nhid:       int
          nout:       int
          b:          float
          d:          float
          ensemblesize: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  ensemble:   class xalglib.mlpensemble

</div></pre>
<a name='sub_mlpecreateb2'></a><h3 class=pageheader><code>mlpecreateb2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Like MLPCreateB2, but for ensembles.
# 
#   -- ALGLIB --
#      Copyright 18.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   ensemble = xalglib.mlpecreateb2(nin, nhid1, nhid2, nout, b, d, ensemblesize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nhid1:      int
          nhid2:      int
          nout:       int
          b:          float
          d:          float
          ensemblesize: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  ensemble:   class xalglib.mlpensemble

</div></pre>
<a name='sub_mlpecreatec0'></a><h3 class=pageheader><code>mlpecreatec0</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Like MLPCreateC0, but for ensembles.
# 
#   -- ALGLIB --
#      Copyright 18.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   ensemble = xalglib.mlpecreatec0(nin, nout, ensemblesize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nout:       int
          ensemblesize: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  ensemble:   class xalglib.mlpensemble

</div></pre>
<a name='sub_mlpecreatec1'></a><h3 class=pageheader><code>mlpecreatec1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Like MLPCreateC1, but for ensembles.
# 
#   -- ALGLIB --
#      Copyright 18.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   ensemble = xalglib.mlpecreatec1(nin, nhid, nout, ensemblesize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nhid:       int
          nout:       int
          ensemblesize: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  ensemble:   class xalglib.mlpensemble

</div></pre>
<a name='sub_mlpecreatec2'></a><h3 class=pageheader><code>mlpecreatec2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Like MLPCreateC2, but for ensembles.
# 
#   -- ALGLIB --
#      Copyright 18.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   ensemble = xalglib.mlpecreatec2(nin, nhid1, nhid2, nout, ensemblesize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nhid1:      int
          nhid2:      int
          nout:       int
          ensemblesize: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  ensemble:   class xalglib.mlpensemble

</div></pre>
<a name='sub_mlpecreatefromnetwork'></a><h3 class=pageheader><code>mlpecreatefromnetwork</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Creates ensemble from network. Only network geometry is copied.
# 
#   -- ALGLIB --
#      Copyright 17.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   ensemble = xalglib.mlpecreatefromnetwork(network, ensemblesize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          ensemblesize: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  ensemble:   class xalglib.mlpensemble

</div></pre>
<a name='sub_mlpecreater0'></a><h3 class=pageheader><code>mlpecreater0</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Like MLPCreateR0, but for ensembles.
# 
#   -- ALGLIB --
#      Copyright 18.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   ensemble = xalglib.mlpecreater0(nin, nout, a, b, ensemblesize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nout:       int
          a:          float
          b:          float
          ensemblesize: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  ensemble:   class xalglib.mlpensemble

</div></pre>
<a name='sub_mlpecreater1'></a><h3 class=pageheader><code>mlpecreater1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Like MLPCreateR1, but for ensembles.
# 
#   -- ALGLIB --
#      Copyright 18.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   ensemble = xalglib.mlpecreater1(nin, nhid, nout, a, b, ensemblesize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nhid:       int
          nout:       int
          a:          float
          b:          float
          ensemblesize: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  ensemble:   class xalglib.mlpensemble

</div></pre>
<a name='sub_mlpecreater2'></a><h3 class=pageheader><code>mlpecreater2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Like MLPCreateR2, but for ensembles.
# 
#   -- ALGLIB --
#      Copyright 18.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   ensemble = xalglib.mlpecreater2(nin, nhid1, nhid2, nout, a, b, ensemblesize)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nhid1:      int
          nhid2:      int
          nout:       int
          a:          float
          b:          float
          ensemblesize: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  ensemble:   class xalglib.mlpensemble

</div></pre>
<a name='sub_mlpeissoftmax'></a><h3 class=pageheader><code>mlpeissoftmax</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Return normalization type (whether ensemble is SOFTMAX-normalized or not).
# 
#   -- ALGLIB --
#      Copyright 17.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpeissoftmax(ensemble)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     ensemble:   class xalglib.mlpensemble
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_mlpeprocess'></a><h3 class=pageheader><code>mlpeprocess</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Procesing
# 
# INPUT PARAMETERS:
#     Ensemble-   neural networks ensemble
#     X       -   input vector,  array[0..NIn-1].
#     Y       -   (possibly) preallocated buffer; if size of Y is less than
#                 NOut, it will be reallocated. If it is large enough, it
#                 is NOT reallocated, so we can save some time on reallocation.
# 
# 
# OUTPUT PARAMETERS:
#     Y       -   result. Regression estimate when solving regression  task,
#                 vector of posterior probabilities for classification task.
# 
#   -- ALGLIB --
#      Copyright 17.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.mlpeprocess(ensemble, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     ensemble:   class xalglib.mlpensemble
          x:          1D array/list of float
          y:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> ensemble
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_mlpeprocessi'></a><h3 class=pageheader><code>mlpeprocessi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 'interactive'  variant  of  MLPEProcess  for  languages  like Python which
# support constructs like &quot;Y = MLPEProcess(LM,X)&quot; and interactive mode of the
# interpreter
# 
# This function allocates new array on each call,  so  it  is  significantly
# slower than its 'non-interactive' counterpart, but it is  more  convenient
# when you call it from command line.
# 
#   -- ALGLIB --
#      Copyright 17.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.mlpeprocessi(ensemble, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     ensemble:   class xalglib.mlpensemble
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> ensemble
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_mlpeproperties'></a><h3 class=pageheader><code>mlpeproperties</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Return ensemble properties (number of inputs and outputs).
# 
#   -- ALGLIB --
#      Copyright 17.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   nin, nout = xalglib.mlpeproperties(ensemble)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     ensemble:   class xalglib.mlpensemble
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  nin:        int
          nout:       int

</div></pre>
<a name='sub_mlperandomize'></a><h3 class=pageheader><code>mlperandomize</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Randomization of MLP ensemble
# 
#   -- ALGLIB --
#      Copyright 17.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mlperandomize(ensemble)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     ensemble:   class xalglib.mlpensemble
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> ensemble
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mlperelclserror'></a><h3 class=pageheader><code>mlperelclserror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Relative classification error on the test set
# 
# INPUT PARAMETERS:
#     Ensemble-   ensemble
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     percent of incorrectly classified cases.
#     Works both for classifier betwork and for regression networks which
# are used as classifiers.
# 
#   -- ALGLIB --
#      Copyright 17.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlperelclserror(ensemble, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     ensemble:   class xalglib.mlpensemble
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> ensemble
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_mlpermserror'></a><h3 class=pageheader><code>mlpermserror</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# RMS error on the test set
# 
# INPUT PARAMETERS:
#     Ensemble-   ensemble
#     XY      -   test set
#     NPoints -   test set size
# 
# RESULT:
#     root mean square error.
#     Its meaning for regression task is obvious. As for classification task
# RMS error means error when estimating posterior probabilities.
# 
#   -- ALGLIB --
#      Copyright 17.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpermserror(ensemble, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     ensemble:   class xalglib.mlpensemble
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> ensemble
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_mlptrain></a><h2 class=pageheader><code>mlptrain</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_mlpcontinuetraining' class=toc>mlpcontinuetraining</a><br>
<a href='#sub_mlpcreatetrainer' class=toc>mlpcreatetrainer</a><br>
<a href='#sub_mlpcreatetrainercls' class=toc>mlpcreatetrainercls</a><br>
<a href='#sub_mlpebagginglbfgs' class=toc>mlpebagginglbfgs</a><br>
<a href='#sub_mlpebagginglm' class=toc>mlpebagginglm</a><br>
<a href='#sub_mlpetraines' class=toc>mlpetraines</a><br>
<a href='#sub_mlpkfoldcv' class=toc>mlpkfoldcv</a><br>
<a href='#sub_mlpkfoldcvlbfgs' class=toc>mlpkfoldcvlbfgs</a><br>
<a href='#sub_mlpkfoldcvlm' class=toc>mlpkfoldcvlm</a><br>
<a href='#sub_mlpsetalgobatch' class=toc>mlpsetalgobatch</a><br>
<a href='#sub_mlpsetcond' class=toc>mlpsetcond</a><br>
<a href='#sub_mlpsetdataset' class=toc>mlpsetdataset</a><br>
<a href='#sub_mlpsetdecay' class=toc>mlpsetdecay</a><br>
<a href='#sub_mlpsetsparsedataset' class=toc>mlpsetsparsedataset</a><br>
<a href='#sub_mlpstarttraining' class=toc>mlpstarttraining</a><br>
<a href='#sub_mlptrainensemblees' class=toc>mlptrainensemblees</a><br>
<a href='#sub_mlptraines' class=toc>mlptraines</a><br>
<a href='#sub_mlptrainlbfgs' class=toc>mlptrainlbfgs</a><br>
<a href='#sub_mlptrainlm' class=toc>mlptrainlm</a><br>
<a href='#sub_mlptrainnetwork' class=toc>mlptrainnetwork</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_mlpcontinuetraining'></a><h3 class=pageheader><code>mlpcontinuetraining</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# IMPORTANT: this is an &quot;expert&quot; version of the MLPTrain() function.  We  do
#            not recommend you to use it unless you are pretty sure that you
#            need ability to monitor training progress.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# This function performs step-by-step training of the neural  network.  Here
# &quot;step-by-step&quot; means that training starts  with  MLPStartTraining()  call,
# and then user subsequently calls MLPContinueTraining() to perform one more
# iteration of the training.
# 
# This  function  performs  one  more  iteration of the training and returns
# either True (training continues) or False (training stopped). In case True
# was returned, Network weights are updated according to the  current  state
# of the optimization progress. In case False was  returned,  no  additional
# updates is performed (previous update of  the  network weights moved us to
# the final point, and no additional updates is needed).
# 
# EXAMPLE:
#     &gt;
#     &gt; [initialize network and trainer object]
#     &gt;
#     &gt; MLPStartTraining(Trainer, Network, True)
#     &gt; while MLPContinueTraining(Trainer, Network) do
#     &gt;     [visualize training progress]
#     &gt;
# 
# INPUT PARAMETERS:
#     S           -   trainer object
#     Network     -   neural  network  structure,  which  is  used to  store
#                     current state of the training process.
# 
# OUTPUT PARAMETERS:
#     Network     -   weights of the neural network  are  rewritten  by  the
#                     current approximation.
# 
# NOTE: this method uses sum-of-squares error function for training.
# 
# NOTE: it is expected that trainer object settings are NOT  changed  during
#       step-by-step training, i.e. no  one  changes  stopping  criteria  or
#       training set during training. It is possible and there is no defense
#       against  such  actions,  but  algorithm  behavior  in  such cases is
#       undefined and can be unpredictable.
# 
# NOTE: It  is  expected that Network is the same one which  was  passed  to
#       MLPStartTraining() function.  However,  THIS  function  checks  only
#       following:
#       * that number of network inputs is consistent with trainer object
#         settings
#       * that number of network outputs/classes is consistent with  trainer
#         object settings
#       * that number of network weights is the same as number of weights in
#         the network passed to MLPStartTraining() function
#       Exception is thrown when these conditions are violated.
# 
#       It is also expected that you do not change state of the  network  on
#       your own - the only party who has right to change network during its
#       training is a trainer object. Any attempt to interfere with  trainer
#       may lead to unpredictable results.
# 
# 
#   -- ALGLIB --
#      Copyright 23.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.mlpcontinuetraining(s, network)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mlptrainer
          network:    class xalglib.multilayerperceptron
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s, network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_mlpcreatetrainer'></a><h3 class=pageheader><code>mlpcreatetrainer</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Creation of the network trainer object for regression networks
# 
# INPUT PARAMETERS:
#     NIn         -   number of inputs, NIn&gt;=1
#     NOut        -   number of outputs, NOut&gt;=1
# 
# OUTPUT PARAMETERS:
#     S           -   neural network trainer object.
#                     This structure can be used to train any regression
#                     network with NIn inputs and NOut outputs.
# 
#   -- ALGLIB --
#      Copyright 23.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.mlpcreatetrainer(nin, nout)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nout:       int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.mlptrainer

</div></pre>
<a name='sub_mlpcreatetrainercls'></a><h3 class=pageheader><code>mlpcreatetrainercls</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Creation of the network trainer object for classification networks
# 
# INPUT PARAMETERS:
#     NIn         -   number of inputs, NIn&gt;=1
#     NClasses    -   number of classes, NClasses&gt;=2
# 
# OUTPUT PARAMETERS:
#     S           -   neural network trainer object.
#                     This structure can be used to train any classification
#                     network with NIn inputs and NOut outputs.
# 
#   -- ALGLIB --
#      Copyright 23.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.mlpcreatetrainercls(nin, nclasses)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nin:        int
          nclasses:   int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.mlptrainer

</div></pre>
<a name='sub_mlpebagginglbfgs'></a><h3 class=pageheader><code>mlpebagginglbfgs</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Training neural networks ensemble using  bootstrap  aggregating (bagging).
# L-BFGS algorithm is used as base training method.
# 
# INPUT PARAMETERS:
#     Ensemble    -   model with initialized geometry
#     XY          -   training set
#     NPoints     -   training set size
#     Decay       -   weight decay coefficient, &gt;=0.001
#     Restarts    -   restarts, &gt;0.
#     WStep       -   stopping criterion, same as in MLPTrainLBFGS
#     MaxIts      -   stopping criterion, same as in MLPTrainLBFGS
# 
# OUTPUT PARAMETERS:
#     Ensemble    -   trained model
#     Info        -   return code:
#                     * -8, if both WStep=0 and MaxIts=0
#                     * -2, if there is a point with class number
#                           outside of [0..NClasses-1].
#                     * -1, if incorrect parameters was passed
#                           (NPoints&lt;0, Restarts&lt;1).
#                     *  2, if task has been solved.
#     Rep         -   training report.
#     OOBErrors   -   out-of-bag generalization error estimate
# 
#   -- ALGLIB --
#      Copyright 17.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, rep, ooberrors = xalglib.mlpebagginglbfgs(ensemble, xy, npoints, decay, restarts, wstep, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     ensemble:   class xalglib.mlpensemble
          xy:         2D array/list of float
          npoints:    int
          decay:      float
          restarts:   int
          wstep:      float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> ensemble
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          rep:        class xalglib.mlpreport
          ooberrors:  class xalglib.mlpcvreport

</div></pre>
<a name='sub_mlpebagginglm'></a><h3 class=pageheader><code>mlpebagginglm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Training neural networks ensemble using  bootstrap  aggregating (bagging).
# Modified Levenberg-Marquardt algorithm is used as base training method.
# 
# INPUT PARAMETERS:
#     Ensemble    -   model with initialized geometry
#     XY          -   training set
#     NPoints     -   training set size
#     Decay       -   weight decay coefficient, &gt;=0.001
#     Restarts    -   restarts, &gt;0.
# 
# OUTPUT PARAMETERS:
#     Ensemble    -   trained model
#     Info        -   return code:
#                     * -2, if there is a point with class number
#                           outside of [0..NClasses-1].
#                     * -1, if incorrect parameters was passed
#                           (NPoints&lt;0, Restarts&lt;1).
#                     *  2, if task has been solved.
#     Rep         -   training report.
#     OOBErrors   -   out-of-bag generalization error estimate
# 
#   -- ALGLIB --
#      Copyright 17.02.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, rep, ooberrors = xalglib.mlpebagginglm(ensemble, xy, npoints, decay, restarts)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     ensemble:   class xalglib.mlpensemble
          xy:         2D array/list of float
          npoints:    int
          decay:      float
          restarts:   int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> ensemble
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          rep:        class xalglib.mlpreport
          ooberrors:  class xalglib.mlpcvreport

</div></pre>
<a name='sub_mlpetraines'></a><h3 class=pageheader><code>mlpetraines</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Training neural networks ensemble using early stopping.
# 
# INPUT PARAMETERS:
#     Ensemble    -   model with initialized geometry
#     XY          -   training set
#     NPoints     -   training set size
#     Decay       -   weight decay coefficient, &gt;=0.001
#     Restarts    -   restarts, &gt;0.
# 
# OUTPUT PARAMETERS:
#     Ensemble    -   trained model
#     Info        -   return code:
#                     * -2, if there is a point with class number
#                           outside of [0..NClasses-1].
#                     * -1, if incorrect parameters was passed
#                           (NPoints&lt;0, Restarts&lt;1).
#                     *  6, if task has been solved.
#     Rep         -   training report.
#     OOBErrors   -   out-of-bag generalization error estimate
# 
#   -- ALGLIB --
#      Copyright 10.03.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, rep = xalglib.mlpetraines(ensemble, xy, npoints, decay, restarts)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     ensemble:   class xalglib.mlpensemble
          xy:         2D array/list of float
          npoints:    int
          decay:      float
          restarts:   int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> ensemble
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          rep:        class xalglib.mlpreport

</div></pre>
<a name='sub_mlpkfoldcv'></a><h3 class=pageheader><code>mlpkfoldcv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function estimates generalization error using cross-validation on the
# current dataset with current training settings.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     S           -   trainer object
#     Network     -   neural network. It must have same number of inputs and
#                     output/classes as was specified during creation of the
#                     trainer object. Network is not changed  during  cross-
#                     validation and is not trained - it  is  used  only  as
#                     representative of its architecture. I.e., we  estimate
#                     generalization properties of  ARCHITECTURE,  not  some
#                     specific network.
#     NRestarts   -   number of restarts, &gt;=0:
#                     * NRestarts&gt;0  means  that  for  each cross-validation
#                       round   specified  number   of  random  restarts  is
#                       performed,  with  best  network  being  chosen after
#                       training.
#                     * NRestarts=0 is same as NRestarts=1
#     FoldsCount  -   number of folds in k-fold cross-validation:
#                     * 2&lt;=FoldsCount&lt;=size of dataset
#                     * recommended value: 10.
#                     * values larger than dataset size will be silently
#                       truncated down to dataset size
# 
# OUTPUT PARAMETERS:
#     Rep         -   structure which contains cross-validation estimates:
#                     * Rep.RelCLSError - fraction of misclassified cases.
#                     * Rep.AvgCE - acerage cross-entropy
#                     * Rep.RMSError - root-mean-square error
#                     * Rep.AvgError - average error
#                     * Rep.AvgRelError - average relative error
# 
# NOTE: when no dataset was specified with MLPSetDataset/SetSparseDataset(),
#       or subset with only one point  was  given,  zeros  are  returned  as
#       estimates.
# 
# NOTE: this method performs FoldsCount cross-validation  rounds,  each  one
#       with NRestarts random starts.  Thus,  FoldsCount*NRestarts  networks
#       are trained in total.
# 
# NOTE: Rep.RelCLSError/Rep.AvgCE are zero on regression problems.
# 
# NOTE: on classification problems Rep.RMSError/Rep.AvgError/Rep.AvgRelError
#       contain errors in prediction of posterior probabilities.
# 
#   -- ALGLIB --
#      Copyright 23.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.mlpkfoldcv(s, network, nrestarts, foldscount)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mlptrainer
          network:    class xalglib.multilayerperceptron
          nrestarts:  int
          foldscount: int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.mlpreport

</div></pre>
<a name='sub_mlpkfoldcvlbfgs'></a><h3 class=pageheader><code>mlpkfoldcvlbfgs</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Cross-validation estimate of generalization error.
# 
# Base algorithm - L-BFGS.
# 
# INPUT PARAMETERS:
#     Network     -   neural network with initialized geometry.   Network is
#                     not changed during cross-validation -  it is used only
#                     as a representative of its architecture.
#     XY          -   training set.
#     SSize       -   training set size
#     Decay       -   weight  decay, same as in MLPTrainLBFGS
#     Restarts    -   number of restarts, &gt;0.
#                     restarts are counted for each partition separately, so
#                     total number of restarts will be Restarts*FoldsCount.
#     WStep       -   stopping criterion, same as in MLPTrainLBFGS
#     MaxIts      -   stopping criterion, same as in MLPTrainLBFGS
#     FoldsCount  -   number of folds in k-fold cross-validation,
#                     2&lt;=FoldsCount&lt;=SSize.
#                     recommended value: 10.
# 
# OUTPUT PARAMETERS:
#     Info        -   return code, same as in MLPTrainLBFGS
#     Rep         -   report, same as in MLPTrainLM/MLPTrainLBFGS
#     CVRep       -   generalization error estimates
# 
#   -- ALGLIB --
#      Copyright 09.12.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, rep, cvrep = xalglib.mlpkfoldcvlbfgs(network, xy, npoints, decay, restarts, wstep, maxits, foldscount)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          npoints:    int
          decay:      float
          restarts:   int
          wstep:      float
          maxits:     int
          foldscount: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          rep:        class xalglib.mlpreport
          cvrep:      class xalglib.mlpcvreport

</div></pre>
<a name='sub_mlpkfoldcvlm'></a><h3 class=pageheader><code>mlpkfoldcvlm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Cross-validation estimate of generalization error.
# 
# Base algorithm - Levenberg-Marquardt.
# 
# INPUT PARAMETERS:
#     Network     -   neural network with initialized geometry.   Network is
#                     not changed during cross-validation -  it is used only
#                     as a representative of its architecture.
#     XY          -   training set.
#     SSize       -   training set size
#     Decay       -   weight  decay, same as in MLPTrainLBFGS
#     Restarts    -   number of restarts, &gt;0.
#                     restarts are counted for each partition separately, so
#                     total number of restarts will be Restarts*FoldsCount.
#     FoldsCount  -   number of folds in k-fold cross-validation,
#                     2&lt;=FoldsCount&lt;=SSize.
#                     recommended value: 10.
# 
# OUTPUT PARAMETERS:
#     Info        -   return code, same as in MLPTrainLBFGS
#     Rep         -   report, same as in MLPTrainLM/MLPTrainLBFGS
#     CVRep       -   generalization error estimates
# 
#   -- ALGLIB --
#      Copyright 09.12.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, rep, cvrep = xalglib.mlpkfoldcvlm(network, xy, npoints, decay, restarts, foldscount)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          npoints:    int
          decay:      float
          restarts:   int
          foldscount: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          rep:        class xalglib.mlpreport
          cvrep:      class xalglib.mlpcvreport

</div></pre>
<a name='sub_mlpsetalgobatch'></a><h3 class=pageheader><code>mlpsetalgobatch</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets training algorithm: batch training using L-BFGS will be
# used.
# 
# This algorithm:
# * the most robust for small-scale problems, but may be too slow for  large
#   scale ones.
# * perfoms full pass through the dataset before performing step
# * uses conditions specified by MLPSetCond() for stopping
# * is default one used by trainer object
# 
# INPUT PARAMETERS:
#     S           -   trainer object
# 
#   -- ALGLIB --
#      Copyright 23.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mlpsetalgobatch(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mlptrainer
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mlpsetcond'></a><h3 class=pageheader><code>mlpsetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping criteria for the optimizer.
# 
# INPUT PARAMETERS:
#     S           -   trainer object
#     WStep       -   stopping criterion. Algorithm stops if  step  size  is
#                     less than WStep. Recommended value - 0.01.  Zero  step
#                     size means stopping after MaxIts iterations.
#                     WStep&gt;=0.
#     MaxIts      -   stopping   criterion.  Algorithm  stops  after  MaxIts
#                     epochs (full passes over entire dataset).  Zero MaxIts
#                     means stopping when step is sufficiently small.
#                     MaxIts&gt;=0.
# 
# NOTE: by default, WStep=0.005 and MaxIts=0 are used. These values are also
#       used when MLPSetCond() is called with WStep=0 and MaxIts=0.
# 
# NOTE: these stopping criteria are used for all kinds of neural training  -
#       from &quot;conventional&quot; networks to early stopping ensembles. When  used
#       for &quot;conventional&quot; networks, they are  used  as  the  only  stopping
#       criteria. When combined with early stopping, they used as ADDITIONAL
#       stopping criteria which can terminate early stopping algorithm.
# 
#   -- ALGLIB --
#      Copyright 23.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mlpsetcond(s, wstep, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mlptrainer
          wstep:      float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mlpsetdataset'></a><h3 class=pageheader><code>mlpsetdataset</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets &quot;current dataset&quot; of the trainer object to  one  passed
# by user.
# 
# INPUT PARAMETERS:
#     S           -   trainer object
#     XY          -   training  set,  see  below  for  information  on   the
#                     training set format. This function checks  correctness
#                     of  the  dataset  (no  NANs/INFs,  class  numbers  are
#                     correct) and throws exception when  incorrect  dataset
#                     is passed.
#     NPoints     -   points count, &gt;=0.
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# datasetformat is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 23.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mlpsetdataset(s, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mlptrainer
          xy:         2D array/list of float
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mlpsetdecay'></a><h3 class=pageheader><code>mlpsetdecay</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets weight decay coefficient which is used for training.
# 
# INPUT PARAMETERS:
#     S           -   trainer object
#     Decay       -   weight  decay  coefficient,  &gt;=0.  Weight  decay  term
#                     'Decay*||Weights||^2' is added to error  function.  If
#                     you don't know what Decay to choose, use 1.0E-3.
#                     Weight decay can be set to zero,  in this case network
#                     is trained without weight decay.
# 
# NOTE: by default network uses some small nonzero value for weight decay.
# 
#   -- ALGLIB --
#      Copyright 23.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mlpsetdecay(s, decay)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mlptrainer
          decay:      float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mlpsetsparsedataset'></a><h3 class=pageheader><code>mlpsetsparsedataset</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets &quot;current dataset&quot; of the trainer object to  one  passed
# by user (sparse matrix is used to store dataset).
# 
# INPUT PARAMETERS:
#     S           -   trainer object
#     XY          -   training  set,  see  below  for  information  on   the
#                     training set format. This function checks  correctness
#                     of  the  dataset  (no  NANs/INFs,  class  numbers  are
#                     correct) and throws exception when  incorrect  dataset
#                     is passed. Any  sparse  storage  format  can be  used:
#                     Hash-table, CRS...
#     NPoints     -   points count, &gt;=0
# 
# DATASET FORMAT:
# 
# This  function  uses  two  different  dataset formats - one for regression
# networks, another one for classification networks.
# 
# For regression networks with NIn inputs and NOut outputs following dataset
# format is used:
# * dataset is given by NPoints*(NIn+NOut) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, next NOut columns are outputs
# 
# For classification networks with NIn inputs and NClasses clases  following
# datasetformat is used:
# * dataset is given by NPoints*(NIn+1) matrix
# * each row corresponds to one example
# * first NIn columns are inputs, last column stores class number (from 0 to
#   NClasses-1).
# 
#   -- ALGLIB --
#      Copyright 23.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mlpsetsparsedataset(s, xy, npoints)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mlptrainer
          xy:         class xalglib.sparsematrix
          npoints:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mlpstarttraining'></a><h3 class=pageheader><code>mlpstarttraining</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# IMPORTANT: this is an &quot;expert&quot; version of the MLPTrain() function.  We  do
#            not recommend you to use it unless you are pretty sure that you
#            need ability to monitor training progress.
# 
# This function performs step-by-step training of the neural  network.  Here
# &quot;step-by-step&quot; means that training  starts  with  MLPStartTraining() call,
# and then user subsequently calls MLPContinueTraining() to perform one more
# iteration of the training.
# 
# After call to this function trainer object remembers network and  is ready
# to  train  it.  However,  no  training  is  performed  until first call to
# MLPContinueTraining() function. Subsequent calls  to MLPContinueTraining()
# will advance training progress one iteration further.
# 
# EXAMPLE:
#     &gt;
#     &gt; ...initialize network and trainer object....
#     &gt;
#     &gt; MLPStartTraining(Trainer, Network, True)
#     &gt; while MLPContinueTraining(Trainer, Network) do
#     &gt;     ...visualize training progress...
#     &gt;
# 
# INPUT PARAMETERS:
#     S           -   trainer object
#     Network     -   neural network. It must have same number of inputs and
#                     output/classes as was specified during creation of the
#                     trainer object.
#     RandomStart -   randomize network before training or not:
#                     * True  means  that  network  is  randomized  and  its
#                       initial state (one which was passed to  the  trainer
#                       object) is lost.
#                     * False  means  that  training  is  started  from  the
#                       current state of the network
# 
# OUTPUT PARAMETERS:
#     Network     -   neural network which is ready to training (weights are
#                     initialized, preprocessor is initialized using current
#                     training set)
# 
# NOTE: this method uses sum-of-squares error function for training.
# 
# NOTE: it is expected that trainer object settings are NOT  changed  during
#       step-by-step training, i.e. no  one  changes  stopping  criteria  or
#       training set during training. It is possible and there is no defense
#       against  such  actions,  but  algorithm  behavior  in  such cases is
#       undefined and can be unpredictable.
# 
#   -- ALGLIB --
#      Copyright 23.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.mlpstarttraining(s, network, randomstart)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mlptrainer
          network:    class xalglib.multilayerperceptron
          randomstart: bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s, network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_mlptrainensemblees'></a><h3 class=pageheader><code>mlptrainensemblees</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function trains neural network ensemble passed to this function using
# current dataset and early stopping training algorithm. Each early stopping
# round performs NRestarts  random  restarts  (thus,  EnsembleSize*NRestarts
# training rounds is performed in total).
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     S           -   trainer object;
#     Ensemble    -   neural network ensemble. It must have same  number  of
#                     inputs and outputs/classes  as  was  specified  during
#                     creation of the trainer object.
#     NRestarts   -   number of restarts, &gt;=0:
#                     * NRestarts&gt;0 means that specified  number  of  random
#                       restarts are performed during each ES round;
#                     * NRestarts=0 is silently replaced by 1.
# 
# OUTPUT PARAMETERS:
#     Ensemble    -   trained ensemble;
#     Rep         -   it contains all type of errors.
# 
# NOTE: this training method uses BOTH early stopping and weight decay!  So,
#       you should select weight decay before starting training just as  you
#       select it before training &quot;conventional&quot; networks.
# 
# NOTE: when no dataset was specified with MLPSetDataset/SetSparseDataset(),
#       or  single-point  dataset  was  passed,  ensemble  is filled by zero
#       values.
# 
# NOTE: this method uses sum-of-squares error function for training.
# 
#   -- ALGLIB --
#      Copyright 22.08.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.mlptrainensemblees(s, ensemble, nrestarts)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mlptrainer
          ensemble:   class xalglib.mlpensemble
          nrestarts:  int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s, ensemble
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.mlpreport

</div></pre>
<a name='sub_mlptraines'></a><h3 class=pageheader><code>mlptraines</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Neural network training using early stopping (base algorithm - L-BFGS with
# regularization).
# 
# INPUT PARAMETERS:
#     Network     -   neural network with initialized geometry
#     TrnXY       -   training set
#     TrnSize     -   training set size, TrnSize&gt;0
#     ValXY       -   validation set
#     ValSize     -   validation set size, ValSize&gt;0
#     Decay       -   weight decay constant, &gt;=0.001
#                     Decay term 'Decay*||Weights||^2' is added to error
#                     function.
#                     If you don't know what Decay to choose, use 0.001.
#     Restarts    -   number of restarts, either:
#                     * strictly positive number - algorithm make specified
#                       number of restarts from random position.
#                     * -1, in which case algorithm makes exactly one run
#                       from the initial state of the network (no randomization).
#                     If you don't know what Restarts to choose, choose one
#                     one the following:
#                     * -1 (deterministic start)
#                     * +1 (one random restart)
#                     * +5 (moderate amount of random restarts)
# 
# OUTPUT PARAMETERS:
#     Network     -   trained neural network.
#     Info        -   return code:
#                     * -2, if there is a point with class number
#                           outside of [0..NOut-1].
#                     * -1, if wrong parameters specified
#                           (NPoints&lt;0, Restarts&lt;1, ...).
#                     *  2, task has been solved, stopping  criterion  met -
#                           sufficiently small step size.  Not expected  (we
#                           use  EARLY  stopping)  but  possible  and not an
#                           error.
#                     *  6, task has been solved, stopping  criterion  met -
#                           increasing of validation set error.
#     Rep         -   training report
# 
# NOTE:
# 
# Algorithm stops if validation set error increases for  a  long  enough  or
# step size is small enought  (there  are  task  where  validation  set  may
# decrease for eternity). In any case solution returned corresponds  to  the
# minimum of validation set error.
# 
#   -- ALGLIB --
#      Copyright 10.03.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, rep = xalglib.mlptraines(network, trnxy, trnsize, valxy, valsize, decay, restarts)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          trnxy:      2D array/list of float
          trnsize:    int
          valxy:      2D array/list of float
          valsize:    int
          decay:      float
          restarts:   int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          rep:        class xalglib.mlpreport

</div></pre>
<a name='sub_mlptrainlbfgs'></a><h3 class=pageheader><code>mlptrainlbfgs</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Neural  network  training  using  L-BFGS  algorithm  with  regularization.
# Subroutine  trains  neural  network  with  restarts from random positions.
# Algorithm  is  well  suited  for  problems  of  any dimensionality (memory
# requirements and step complexity are linear by weights number).
# 
# INPUT PARAMETERS:
#     Network     -   neural network with initialized geometry
#     XY          -   training set
#     NPoints     -   training set size
#     Decay       -   weight decay constant, &gt;=0.001
#                     Decay term 'Decay*||Weights||^2' is added to error
#                     function.
#                     If you don't know what Decay to choose, use 0.001.
#     Restarts    -   number of restarts from random position, &gt;0.
#                     If you don't know what Restarts to choose, use 2.
#     WStep       -   stopping criterion. Algorithm stops if  step  size  is
#                     less than WStep. Recommended value - 0.01.  Zero  step
#                     size means stopping after MaxIts iterations.
#     MaxIts      -   stopping   criterion.  Algorithm  stops  after  MaxIts
#                     iterations (NOT gradient  calculations).  Zero  MaxIts
#                     means stopping when step is sufficiently small.
# 
# OUTPUT PARAMETERS:
#     Network     -   trained neural network.
#     Info        -   return code:
#                     * -8, if both WStep=0 and MaxIts=0
#                     * -2, if there is a point with class number
#                           outside of [0..NOut-1].
#                     * -1, if wrong parameters specified
#                           (NPoints&lt;0, Restarts&lt;1).
#                     *  2, if task has been solved.
#     Rep         -   training report
# 
#   -- ALGLIB --
#      Copyright 09.12.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, rep = xalglib.mlptrainlbfgs(network, xy, npoints, decay, restarts, wstep, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          npoints:    int
          decay:      float
          restarts:   int
          wstep:      float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          rep:        class xalglib.mlpreport

</div></pre>
<a name='sub_mlptrainlm'></a><h3 class=pageheader><code>mlptrainlm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Neural network training  using  modified  Levenberg-Marquardt  with  exact
# Hessian calculation and regularization. Subroutine trains  neural  network
# with restarts from random positions. Algorithm is well  suited  for  small
# and medium scale problems (hundreds of weights).
# 
# INPUT PARAMETERS:
#     Network     -   neural network with initialized geometry
#     XY          -   training set
#     NPoints     -   training set size
#     Decay       -   weight decay constant, &gt;=0.001
#                     Decay term 'Decay*||Weights||^2' is added to error
#                     function.
#                     If you don't know what Decay to choose, use 0.001.
#     Restarts    -   number of restarts from random position, &gt;0.
#                     If you don't know what Restarts to choose, use 2.
# 
# OUTPUT PARAMETERS:
#     Network     -   trained neural network.
#     Info        -   return code:
#                     * -9, if internal matrix inverse subroutine failed
#                     * -2, if there is a point with class number
#                           outside of [0..NOut-1].
#                     * -1, if wrong parameters specified
#                           (NPoints&lt;0, Restarts&lt;1).
#                     *  2, if task has been solved.
#     Rep         -   training report
# 
#   -- ALGLIB --
#      Copyright 10.03.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   info, rep = xalglib.mlptrainlm(network, xy, npoints, decay, restarts)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     network:    class xalglib.multilayerperceptron
          xy:         2D array/list of float
          npoints:    int
          decay:      float
          restarts:   int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  info:       int
          rep:        class xalglib.mlpreport

</div></pre>
<a name='sub_mlptrainnetwork'></a><h3 class=pageheader><code>mlptrainnetwork</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function trains neural network passed to this function, using current
# dataset (one which was passed to MLPSetDataset() or MLPSetSparseDataset())
# and current training settings. Training  from  NRestarts  random  starting
# positions is performed, best network is chosen.
# 
# Training is performed using current training algorithm.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     S           -   trainer object
#     Network     -   neural network. It must have same number of inputs and
#                     output/classes as was specified during creation of the
#                     trainer object.
#     NRestarts   -   number of restarts, &gt;=0:
#                     * NRestarts&gt;0 means that specified  number  of  random
#                       restarts are performed, best network is chosen after
#                       training
#                     * NRestarts=0 means that current state of the  network
#                       is used for training.
# 
# OUTPUT PARAMETERS:
#     Network     -   trained network
# 
# NOTE: when no dataset was specified with MLPSetDataset/SetSparseDataset(),
#       network  is  filled  by zero  values.  Same  behavior  for functions
#       MLPStartTraining and MLPContinueTraining.
# 
# NOTE: this method uses sum-of-squares error function for training.
# 
#   -- ALGLIB --
#      Copyright 23.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.mlptrainnetwork(s, network, nrestarts)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.mlptrainer
          network:    class xalglib.multilayerperceptron
          nrestarts:  int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s, network
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.mlpreport

</div></pre>
<a name=unit_nearestneighbor></a><h2 class=pageheader><code>nearestneighbor</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_kdtreebuild' class=toc>kdtreebuild</a><br>
<a href='#sub_kdtreebuildtagged' class=toc>kdtreebuildtagged</a><br>
<a href='#sub_kdtreecreaterequestbuffer' class=toc>kdtreecreaterequestbuffer</a><br>
<a href='#sub_kdtreequeryaknn' class=toc>kdtreequeryaknn</a><br>
<a href='#sub_kdtreequerybox' class=toc>kdtreequerybox</a><br>
<a href='#sub_kdtreequeryknn' class=toc>kdtreequeryknn</a><br>
<a href='#sub_kdtreequeryresultsdistances' class=toc>kdtreequeryresultsdistances</a><br>
<a href='#sub_kdtreequeryresultsdistancesi' class=toc>kdtreequeryresultsdistancesi</a><br>
<a href='#sub_kdtreequeryresultstags' class=toc>kdtreequeryresultstags</a><br>
<a href='#sub_kdtreequeryresultstagsi' class=toc>kdtreequeryresultstagsi</a><br>
<a href='#sub_kdtreequeryresultsx' class=toc>kdtreequeryresultsx</a><br>
<a href='#sub_kdtreequeryresultsxi' class=toc>kdtreequeryresultsxi</a><br>
<a href='#sub_kdtreequeryresultsxy' class=toc>kdtreequeryresultsxy</a><br>
<a href='#sub_kdtreequeryresultsxyi' class=toc>kdtreequeryresultsxyi</a><br>
<a href='#sub_kdtreequeryrnn' class=toc>kdtreequeryrnn</a><br>
<a href='#sub_kdtreequeryrnnu' class=toc>kdtreequeryrnnu</a><br>
<a href='#sub_kdtreetsqueryaknn' class=toc>kdtreetsqueryaknn</a><br>
<a href='#sub_kdtreetsquerybox' class=toc>kdtreetsquerybox</a><br>
<a href='#sub_kdtreetsqueryknn' class=toc>kdtreetsqueryknn</a><br>
<a href='#sub_kdtreetsqueryresultsdistances' class=toc>kdtreetsqueryresultsdistances</a><br>
<a href='#sub_kdtreetsqueryresultstags' class=toc>kdtreetsqueryresultstags</a><br>
<a href='#sub_kdtreetsqueryresultsx' class=toc>kdtreetsqueryresultsx</a><br>
<a href='#sub_kdtreetsqueryresultsxy' class=toc>kdtreetsqueryresultsxy</a><br>
<a href='#sub_kdtreetsqueryrnn' class=toc>kdtreetsqueryrnn</a><br>
<a href='#sub_kdtreetsqueryrnnu' class=toc>kdtreetsqueryrnnu</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_kdtreebuild'></a><h3 class=pageheader><code>kdtreebuild</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# KD-tree creation
# 
# This subroutine creates KD-tree from set of X-values and optional Y-values
# 
# INPUT PARAMETERS
#     XY      -   dataset, array[0..N-1,0..NX+NY-1].
#                 one row corresponds to one point.
#                 first NX columns contain X-values, next NY (NY may be zero)
#                 columns may contain associated Y-values
#     N       -   number of points, N&gt;=0.
#     NX      -   space dimension, NX&gt;=1.
#     NY      -   number of optional Y-values, NY&gt;=0.
#     NormType-   norm type:
#                 * 0 denotes infinity-norm
#                 * 1 denotes 1-norm
#                 * 2 denotes 2-norm (Euclidean norm)
# 
# OUTPUT PARAMETERS
#     KDT     -   KD-tree
# 
# 
# NOTES
# 
# 1. KD-tree  creation  have O(N*logN) complexity and O(N*(2*NX+NY))  memory
#    requirements.
# 2. Although KD-trees may be used with any combination of N  and  NX,  they
#    are more efficient than brute-force search only when N &gt;&gt; 4^NX. So they
#    are most useful in low-dimensional tasks (NX=2, NX=3). NX=1  is another
#    inefficient case, because  simple  binary  search  (without  additional
#    structures) is much more efficient in such tasks than KD-trees.
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   kdt = xalglib.kdtreebuild(xy, n, nx, ny, normtype)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   kdt = xalglib.kdtreebuild(xy, nx, ny, normtype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          n:          int
          nx:         int
          ny:         int
          normtype:   int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  kdt:        class xalglib.kdtree

</div></pre>
<a name='sub_kdtreebuildtagged'></a><h3 class=pageheader><code>kdtreebuildtagged</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# KD-tree creation
# 
# This  subroutine  creates  KD-tree  from set of X-values, integer tags and
# optional Y-values
# 
# INPUT PARAMETERS
#     XY      -   dataset, array[0..N-1,0..NX+NY-1].
#                 one row corresponds to one point.
#                 first NX columns contain X-values, next NY (NY may be zero)
#                 columns may contain associated Y-values
#     Tags    -   tags, array[0..N-1], contains integer tags associated
#                 with points.
#     N       -   number of points, N&gt;=0
#     NX      -   space dimension, NX&gt;=1.
#     NY      -   number of optional Y-values, NY&gt;=0.
#     NormType-   norm type:
#                 * 0 denotes infinity-norm
#                 * 1 denotes 1-norm
#                 * 2 denotes 2-norm (Euclidean norm)
# 
# OUTPUT PARAMETERS
#     KDT     -   KD-tree
# 
# NOTES
# 
# 1. KD-tree  creation  have O(N*logN) complexity and O(N*(2*NX+NY))  memory
#    requirements.
# 2. Although KD-trees may be used with any combination of N  and  NX,  they
#    are more efficient than brute-force search only when N &gt;&gt; 4^NX. So they
#    are most useful in low-dimensional tasks (NX=2, NX=3). NX=1  is another
#    inefficient case, because  simple  binary  search  (without  additional
#    structures) is much more efficient in such tasks than KD-trees.
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   kdt = xalglib.kdtreebuildtagged(xy, tags, n, nx, ny, normtype)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   kdt = xalglib.kdtreebuildtagged(xy, tags, nx, ny, normtype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          tags:       1D array/list of int
          n:          int
          nx:         int
          ny:         int
          normtype:   int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  kdt:        class xalglib.kdtree

</div></pre>
<a name='sub_kdtreecreaterequestbuffer'></a><h3 class=pageheader><code>kdtreecreaterequestbuffer</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates buffer  structure  which  can  be  used  to  perform
# parallel KD-tree requests.
# 
# KD-tree subpackage provides two sets of request functions - ones which use
# internal buffer of KD-tree object  (these  functions  are  single-threaded
# because they use same buffer, which can not shared between  threads),  and
# ones which use external buffer.
# 
# This function is used to initialize external buffer.
# 
# INPUT PARAMETERS
#     KDT         -   KD-tree which is associated with newly created buffer
# 
# OUTPUT PARAMETERS
#     Buf         -   external buffer.
# 
# 
# IMPORTANT: KD-tree buffer should be used only with  KD-tree  object  which
#            was used to initialize buffer. Any attempt to use buffer   with
#            different object is dangerous - you  may  get  integrity  check
#            failure (exception) because sizes of internal arrays do not fit
#            to dimensions of KD-tree structure.
# 
#   -- ALGLIB --
#      Copyright 18.03.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   buf = xalglib.kdtreecreaterequestbuffer(kdt)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  buf:        class xalglib.kdtreerequestbuffer

</div></pre>
<a name='sub_kdtreequeryaknn'></a><h3 class=pageheader><code>kdtreequeryaknn</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# K-NN query: approximate K nearest neighbors
# 
# IMPORTANT: this function can not be used in multithreaded code because  it
#            uses internal temporary buffer of kd-tree object, which can not
#            be shared between multiple threads.  If  you  want  to  perform
#            parallel requests, use function  which  uses  external  request
#            buffer: KDTreeTsQueryAKNN() (&quot;Ts&quot; stands for &quot;thread-safe&quot;).
# 
# INPUT PARAMETERS
#     KDT         -   KD-tree
#     X           -   point, array[0..NX-1].
#     K           -   number of neighbors to return, K&gt;=1
#     SelfMatch   -   whether self-matches are allowed:
#                     * if True, nearest neighbor may be the point itself
#                       (if it exists in original dataset)
#                     * if False, then only points with non-zero distance
#                       are returned
#                     * if not given, considered True
#     Eps         -   approximation factor, Eps&gt;=0. eps-approximate  nearest
#                     neighbor  is  a  neighbor  whose distance from X is at
#                     most (1+eps) times distance of true nearest neighbor.
# 
# RESULT
#     number of actual neighbors found (either K or N, if K&gt;N).
# 
# NOTES
#     significant performance gain may be achieved only when Eps  is  is  on
#     the order of magnitude of 1 or larger.
# 
# This  subroutine  performs  query  and  stores  its result in the internal
# structures of the KD-tree. You can use  following  subroutines  to  obtain
# these results:
# * KDTreeQueryResultsX() to get X-values
# * KDTreeQueryResultsXY() to get X- and Y-values
# * KDTreeQueryResultsTags() to get tag values
# * KDTreeQueryResultsDistances() to get distances
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreequeryaknn(kdt, x, k, selfmatch, eps)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreequeryaknn(kdt, x, k, eps)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          x:          1D array/list of float
          k:          int
          selfmatch:  bool
          eps:        float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> kdt
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_kdtreequerybox'></a><h3 class=pageheader><code>kdtreequerybox</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Box query: all points within user-specified box.
# 
# IMPORTANT: this function can not be used in multithreaded code because  it
#            uses internal temporary buffer of kd-tree object, which can not
#            be shared between multiple threads.  If  you  want  to  perform
#            parallel requests, use function  which  uses  external  request
#            buffer: KDTreeTsQueryBox() (&quot;Ts&quot; stands for &quot;thread-safe&quot;).
# 
# INPUT PARAMETERS
#     KDT         -   KD-tree
#     BoxMin      -   lower bounds, array[0..NX-1].
#     BoxMax      -   upper bounds, array[0..NX-1].
# 
# 
# RESULT
#     number of actual neighbors found (in [0,N]).
# 
# This  subroutine  performs  query  and  stores  its result in the internal
# structures of the KD-tree. You can use  following  subroutines  to  obtain
# these results:
# * KDTreeQueryResultsX() to get X-values
# * KDTreeQueryResultsXY() to get X- and Y-values
# * KDTreeQueryResultsTags() to get tag values
# * KDTreeQueryResultsDistances() returns zeros for this request
# 
# NOTE: this particular query returns unordered results, because there is no
#       meaningful way of  ordering  points.  Furthermore,  no 'distance' is
#       associated with points - it is either INSIDE  or OUTSIDE (so request
#       for distances will return zeros).
# 
#   -- ALGLIB --
#      Copyright 14.05.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreequerybox(kdt, boxmin, boxmax)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          boxmin:     1D array/list of float
          boxmax:     1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> kdt
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_kdtreequeryknn'></a><h3 class=pageheader><code>kdtreequeryknn</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# K-NN query: K nearest neighbors
# 
# IMPORTANT: this function can not be used in multithreaded code because  it
#            uses internal temporary buffer of kd-tree object, which can not
#            be shared between multiple threads.  If  you  want  to  perform
#            parallel requests, use function  which  uses  external  request
#            buffer: KDTreeTsQueryKNN() (&quot;Ts&quot; stands for &quot;thread-safe&quot;).
# 
# INPUT PARAMETERS
#     KDT         -   KD-tree
#     X           -   point, array[0..NX-1].
#     K           -   number of neighbors to return, K&gt;=1
#     SelfMatch   -   whether self-matches are allowed:
#                     * if True, nearest neighbor may be the point itself
#                       (if it exists in original dataset)
#                     * if False, then only points with non-zero distance
#                       are returned
#                     * if not given, considered True
# 
# RESULT
#     number of actual neighbors found (either K or N, if K&gt;N).
# 
# This  subroutine  performs  query  and  stores  its result in the internal
# structures of the KD-tree. You can use  following  subroutines  to  obtain
# these results:
# * KDTreeQueryResultsX() to get X-values
# * KDTreeQueryResultsXY() to get X- and Y-values
# * KDTreeQueryResultsTags() to get tag values
# * KDTreeQueryResultsDistances() to get distances
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreequeryknn(kdt, x, k, selfmatch)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreequeryknn(kdt, x, k)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          x:          1D array/list of float
          k:          int
          selfmatch:  bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> kdt
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_kdtreequeryresultsdistances'></a><h3 class=pageheader><code>kdtreequeryresultsdistances</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Distances from last query
# 
# This function retuns results stored in  the  internal  buffer  of  kd-tree
# object. If you performed buffered requests (ones which  use  instances  of
# kdtreerequestbuffer class), you  should  call  buffered  version  of  this
# function - kdtreetsqueryresultsdistances().
# 
# INPUT PARAMETERS
#     KDT     -   KD-tree
#     R       -   possibly pre-allocated buffer. If X is too small to store
#                 result, it is resized. If size(X) is enough to store
#                 result, it is left unchanged.
# 
# OUTPUT PARAMETERS
#     R       -   filled with distances (in corresponding norm)
# 
# NOTES
# 1. points are ordered by distance from the query point (first = closest)
# 2. if  XY is larger than required to store result, only leading part  will
#    be overwritten; trailing part will be left unchanged. So  if  on  input
#    XY = [[A,B],[C,D]], and result is [1,2],  then  on  exit  we  will  get
#    XY = [[1,2],[C,D]]. This is done purposely to increase performance;  if
#    you want function  to  resize  array  according  to  result  size,  use
#    function with same name and suffix 'I'.
# 
# SEE ALSO
# * KDTreeQueryResultsX()             X-values
# * KDTreeQueryResultsXY()            X- and Y-values
# * KDTreeQueryResultsTags()          tag values
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.kdtreequeryresultsdistances(kdt, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          r:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of float

</div></pre>
<a name='sub_kdtreequeryresultsdistancesi'></a><h3 class=pageheader><code>kdtreequeryresultsdistancesi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Distances from last query; 'interactive' variant for languages like Python
# which  support  constructs   like  &quot;R = KDTreeQueryResultsDistancesI(KDT)&quot;
# and interactive mode of interpreter.
# 
# This function allocates new array on each call,  so  it  is  significantly
# slower than its 'non-interactive' counterpart, but it is  more  convenient
# when you call it from command line.
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.kdtreequeryresultsdistancesi(kdt)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of float

</div></pre>
<a name='sub_kdtreequeryresultstags'></a><h3 class=pageheader><code>kdtreequeryresultstags</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Tags from last query
# 
# This function retuns results stored in  the  internal  buffer  of  kd-tree
# object. If you performed buffered requests (ones which  use  instances  of
# kdtreerequestbuffer class), you  should  call  buffered  version  of  this
# function - kdtreetsqueryresultstags().
# 
# INPUT PARAMETERS
#     KDT     -   KD-tree
#     Tags    -   possibly pre-allocated buffer. If X is too small to store
#                 result, it is resized. If size(X) is enough to store
#                 result, it is left unchanged.
# 
# OUTPUT PARAMETERS
#     Tags    -   filled with tags associated with points,
#                 or, when no tags were supplied, with zeros
# 
# NOTES
# 1. points are ordered by distance from the query point (first = closest)
# 2. if  XY is larger than required to store result, only leading part  will
#    be overwritten; trailing part will be left unchanged. So  if  on  input
#    XY = [[A,B],[C,D]], and result is [1,2],  then  on  exit  we  will  get
#    XY = [[1,2],[C,D]]. This is done purposely to increase performance;  if
#    you want function  to  resize  array  according  to  result  size,  use
#    function with same name and suffix 'I'.
# 
# SEE ALSO
# * KDTreeQueryResultsX()             X-values
# * KDTreeQueryResultsXY()            X- and Y-values
# * KDTreeQueryResultsDistances()     distances
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   tags = xalglib.kdtreequeryresultstags(kdt, tags)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          tags:       1D array/list of int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  tags:       1D array/list of int

</div></pre>
<a name='sub_kdtreequeryresultstagsi'></a><h3 class=pageheader><code>kdtreequeryresultstagsi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Tags  from  last  query;  'interactive' variant for languages like  Python
# which  support  constructs  like &quot;Tags = KDTreeQueryResultsTagsI(KDT)&quot; and
# interactive mode of interpreter.
# 
# This function allocates new array on each call,  so  it  is  significantly
# slower than its 'non-interactive' counterpart, but it is  more  convenient
# when you call it from command line.
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   tags = xalglib.kdtreequeryresultstagsi(kdt)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  tags:       1D array/list of int

</div></pre>
<a name='sub_kdtreequeryresultsx'></a><h3 class=pageheader><code>kdtreequeryresultsx</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# X-values from last query.
# 
# This function retuns results stored in  the  internal  buffer  of  kd-tree
# object. If you performed buffered requests (ones which  use  instances  of
# kdtreerequestbuffer class), you  should  call  buffered  version  of  this
# function - kdtreetsqueryresultsx().
# 
# INPUT PARAMETERS
#     KDT     -   KD-tree
#     X       -   possibly pre-allocated buffer. If X is too small to store
#                 result, it is resized. If size(X) is enough to store
#                 result, it is left unchanged.
# 
# OUTPUT PARAMETERS
#     X       -   rows are filled with X-values
# 
# NOTES
# 1. points are ordered by distance from the query point (first = closest)
# 2. if  XY is larger than required to store result, only leading part  will
#    be overwritten; trailing part will be left unchanged. So  if  on  input
#    XY = [[A,B],[C,D]], and result is [1,2],  then  on  exit  we  will  get
#    XY = [[1,2],[C,D]]. This is done purposely to increase performance;  if
#    you want function  to  resize  array  according  to  result  size,  use
#    function with same name and suffix 'I'.
# 
# SEE ALSO
# * KDTreeQueryResultsXY()            X- and Y-values
# * KDTreeQueryResultsTags()          tag values
# * KDTreeQueryResultsDistances()     distances
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.kdtreequeryresultsx(kdt, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          x:          2D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          2D array/list of float

</div></pre>
<a name='sub_kdtreequeryresultsxi'></a><h3 class=pageheader><code>kdtreequeryresultsxi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# X-values from last query; 'interactive' variant for languages like  Python
# which   support    constructs   like  &quot;X = KDTreeQueryResultsXI(KDT)&quot;  and
# interactive mode of interpreter.
# 
# This function allocates new array on each call,  so  it  is  significantly
# slower than its 'non-interactive' counterpart, but it is  more  convenient
# when you call it from command line.
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.kdtreequeryresultsxi(kdt)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          2D array/list of float

</div></pre>
<a name='sub_kdtreequeryresultsxy'></a><h3 class=pageheader><code>kdtreequeryresultsxy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# X- and Y-values from last query
# 
# This function retuns results stored in  the  internal  buffer  of  kd-tree
# object. If you performed buffered requests (ones which  use  instances  of
# kdtreerequestbuffer class), you  should  call  buffered  version  of  this
# function - kdtreetsqueryresultsxy().
# 
# INPUT PARAMETERS
#     KDT     -   KD-tree
#     XY      -   possibly pre-allocated buffer. If XY is too small to store
#                 result, it is resized. If size(XY) is enough to store
#                 result, it is left unchanged.
# 
# OUTPUT PARAMETERS
#     XY      -   rows are filled with points: first NX columns with
#                 X-values, next NY columns - with Y-values.
# 
# NOTES
# 1. points are ordered by distance from the query point (first = closest)
# 2. if  XY is larger than required to store result, only leading part  will
#    be overwritten; trailing part will be left unchanged. So  if  on  input
#    XY = [[A,B],[C,D]], and result is [1,2],  then  on  exit  we  will  get
#    XY = [[1,2],[C,D]]. This is done purposely to increase performance;  if
#    you want function  to  resize  array  according  to  result  size,  use
#    function with same name and suffix 'I'.
# 
# SEE ALSO
# * KDTreeQueryResultsX()             X-values
# * KDTreeQueryResultsTags()          tag values
# * KDTreeQueryResultsDistances()     distances
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xy = xalglib.kdtreequeryresultsxy(kdt, xy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          xy:         2D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  xy:         2D array/list of float

</div></pre>
<a name='sub_kdtreequeryresultsxyi'></a><h3 class=pageheader><code>kdtreequeryresultsxyi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# XY-values from last query; 'interactive' variant for languages like Python
# which   support    constructs   like &quot;XY = KDTreeQueryResultsXYI(KDT)&quot; and
# interactive mode of interpreter.
# 
# This function allocates new array on each call,  so  it  is  significantly
# slower than its 'non-interactive' counterpart, but it is  more  convenient
# when you call it from command line.
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xy = xalglib.kdtreequeryresultsxyi(kdt)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  xy:         2D array/list of float

</div></pre>
<a name='sub_kdtreequeryrnn'></a><h3 class=pageheader><code>kdtreequeryrnn</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# R-NN query: all points within R-sphere centered at X, ordered by  distance
# between point and X (by ascending).
# 
# NOTE: it is also possible to perform undordered queries performed by means
#       of kdtreequeryrnnu() and kdtreetsqueryrnnu() functions. Such queries
#       are faster because we do not have to use heap structure for sorting.
# 
# IMPORTANT: this function can not be used in multithreaded code because  it
#            uses internal temporary buffer of kd-tree object, which can not
#            be shared between multiple threads.  If  you  want  to  perform
#            parallel requests, use function  which  uses  external  request
#            buffer: kdtreetsqueryrnn() (&quot;Ts&quot; stands for &quot;thread-safe&quot;).
# 
# INPUT PARAMETERS
#     KDT         -   KD-tree
#     X           -   point, array[0..NX-1].
#     R           -   radius of sphere (in corresponding norm), R&gt;0
#     SelfMatch   -   whether self-matches are allowed:
#                     * if True, nearest neighbor may be the point itself
#                       (if it exists in original dataset)
#                     * if False, then only points with non-zero distance
#                       are returned
#                     * if not given, considered True
# 
# RESULT
#     number of neighbors found, &gt;=0
# 
# This  subroutine  performs  query  and  stores  its result in the internal
# structures of the KD-tree. You can use  following  subroutines  to  obtain
# actual results:
# * KDTreeQueryResultsX() to get X-values
# * KDTreeQueryResultsXY() to get X- and Y-values
# * KDTreeQueryResultsTags() to get tag values
# * KDTreeQueryResultsDistances() to get distances
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreequeryrnn(kdt, x, r, selfmatch)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreequeryrnn(kdt, x, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          x:          1D array/list of float
          r:          float
          selfmatch:  bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> kdt
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_kdtreequeryrnnu'></a><h3 class=pageheader><code>kdtreequeryrnnu</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# R-NN query: all points within R-sphere  centered  at  X,  no  ordering  by
# distance as undicated by &quot;U&quot; suffix (faster that ordered query, for  large
# queries - significantly faster).
# 
# IMPORTANT: this function can not be used in multithreaded code because  it
#            uses internal temporary buffer of kd-tree object, which can not
#            be shared between multiple threads.  If  you  want  to  perform
#            parallel requests, use function  which  uses  external  request
#            buffer: kdtreetsqueryrnn() (&quot;Ts&quot; stands for &quot;thread-safe&quot;).
# 
# INPUT PARAMETERS
#     KDT         -   KD-tree
#     X           -   point, array[0..NX-1].
#     R           -   radius of sphere (in corresponding norm), R&gt;0
#     SelfMatch   -   whether self-matches are allowed:
#                     * if True, nearest neighbor may be the point itself
#                       (if it exists in original dataset)
#                     * if False, then only points with non-zero distance
#                       are returned
#                     * if not given, considered True
# 
# RESULT
#     number of neighbors found, &gt;=0
# 
# This  subroutine  performs  query  and  stores  its result in the internal
# structures of the KD-tree. You can use  following  subroutines  to  obtain
# actual results:
# * KDTreeQueryResultsX() to get X-values
# * KDTreeQueryResultsXY() to get X- and Y-values
# * KDTreeQueryResultsTags() to get tag values
# * KDTreeQueryResultsDistances() to get distances
# 
# As indicated by &quot;U&quot; suffix, this function returns unordered results.
# 
#   -- ALGLIB --
#      Copyright 01.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreequeryrnnu(kdt, x, r, selfmatch)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreequeryrnnu(kdt, x, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          x:          1D array/list of float
          r:          float
          selfmatch:  bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> kdt
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_kdtreetsqueryaknn'></a><h3 class=pageheader><code>kdtreetsqueryaknn</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# K-NN query: approximate K nearest neighbors, using thread-local buffer.
# 
# You can call this function from multiple threads for same kd-tree instance,
# assuming that different instances of buffer object are passed to different
# threads.
# 
# INPUT PARAMETERS
#     KDT         -   KD-tree
#     Buf         -   request buffer  object  created  for  this  particular
#                     instance of kd-tree structure with kdtreecreaterequestbuffer()
#                     function.
#     X           -   point, array[0..NX-1].
#     K           -   number of neighbors to return, K&gt;=1
#     SelfMatch   -   whether self-matches are allowed:
#                     * if True, nearest neighbor may be the point itself
#                       (if it exists in original dataset)
#                     * if False, then only points with non-zero distance
#                       are returned
#                     * if not given, considered True
#     Eps         -   approximation factor, Eps&gt;=0. eps-approximate  nearest
#                     neighbor  is  a  neighbor  whose distance from X is at
#                     most (1+eps) times distance of true nearest neighbor.
# 
# RESULT
#     number of actual neighbors found (either K or N, if K&gt;N).
# 
# NOTES
#     significant performance gain may be achieved only when Eps  is  is  on
#     the order of magnitude of 1 or larger.
# 
# This  subroutine  performs  query  and  stores  its result in the internal
# structures  of  the  buffer object. You can use following  subroutines  to
# obtain these results (pay attention to &quot;buf&quot; in their names):
# * KDTreeTsQueryResultsX() to get X-values
# * KDTreeTsQueryResultsXY() to get X- and Y-values
# * KDTreeTsQueryResultsTags() to get tag values
# * KDTreeTsQueryResultsDistances() to get distances
# 
# IMPORTANT: kd-tree buffer should be used only with  KD-tree  object  which
#            was used to initialize buffer. Any attempt to use biffer   with
#            different object is dangerous - you  may  get  integrity  check
#            failure (exception) because sizes of internal arrays do not fit
#            to dimensions of KD-tree structure.
# 
#   -- ALGLIB --
#      Copyright 18.03.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreetsqueryaknn(kdt, buf, x, k, selfmatch, eps)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreetsqueryaknn(kdt, buf, x, k, eps)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          buf:        class xalglib.kdtreerequestbuffer
          x:          1D array/list of float
          k:          int
          selfmatch:  bool
          eps:        float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> buf
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_kdtreetsquerybox'></a><h3 class=pageheader><code>kdtreetsquerybox</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Box query: all points within user-specified box, using thread-local buffer.
# 
# You can call this function from multiple threads for same kd-tree instance,
# assuming that different instances of buffer object are passed to different
# threads.
# 
# INPUT PARAMETERS
#     KDT         -   KD-tree
#     Buf         -   request buffer  object  created  for  this  particular
#                     instance of kd-tree structure with kdtreecreaterequestbuffer()
#                     function.
#     BoxMin      -   lower bounds, array[0..NX-1].
#     BoxMax      -   upper bounds, array[0..NX-1].
# 
# RESULT
#     number of actual neighbors found (in [0,N]).
# 
# This  subroutine  performs  query  and  stores  its result in the internal
# structures  of  the  buffer object. You can use following  subroutines  to
# obtain these results (pay attention to &quot;ts&quot; in their names):
# * KDTreeTsQueryResultsX() to get X-values
# * KDTreeTsQueryResultsXY() to get X- and Y-values
# * KDTreeTsQueryResultsTags() to get tag values
# * KDTreeTsQueryResultsDistances() returns zeros for this query
# 
# NOTE: this particular query returns unordered results, because there is no
#       meaningful way of  ordering  points.  Furthermore,  no 'distance' is
#       associated with points - it is either INSIDE  or OUTSIDE (so request
#       for distances will return zeros).
# 
# IMPORTANT: kd-tree buffer should be used only with  KD-tree  object  which
#            was used to initialize buffer. Any attempt to use biffer   with
#            different object is dangerous - you  may  get  integrity  check
#            failure (exception) because sizes of internal arrays do not fit
#            to dimensions of KD-tree structure.
# 
#   -- ALGLIB --
#      Copyright 14.05.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreetsquerybox(kdt, buf, boxmin, boxmax)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          buf:        class xalglib.kdtreerequestbuffer
          boxmin:     1D array/list of float
          boxmax:     1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> buf
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_kdtreetsqueryknn'></a><h3 class=pageheader><code>kdtreetsqueryknn</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# K-NN query: K nearest neighbors, using external thread-local buffer.
# 
# You can call this function from multiple threads for same kd-tree instance,
# assuming that different instances of buffer object are passed to different
# threads.
# 
# INPUT PARAMETERS
#     KDT         -   kd-tree
#     Buf         -   request buffer  object  created  for  this  particular
#                     instance of kd-tree structure with kdtreecreaterequestbuffer()
#                     function.
#     X           -   point, array[0..NX-1].
#     K           -   number of neighbors to return, K&gt;=1
#     SelfMatch   -   whether self-matches are allowed:
#                     * if True, nearest neighbor may be the point itself
#                       (if it exists in original dataset)
#                     * if False, then only points with non-zero distance
#                       are returned
#                     * if not given, considered True
# 
# RESULT
#     number of actual neighbors found (either K or N, if K&gt;N).
# 
# This  subroutine  performs  query  and  stores  its result in the internal
# structures  of  the  buffer object. You can use following  subroutines  to
# obtain these results (pay attention to &quot;buf&quot; in their names):
# * KDTreeTsQueryResultsX() to get X-values
# * KDTreeTsQueryResultsXY() to get X- and Y-values
# * KDTreeTsQueryResultsTags() to get tag values
# * KDTreeTsQueryResultsDistances() to get distances
# 
# IMPORTANT: kd-tree buffer should be used only with  KD-tree  object  which
#            was used to initialize buffer. Any attempt to use biffer   with
#            different object is dangerous - you  may  get  integrity  check
#            failure (exception) because sizes of internal arrays do not fit
#            to dimensions of KD-tree structure.
# 
#   -- ALGLIB --
#      Copyright 18.03.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreetsqueryknn(kdt, buf, x, k, selfmatch)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreetsqueryknn(kdt, buf, x, k)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          buf:        class xalglib.kdtreerequestbuffer
          x:          1D array/list of float
          k:          int
          selfmatch:  bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> buf
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_kdtreetsqueryresultsdistances'></a><h3 class=pageheader><code>kdtreetsqueryresultsdistances</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Distances from last query associated with kdtreerequestbuffer object.
# 
# This function retuns results stored in  the  internal  buffer  of  kd-tree
# object. If you performed buffered requests (ones which  use  instances  of
# kdtreerequestbuffer class), you  should  call  buffered  version  of  this
# function - KDTreeTsqueryresultsdistances().
# 
# INPUT PARAMETERS
#     KDT     -   KD-tree
#     Buf     -   request  buffer  object  created   for   this   particular
#                 instance of kd-tree structure.
#     R       -   possibly pre-allocated buffer. If X is too small to store
#                 result, it is resized. If size(X) is enough to store
#                 result, it is left unchanged.
# 
# OUTPUT PARAMETERS
#     R       -   filled with distances (in corresponding norm)
# 
# NOTES
# 1. points are ordered by distance from the query point (first = closest)
# 2. if  XY is larger than required to store result, only leading part  will
#    be overwritten; trailing part will be left unchanged. So  if  on  input
#    XY = [[A,B],[C,D]], and result is [1,2],  then  on  exit  we  will  get
#    XY = [[1,2],[C,D]]. This is done purposely to increase performance;  if
#    you want function  to  resize  array  according  to  result  size,  use
#    function with same name and suffix 'I'.
# 
# SEE ALSO
# * KDTreeQueryResultsX()             X-values
# * KDTreeQueryResultsXY()            X- and Y-values
# * KDTreeQueryResultsTags()          tag values
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.kdtreetsqueryresultsdistances(kdt, buf, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          buf:        class xalglib.kdtreerequestbuffer
          r:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of float

</div></pre>
<a name='sub_kdtreetsqueryresultstags'></a><h3 class=pageheader><code>kdtreetsqueryresultstags</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Tags from last query associated with kdtreerequestbuffer object.
# 
# This function retuns results stored in  the  internal  buffer  of  kd-tree
# object. If you performed buffered requests (ones which  use  instances  of
# kdtreerequestbuffer class), you  should  call  buffered  version  of  this
# function - KDTreeTsqueryresultstags().
# 
# INPUT PARAMETERS
#     KDT     -   KD-tree
#     Buf     -   request  buffer  object  created   for   this   particular
#                 instance of kd-tree structure.
#     Tags    -   possibly pre-allocated buffer. If X is too small to store
#                 result, it is resized. If size(X) is enough to store
#                 result, it is left unchanged.
# 
# OUTPUT PARAMETERS
#     Tags    -   filled with tags associated with points,
#                 or, when no tags were supplied, with zeros
# 
# NOTES
# 1. points are ordered by distance from the query point (first = closest)
# 2. if  XY is larger than required to store result, only leading part  will
#    be overwritten; trailing part will be left unchanged. So  if  on  input
#    XY = [[A,B],[C,D]], and result is [1,2],  then  on  exit  we  will  get
#    XY = [[1,2],[C,D]]. This is done purposely to increase performance;  if
#    you want function  to  resize  array  according  to  result  size,  use
#    function with same name and suffix 'I'.
# 
# SEE ALSO
# * KDTreeQueryResultsX()             X-values
# * KDTreeQueryResultsXY()            X- and Y-values
# * KDTreeQueryResultsDistances()     distances
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   tags = xalglib.kdtreetsqueryresultstags(kdt, buf, tags)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          buf:        class xalglib.kdtreerequestbuffer
          tags:       1D array/list of int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  tags:       1D array/list of int

</div></pre>
<a name='sub_kdtreetsqueryresultsx'></a><h3 class=pageheader><code>kdtreetsqueryresultsx</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# X-values from last query associated with kdtreerequestbuffer object.
# 
# INPUT PARAMETERS
#     KDT     -   KD-tree
#     Buf     -   request  buffer  object  created   for   this   particular
#                 instance of kd-tree structure.
#     X       -   possibly pre-allocated buffer. If X is too small to store
#                 result, it is resized. If size(X) is enough to store
#                 result, it is left unchanged.
# 
# OUTPUT PARAMETERS
#     X       -   rows are filled with X-values
# 
# NOTES
# 1. points are ordered by distance from the query point (first = closest)
# 2. if  XY is larger than required to store result, only leading part  will
#    be overwritten; trailing part will be left unchanged. So  if  on  input
#    XY = [[A,B],[C,D]], and result is [1,2],  then  on  exit  we  will  get
#    XY = [[1,2],[C,D]]. This is done purposely to increase performance;  if
#    you want function  to  resize  array  according  to  result  size,  use
#    function with same name and suffix 'I'.
# 
# SEE ALSO
# * KDTreeQueryResultsXY()            X- and Y-values
# * KDTreeQueryResultsTags()          tag values
# * KDTreeQueryResultsDistances()     distances
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.kdtreetsqueryresultsx(kdt, buf, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          buf:        class xalglib.kdtreerequestbuffer
          x:          2D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          2D array/list of float

</div></pre>
<a name='sub_kdtreetsqueryresultsxy'></a><h3 class=pageheader><code>kdtreetsqueryresultsxy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# X- and Y-values from last query associated with kdtreerequestbuffer object.
# 
# INPUT PARAMETERS
#     KDT     -   KD-tree
#     Buf     -   request  buffer  object  created   for   this   particular
#                 instance of kd-tree structure.
#     XY      -   possibly pre-allocated buffer. If XY is too small to store
#                 result, it is resized. If size(XY) is enough to store
#                 result, it is left unchanged.
# 
# OUTPUT PARAMETERS
#     XY      -   rows are filled with points: first NX columns with
#                 X-values, next NY columns - with Y-values.
# 
# NOTES
# 1. points are ordered by distance from the query point (first = closest)
# 2. if  XY is larger than required to store result, only leading part  will
#    be overwritten; trailing part will be left unchanged. So  if  on  input
#    XY = [[A,B],[C,D]], and result is [1,2],  then  on  exit  we  will  get
#    XY = [[1,2],[C,D]]. This is done purposely to increase performance;  if
#    you want function  to  resize  array  according  to  result  size,  use
#    function with same name and suffix 'I'.
# 
# SEE ALSO
# * KDTreeQueryResultsX()             X-values
# * KDTreeQueryResultsTags()          tag values
# * KDTreeQueryResultsDistances()     distances
# 
#   -- ALGLIB --
#      Copyright 28.02.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xy = xalglib.kdtreetsqueryresultsxy(kdt, buf, xy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          buf:        class xalglib.kdtreerequestbuffer
          xy:         2D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  xy:         2D array/list of float

</div></pre>
<a name='sub_kdtreetsqueryrnn'></a><h3 class=pageheader><code>kdtreetsqueryrnn</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# R-NN query: all points within  R-sphere  centered  at  X,  using  external
# thread-local buffer, sorted by distance between point and X (by ascending)
# 
# You can call this function from multiple threads for same kd-tree instance,
# assuming that different instances of buffer object are passed to different
# threads.
# 
# NOTE: it is also possible to perform undordered queries performed by means
#       of kdtreequeryrnnu() and kdtreetsqueryrnnu() functions. Such queries
#       are faster because we do not have to use heap structure for sorting.
# 
# INPUT PARAMETERS
#     KDT         -   KD-tree
#     Buf         -   request buffer  object  created  for  this  particular
#                     instance of kd-tree structure with kdtreecreaterequestbuffer()
#                     function.
#     X           -   point, array[0..NX-1].
#     R           -   radius of sphere (in corresponding norm), R&gt;0
#     SelfMatch   -   whether self-matches are allowed:
#                     * if True, nearest neighbor may be the point itself
#                       (if it exists in original dataset)
#                     * if False, then only points with non-zero distance
#                       are returned
#                     * if not given, considered True
# 
# RESULT
#     number of neighbors found, &gt;=0
# 
# This  subroutine  performs  query  and  stores  its result in the internal
# structures  of  the  buffer object. You can use following  subroutines  to
# obtain these results (pay attention to &quot;buf&quot; in their names):
# * KDTreeTsQueryResultsX() to get X-values
# * KDTreeTsQueryResultsXY() to get X- and Y-values
# * KDTreeTsQueryResultsTags() to get tag values
# * KDTreeTsQueryResultsDistances() to get distances
# 
# IMPORTANT: kd-tree buffer should be used only with  KD-tree  object  which
#            was used to initialize buffer. Any attempt to use biffer   with
#            different object is dangerous - you  may  get  integrity  check
#            failure (exception) because sizes of internal arrays do not fit
#            to dimensions of KD-tree structure.
# 
#   -- ALGLIB --
#      Copyright 18.03.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreetsqueryrnn(kdt, buf, x, r, selfmatch)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreetsqueryrnn(kdt, buf, x, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          buf:        class xalglib.kdtreerequestbuffer
          x:          1D array/list of float
          r:          float
          selfmatch:  bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> buf
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_kdtreetsqueryrnnu'></a><h3 class=pageheader><code>kdtreetsqueryrnnu</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# R-NN query: all points within  R-sphere  centered  at  X,  using  external
# thread-local buffer, no ordering by distance as undicated  by  &quot;U&quot;  suffix
# (faster that ordered query, for large queries - significantly faster).
# 
# You can call this function from multiple threads for same kd-tree instance,
# assuming that different instances of buffer object are passed to different
# threads.
# 
# INPUT PARAMETERS
#     KDT         -   KD-tree
#     Buf         -   request buffer  object  created  for  this  particular
#                     instance of kd-tree structure with kdtreecreaterequestbuffer()
#                     function.
#     X           -   point, array[0..NX-1].
#     R           -   radius of sphere (in corresponding norm), R&gt;0
#     SelfMatch   -   whether self-matches are allowed:
#                     * if True, nearest neighbor may be the point itself
#                       (if it exists in original dataset)
#                     * if False, then only points with non-zero distance
#                       are returned
#                     * if not given, considered True
# 
# RESULT
#     number of neighbors found, &gt;=0
# 
# This  subroutine  performs  query  and  stores  its result in the internal
# structures  of  the  buffer object. You can use following  subroutines  to
# obtain these results (pay attention to &quot;buf&quot; in their names):
# * KDTreeTsQueryResultsX() to get X-values
# * KDTreeTsQueryResultsXY() to get X- and Y-values
# * KDTreeTsQueryResultsTags() to get tag values
# * KDTreeTsQueryResultsDistances() to get distances
# 
# As indicated by &quot;U&quot; suffix, this function returns unordered results.
# 
# IMPORTANT: kd-tree buffer should be used only with  KD-tree  object  which
#            was used to initialize buffer. Any attempt to use biffer   with
#            different object is dangerous - you  may  get  integrity  check
#            failure (exception) because sizes of internal arrays do not fit
#            to dimensions of KD-tree structure.
# 
#   -- ALGLIB --
#      Copyright 18.03.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreetsqueryrnnu(kdt, buf, x, r, selfmatch)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.kdtreetsqueryrnnu(kdt, buf, x, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     kdt:        class xalglib.kdtree
          buf:        class xalglib.kdtreerequestbuffer
          x:          1D array/list of float
          r:          float
          selfmatch:  bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> buf
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name=unit_nleq></a><h2 class=pageheader><code>nleq</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_nleqcreatelm' class=toc>nleqcreatelm</a><br>
<a href='#sub_nleqrestartfrom' class=toc>nleqrestartfrom</a><br>
<a href='#sub_nleqresults' class=toc>nleqresults</a><br>
<a href='#sub_nleqresultsbuf' class=toc>nleqresultsbuf</a><br>
<a href='#sub_nleqsetcond' class=toc>nleqsetcond</a><br>
<a href='#sub_nleqsetstpmax' class=toc>nleqsetstpmax</a><br>
<a href='#sub_nleqsetxrep' class=toc>nleqsetxrep</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_nleqcreatelm'></a><h3 class=pageheader><code>nleqcreatelm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
#                 LEVENBERG-MARQUARDT-LIKE NONLINEAR SOLVER
# 
# DESCRIPTION:
# This algorithm solves system of nonlinear equations
#     F[0](x[0], ..., x[n-1])   = 0
#     F[1](x[0], ..., x[n-1])   = 0
#     ...
#     F[M-1](x[0], ..., x[n-1]) = 0
# with M/N do not necessarily coincide.  Algorithm  converges  quadratically
# under following conditions:
#     * the solution set XS is nonempty
#     * for some xs in XS there exist such neighbourhood N(xs) that:
#       * vector function F(x) and its Jacobian J(x) are continuously
#         differentiable on N
#       * ||F(x)|| provides local error bound on N, i.e. there  exists  such
#         c1, that ||F(x)||&gt;c1*distance(x,XS)
# Note that these conditions are much more weaker than usual non-singularity
# conditions. For example, algorithm will converge for any  affine  function
# F (whether its Jacobian singular or not).
# 
# 
# REQUIREMENTS:
# Algorithm will request following information during its operation:
# * function vector F[] and Jacobian matrix at given point X
# * value of merit function f(x)=F[0]^2(x)+...+F[M-1]^2(x) at given point X
# 
# 
# USAGE:
# 1. User initializes algorithm state with NLEQCreateLM() call
# 2. User tunes solver parameters with  NLEQSetCond(),  NLEQSetStpMax()  and
#    other functions
# 3. User  calls  NLEQSolve()  function  which  takes  algorithm  state  and
#    pointers (delegates, etc.) to callback functions which calculate  merit
#    function value and Jacobian.
# 4. User calls NLEQResults() to get solution
# 5. Optionally, user may call NLEQRestartFrom() to  solve  another  problem
#    with same parameters (N/M) but another starting  point  and/or  another
#    function vector. NLEQRestartFrom() allows to reuse already  initialized
#    structure.
# 
# 
# INPUT PARAMETERS:
#     N       -   space dimension, N&gt;1:
#                 * if provided, only leading N elements of X are used
#                 * if not provided, determined automatically from size of X
#     M       -   system size
#     X       -   starting point
# 
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# 
# NOTES:
# 1. you may tune stopping conditions with NLEQSetCond() function
# 2. if target function contains exp() or other fast growing functions,  and
#    optimization algorithm makes too large steps which leads  to  overflow,
#    use NLEQSetStpMax() function to bound algorithm's steps.
# 3. this  algorithm  is  a  slightly  modified implementation of the method
#    described  in  'Levenberg-Marquardt  method  for constrained  nonlinear
#    equations with strong local convergence properties' by Christian Kanzow
#    Nobuo Yamashita and Masao Fukushima and further  developed  in  'On the
#    convergence of a New Levenberg-Marquardt Method'  by  Jin-yan  Fan  and
#    Ya-Xiang Yuan.
# 
# 
#   -- ALGLIB --
#      Copyright 20.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.nleqcreatelm(n, m, x)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.nleqcreatelm(m, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          m:          int
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.nleqstate

</div></pre>
<a name='sub_nleqrestartfrom'></a><h3 class=pageheader><code>nleqrestartfrom</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  subroutine  restarts  CG  algorithm from new point. All optimization
# parameters are left unchanged.
# 
# This  function  allows  to  solve multiple  optimization  problems  (which
# must have same number of dimensions) without object reallocation penalty.
# 
# INPUT PARAMETERS:
#     State   -   structure used for reverse communication previously
#                 allocated with MinCGCreate call.
#     X       -   new starting point.
#     BndL    -   new lower bounds
#     BndU    -   new upper bounds
# 
#   -- ALGLIB --
#      Copyright 30.07.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.nleqrestartfrom(state, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.nleqstate
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_nleqresults'></a><h3 class=pageheader><code>nleqresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# NLEQ solver results
# 
# INPUT PARAMETERS:
#     State   -   algorithm state.
# 
# OUTPUT PARAMETERS:
#     X       -   array[0..N-1], solution
#     Rep     -   optimization report:
#                 * Rep.TerminationType completetion code:
#                     * -4    ERROR:  algorithm   has   converged   to   the
#                             stationary point Xf which is local minimum  of
#                             f=F[0]^2+...+F[m-1]^2, but is not solution  of
#                             nonlinear system.
#                     *  1    sqrt(f)&lt;=EpsF.
#                     *  5    MaxIts steps was taken
#                     *  7    stopping conditions are too stringent,
#                             further improvement is impossible
#                 * Rep.IterationsCount contains iterations count
#                 * NFEV countains number of function calculations
#                 * ActiveConstraints contains number of active constraints
# 
#   -- ALGLIB --
#      Copyright 20.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.nleqresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.nleqstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.nleqreport

</div></pre>
<a name='sub_nleqresultsbuf'></a><h3 class=pageheader><code>nleqresultsbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# NLEQ solver results
# 
# Buffered implementation of NLEQResults(), which uses pre-allocated  buffer
# to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
# intended to be used in the inner cycles of performance critical algorithms
# where array reallocation penalty is too large to be ignored.
# 
#   -- ALGLIB --
#      Copyright 20.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.nleqresultsbuf(state, x, rep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.nleqstate
          x:          1D array/list of float
          rep:        class xalglib.nleqreport
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> rep
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float

</div></pre>
<a name='sub_nleqsetcond'></a><h3 class=pageheader><code>nleqsetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping conditions for the nonlinear solver
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     EpsF    -   &gt;=0
#                 The subroutine finishes  its work if on k+1-th iteration
#                 the condition ||F||&lt;=EpsF is satisfied
#     MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
#                 iterations is unlimited.
# 
# Passing EpsF=0 and MaxIts=0 simultaneously will lead to  automatic
# stopping criterion selection (small EpsF).
# 
# NOTES:
# 
#   -- ALGLIB --
#      Copyright 20.08.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.nleqsetcond(state, epsf, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.nleqstate
          epsf:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_nleqsetstpmax'></a><h3 class=pageheader><code>nleqsetstpmax</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets maximum step length
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     StpMax  -   maximum step length, &gt;=0. Set StpMax to 0.0,  if you don't
#                 want to limit step length.
# 
# Use this subroutine when target function  contains  exp()  or  other  fast
# growing functions, and algorithm makes  too  large  steps  which  lead  to
# overflow. This function allows us to reject steps that are too large  (and
# therefore expose us to the possible overflow) without actually calculating
# function value at the x+stp*d.
# 
#   -- ALGLIB --
#      Copyright 20.08.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.nleqsetstpmax(state, stpmax)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.nleqstate
          stpmax:     float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_nleqsetxrep'></a><h3 class=pageheader><code>nleqsetxrep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function turns on/off reporting.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     NeedXRep-   whether iteration reports are needed or not
# 
# If NeedXRep is True, algorithm will call rep() callback function if  it is
# provided to NLEQSolve().
# 
#   -- ALGLIB --
#      Copyright 20.08.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.nleqsetxrep(state, needxrep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.nleqstate
          needxrep:   bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_nls></a><h2 class=pageheader><code>nls</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_nlscreatedfo' class=toc>nlscreatedfo</a><br>
<a href='#sub_nlsrequesttermination' class=toc>nlsrequesttermination</a><br>
<a href='#sub_nlsrestartfrom' class=toc>nlsrestartfrom</a><br>
<a href='#sub_nlsresults' class=toc>nlsresults</a><br>
<a href='#sub_nlsresultsbuf' class=toc>nlsresultsbuf</a><br>
<a href='#sub_nlssetalgo2ps' class=toc>nlssetalgo2ps</a><br>
<a href='#sub_nlssetalgodfolsa' class=toc>nlssetalgodfolsa</a><br>
<a href='#sub_nlssetbc' class=toc>nlssetbc</a><br>
<a href='#sub_nlssetcond' class=toc>nlssetcond</a><br>
<a href='#sub_nlssetscale' class=toc>nlssetscale</a><br>
<a href='#sub_nlssetxrep' class=toc>nlssetxrep</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_nlscreatedfo'></a><h3 class=pageheader><code>nlscreatedfo</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
#                 DERIVATIVE-FREE NONLINEAR LEAST SQUARES
# 
# DESCRIPTION:
# 
# This function creates a NLS  solver  configured  to  solve  a  constrained
# nonlinear least squares problem
# 
#     min F(x) = f[0]^2 + f[1]^2 + ... + f[m-1]^2
# 
# where f[i] are available, but not their derivatives.
# 
# The  functions  f[i]  are  assumed  to  be   smooth,  but  may  have  some
# amount of numerical noise (either  random  noise  or  deterministic  noise
# arising from numerical simulations or other complex numerical processes).
# 
# INPUT PARAMETERS:
#     N       -   dimension, N&gt;1
#                 * if given, only leading N elements of X are used
#                 * if not given, automatically determined from size of X
#     M       -   number of functions f[i], M&gt;=1
#     X       -   initial point, array[N]
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
#   -- ALGLIB --
#      Copyright 15.10.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.nlscreatedfo(n, m, x)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.nlscreatedfo(m, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          m:          int
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.nlsstate

</div></pre>
<a name='sub_nlsrequesttermination'></a><h3 class=pageheader><code>nlsrequesttermination</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine submits request for termination of running  optimizer.  It
# should be called from user-supplied callback when user decides that it  is
# time to &quot;smoothly&quot; terminate optimization process.  As  result,  optimizer
# stops at point which was &quot;current accepted&quot; when termination  request  was
# submitted and returns error code 8 (successful termination).
# 
# INPUT PARAMETERS:
#     State   -   optimizer structure
# 
# NOTE: after  request  for  termination  optimizer  may   perform   several
#       additional calls to user-supplied callbacks. It does  NOT  guarantee
#       to stop immediately - it just guarantees that these additional calls
#       will be discarded later.
# 
# NOTE: calling this function on optimizer which is NOT running will have no
#       effect.
# 
# NOTE: multiple calls to this function are possible. First call is counted,
#       subsequent calls are silently ignored.
# 
#   -- ALGLIB --
#      Copyright 08.10.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.nlsrequesttermination(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.nlsstate
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_nlsrestartfrom'></a><h3 class=pageheader><code>nlsrestartfrom</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  subroutine  restarts solver from the new point. All optimization
# parameters are left unchanged.
# 
# This  function  allows  to  solve multiple  optimization  problems  (which
# must have same number of dimensions) without object reallocation penalty.
# 
# INPUT PARAMETERS:
#     State   -   optimizer
#     X       -   new starting point.
# 
#   -- ALGLIB --
#      Copyright 30.07.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.nlsrestartfrom(state, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.nlsstate
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_nlsresults'></a><h3 class=pageheader><code>nlsresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Nonlinear least squares solver results
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     X       -   array[N], solution
#     Rep     -   optimization  report;  includes  termination   codes   and
#                 additional information. Termination codes are returned  in
#                 rep.terminationtype field, its possible values are  listed
#                 below, see comments for this structure for more info.
# 
#                 The termination code is a sum of a basic code (success  or
#                 failure)  and  one/several  additional  codes.  Additional
#                 codes are returned only for successful termination.
# 
#                 The following basic codes can be returned:
#                 * -8    optimizer detected NAN/INF values in the target or
#                         nonlinear constraints and failed to recover
#                 * -3    box constraints are inconsistent
#                 *  2    relative step is no more than EpsX.
#                 *  5    MaxIts steps was taken
#                 *  7    stopping conditions are too stringent,
#                         further improvement is impossible
#                 *  8    terminated by user who called nlsrequesttermination().
#                         X contains point which was &quot;current accepted&quot; when
#                         termination request was submitted.
# 
#                 The following additional codes can be returned  (added  to
#                 a basic code):
#                 * +800      if   during  algorithm  execution  the  solver
#                             encountered NAN/INF values in  the  target  or
#                             constraints but managed to recover by reducing
#                             trust region radius, the  solver  returns  one
#                             of SUCCESS codes but adds +800 to the code.
# 
#   -- ALGLIB --
#      Copyright 15.10.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.nlsresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.nlsstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float
          rep:        class xalglib.nlsreport

</div></pre>
<a name='sub_nlsresultsbuf'></a><h3 class=pageheader><code>nlsresultsbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Buffered implementation of NLSResults(), which uses pre-allocated buffer
# to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
# intended to be used in the inner cycles of performance critical algorithms
# where array reallocation penalty is too large to be ignored.
# 
#   -- ALGLIB --
#      Copyright 10.03.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x = xalglib.nlsresultsbuf(state, x, rep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.nlsstate
          x:          1D array/list of float
          rep:        class xalglib.nlsreport
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> rep
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of float

</div></pre>
<a name='sub_nlssetalgo2ps'></a><h3 class=pageheader><code>nlssetalgo2ps</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets the derivative-free NLS optimization algorithm  to  the
# 2PS (2-Point Stencil) algorithm.
# 
# This solver is recommended for the following cases:
# * an expensive target function is minimized  by the commercial ALGLIB with
#   callback  parallelism  activated  (see  ALGLIB Reference Manual for more
#   information about parallel callbacks)
# * an inexpensive target function is minimized by any ALGLIB edition  (free
#   or commercial)
# 
# This function works only with solvers created with nlscreatedfo(), i.e. in
# the derivative-free mode.
# 
# See the end of this comment for more information about the algorithm.
# 
# INPUT PARAMETERS:
#     State           -   solver; must be created with nlscreatedfo() call -
#                         passing  an  object   initialized   with   another
#                         constructor function will result in an exception.
#     NNoisyRestarts  -   number of restarts performed to combat a noise  in
#                         the target. (see below, section 'RESTARTS', for  a
#                         detailed discussion):
#                         * 0     means that no restarts is performed, the
#                                 solver stops as soon as stopping  criteria
#                                 are met. Recommended for noise-free tasks.
#                         * &gt;0    means  that when the stopping criteria are
#                                 met, the solver will  perform  a  restart:
#                                 increase the trust   radius  and  resample
#                                 points. It often helps to  solve  problems
#                                 with random or deterministic noise.
# 
# ALGORITHM DESCRIPTION AND DISCUSSION
# 
# The 2PS algorithm is a derivative-free model-based nonlinear least squares
# solver which builds local models by evaluating the target at  N additional
# points around the current one, with geometry similar to the 2-point finite
# difference stencil.
# 
# Similarly to the Levenberg-Marquardt algorithm, the solver shows quadratic
# convergence despite the fact that it builds linear models.
# 
# When compared with the DFO-LSA solver, the 2PS algorithm has the following
# distinctive properties:
# * the 2PS algorithm performs more target function evaluations per iteration
#   (at least N+1 instead of 1-2 usually performed by the DFO-LSA)
# * 2PS requires several times less iterations than the DFO-LSA because each
#   iteration extracts and utilizes more information about the  target. This
#   difference tends to exaggerate when N increases
# * contrary to that, DFO-LSA is much better at reuse of previously computed
#   points. Thus, DFO-LSA needs several times less target  evaluations  than
#   2PS, usually about 3-4 times less (this ratio seems to be more  or  less
#   constant independently of N).
# 
# The summary is that:
# * for  expensive  targets  2PS  provides better parallelism potential than
#   DFO-LSA because the former issues many  simultaneous  target  evaluation
#   requests which can be easily parallelized. It  is  possible  for  2PS to
#   outperform DFO-LSA by parallelism  alone,  despite  the  fact  that  the
#   latter needs 3-4 times less target function evaluations.
# * for inexpensive targets 2PS may win  because  it  needs many  times less
#   iterations, and thus the overhead associated with the working set updates
#   is also many times less.
# 
# RESTARTS
# 
# Restarts is a strategy used to deal with random and deterministic noise in
# the target/constraints.
# 
# Noise in the objective function can be random, arising from measurement or
# simulation   uncertainty,  or  deterministic,   resulting   from   complex
# underlying phenomena like numerical errors or branches in the target.  Its
# influence is especially high at last stages of the optimization, when  all
# computations are performed with small values of a trust radius.
# 
# Restarts allow the optimization algorithm to be robust against both  types
# of noise by temporarily increasing a trust radius in order  to  capture  a
# global structure of the target and avoid being trapped  by  noise-produced
# local features.
# 
# A restart is usually performed when the stopping criteria  are  triggered.
# Instead of stopping, the solver increases  trust  radius  to  its  initial
# value and tries to rebuild a model.
# 
# If you decide to optimize with restarts,  it  is  recommended  to  perform
# a small amount of restarts, up to 5. Generally, restarts do not allow  one
# to completely solve the problem of noise, but still   it  is  possible  to
# achieve some additional progress.
# 
#   -- ALGLIB --
#      Copyright 15.10.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.nlssetalgo2ps(state, nnoisyrestarts)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.nlssetalgo2ps(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.nlsstate
          nnoisyrestarts: int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_nlssetalgodfolsa'></a><h3 class=pageheader><code>nlssetalgodfolsa</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets the derivative-free NLS optimization algorithm  to  the
# DFO-LSA algorithm, an ALGLIB implementation (with several modifications)of
# the original DFO-LS algorithm  by  Cartis, C., Fiala, J., Marteau, B.  and
# Roberts, L. ('Improving the  Flexibility  and  Robustness  of  Model-Based
# Derivative-Free Optimization Solvers', 2019). The A in DFO-LSA stands  for
# ALGLIB, in order to distinguish our slightly modified implementation  from
# the original algorithm.
# 
# This solver is recommended for the following  case:  an  expensive  target
# function is minimized without parallelism being used (either  free  ALGLIB
# is used or commercial one is used but the target callback is non-reentrant
# i.e. it can not be simultaneously called from multiple threads)
# 
# This function works only with solvers created with nlscreatedfo(), i.e. in
# the derivative-free mode.
# 
# See the end of this comment for more information about the algorithm.
# 
# INPUT PARAMETERS:
#     State           -   solver; must be created with nlscreatedfo() call -
#                         passing  an  object   initialized   with   another
#                         constructor function will result in an exception.
#     NNoisyRestarts  -   number of restarts performed to combat a noise  in
#                         the target. (see below, section 'RESTARTS', for  a
#                         detailed discussion):
#                         * 0     means that no restarts is performed, the
#                                 solver stops as soon as stopping  criteria
#                                 are met. Recommended for noise-free tasks.
#                         * &gt;0    means  that when the stopping criteria are
#                                 met, the solver will  perform  a  restart:
#                                 increase the trust   radius  and  resample
#                                 points. It often helps to  solve  problems
#                                 with random or deterministic noise.
# 
# ALGORITHM DESCRIPTION AND DISCUSSION
# 
# The DFO-LSA algorithm is a derivative-free model-based  NLS  solver  which
# builds local models by remembering N+1 previously computed  target  values
# and updating them as optimization progresses.
# 
# Similarly to the Levenberg-Marquardt algorithm, the solver shows quadratic
# convergence  despite  the  fact  that  it  builds   linear   models.   Our
# implementation generally follows the same lines as the  original  DFO-LSA,
# with several modifications to trust radius  update  strategies,  stability
# fixes (unlike original DFO-LS, our implementation can handle  and  recover
# from the target breaking down due to infeasible arguments) and other minor
# implementation details.
# 
# When compared with the 2PS solver, the DFO-LSA algorithm has the following
# distinctive properties:
# * the 2PS algorithm performs more target function evaluations per iteration
#   (at least N+1 instead of 1-2 usually performed by DFO-LSA)
# * 2PS requires several times less iterations  than  DFO-LSA  because  each
#   iterations extracts and utilizes more information about the target. This
#   difference tends to exaggerate when N increases
# * contrary to that, DFO-LSA is much better at reuse of previously computed
#   points. Thus, DFO-LSA needs several times less target  evaluations  than
#   2PS, usually about 3-4 times less (this ratio seems to be more  or  less
#   constant independently of N).
# 
# The summary is that:
# * for  expensive  targets DFO-LSA is much more efficient than 2PS  because
#   it reuses previously computed target values as much as possible.
# * however, DFO-LSA has little parallelism potential because  (unlike  2PS)
#   it  does  not  evaluate the target  in several points simultaneously and
#   independently
# * additionally, because DFO-LSA performs many times more  iterations  than
#   2PS, iteration overhead (working set updates and matrix  inversions)  is
#   an issue here. For inexpensive targets it is possible for DFO-LSA to  be
#   outperformed by 2PS merely because of the linear algebra cost.
# 
# RESTARTS
# 
# Restarts is a strategy used to deal with random and deterministic noise in
# the target/constraints.
# 
# Noise in the objective function can be random, arising from measurement or
# simulation   uncertainty,  or  deterministic,   resulting   from   complex
# underlying phenomena like numerical errors or branches in the target.  Its
# influence is especially high at last stages of the optimization, when  all
# computations are performed with small values of a trust radius.
# 
# Restarts allow the optimization algorithm to be robust against both  types
# of noise by temporarily increasing a trust radius in order  to  capture  a
# global structure of the target and avoid being trapped  by  noise-produced
# local features.
# 
# A restart is usually performed when the stopping criteria  are  triggered.
# Instead of stopping, the solver increases  trust  radius  to  its  initial
# value and tries to rebuild a model.
# 
# If you decide to optimize with restarts,  it  is  recommended  to  perform
# a small amount of restarts, up to 5. Generally, restarts do not allow  one
# to completely solve the problem of noise, but still   it  is  possible  to
# achieve some additional progress.
# 
#   -- ALGLIB --
#      Copyright 15.10.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.nlssetalgodfolsa(state, nnoisyrestarts)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.nlssetalgodfolsa(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.nlsstate
          nnoisyrestarts: int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_nlssetbc'></a><h3 class=pageheader><code>nlssetbc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets box constraints
# 
# Box constraints are inactive by default (after initial creation). They are
# preserved until explicitly turned off with another SetBC() call.
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     BndL    -   lower bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 very small number or -INF (the latter is recommended).
#     BndU    -   upper bounds, array[N].
#                 If some (all) variables are unbounded, you may specify
#                 very large number or +INF (the latter is recommended).
# 
# NOTE 1: it is possible to specify BndL[i]=BndU[i]. In this case I-th
# variable will be &quot;frozen&quot; at X[i]=BndL[i]=BndU[i].
# 
# NOTE 2: unless  explicitly  mentioned  in  the   specific   NLS  algorithm
#         description, the following holds:
#         * box constraints are always satisfied exactly
#         * the target is NOT evaluated outside of the box-constrained area
# 
#   -- ALGLIB --
#      Copyright 15.10.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.nlssetbc(state, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.nlsstate
          bndl:       1D array/list of float
          bndu:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_nlssetcond'></a><h3 class=pageheader><code>nlssetcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping conditions
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     EpsX    -   stop when the scaled trust region radius is  smaller  than
#                 EpsX.
#     MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
#                 iterations   is    unlimited.
# 
# Passing  EpsX=0  and  MaxIts=0  (simultaneously)  will  lead  to automatic
# stopping criterion selection (small EpsX).
# 
#   -- ALGLIB --
#      Copyright 15.10.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.nlssetcond(state, epsx, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.nlsstate
          epsx:       float
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_nlssetscale'></a><h3 class=pageheader><code>nlssetscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets variable scales
# 
# ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
# size and gradient are scaled before comparison with tolerances).  Scale of
# the I-th variable is a translation invariant measure of:
# a) &quot;how large&quot; the variable is
# b) how large the step should be to make significant changes in the function
# 
# Generally, scale is NOT considered to be a  form  of  preconditioner.  But
# derivative-free optimizers often use scaling matrix both  in  the stopping
# condition tests and as a preconditioner.
# 
# Proper scaling is very important for the algorithm performance. It is less
# important for the quality of results, but still has some influence (it  is
# easier  to  converge  when  variables  are  properly  scaled, so premature
# stopping is possible when very badly scalled variables are  combined  with
# relaxed stopping conditions).
# 
# INPUT PARAMETERS:
#     State   -   structure stores algorithm state
#     S       -   array[N], non-zero scaling coefficients
#                 S[i] may be negative, sign doesn't matter.
# 
#   -- ALGLIB --
#      Copyright 15.10.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.nlssetscale(state, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.nlsstate
          s:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_nlssetxrep'></a><h3 class=pageheader><code>nlssetxrep</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function turns on/off reporting.
# 
# INPUT PARAMETERS:
#     State   -   structure which stores algorithm state
#     NeedXRep-   whether iteration reports are needed or not
# 
# If NeedXRep is True, algorithm will call rep() callback function if  it is
# provided to NLSOptimize().
# 
#   -- ALGLIB --
#      Copyright 15.10.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.nlssetxrep(state, needxrep)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.nlsstate
          needxrep:   bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_normaldistr></a><h2 class=pageheader><code>normaldistr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_bivariatenormalcdf' class=toc>bivariatenormalcdf</a><br>
<a href='#sub_bivariatenormalpdf' class=toc>bivariatenormalpdf</a><br>
<a href='#sub_errorfunction' class=toc>errorfunction</a><br>
<a href='#sub_errorfunctionc' class=toc>errorfunctionc</a><br>
<a href='#sub_inverf' class=toc>inverf</a><br>
<a href='#sub_invnormalcdf' class=toc>invnormalcdf</a><br>
<a href='#sub_invnormaldistribution' class=toc>invnormaldistribution</a><br>
<a href='#sub_normalcdf' class=toc>normalcdf</a><br>
<a href='#sub_normaldistribution' class=toc>normaldistribution</a><br>
<a href='#sub_normalpdf' class=toc>normalpdf</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_bivariatenormalcdf'></a><h3 class=pageheader><code>bivariatenormalcdf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Bivariate normal CDF
# 
# Returns the area under the bivariate Gaussian  PDF  with  correlation
# parameter equal to Rho, integrated from minus infinity to (x,y):
# 
# 
#                                           x      y
#                                           -      -
#                             1            | |    | |
#     bvn(x,y,rho) = -------------------   |      |   f(u,v,rho)*du*dv
#                     2pi*sqrt(1-rho^2)  | |    | |
#                                         -      -
#                                        -INF   -INF
# 
# 
# where
# 
#                       (    u^2 - 2*rho*u*v + v^2  )
#     f(u,v,rho)   = exp( - ----------------------- )
#                       (        2*(1-rho^2)        )
# 
# 
# with -1&lt;rho&lt;+1 and arbitrary x, y.
# 
# This subroutine uses high-precision approximation scheme proposed  by
# Alan Genz in &quot;Numerical  Computation  of  Rectangular  Bivariate  and
# Trivariate Normal and  t  probabilities&quot;,  which  computes  CDF  with
# absolute error roughly equal to 1e-14.
# 
# This function won't fail as long as Rho is in (-1,+1) range.
# 
#   -- ALGLIB --
#      Copyright 15.11.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.bivariatenormalcdf(x, y, rho)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
          y:          float
          rho:        float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_bivariatenormalpdf'></a><h3 class=pageheader><code>bivariatenormalpdf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Bivariate normal PDF
# 
# Returns probability density function of the bivariate  Gaussian  with
# correlation parameter equal to Rho:
# 
#                          1              (    x^2 - 2*rho*x*y + y^2  )
#     f(x,y,rho) = ----------------- * exp( - ----------------------- )
#                  2pi*sqrt(1-rho^2)      (        2*(1-rho^2)        )
# 
# 
# with -1&lt;rho&lt;+1 and arbitrary x, y.
# 
# This function won't fail as long as Rho is in (-1,+1) range.
# 
#   -- ALGLIB --
#      Copyright 15.11.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.bivariatenormalpdf(x, y, rho)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
          y:          float
          rho:        float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_errorfunction'></a><h3 class=pageheader><code>errorfunction</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Error function
# 
# The integral is
# 
#                           x
#                            -
#                 2         | |          2
#   erf(x)  =  --------     |    exp( - t  ) dt.
#              sqrt(pi)   | |
#                          -
#                           0
# 
# For 0 &lt;= |x| &lt; 1, erf(x) = x * P4(x**2)/Q5(x**2); otherwise
# erf(x) = 1 - erfc(x).
# 
# 
# ACCURACY:
# 
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE      0,1         30000       3.7e-16     1.0e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1988, 1992, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.errorfunction(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_errorfunctionc'></a><h3 class=pageheader><code>errorfunctionc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Complementary error function
# 
#  1 - erf(x) =
# 
#                           inf.
#                             -
#                  2         | |          2
#   erfc(x)  =  --------     |    exp( - t  ) dt
#               sqrt(pi)   | |
#                           -
#                            x
# 
# 
# For small x, erfc(x) = 1 - erf(x); otherwise rational
# approximations are computed.
# 
# 
# ACCURACY:
# 
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE      0,26.6417   30000       5.7e-14     1.5e-14
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1988, 1992, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.errorfunctionc(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_inverf'></a><h3 class=pageheader><code>inverf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inverse of the error function
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1988, 1992, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.inverf(e)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     e:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_invnormalcdf'></a><h3 class=pageheader><code>invnormalcdf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inverse of Normal CDF
# 
# Returns the argument, x, for which the area under the
# Gaussian probability density function (integrated from
# minus infinity to x) is equal to y.
# 
# 
# For small arguments 0 &lt; y &lt; exp(-2), the program computes
# z = sqrt( -2.0 * log(y) );  then the approximation is
# x = z - log(z)/z  - (1/z) P(1/z) / Q(1/z).
# There are two rational functions P/Q, one for 0 &lt; y &lt; exp(-32)
# and the other for y up to exp(-2).  For larger arguments,
# w = y - 0.5, and  x/sqrt(2pi) = w + w**3 R(w**2)/S(w**2)).
# 
# ACCURACY:
# 
#                      Relative error:
# arithmetic   domain        # trials      peak         rms
#    IEEE     0.125, 1        20000       7.2e-16     1.3e-16
#    IEEE     3e-308, 0.135   50000       4.6e-16     9.8e-17
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1988, 1992, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.invnormalcdf(y0)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     y0:         float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_invnormaldistribution'></a><h3 class=pageheader><code>invnormaldistribution</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Same as invnormalcdf(), deprecated name
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.invnormaldistribution(y0)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     y0:         float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_normalcdf'></a><h3 class=pageheader><code>normalcdf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Normal distribution CDF
# 
# Returns the area under the Gaussian probability density
# function, integrated from minus infinity to x:
# 
#                            x
#                             -
#                   1        | |          2
#    ndtr(x)  = ---------    |    exp( - t /2 ) dt
#               sqrt(2pi)  | |
#                           -
#                          -inf.
# 
#             =  ( 1 + erf(z) ) / 2
#             =  erfc(z) / 2
# 
# where z = x/sqrt(2). Computation is via the functions
# erf and erfc.
# 
# 
# ACCURACY:
# 
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE     -13,0        30000       3.4e-14     6.7e-15
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1988, 1992, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.normalcdf(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_normaldistribution'></a><h3 class=pageheader><code>normaldistribution</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Same as normalcdf(), obsolete name.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.normaldistribution(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_normalpdf'></a><h3 class=pageheader><code>normalpdf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Normal distribution PDF
# 
# Returns Gaussian probability density function:
# 
#                1
#    f(x)  = --------- * exp(-x^2/2)
#            sqrt(2pi)
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1988, 1992, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.normalpdf(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_normestimator></a><h2 class=pageheader><code>normestimator</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_normestimatorcreate' class=toc>normestimatorcreate</a><br>
<a href='#sub_normestimatorestimatesparse' class=toc>normestimatorestimatesparse</a><br>
<a href='#sub_normestimatorresults' class=toc>normestimatorresults</a><br>
<a href='#sub_normestimatorsetseed' class=toc>normestimatorsetseed</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_normestimatorcreate'></a><h3 class=pageheader><code>normestimatorcreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This procedure initializes matrix norm estimator.
# 
# USAGE:
# 1. User initializes algorithm state with NormEstimatorCreate() call
# 2. User calls NormEstimatorEstimateSparse() (or NormEstimatorIteration())
# 3. User calls NormEstimatorResults() to get solution.
# 
# INPUT PARAMETERS:
#     M       -   number of rows in the matrix being estimated, M&gt;0
#     N       -   number of columns in the matrix being estimated, N&gt;0
#     NStart  -   number of random starting vectors
#                 recommended value - at least 5.
#     NIts    -   number of iterations to do with best starting vector
#                 recommended value - at least 5.
# 
# OUTPUT PARAMETERS:
#     State   -   structure which stores algorithm state
# 
# 
# NOTE: this algorithm is effectively deterministic, i.e. it always  returns
# same result when repeatedly called for the same matrix. In fact, algorithm
# uses randomized starting vectors, but internal  random  numbers  generator
# always generates same sequence of the random values (it is a  feature, not
# bug).
# 
# Algorithm can be made non-deterministic with NormEstimatorSetSeed(0) call.
# 
#   -- ALGLIB --
#      Copyright 06.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.normestimatorcreate(m, n, nstart, nits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          nstart:     int
          nits:       int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.normestimatorstate

</div></pre>
<a name='sub_normestimatorestimatesparse'></a><h3 class=pageheader><code>normestimatorestimatesparse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function estimates norm of the sparse M*N matrix A.
# 
# INPUT PARAMETERS:
#     State       -   norm estimator state, must be initialized with a  call
#                     to NormEstimatorCreate()
#     A           -   sparse M*N matrix, must be converted to CRS format
#                     prior to calling this function.
# 
# After this function  is  over  you can call NormEstimatorResults() to get
# estimate of the norm(A).
# 
#   -- ALGLIB --
#      Copyright 06.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.normestimatorestimatesparse(state, a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.normestimatorstate
          a:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_normestimatorresults'></a><h3 class=pageheader><code>normestimatorresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Matrix norm estimation results
# 
# INPUT PARAMETERS:
#     State   -   algorithm state
# 
# OUTPUT PARAMETERS:
#     Nrm     -   estimate of the matrix norm, Nrm&gt;=0
# 
#   -- ALGLIB --
#      Copyright 06.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   nrm = xalglib.normestimatorresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.normestimatorstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  nrm:        float

</div></pre>
<a name='sub_normestimatorsetseed'></a><h3 class=pageheader><code>normestimatorsetseed</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function changes seed value used by algorithm. In some cases we  need
# deterministic processing, i.e. subsequent calls must return equal results,
# in other cases we need non-deterministic algorithm which returns different
# results for the same matrix on every pass.
# 
# Setting zero seed will lead to non-deterministic algorithm, while non-zero
# value will make our algorithm deterministic.
# 
# INPUT PARAMETERS:
#     State       -   norm estimator state, must be initialized with a  call
#                     to NormEstimatorCreate()
#     SeedVal     -   seed value, &gt;=0. Zero value = non-deterministic algo.
# 
#   -- ALGLIB --
#      Copyright 06.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.normestimatorsetseed(state, seedval)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.normestimatorstate
          seedval:    int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_odesolver></a><h2 class=pageheader><code>odesolver</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_odesolverresults' class=toc>odesolverresults</a><br>
<a href='#sub_odesolverrkck' class=toc>odesolverrkck</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_odesolverresults'></a><h3 class=pageheader><code>odesolverresults</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# ODE solver results
# 
# Called after OdeSolverIteration returned False.
# 
# INPUT PARAMETERS:
#     State   -   algorithm state (used by OdeSolverIteration).
# 
# OUTPUT PARAMETERS:
#     M       -   number of tabulated values, M&gt;=1
#     XTbl    -   array[0..M-1], values of X
#     YTbl    -   array[0..M-1,0..N-1], values of Y in X[i]
#     Rep     -   solver report:
#                 * Rep.TerminationType completetion code:
#                     * -2    X is not ordered  by  ascending/descending  or
#                             there are non-distinct X[],  i.e.  X[i]=X[i+1]
#                     * -1    incorrect parameters were specified
#                     *  1    task has been solved
#                 * Rep.NFEV contains number of function calculations
# 
#   -- ALGLIB --
#      Copyright 01.09.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   m, xtbl, ytbl, rep = xalglib.odesolverresults(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.odesolverstate
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  m:          int
          xtbl:       1D array/list of float
          ytbl:       2D array/list of float
          rep:        class xalglib.odesolverreport

</div></pre>
<a name='sub_odesolverrkck'></a><h3 class=pageheader><code>odesolverrkck</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Cash-Karp adaptive ODE solver.
# 
# This subroutine solves ODE  Y'=f(Y,x)  with  initial  conditions  Y(xs)=Ys
# (here Y may be single variable or vector of N variables).
# 
# INPUT PARAMETERS:
#     Y       -   initial conditions, array[0..N-1].
#                 contains values of Y[] at X[0]
#     N       -   system size
#     X       -   points at which Y should be tabulated, array[0..M-1]
#                 integrations starts at X[0], ends at X[M-1],  intermediate
#                 values at X[i] are returned too.
#                 SHOULD BE ORDERED BY ASCENDING OR BY DESCENDING!
#     M       -   number of intermediate points + first point + last point:
#                 * M&gt;2 means that you need both Y(X[M-1]) and M-2 values at
#                   intermediate points
#                 * M=2 means that you want just to integrate from  X[0]  to
#                   X[1] and don't interested in intermediate values.
#                 * M=1 means that you don't want to integrate :)
#                   it is degenerate case, but it will be handled correctly.
#                 * M&lt;1 means error
#     Eps     -   tolerance (absolute/relative error on each  step  will  be
#                 less than Eps). When passing:
#                 * Eps&gt;0, it means desired ABSOLUTE error
#                 * Eps&lt;0, it means desired RELATIVE error.  Relative errors
#                   are calculated with respect to maximum values of  Y seen
#                   so far. Be careful to use this criterion  when  starting
#                   from Y[] that are close to zero.
#     H       -   initial  step  lenth,  it  will  be adjusted automatically
#                 after the first  step.  If  H=0,  step  will  be  selected
#                 automatically  (usualy  it  will  be  equal  to  0.001  of
#                 min(x[i]-x[j])).
# 
# OUTPUT PARAMETERS
#     State   -   structure which stores algorithm state between  subsequent
#                 calls of OdeSolverIteration. Used for reverse communication.
#                 This structure should be passed  to the OdeSolverIteration
#                 subroutine.
# 
# SEE ALSO
#     AutoGKSmoothW, AutoGKSingular, AutoGKIteration, AutoGKResults.
# 
# 
#   -- ALGLIB --
#      Copyright 01.09.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.odesolverrkck(y, n, x, m, eps, h)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.odesolverrkck(y, x, eps, h)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     y:          1D array/list of float
          n:          int
          x:          1D array/list of float
          m:          int
          eps:        float
          h:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.odesolverstate

</div></pre>
<a name=unit_opts></a><h2 class=pageheader><code>opts</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_lptestproblemcreate' class=toc>lptestproblemcreate</a><br>
<a href='#sub_lptestproblemgetm' class=toc>lptestproblemgetm</a><br>
<a href='#sub_lptestproblemgetn' class=toc>lptestproblemgetn</a><br>
<a href='#sub_lptestproblemgettargetf' class=toc>lptestproblemgettargetf</a><br>
<a href='#sub_lptestproblemhasknowntarget' class=toc>lptestproblemhasknowntarget</a><br>
<a href='#sub_lptestproblemsetbc' class=toc>lptestproblemsetbc</a><br>
<a href='#sub_lptestproblemsetcost' class=toc>lptestproblemsetcost</a><br>
<a href='#sub_lptestproblemsetlc2' class=toc>lptestproblemsetlc2</a><br>
<a href='#sub_lptestproblemsetscale' class=toc>lptestproblemsetscale</a><br>
<a href='#sub_qpxproblemaddqc2' class=toc>qpxproblemaddqc2</a><br>
<a href='#sub_qpxproblemcreate' class=toc>qpxproblemcreate</a><br>
<a href='#sub_qpxproblemgetbc' class=toc>qpxproblemgetbc</a><br>
<a href='#sub_qpxproblemgetinitialpoint' class=toc>qpxproblemgetinitialpoint</a><br>
<a href='#sub_qpxproblemgetlc2' class=toc>qpxproblemgetlc2</a><br>
<a href='#sub_qpxproblemgetlinearterm' class=toc>qpxproblemgetlinearterm</a><br>
<a href='#sub_qpxproblemgetmcc' class=toc>qpxproblemgetmcc</a><br>
<a href='#sub_qpxproblemgetmlc' class=toc>qpxproblemgetmlc</a><br>
<a href='#sub_qpxproblemgetmqc' class=toc>qpxproblemgetmqc</a><br>
<a href='#sub_qpxproblemgetn' class=toc>qpxproblemgetn</a><br>
<a href='#sub_qpxproblemgetorigin' class=toc>qpxproblemgetorigin</a><br>
<a href='#sub_qpxproblemgetqc2i' class=toc>qpxproblemgetqc2i</a><br>
<a href='#sub_qpxproblemgetquadraticterm' class=toc>qpxproblemgetquadraticterm</a><br>
<a href='#sub_qpxproblemgetscale' class=toc>qpxproblemgetscale</a><br>
<a href='#sub_qpxproblemgettotalconstraints' class=toc>qpxproblemgettotalconstraints</a><br>
<a href='#sub_qpxproblemhasinitialpoint' class=toc>qpxproblemhasinitialpoint</a><br>
<a href='#sub_qpxproblemhasorigin' class=toc>qpxproblemhasorigin</a><br>
<a href='#sub_qpxproblemhasquadraticterm' class=toc>qpxproblemhasquadraticterm</a><br>
<a href='#sub_qpxproblemhasscale' class=toc>qpxproblemhasscale</a><br>
<a href='#sub_qpxproblemisquadraticobjective' class=toc>qpxproblemisquadraticobjective</a><br>
<a href='#sub_qpxproblemsetbc' class=toc>qpxproblemsetbc</a><br>
<a href='#sub_qpxproblemsetinitialpoint' class=toc>qpxproblemsetinitialpoint</a><br>
<a href='#sub_qpxproblemsetlc2' class=toc>qpxproblemsetlc2</a><br>
<a href='#sub_qpxproblemsetlinearterm' class=toc>qpxproblemsetlinearterm</a><br>
<a href='#sub_qpxproblemsetorigin' class=toc>qpxproblemsetorigin</a><br>
<a href='#sub_qpxproblemsetquadraticterm' class=toc>qpxproblemsetquadraticterm</a><br>
<a href='#sub_qpxproblemsetscale' class=toc>qpxproblemsetscale</a><br>
<a href='#sub_xdbgminlpcreatefromtestproblem' class=toc>xdbgminlpcreatefromtestproblem</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_lptestproblemcreate'></a><h3 class=pageheader><code>lptestproblemcreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Initialize test LP problem.
# 
# This function is intended for internal use by ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 20.07.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.lptestproblemcreate(n, hasknowntarget, targetf)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          hasknowntarget: bool
          targetf:    float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          class xalglib.lptestproblem

</div></pre>
<a name='sub_lptestproblemgetm'></a><h3 class=pageheader><code>lptestproblemgetm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Query test problem info
# 
# This function is intended for internal use by ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 20.07.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.lptestproblemgetm(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.lptestproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_lptestproblemgetn'></a><h3 class=pageheader><code>lptestproblemgetn</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Query test problem info
# 
# This function is intended for internal use by ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 20.07.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.lptestproblemgetn(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.lptestproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_lptestproblemgettargetf'></a><h3 class=pageheader><code>lptestproblemgettargetf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Query test problem info
# 
# This function is intended for internal use by ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 20.07.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.lptestproblemgettargetf(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.lptestproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_lptestproblemhasknowntarget'></a><h3 class=pageheader><code>lptestproblemhasknowntarget</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Query test problem info
# 
# This function is intended for internal use by ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 20.07.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.lptestproblemhasknowntarget(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.lptestproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_lptestproblemsetbc'></a><h3 class=pageheader><code>lptestproblemsetbc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Set box constraints for test LP problem
# 
# This function is intended for internal use by ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 20.07.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lptestproblemsetbc(p, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.lptestproblem
          bndl:       1D array/list of float
          bndu:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lptestproblemsetcost'></a><h3 class=pageheader><code>lptestproblemsetcost</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Set cost for test LP problem
# 
# This function is intended for internal use by ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 20.07.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lptestproblemsetcost(p, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.lptestproblem
          c:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lptestproblemsetlc2'></a><h3 class=pageheader><code>lptestproblemsetlc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Set box constraints for test LP problem
# 
# This function is intended for internal use by ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 20.07.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lptestproblemsetlc2(p, a, al, au, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.lptestproblem
          a:          class xalglib.sparsematrix
          al:         1D array/list of float
          au:         1D array/list of float
          m:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_lptestproblemsetscale'></a><h3 class=pageheader><code>lptestproblemsetscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Set scale for test LP problem
# 
# This function is intended for internal use by ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 20.07.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.lptestproblemsetscale(p, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.lptestproblem
          s:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_qpxproblemaddqc2'></a><h3 class=pageheader><code>qpxproblemaddqc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Append two-sided quadratic constraint, same format as minqpaddqc2()
# 
#   -- ALGLIB --
#      Copyright 19.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.qpxproblemaddqc2(p, q, isupper, b, cl, cu, applyorigin)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
          q:          class xalglib.sparsematrix
          isupper:    bool
          b:          1D array/list of float
          cl:         float
          cu:         float
          applyorigin: bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_qpxproblemcreate'></a><h3 class=pageheader><code>qpxproblemcreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Initialize QPX problem.
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.qpxproblemcreate(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          class xalglib.qpxproblem

</div></pre>
<a name='sub_qpxproblemgetbc'></a><h3 class=pageheader><code>qpxproblemgetbc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Get box constraints
# 
#   -- ALGLIB --
#      Copyright 20.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   bndl, bndu = xalglib.qpxproblemgetbc(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  bndl:       1D array/list of float
          bndu:       1D array/list of float

</div></pre>
<a name='sub_qpxproblemgetinitialpoint'></a><h3 class=pageheader><code>qpxproblemgetinitialpoint</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Get initial point
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x0 = xalglib.qpxproblemgetinitialpoint(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x0:         1D array/list of float

</div></pre>
<a name='sub_qpxproblemgetlc2'></a><h3 class=pageheader><code>qpxproblemgetlc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Get linear constraints
# 
#   -- ALGLIB --
#      Copyright 20.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a, al, au, m = xalglib.qpxproblemgetlc2(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          class xalglib.sparsematrix
          al:         1D array/list of float
          au:         1D array/list of float
          m:          int

</div></pre>
<a name='sub_qpxproblemgetlinearterm'></a><h3 class=pageheader><code>qpxproblemgetlinearterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Get linear term
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.qpxproblemgetlinearterm(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          1D array/list of float

</div></pre>
<a name='sub_qpxproblemgetmcc'></a><h3 class=pageheader><code>qpxproblemgetmcc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Get conic constraints count
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.qpxproblemgetmcc(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_qpxproblemgetmlc'></a><h3 class=pageheader><code>qpxproblemgetmlc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Get linear constraints count
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.qpxproblemgetmlc(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_qpxproblemgetmqc'></a><h3 class=pageheader><code>qpxproblemgetmqc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Get quadratic constraints count
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.qpxproblemgetmqc(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_qpxproblemgetn'></a><h3 class=pageheader><code>qpxproblemgetn</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Get variables count
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.qpxproblemgetn(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_qpxproblemgetorigin'></a><h3 class=pageheader><code>qpxproblemgetorigin</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Get origin
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xorigin = xalglib.qpxproblemgetorigin(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  xorigin:    1D array/list of float

</div></pre>
<a name='sub_qpxproblemgetqc2i'></a><h3 class=pageheader><code>qpxproblemgetqc2i</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Get IDX-th two-sided quadratic constraint, same format as minqpaddqc2(),
# except for the fact that it always returns isUpper=False, even if the
# original matrix was an upper triangular one.
# 
# NOTE: this function is not optimized for big matrices. Whilst still having
#       O(max(N,Nonzeros)) running time, it may  be  somewhat  slow  due  to
#       dynamic structures being used internally.
# 
# 
#   -- ALGLIB --
#      Copyright 19.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   q, isupper, b, cl, cu, applyorigin = xalglib.qpxproblemgetqc2i(p, idx)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
          idx:        int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  q:          class xalglib.sparsematrix
          isupper:    bool
          b:          1D array/list of float
          cl:         float
          cu:         float
          applyorigin: bool

</div></pre>
<a name='sub_qpxproblemgetquadraticterm'></a><h3 class=pageheader><code>qpxproblemgetquadraticterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Get quadratic term, returns zero matrix if no quadratic term is present
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   q, isupper = xalglib.qpxproblemgetquadraticterm(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  q:          class xalglib.sparsematrix
          isupper:    bool

</div></pre>
<a name='sub_qpxproblemgetscale'></a><h3 class=pageheader><code>qpxproblemgetscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Get scale
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.qpxproblemgetscale(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          1D array/list of float

</div></pre>
<a name='sub_qpxproblemgettotalconstraints'></a><h3 class=pageheader><code>qpxproblemgettotalconstraints</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Get total constraints count
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.qpxproblemgettotalconstraints(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_qpxproblemhasinitialpoint'></a><h3 class=pageheader><code>qpxproblemhasinitialpoint</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Get initial point presence
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.qpxproblemhasinitialpoint(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_qpxproblemhasorigin'></a><h3 class=pageheader><code>qpxproblemhasorigin</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Get origin presence
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.qpxproblemhasorigin(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_qpxproblemhasquadraticterm'></a><h3 class=pageheader><code>qpxproblemhasquadraticterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Returns False if no quadratic term was specified, or quadratic term is
# numerically zero.
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.qpxproblemhasquadraticterm(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_qpxproblemhasscale'></a><h3 class=pageheader><code>qpxproblemhasscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Get scale presence
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.qpxproblemhasscale(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_qpxproblemisquadraticobjective'></a><h3 class=pageheader><code>qpxproblemisquadraticobjective</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Returns objective type: True for zero/linear/constant.
# 
# Present version does not return False.
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.qpxproblemisquadraticobjective(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_qpxproblemsetbc'></a><h3 class=pageheader><code>qpxproblemsetbc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Set box constraints
# 
#   -- ALGLIB --
#      Copyright 20.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.qpxproblemsetbc(p, bndl, bndu)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
          bndl:       1D array/list of float
          bndu:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_qpxproblemsetinitialpoint'></a><h3 class=pageheader><code>qpxproblemsetinitialpoint</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Set initial point
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.qpxproblemsetinitialpoint(p, x0)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
          x0:         1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_qpxproblemsetlc2'></a><h3 class=pageheader><code>qpxproblemsetlc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Set linear constraints
# 
#   -- ALGLIB --
#      Copyright 20.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.qpxproblemsetlc2(p, a, al, au, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
          a:          class xalglib.sparsematrix
          al:         1D array/list of float
          au:         1D array/list of float
          m:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_qpxproblemsetlinearterm'></a><h3 class=pageheader><code>qpxproblemsetlinearterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Set linear term
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.qpxproblemsetlinearterm(p, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
          c:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_qpxproblemsetorigin'></a><h3 class=pageheader><code>qpxproblemsetorigin</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Set origin
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.qpxproblemsetorigin(p, xorigin)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
          xorigin:    1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_qpxproblemsetquadraticterm'></a><h3 class=pageheader><code>qpxproblemsetquadraticterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Set quadratic term; Q can be in any sparse matrix format.
# 
# Only one triangle (lower or upper) is referenced by this function.
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.qpxproblemsetquadraticterm(p, q, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
          q:          class xalglib.sparsematrix
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_qpxproblemsetscale'></a><h3 class=pageheader><code>qpxproblemsetscale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Set scale
# 
#   -- ALGLIB --
#      Copyright 25.08.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.qpxproblemsetscale(p, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.qpxproblem
          s:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> p
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_xdbgminlpcreatefromtestproblem'></a><h3 class=pageheader><code>xdbgminlpcreatefromtestproblem</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is internal function intended to  be  used  only  by  ALGLIB  itself.
# Although for technical reasons it is made publicly available (and has  its
# own manual entry), you should never call it.
# 
#   -- ALGLIB --
#      Copyright 11.01.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.xdbgminlpcreatefromtestproblem(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.lptestproblem
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.minlpstate

</div></pre>
<a name=unit_ortfac></a><h2 class=pageheader><code>ortfac</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cmatrixlq' class=toc>cmatrixlq</a><br>
<a href='#sub_cmatrixlqunpackl' class=toc>cmatrixlqunpackl</a><br>
<a href='#sub_cmatrixlqunpackq' class=toc>cmatrixlqunpackq</a><br>
<a href='#sub_cmatrixqr' class=toc>cmatrixqr</a><br>
<a href='#sub_cmatrixqrunpackq' class=toc>cmatrixqrunpackq</a><br>
<a href='#sub_cmatrixqrunpackr' class=toc>cmatrixqrunpackr</a><br>
<a href='#sub_hmatrixtd' class=toc>hmatrixtd</a><br>
<a href='#sub_hmatrixtdunpackq' class=toc>hmatrixtdunpackq</a><br>
<a href='#sub_rmatrixbd' class=toc>rmatrixbd</a><br>
<a href='#sub_rmatrixbdmultiplybyp' class=toc>rmatrixbdmultiplybyp</a><br>
<a href='#sub_rmatrixbdmultiplybyq' class=toc>rmatrixbdmultiplybyq</a><br>
<a href='#sub_rmatrixbdunpackdiagonals' class=toc>rmatrixbdunpackdiagonals</a><br>
<a href='#sub_rmatrixbdunpackpt' class=toc>rmatrixbdunpackpt</a><br>
<a href='#sub_rmatrixbdunpackq' class=toc>rmatrixbdunpackq</a><br>
<a href='#sub_rmatrixhessenberg' class=toc>rmatrixhessenberg</a><br>
<a href='#sub_rmatrixhessenbergunpackh' class=toc>rmatrixhessenbergunpackh</a><br>
<a href='#sub_rmatrixhessenbergunpackq' class=toc>rmatrixhessenbergunpackq</a><br>
<a href='#sub_rmatrixlq' class=toc>rmatrixlq</a><br>
<a href='#sub_rmatrixlqunpackl' class=toc>rmatrixlqunpackl</a><br>
<a href='#sub_rmatrixlqunpackq' class=toc>rmatrixlqunpackq</a><br>
<a href='#sub_rmatrixqr' class=toc>rmatrixqr</a><br>
<a href='#sub_rmatrixqrunpackq' class=toc>rmatrixqrunpackq</a><br>
<a href='#sub_rmatrixqrunpackr' class=toc>rmatrixqrunpackr</a><br>
<a href='#sub_smatrixtd' class=toc>smatrixtd</a><br>
<a href='#sub_smatrixtdunpackq' class=toc>smatrixtdunpackq</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_cmatrixlq'></a><h3 class=pageheader><code>cmatrixlq</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# LQ decomposition of a rectangular complex matrix of size MxN
# 
# Input parameters:
#     A   -   matrix A whose indexes range within [0..M-1, 0..N-1]
#     M   -   number of rows in matrix A.
#     N   -   number of columns in matrix A.
# 
# Output parameters:
#     A   -   matrices Q and L in compact form
#     Tau -   array of scalar factors which are used to form matrix Q. Array
#             whose indexes range within [0.. Min(M,N)-1]
# 
# Matrix A is represented as A = LQ, where Q is an orthogonal matrix of size
# MxM, L - lower triangular (or lower trapezoid) matrix of size MxN.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- LAPACK routine (version 3.0) --
#      Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
#      Courant Institute, Argonne National Lab, and Rice University
#      September 30, 1994
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   tau = xalglib.cmatrixlq(a, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  tau:        1D array/list of complex

</div></pre>
<a name='sub_cmatrixlqunpackl'></a><h3 class=pageheader><code>cmatrixlqunpackl</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Unpacking of matrix L from the LQ decomposition of a matrix A
# 
# Input parameters:
#     A       -   matrices Q and L in compact form.
#                 Output of CMatrixLQ subroutine.
#     M       -   number of rows in given matrix A. M&gt;=0.
#     N       -   number of columns in given matrix A. N&gt;=0.
# 
# Output parameters:
#     L       -   matrix L, array[0..M-1, 0..N-1].
# 
#   -- ALGLIB routine --
#      17.02.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   l = xalglib.cmatrixlqunpackl(a, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  l:          2D array/list of complex

</div></pre>
<a name='sub_cmatrixlqunpackq'></a><h3 class=pageheader><code>cmatrixlqunpackq</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Partial unpacking of matrix Q from LQ decomposition of a complex matrix A.
# 
# Input parameters:
#     A           -   matrices Q and R in compact form.
#                     Output of CMatrixLQ subroutine .
#     M           -   number of rows in matrix A. M&gt;=0.
#     N           -   number of columns in matrix A. N&gt;=0.
#     Tau         -   scalar factors which are used to form Q.
#                     Output of CMatrixLQ subroutine .
#     QRows       -   required number of rows in matrix Q. N&gt;=QColumns&gt;=0.
# 
# Output parameters:
#     Q           -   first QRows rows of matrix Q.
#                     Array whose index ranges within [0..QRows-1, 0..N-1].
#                     If QRows=0, array isn't changed.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      17.02.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   q = xalglib.cmatrixlqunpackq(a, m, n, tau, qrows)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          m:          int
          n:          int
          tau:        1D array/list of complex
          qrows:      int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  q:          2D array/list of complex

</div></pre>
<a name='sub_cmatrixqr'></a><h3 class=pageheader><code>cmatrixqr</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# QR decomposition of a rectangular complex matrix of size MxN
# 
# Input parameters:
#     A   -   matrix A whose indexes range within [0..M-1, 0..N-1]
#     M   -   number of rows in matrix A.
#     N   -   number of columns in matrix A.
# 
# Output parameters:
#     A   -   matrices Q and R in compact form
#     Tau -   array of scalar factors which are used to form matrix Q. Array
#             whose indexes range within [0.. Min(M,N)-1]
# 
# Matrix A is represented as A = QR, where Q is an orthogonal matrix of size
# MxM, R - upper triangular (or upper trapezoid) matrix of size MxN.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- LAPACK routine (version 3.0) --
#      Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
#      Courant Institute, Argonne National Lab, and Rice University
#      September 30, 1994
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   tau = xalglib.cmatrixqr(a, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  tau:        1D array/list of complex

</div></pre>
<a name='sub_cmatrixqrunpackq'></a><h3 class=pageheader><code>cmatrixqrunpackq</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Partial unpacking of matrix Q from QR decomposition of a complex matrix A.
# 
# Input parameters:
#     A           -   matrices Q and R in compact form.
#                     Output of CMatrixQR subroutine .
#     M           -   number of rows in matrix A. M&gt;=0.
#     N           -   number of columns in matrix A. N&gt;=0.
#     Tau         -   scalar factors which are used to form Q.
#                     Output of CMatrixQR subroutine .
#     QColumns    -   required number of columns in matrix Q. M&gt;=QColumns&gt;=0.
# 
# Output parameters:
#     Q           -   first QColumns columns of matrix Q.
#                     Array whose index ranges within [0..M-1, 0..QColumns-1].
#                     If QColumns=0, array isn't changed.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      17.02.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   q = xalglib.cmatrixqrunpackq(a, m, n, tau, qcolumns)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          m:          int
          n:          int
          tau:        1D array/list of complex
          qcolumns:   int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  q:          2D array/list of complex

</div></pre>
<a name='sub_cmatrixqrunpackr'></a><h3 class=pageheader><code>cmatrixqrunpackr</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Unpacking of matrix R from the QR decomposition of a matrix A
# 
# Input parameters:
#     A       -   matrices Q and R in compact form.
#                 Output of CMatrixQR subroutine.
#     M       -   number of rows in given matrix A. M&gt;=0.
#     N       -   number of columns in given matrix A. N&gt;=0.
# 
# Output parameters:
#     R       -   matrix R, array[0..M-1, 0..N-1].
# 
#   -- ALGLIB routine --
#      17.02.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.cmatrixqrunpackr(a, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          2D array/list of complex

</div></pre>
<a name='sub_hmatrixtd'></a><h3 class=pageheader><code>hmatrixtd</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Reduction of a Hermitian matrix which is given  by  its  higher  or  lower
# triangular part to a real  tridiagonal  matrix  using  unitary  similarity
# transformation: Q'*A*Q = T.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# Input parameters:
#     A       -   matrix to be transformed
#                 array with elements [0..N-1, 0..N-1].
#     N       -   size of matrix A.
#     IsUpper -   storage format. If IsUpper = True, then matrix A is  given
#                 by its upper triangle, and the lower triangle is not  used
#                 and not modified by the algorithm, and vice versa
#                 if IsUpper = False.
# 
# Output parameters:
#     A       -   matrices T and Q in  compact form (see lower)
#     Tau     -   array of factors which are forming matrices H(i)
#                 array with elements [0..N-2].
#     D       -   main diagonal of real symmetric matrix T.
#                 array with elements [0..N-1].
#     E       -   secondary diagonal of real symmetric matrix T.
#                 array with elements [0..N-2].
# 
# 
#   If IsUpper=True, the matrix Q is represented as a product of elementary
#   reflectors
# 
#      Q = H(n-2) . . . H(2) H(0).
# 
#   Each H(i) has the form
# 
#      H(i) = I - tau * v * v'
# 
#   where tau is a complex scalar, and v is a complex vector with
#   v(i+1:n-1) = 0, v(i) = 1, v(0:i-1) is stored on exit in
#   A(0:i-1,i+1), and tau in TAU(i).
# 
#   If IsUpper=False, the matrix Q is represented as a product of elementary
#   reflectors
# 
#      Q = H(0) H(2) . . . H(n-2).
# 
#   Each H(i) has the form
# 
#      H(i) = I - tau * v * v'
# 
#   where tau is a complex scalar, and v is a complex vector with
#   v(0:i) = 0, v(i+1) = 1, v(i+2:n-1) is stored on exit in A(i+2:n-1,i),
#   and tau in TAU(i).
# 
#   The contents of A on exit are illustrated by the following examples
#   with n = 5:
# 
#   if UPLO = 'U':                       if UPLO = 'L':
# 
#     (  d   e   v1  v2  v3 )              (  d                  )
#     (      d   e   v2  v3 )              (  e   d              )
#     (          d   e   v3 )              (  v0  e   d          )
#     (              d   e  )              (  v0  v1  e   d      )
#     (                  d  )              (  v0  v1  v2  e   d  )
# 
# where d and e denote diagonal and off-diagonal elements of T, and vi
# denotes an element of the vector defining H(i).
# 
#   -- LAPACK routine (version 3.0) --
#      Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
#      Courant Institute, Argonne National Lab, and Rice University
#      October 31, 1992
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   tau, d, e = xalglib.hmatrixtd(a, n, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  tau:        1D array/list of complex
          d:          1D array/list of float
          e:          1D array/list of float

</div></pre>
<a name='sub_hmatrixtdunpackq'></a><h3 class=pageheader><code>hmatrixtdunpackq</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Unpacking matrix Q which reduces a Hermitian matrix to a real  tridiagonal
# form.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# Input parameters:
#     A       -   the result of a HMatrixTD subroutine
#     N       -   size of matrix A.
#     IsUpper -   storage format (a parameter of HMatrixTD subroutine)
#     Tau     -   the result of a HMatrixTD subroutine
# 
# Output parameters:
#     Q       -   transformation matrix.
#                 array with elements [0..N-1, 0..N-1].
# 
#   -- ALGLIB --
#      Copyright 2005-2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   q = xalglib.hmatrixtdunpackq(a, n, isupper, tau)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          isupper:    bool
          tau:        1D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  q:          2D array/list of complex

</div></pre>
<a name='sub_rmatrixbd'></a><h3 class=pageheader><code>rmatrixbd</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Reduction of a rectangular matrix to  bidiagonal form
# 
# The algorithm reduces the rectangular matrix A to  bidiagonal form by
# orthogonal transformations P and Q: A = Q*B*(P^T).
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# Input parameters:
#     A       -   source matrix. array[0..M-1, 0..N-1]
#     M       -   number of rows in matrix A.
#     N       -   number of columns in matrix A.
# 
# Output parameters:
#     A       -   matrices Q, B, P in compact form (see below).
#     TauQ    -   scalar factors which are used to form matrix Q.
#     TauP    -   scalar factors which are used to form matrix P.
# 
# The main diagonal and one of the  secondary  diagonals  of  matrix  A  are
# replaced with bidiagonal  matrix  B.  Other  elements  contain  elementary
# reflections which form MxM matrix Q and NxN matrix P, respectively.
# 
# If M&gt;=N, B is the upper  bidiagonal  MxN  matrix  and  is  stored  in  the
# corresponding  elements  of  matrix  A.  Matrix  Q  is  represented  as  a
# product   of   elementary   reflections   Q = H(0)*H(1)*...*H(n-1),  where
# H(i) = 1-tau*v*v'. Here tau is a scalar which is stored  in  TauQ[i],  and
# vector v has the following  structure:  v(0:i-1)=0, v(i)=1, v(i+1:m-1)  is
# stored   in   elements   A(i+1:m-1,i).   Matrix   P  is  as  follows:  P =
# G(0)*G(1)*...*G(n-2), where G(i) = 1 - tau*u*u'. Tau is stored in TauP[i],
# u(0:i)=0, u(i+1)=1, u(i+2:n-1) is stored in elements A(i,i+2:n-1).
# 
# If M&lt;N, B is the  lower  bidiagonal  MxN  matrix  and  is  stored  in  the
# corresponding   elements  of  matrix  A.  Q = H(0)*H(1)*...*H(m-2),  where
# H(i) = 1 - tau*v*v', tau is stored in TauQ, v(0:i)=0, v(i+1)=1, v(i+2:m-1)
# is    stored    in   elements   A(i+2:m-1,i).    P = G(0)*G(1)*...*G(m-1),
# G(i) = 1-tau*u*u', tau is stored in  TauP,  u(0:i-1)=0, u(i)=1, u(i+1:n-1)
# is stored in A(i,i+1:n-1).
# 
# EXAMPLE:
# 
# m=6, n=5 (m &gt; n):               m=5, n=6 (m &lt; n):
# 
# (  d   e   u1  u1  u1 )         (  d   u1  u1  u1  u1  u1 )
# (  v1  d   e   u2  u2 )         (  e   d   u2  u2  u2  u2 )
# (  v1  v2  d   e   u3 )         (  v1  e   d   u3  u3  u3 )
# (  v1  v2  v3  d   e  )         (  v1  v2  e   d   u4  u4 )
# (  v1  v2  v3  v4  d  )         (  v1  v2  v3  e   d   u5 )
# (  v1  v2  v3  v4  v5 )
# 
# Here vi and ui are vectors which form H(i) and G(i), and d and e -
# are the diagonal and off-diagonal elements of matrix B.
# 
#   -- LAPACK routine (version 3.0) --
#      Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
#      Courant Institute, Argonne National Lab, and Rice University
#      September 30, 1994.
#      Sergey Bochkanov, ALGLIB project, translation from FORTRAN to
#      pseudocode, 2007-2010.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   tauq, taup = xalglib.rmatrixbd(a, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  tauq:       1D array/list of float
          taup:       1D array/list of float

</div></pre>
<a name='sub_rmatrixbdmultiplybyp'></a><h3 class=pageheader><code>rmatrixbdmultiplybyp</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Multiplication by matrix P which reduces matrix A to  bidiagonal form.
# 
# The algorithm allows pre- or post-multiply by P or P'.
# 
# Input parameters:
#     QP          -   matrices Q and P in compact form.
#                     Output of RMatrixBD subroutine.
#     M           -   number of rows in matrix A.
#     N           -   number of columns in matrix A.
#     TAUP        -   scalar factors which are used to form P.
#                     Output of RMatrixBD subroutine.
#     Z           -   multiplied matrix.
#                     Array whose indexes range within [0..ZRows-1,0..ZColumns-1].
#     ZRows       -   number of rows in matrix Z. If FromTheRight=False,
#                     ZRows=N, otherwise ZRows can be arbitrary.
#     ZColumns    -   number of columns in matrix Z. If FromTheRight=True,
#                     ZColumns=N, otherwise ZColumns can be arbitrary.
#     FromTheRight -  pre- or post-multiply.
#     DoTranspose -   multiply by P or P'.
# 
# Output parameters:
#     Z - product of Z and P.
#                 Array whose indexes range within [0..ZRows-1,0..ZColumns-1].
#                 If ZRows=0 or ZColumns=0, the array is not modified.
# 
#   -- ALGLIB --
#      2005-2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixbdmultiplybyp(qp, m, n, taup, z, zrows, zcolumns, fromtheright, dotranspose)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     qp:         2D array/list of float
          m:          int
          n:          int
          taup:       1D array/list of float
          z:          2D array/list of float
          zrows:      int
          zcolumns:   int
          fromtheright: bool
          dotranspose: bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> z
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixbdmultiplybyq'></a><h3 class=pageheader><code>rmatrixbdmultiplybyq</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Multiplication by matrix Q which reduces matrix A to  bidiagonal form.
# 
# The algorithm allows pre- or post-multiply by Q or Q'.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# Input parameters:
#     QP          -   matrices Q and P in compact form.
#                     Output of ToBidiagonal subroutine.
#     M           -   number of rows in matrix A.
#     N           -   number of columns in matrix A.
#     TAUQ        -   scalar factors which are used to form Q.
#                     Output of ToBidiagonal subroutine.
#     Z           -   multiplied matrix.
#                     array[0..ZRows-1,0..ZColumns-1]
#     ZRows       -   number of rows in matrix Z. If FromTheRight=False,
#                     ZRows=M, otherwise ZRows can be arbitrary.
#     ZColumns    -   number of columns in matrix Z. If FromTheRight=True,
#                     ZColumns=M, otherwise ZColumns can be arbitrary.
#     FromTheRight -  pre- or post-multiply.
#     DoTranspose -   multiply by Q or Q'.
# 
# Output parameters:
#     Z           -   product of Z and Q.
#                     Array[0..ZRows-1,0..ZColumns-1]
#                     If ZRows=0 or ZColumns=0, the array is not modified.
# 
#   -- ALGLIB --
#      2005-2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rmatrixbdmultiplybyq(qp, m, n, tauq, z, zrows, zcolumns, fromtheright, dotranspose)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     qp:         2D array/list of float
          m:          int
          n:          int
          tauq:       1D array/list of float
          z:          2D array/list of float
          zrows:      int
          zcolumns:   int
          fromtheright: bool
          dotranspose: bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> z
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rmatrixbdunpackdiagonals'></a><h3 class=pageheader><code>rmatrixbdunpackdiagonals</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Unpacking of the main and secondary diagonals of bidiagonal decomposition
# of matrix A.
# 
# Input parameters:
#     B   -   output of RMatrixBD subroutine.
#     M   -   number of rows in matrix B.
#     N   -   number of columns in matrix B.
# 
# Output parameters:
#     IsUpper -   True, if the matrix is upper bidiagonal.
#                 otherwise IsUpper is False.
#     D       -   the main diagonal.
#                 Array whose index ranges within [0..Min(M,N)-1].
#     E       -   the secondary diagonal (upper or lower, depending on
#                 the value of IsUpper).
#                 Array index ranges within [0..Min(M,N)-1], the last
#                 element is not used.
# 
#   -- ALGLIB --
#      2005-2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   isupper, d, e = xalglib.rmatrixbdunpackdiagonals(b, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     b:          2D array/list of float
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  isupper:    bool
          d:          1D array/list of float
          e:          1D array/list of float

</div></pre>
<a name='sub_rmatrixbdunpackpt'></a><h3 class=pageheader><code>rmatrixbdunpackpt</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Unpacking matrix P which reduces matrix A to bidiagonal form.
# The subroutine returns transposed matrix P.
# 
# Input parameters:
#     QP      -   matrices Q and P in compact form.
#                 Output of ToBidiagonal subroutine.
#     M       -   number of rows in matrix A.
#     N       -   number of columns in matrix A.
#     TAUP    -   scalar factors which are used to form P.
#                 Output of ToBidiagonal subroutine.
#     PTRows  -   required number of rows of matrix P^T. N &gt;= PTRows &gt;= 0.
# 
# Output parameters:
#     PT      -   first PTRows columns of matrix P^T
#                 Array[0..PTRows-1, 0..N-1]
#                 If PTRows=0, the array is not modified.
# 
#   -- ALGLIB --
#      2005-2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   pt = xalglib.rmatrixbdunpackpt(qp, m, n, taup, ptrows)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     qp:         2D array/list of float
          m:          int
          n:          int
          taup:       1D array/list of float
          ptrows:     int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  pt:         2D array/list of float

</div></pre>
<a name='sub_rmatrixbdunpackq'></a><h3 class=pageheader><code>rmatrixbdunpackq</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Unpacking matrix Q which reduces a matrix to bidiagonal form.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# Input parameters:
#     QP          -   matrices Q and P in compact form.
#                     Output of ToBidiagonal subroutine.
#     M           -   number of rows in matrix A.
#     N           -   number of columns in matrix A.
#     TAUQ        -   scalar factors which are used to form Q.
#                     Output of ToBidiagonal subroutine.
#     QColumns    -   required number of columns in matrix Q.
#                     M&gt;=QColumns&gt;=0.
# 
# Output parameters:
#     Q           -   first QColumns columns of matrix Q.
#                     Array[0..M-1, 0..QColumns-1]
#                     If QColumns=0, the array is not modified.
# 
#   -- ALGLIB --
#      2005-2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   q = xalglib.rmatrixbdunpackq(qp, m, n, tauq, qcolumns)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     qp:         2D array/list of float
          m:          int
          n:          int
          tauq:       1D array/list of float
          qcolumns:   int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  q:          2D array/list of float

</div></pre>
<a name='sub_rmatrixhessenberg'></a><h3 class=pageheader><code>rmatrixhessenberg</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Reduction of a square matrix to  upper Hessenberg form: Q'*A*Q = H,
# where Q is an orthogonal matrix, H - Hessenberg matrix.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# Input parameters:
#     A       -   matrix A with elements [0..N-1, 0..N-1]
#     N       -   size of matrix A.
# 
# Output parameters:
#     A       -   matrices Q and P in  compact form (see below).
#     Tau     -   array of scalar factors which are used to form matrix Q.
#                 Array whose index ranges within [0..N-2]
# 
# Matrix H is located on the main diagonal, on the lower secondary  diagonal
# and above the main diagonal of matrix A. The elements which are used to
# form matrix Q are situated in array Tau and below the lower secondary
# diagonal of matrix A as follows:
# 
# Matrix Q is represented as a product of elementary reflections
# 
# Q = H(0)*H(2)*...*H(n-2),
# 
# where each H(i) is given by
# 
# H(i) = 1 - tau * v * (v^T)
# 
# where tau is a scalar stored in Tau[I]; v - is a real vector,
# so that v(0:i) = 0, v(i+1) = 1, v(i+2:n-1) stored in A(i+2:n-1,i).
# 
#   -- LAPACK routine (version 3.0) --
#      Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
#      Courant Institute, Argonne National Lab, and Rice University
#      October 31, 1992
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   tau = xalglib.rmatrixhessenberg(a, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  tau:        1D array/list of float

</div></pre>
<a name='sub_rmatrixhessenbergunpackh'></a><h3 class=pageheader><code>rmatrixhessenbergunpackh</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Unpacking matrix H (the result of matrix A reduction to upper Hessenberg form)
# 
# Input parameters:
#     A   -   output of RMatrixHessenberg subroutine.
#     N   -   size of matrix A.
# 
# Output parameters:
#     H   -   matrix H. Array whose indexes range within [0..N-1, 0..N-1].
# 
#   -- ALGLIB --
#      2005-2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   h = xalglib.rmatrixhessenbergunpackh(a, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  h:          2D array/list of float

</div></pre>
<a name='sub_rmatrixhessenbergunpackq'></a><h3 class=pageheader><code>rmatrixhessenbergunpackq</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Unpacking matrix Q which reduces matrix A to upper Hessenberg form
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# Input parameters:
#     A   -   output of RMatrixHessenberg subroutine.
#     N   -   size of matrix A.
#     Tau -   scalar factors which are used to form Q.
#             Output of RMatrixHessenberg subroutine.
# 
# Output parameters:
#     Q   -   matrix Q.
#             Array whose indexes range within [0..N-1, 0..N-1].
# 
#   -- ALGLIB --
#      2005-2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   q = xalglib.rmatrixhessenbergunpackq(a, n, tau)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          tau:        1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  q:          2D array/list of float

</div></pre>
<a name='sub_rmatrixlq'></a><h3 class=pageheader><code>rmatrixlq</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# LQ decomposition of a rectangular matrix of size MxN
# 
# Input parameters:
#     A   -   matrix A whose indexes range within [0..M-1, 0..N-1].
#     M   -   number of rows in matrix A.
#     N   -   number of columns in matrix A.
# 
# Output parameters:
#     A   -   matrices L and Q in compact form (see below)
#     Tau -   array of scalar factors which are used to form
#             matrix Q. Array whose index ranges within [0..Min(M,N)-1].
# 
# Matrix A is represented as A = LQ, where Q is an orthogonal matrix of size
# MxM, L - lower triangular (or lower trapezoid) matrix of size M x N.
# 
# The elements of matrix L are located on and below  the  main  diagonal  of
# matrix A. The elements which are located in Tau array and above  the  main
# diagonal of matrix A are used to form matrix Q as follows:
# 
# Matrix Q is represented as a product of elementary reflections
# 
# Q = H(k-1)*H(k-2)*...*H(1)*H(0),
# 
# where k = min(m,n), and each H(i) is of the form
# 
# H(i) = 1 - tau * v * (v^T)
# 
# where tau is a scalar stored in Tau[I]; v - real vector, so that v(0:i-1)=0,
# v(i) = 1, v(i+1:n-1) stored in A(i,i+1:n-1).
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      17.02.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   tau = xalglib.rmatrixlq(a, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  tau:        1D array/list of float

</div></pre>
<a name='sub_rmatrixlqunpackl'></a><h3 class=pageheader><code>rmatrixlqunpackl</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Unpacking of matrix L from the LQ decomposition of a matrix A
# 
# Input parameters:
#     A       -   matrices Q and L in compact form.
#                 Output of RMatrixLQ subroutine.
#     M       -   number of rows in given matrix A. M&gt;=0.
#     N       -   number of columns in given matrix A. N&gt;=0.
# 
# Output parameters:
#     L       -   matrix L, array[0..M-1, 0..N-1].
# 
#   -- ALGLIB routine --
#      17.02.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   l = xalglib.rmatrixlqunpackl(a, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  l:          2D array/list of float

</div></pre>
<a name='sub_rmatrixlqunpackq'></a><h3 class=pageheader><code>rmatrixlqunpackq</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Partial unpacking of matrix Q from the LQ decomposition of a matrix A
# 
# Input parameters:
#     A       -   matrices L and Q in compact form.
#                 Output of RMatrixLQ subroutine.
#     M       -   number of rows in given matrix A. M&gt;=0.
#     N       -   number of columns in given matrix A. N&gt;=0.
#     Tau     -   scalar factors which are used to form Q.
#                 Output of the RMatrixLQ subroutine.
#     QRows   -   required number of rows in matrix Q. N&gt;=QRows&gt;=0.
# 
# Output parameters:
#     Q       -   first QRows rows of matrix Q. Array whose indexes range
#                 within [0..QRows-1, 0..N-1]. If QRows=0, the array remains
#                 unchanged.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      17.02.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   q = xalglib.rmatrixlqunpackq(a, m, n, tau, qrows)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          m:          int
          n:          int
          tau:        1D array/list of float
          qrows:      int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  q:          2D array/list of float

</div></pre>
<a name='sub_rmatrixqr'></a><h3 class=pageheader><code>rmatrixqr</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# QR decomposition of a rectangular matrix of size MxN
# 
# Input parameters:
#     A   -   matrix A whose indexes range within [0..M-1, 0..N-1].
#     M   -   number of rows in matrix A.
#     N   -   number of columns in matrix A.
# 
# Output parameters:
#     A   -   matrices Q and R in compact form (see below).
#     Tau -   array of scalar factors which are used to form
#             matrix Q. Array whose index ranges within [0.. Min(M-1,N-1)].
# 
# Matrix A is represented as A = QR, where Q is an orthogonal matrix of size
# MxM, R - upper triangular (or upper trapezoid) matrix of size M x N.
# 
# The elements of matrix R are located on and above the main diagonal of
# matrix A. The elements which are located in Tau array and below the main
# diagonal of matrix A are used to form matrix Q as follows:
# 
# Matrix Q is represented as a product of elementary reflections
# 
# Q = H(0)*H(2)*...*H(k-1),
# 
# where k = min(m,n), and each H(i) is in the form
# 
# H(i) = 1 - tau * v * (v^T)
# 
# where tau is a scalar stored in Tau[I]; v - real vector,
# so that v(0:i-1) = 0, v(i) = 1, v(i+1:m-1) stored in A(i+1:m-1,i).
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      17.02.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   tau = xalglib.rmatrixqr(a, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  tau:        1D array/list of float

</div></pre>
<a name='sub_rmatrixqrunpackq'></a><h3 class=pageheader><code>rmatrixqrunpackq</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Partial unpacking of matrix Q from the QR decomposition of a matrix A
# 
# Input parameters:
#     A       -   matrices Q and R in compact form.
#                 Output of RMatrixQR subroutine.
#     M       -   number of rows in given matrix A. M&gt;=0.
#     N       -   number of columns in given matrix A. N&gt;=0.
#     Tau     -   scalar factors which are used to form Q.
#                 Output of the RMatrixQR subroutine.
#     QColumns -  required number of columns of matrix Q. M&gt;=QColumns&gt;=0.
# 
# Output parameters:
#     Q       -   first QColumns columns of matrix Q.
#                 Array whose indexes range within [0..M-1, 0..QColumns-1].
#                 If QColumns=0, the array remains unchanged.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      17.02.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   q = xalglib.rmatrixqrunpackq(a, m, n, tau, qcolumns)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          m:          int
          n:          int
          tau:        1D array/list of float
          qcolumns:   int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  q:          2D array/list of float

</div></pre>
<a name='sub_rmatrixqrunpackr'></a><h3 class=pageheader><code>rmatrixqrunpackr</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Unpacking of matrix R from the QR decomposition of a matrix A
# 
# Input parameters:
#     A       -   matrices Q and R in compact form.
#                 Output of RMatrixQR subroutine.
#     M       -   number of rows in given matrix A. M&gt;=0.
#     N       -   number of columns in given matrix A. N&gt;=0.
# 
# Output parameters:
#     R       -   matrix R, array[0..M-1, 0..N-1].
# 
#   -- ALGLIB routine --
#      17.02.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r = xalglib.rmatrixqrunpackr(a, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          2D array/list of float

</div></pre>
<a name='sub_smatrixtd'></a><h3 class=pageheader><code>smatrixtd</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Reduction of a symmetric matrix which is given by its higher or lower
# triangular part to a tridiagonal matrix using orthogonal similarity
# transformation: Q'*A*Q=T.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# Input parameters:
#     A       -   matrix to be transformed
#                 array with elements [0..N-1, 0..N-1].
#     N       -   size of matrix A.
#     IsUpper -   storage format. If IsUpper = True, then matrix A is given
#                 by its upper triangle, and the lower triangle is not used
#                 and not modified by the algorithm, and vice versa
#                 if IsUpper = False.
# 
# Output parameters:
#     A       -   matrices T and Q in  compact form (see lower)
#     Tau     -   array of factors which are forming matrices H(i)
#                 array with elements [0..N-2].
#     D       -   main diagonal of symmetric matrix T.
#                 array with elements [0..N-1].
#     E       -   secondary diagonal of symmetric matrix T.
#                 array with elements [0..N-2].
# 
# 
#   If IsUpper=True, the matrix Q is represented as a product of elementary
#   reflectors
# 
#      Q = H(n-2) . . . H(2) H(0).
# 
#   Each H(i) has the form
# 
#      H(i) = I - tau * v * v'
# 
#   where tau is a real scalar, and v is a real vector with
#   v(i+1:n-1) = 0, v(i) = 1, v(0:i-1) is stored on exit in
#   A(0:i-1,i+1), and tau in TAU(i).
# 
#   If IsUpper=False, the matrix Q is represented as a product of elementary
#   reflectors
# 
#      Q = H(0) H(2) . . . H(n-2).
# 
#   Each H(i) has the form
# 
#      H(i) = I - tau * v * v'
# 
#   where tau is a real scalar, and v is a real vector with
#   v(0:i) = 0, v(i+1) = 1, v(i+2:n-1) is stored on exit in A(i+2:n-1,i),
#   and tau in TAU(i).
# 
#   The contents of A on exit are illustrated by the following examples
#   with n = 5:
# 
#   if UPLO = 'U':                       if UPLO = 'L':
# 
#     (  d   e   v1  v2  v3 )              (  d                  )
#     (      d   e   v2  v3 )              (  e   d              )
#     (          d   e   v3 )              (  v0  e   d          )
#     (              d   e  )              (  v0  v1  e   d      )
#     (                  d  )              (  v0  v1  v2  e   d  )
# 
#   where d and e denote diagonal and off-diagonal elements of T, and vi
#   denotes an element of the vector defining H(i).
# 
#   -- LAPACK routine (version 3.0) --
#      Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
#      Courant Institute, Argonne National Lab, and Rice University
#      October 31, 1992
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   tau, d, e = xalglib.smatrixtd(a, n, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  tau:        1D array/list of float
          d:          1D array/list of float
          e:          1D array/list of float

</div></pre>
<a name='sub_smatrixtdunpackq'></a><h3 class=pageheader><code>smatrixtdunpackq</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Unpacking matrix Q which reduces symmetric matrix to a tridiagonal
# form.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# Input parameters:
#     A       -   the result of a SMatrixTD subroutine
#     N       -   size of matrix A.
#     IsUpper -   storage format (a parameter of SMatrixTD subroutine)
#     Tau     -   the result of a SMatrixTD subroutine
# 
# Output parameters:
#     Q       -   transformation matrix.
#                 array with elements [0..N-1, 0..N-1].
# 
#   -- ALGLIB --
#      Copyright 2005-2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   q = xalglib.smatrixtdunpackq(a, n, isupper, tau)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
          tau:        1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  q:          2D array/list of float

</div></pre>
<a name=unit_parametric></a><h2 class=pageheader><code>parametric</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_parametricrdpfixed' class=toc>parametricrdpfixed</a><br>
<a href='#sub_pspline2arclength' class=toc>pspline2arclength</a><br>
<a href='#sub_pspline2build' class=toc>pspline2build</a><br>
<a href='#sub_pspline2buildperiodic' class=toc>pspline2buildperiodic</a><br>
<a href='#sub_pspline2calc' class=toc>pspline2calc</a><br>
<a href='#sub_pspline2diff' class=toc>pspline2diff</a><br>
<a href='#sub_pspline2diff2' class=toc>pspline2diff2</a><br>
<a href='#sub_pspline2parametervalues' class=toc>pspline2parametervalues</a><br>
<a href='#sub_pspline2tangent' class=toc>pspline2tangent</a><br>
<a href='#sub_pspline3arclength' class=toc>pspline3arclength</a><br>
<a href='#sub_pspline3build' class=toc>pspline3build</a><br>
<a href='#sub_pspline3buildperiodic' class=toc>pspline3buildperiodic</a><br>
<a href='#sub_pspline3calc' class=toc>pspline3calc</a><br>
<a href='#sub_pspline3diff' class=toc>pspline3diff</a><br>
<a href='#sub_pspline3diff2' class=toc>pspline3diff2</a><br>
<a href='#sub_pspline3parametervalues' class=toc>pspline3parametervalues</a><br>
<a href='#sub_pspline3tangent' class=toc>pspline3tangent</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_parametricrdpfixed'></a><h3 class=pageheader><code>parametricrdpfixed</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  subroutine fits piecewise linear curve to points with Ramer-Douglas-
# Peucker algorithm. This  function  performs PARAMETRIC fit, i.e. it can be
# used to fit curves like circles.
# 
# On  input  it  accepts dataset which describes parametric multidimensional
# curve X(t), with X being vector, and t taking values in [0,N), where N  is
# a number of points in dataset. As result, it returns reduced  dataset  X2,
# which can be used to build  parametric  curve  X2(t),  which  approximates
# X(t) with desired precision (or has specified number of sections).
# 
# 
# INPUT PARAMETERS:
#     X       -   array of multidimensional points:
#                 * at least N elements, leading N elements are used if more
#                   than N elements were specified
#                 * order of points is IMPORTANT because  it  is  parametric
#                   fit
#                 * each row of array is one point which has D coordinates
#     N       -   number of elements in X
#     D       -   number of dimensions (elements per row of X)
#     StopM   -   stopping condition - desired number of sections:
#                 * at most M sections are generated by this function
#                 * less than M sections can be generated if we have N&lt;M
#                   (or some X are non-distinct).
#                 * zero StopM means that algorithm does not stop after
#                   achieving some pre-specified section count
#     StopEps -   stopping condition - desired precision:
#                 * algorithm stops after error in each section is at most Eps
#                 * zero Eps means that algorithm does not stop after
#                   achieving some pre-specified precision
# 
# OUTPUT PARAMETERS:
#     X2      -   array of corner points for piecewise approximation,
#                 has length NSections+1 or zero (for NSections=0).
#     Idx2    -   array of indexes (parameter values):
#                 * has length NSections+1 or zero (for NSections=0).
#                 * each element of Idx2 corresponds to same-numbered
#                   element of X2
#                 * each element of Idx2 is index of  corresponding  element
#                   of X2 at original array X, i.e. I-th  row  of  X2  is
#                   Idx2[I]-th row of X.
#                 * elements of Idx2 can be treated as parameter values
#                   which should be used when building new parametric curve
#                 * Idx2[0]=0, Idx2[NSections]=N-1
#     NSections-  number of sections found by algorithm, NSections&lt;=M,
#                 NSections can be zero for degenerate datasets
#                 (N&lt;=1 or all X[] are non-distinct).
# 
# NOTE: algorithm stops after:
#       a) dividing curve into StopM sections
#       b) achieving required precision StopEps
#       c) dividing curve into N-1 sections
#       If both StopM and StopEps are non-zero, algorithm is stopped by  the
#       FIRST criterion which is satisfied. In case both StopM  and  StopEps
#       are zero, algorithm stops because of (c).
# 
#   -- ALGLIB --
#      Copyright 02.10.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x2, idx2, nsections = xalglib.parametricrdpfixed(x, n, d, stopm, stopeps)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          2D array/list of float
          n:          int
          d:          int
          stopm:      int
          stopeps:    float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x2:         2D array/list of float
          idx2:       1D array/list of int
          nsections:  int

</div></pre>
<a name='sub_pspline2arclength'></a><h3 class=pageheader><code>pspline2arclength</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function  calculates  arc length, i.e. length of  curve  between  t=a
# and t=b.
# 
# INPUT PARAMETERS:
#     P   -   parametric spline interpolant
#     A,B -   parameter values corresponding to arc ends:
#             * B&gt;A will result in positive length returned
#             * B&lt;A will result in negative length returned
# 
# RESULT:
#     length of arc starting at T=A and ending at T=B.
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 30.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.pspline2arclength(p, a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.pspline2interpolant
          a:          float
          b:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_pspline2build'></a><h3 class=pageheader><code>pspline2build</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function  builds  non-periodic 2-dimensional parametric spline  which
# starts at (X[0],Y[0]) and ends at (X[N-1],Y[N-1]).
# 
# INPUT PARAMETERS:
#     XY  -   points, array[0..N-1,0..1].
#             XY[I,0:1] corresponds to the Ith point.
#             Order of points is important!
#     N   -   points count, N&gt;=5 for Akima splines, N&gt;=2 for other types  of
#             splines.
#     ST  -   spline type:
#             * 0     Akima spline
#             * 1     parabolically terminated Catmull-Rom spline (Tension=0)
#             * 2     parabolically terminated cubic spline
#     PT  -   parameterization type:
#             * 0     uniform
#             * 1     chord length
#             * 2     centripetal
# 
# OUTPUT PARAMETERS:
#     P   -   parametric spline interpolant
# 
# 
# NOTES:
# * this function  assumes  that  there all consequent points  are distinct.
#   I.e. (x0,y0)&lt;&gt;(x1,y1),  (x1,y1)&lt;&gt;(x2,y2),  (x2,y2)&lt;&gt;(x3,y3)  and  so on.
#   However, non-consequent points may coincide, i.e. we can  have  (x0,y0)=
#   =(x2,y2).
# 
#   -- ALGLIB PROJECT --
#      Copyright 28.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.pspline2build(xy, n, st, pt)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          n:          int
          st:         int
          pt:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          class xalglib.pspline2interpolant

</div></pre>
<a name='sub_pspline2buildperiodic'></a><h3 class=pageheader><code>pspline2buildperiodic</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  builds  periodic  2-dimensional  parametric  spline  which
# starts at (X[0],Y[0]), goes through all points to (X[N-1],Y[N-1]) and then
# back to (X[0],Y[0]).
# 
# INPUT PARAMETERS:
#     XY  -   points, array[0..N-1,0..1].
#             XY[I,0:1] corresponds to the Ith point.
#             XY[N-1,0:1] must be different from XY[0,0:1].
#             Order of points is important!
#     N   -   points count, N&gt;=3 for other types of splines.
#     ST  -   spline type:
#             * 1     Catmull-Rom spline (Tension=0) with cyclic boundary conditions
#             * 2     cubic spline with cyclic boundary conditions
#     PT  -   parameterization type:
#             * 0     uniform
#             * 1     chord length
#             * 2     centripetal
# 
# OUTPUT PARAMETERS:
#     P   -   parametric spline interpolant
# 
# 
# NOTES:
# * this function  assumes  that there all consequent points  are  distinct.
#   I.e. (x0,y0)&lt;&gt;(x1,y1), (x1,y1)&lt;&gt;(x2,y2),  (x2,y2)&lt;&gt;(x3,y3)  and  so  on.
#   However, non-consequent points may coincide, i.e. we can  have  (x0,y0)=
#   =(x2,y2).
# * last point of sequence is NOT equal to the first  point.  You  shouldn't
#   make curve &quot;explicitly periodic&quot; by making them equal.
# 
#   -- ALGLIB PROJECT --
#      Copyright 28.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.pspline2buildperiodic(xy, n, st, pt)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          n:          int
          st:         int
          pt:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          class xalglib.pspline2interpolant

</div></pre>
<a name='sub_pspline2calc'></a><h3 class=pageheader><code>pspline2calc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function  calculates  the value of the parametric spline for a  given
# value of parameter T
# 
# INPUT PARAMETERS:
#     P   -   parametric spline interpolant
#     T   -   point:
#             * T in [0,1] corresponds to interval spanned by points
#             * for non-periodic splines T&lt;0 (or T&gt;1) correspond to parts of
#               the curve before the first (after the last) point
#             * for periodic splines T&lt;0 (or T&gt;1) are projected  into  [0,1]
#               by making T=T-floor(T).
# 
# OUTPUT PARAMETERS:
#     X   -   X-position
#     Y   -   Y-position
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 28.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, y = xalglib.pspline2calc(p, t)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.pspline2interpolant
          t:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          float
          y:          float

</div></pre>
<a name='sub_pspline2diff'></a><h3 class=pageheader><code>pspline2diff</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates derivative, i.e. it returns (dX/dT,dY/dT).
# 
# INPUT PARAMETERS:
#     P   -   parametric spline interpolant
#     T   -   point:
#             * T in [0,1] corresponds to interval spanned by points
#             * for non-periodic splines T&lt;0 (or T&gt;1) correspond to parts of
#               the curve before the first (after the last) point
#             * for periodic splines T&lt;0 (or T&gt;1) are projected  into  [0,1]
#               by making T=T-floor(T).
# 
# OUTPUT PARAMETERS:
#     X   -   X-value
#     DX  -   X-derivative
#     Y   -   Y-value
#     DY  -   Y-derivative
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 28.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, dx, y, dy = xalglib.pspline2diff(p, t)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.pspline2interpolant
          t:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          float
          dx:         float
          y:          float
          dy:         float

</div></pre>
<a name='sub_pspline2diff2'></a><h3 class=pageheader><code>pspline2diff2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates first and second derivative with respect to T.
# 
# INPUT PARAMETERS:
#     P   -   parametric spline interpolant
#     T   -   point:
#             * T in [0,1] corresponds to interval spanned by points
#             * for non-periodic splines T&lt;0 (or T&gt;1) correspond to parts of
#               the curve before the first (after the last) point
#             * for periodic splines T&lt;0 (or T&gt;1) are projected  into  [0,1]
#               by making T=T-floor(T).
# 
# OUTPUT PARAMETERS:
#     X   -   X-value
#     DX  -   derivative
#     D2X -   second derivative
#     Y   -   Y-value
#     DY  -   derivative
#     D2Y -   second derivative
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 28.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, dx, d2x, y, dy, d2y = xalglib.pspline2diff2(p, t)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.pspline2interpolant
          t:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          float
          dx:         float
          d2x:        float
          y:          float
          dy:         float
          d2y:        float

</div></pre>
<a name='sub_pspline2parametervalues'></a><h3 class=pageheader><code>pspline2parametervalues</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns vector of parameter values correspoding to points.
# 
# I.e. for P created from (X[0],Y[0])...(X[N-1],Y[N-1]) and U=TValues(P)  we
# have
#     (X[0],Y[0]) = PSpline2Calc(P,U[0]),
#     (X[1],Y[1]) = PSpline2Calc(P,U[1]),
#     (X[2],Y[2]) = PSpline2Calc(P,U[2]),
#     ...
# 
# INPUT PARAMETERS:
#     P   -   parametric spline interpolant
# 
# OUTPUT PARAMETERS:
#     N   -   array size
#     T   -   array[0..N-1]
# 
# 
# NOTES:
# * for non-periodic splines U[0]=0, U[0]&lt;U[1]&lt;...&lt;U[N-1], U[N-1]=1
# * for periodic splines     U[0]=0, U[0]&lt;U[1]&lt;...&lt;U[N-1], U[N-1]&lt;1
# 
#   -- ALGLIB PROJECT --
#      Copyright 28.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   n, t = xalglib.pspline2parametervalues(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.pspline2interpolant
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  n:          int
          t:          1D array/list of float

</div></pre>
<a name='sub_pspline2tangent'></a><h3 class=pageheader><code>pspline2tangent</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function  calculates  tangent vector for a given value of parameter T
# 
# INPUT PARAMETERS:
#     P   -   parametric spline interpolant
#     T   -   point:
#             * T in [0,1] corresponds to interval spanned by points
#             * for non-periodic splines T&lt;0 (or T&gt;1) correspond to parts of
#               the curve before the first (after the last) point
#             * for periodic splines T&lt;0 (or T&gt;1) are projected  into  [0,1]
#               by making T=T-floor(T).
# 
# OUTPUT PARAMETERS:
#     X    -   X-component of tangent vector (normalized)
#     Y    -   Y-component of tangent vector (normalized)
# 
# NOTE:
#     X^2+Y^2 is either 1 (for non-zero tangent vector) or 0.
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 28.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, y = xalglib.pspline2tangent(p, t)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.pspline2interpolant
          t:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          float
          y:          float

</div></pre>
<a name='sub_pspline3arclength'></a><h3 class=pageheader><code>pspline3arclength</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function  calculates  arc length, i.e. length of  curve  between  t=a
# and t=b.
# 
# INPUT PARAMETERS:
#     P   -   parametric spline interpolant
#     A,B -   parameter values corresponding to arc ends:
#             * B&gt;A will result in positive length returned
#             * B&lt;A will result in negative length returned
# 
# RESULT:
#     length of arc starting at T=A and ending at T=B.
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 30.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.pspline3arclength(p, a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.pspline3interpolant
          a:          float
          b:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_pspline3build'></a><h3 class=pageheader><code>pspline3build</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function  builds  non-periodic 3-dimensional parametric spline  which
# starts at (X[0],Y[0],Z[0]) and ends at (X[N-1],Y[N-1],Z[N-1]).
# 
# Same as PSpline2Build() function, but for 3D, so we  won't  duplicate  its
# description here.
# 
#   -- ALGLIB PROJECT --
#      Copyright 28.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.pspline3build(xy, n, st, pt)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          n:          int
          st:         int
          pt:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          class xalglib.pspline3interpolant

</div></pre>
<a name='sub_pspline3buildperiodic'></a><h3 class=pageheader><code>pspline3buildperiodic</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  builds  periodic  3-dimensional  parametric  spline  which
# starts at (X[0],Y[0],Z[0]), goes through all points to (X[N-1],Y[N-1],Z[N-1])
# and then back to (X[0],Y[0],Z[0]).
# 
# Same as PSpline2Build() function, but for 3D, so we  won't  duplicate  its
# description here.
# 
#   -- ALGLIB PROJECT --
#      Copyright 28.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.pspline3buildperiodic(xy, n, st, pt)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     xy:         2D array/list of float
          n:          int
          st:         int
          pt:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          class xalglib.pspline3interpolant

</div></pre>
<a name='sub_pspline3calc'></a><h3 class=pageheader><code>pspline3calc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function  calculates  the value of the parametric spline for a  given
# value of parameter T.
# 
# INPUT PARAMETERS:
#     P   -   parametric spline interpolant
#     T   -   point:
#             * T in [0,1] corresponds to interval spanned by points
#             * for non-periodic splines T&lt;0 (or T&gt;1) correspond to parts of
#               the curve before the first (after the last) point
#             * for periodic splines T&lt;0 (or T&gt;1) are projected  into  [0,1]
#               by making T=T-floor(T).
# 
# OUTPUT PARAMETERS:
#     X   -   X-position
#     Y   -   Y-position
#     Z   -   Z-position
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 28.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, y, z = xalglib.pspline3calc(p, t)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.pspline3interpolant
          t:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          float
          y:          float
          z:          float

</div></pre>
<a name='sub_pspline3diff'></a><h3 class=pageheader><code>pspline3diff</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates derivative, i.e. it returns (dX/dT,dY/dT,dZ/dT).
# 
# INPUT PARAMETERS:
#     P   -   parametric spline interpolant
#     T   -   point:
#             * T in [0,1] corresponds to interval spanned by points
#             * for non-periodic splines T&lt;0 (or T&gt;1) correspond to parts of
#               the curve before the first (after the last) point
#             * for periodic splines T&lt;0 (or T&gt;1) are projected  into  [0,1]
#               by making T=T-floor(T).
# 
# OUTPUT PARAMETERS:
#     X   -   X-value
#     DX  -   X-derivative
#     Y   -   Y-value
#     DY  -   Y-derivative
#     Z   -   Z-value
#     DZ  -   Z-derivative
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 28.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, dx, y, dy, z, dz = xalglib.pspline3diff(p, t)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.pspline3interpolant
          t:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          float
          dx:         float
          y:          float
          dy:         float
          z:          float
          dz:         float

</div></pre>
<a name='sub_pspline3diff2'></a><h3 class=pageheader><code>pspline3diff2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates first and second derivative with respect to T.
# 
# INPUT PARAMETERS:
#     P   -   parametric spline interpolant
#     T   -   point:
#             * T in [0,1] corresponds to interval spanned by points
#             * for non-periodic splines T&lt;0 (or T&gt;1) correspond to parts of
#               the curve before the first (after the last) point
#             * for periodic splines T&lt;0 (or T&gt;1) are projected  into  [0,1]
#               by making T=T-floor(T).
# 
# OUTPUT PARAMETERS:
#     X   -   X-value
#     DX  -   derivative
#     D2X -   second derivative
#     Y   -   Y-value
#     DY  -   derivative
#     D2Y -   second derivative
#     Z   -   Z-value
#     DZ  -   derivative
#     D2Z -   second derivative
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 28.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, dx, d2x, y, dy, d2y, z, dz, d2z = xalglib.pspline3diff2(p, t)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.pspline3interpolant
          t:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          float
          dx:         float
          d2x:        float
          y:          float
          dy:         float
          d2y:        float
          z:          float
          dz:         float
          d2z:        float

</div></pre>
<a name='sub_pspline3parametervalues'></a><h3 class=pageheader><code>pspline3parametervalues</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns vector of parameter values correspoding to points.
# 
# Same as PSpline2ParameterValues(), but for 3D.
# 
#   -- ALGLIB PROJECT --
#      Copyright 28.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   n, t = xalglib.pspline3parametervalues(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.pspline3interpolant
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  n:          int
          t:          1D array/list of float

</div></pre>
<a name='sub_pspline3tangent'></a><h3 class=pageheader><code>pspline3tangent</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function  calculates  tangent vector for a given value of parameter T
# 
# INPUT PARAMETERS:
#     P   -   parametric spline interpolant
#     T   -   point:
#             * T in [0,1] corresponds to interval spanned by points
#             * for non-periodic splines T&lt;0 (or T&gt;1) correspond to parts of
#               the curve before the first (after the last) point
#             * for periodic splines T&lt;0 (or T&gt;1) are projected  into  [0,1]
#               by making T=T-floor(T).
# 
# OUTPUT PARAMETERS:
#     X    -   X-component of tangent vector (normalized)
#     Y    -   Y-component of tangent vector (normalized)
#     Z    -   Z-component of tangent vector (normalized)
# 
# NOTE:
#     X^2+Y^2+Z^2 is either 1 (for non-zero tangent vector) or 0.
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 28.05.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, y, z = xalglib.pspline3tangent(p, t)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.pspline3interpolant
          t:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          float
          y:          float
          z:          float

</div></pre>
<a name=unit_pca></a><h2 class=pageheader><code>pca</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_pcabuildbasis' class=toc>pcabuildbasis</a><br>
<a href='#sub_pcatruncatedsubspace' class=toc>pcatruncatedsubspace</a><br>
<a href='#sub_pcatruncatedsubspacesparse' class=toc>pcatruncatedsubspacesparse</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_pcabuildbasis'></a><h3 class=pageheader><code>pcabuildbasis</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Principal components analysis
# 
# This function builds orthogonal basis  where  first  axis  corresponds  to
# direction with maximum variance, second axis  maximizes  variance  in  the
# subspace orthogonal to first axis and so on.
# 
# This function builds FULL basis, i.e. returns N vectors  corresponding  to
# ALL directions, no matter how informative. If you need  just a  few  (say,
# 10 or 50) of the most important directions, you may find it faster to  use
# one of the reduced versions:
# * pcatruncatedsubspace() - for subspace iteration based method
# 
# It should be noted that, unlike LDA, PCA does not use class labels.
# 
# INPUT PARAMETERS:
#     X           -   dataset, array[NPoints,NVars].
#                     matrix contains ONLY INDEPENDENT VARIABLES.
#     NPoints     -   dataset size, NPoints&gt;=0
#     NVars       -   number of independent variables, NVars&gt;=1
# 
# OUTPUT PARAMETERS:
#     S2          -   array[NVars]. variance values corresponding
#                     to basis vectors.
#     V           -   array[NVars,NVars]
#                     matrix, whose columns store basis vectors.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 25.08.2008 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s2, v = xalglib.pcabuildbasis(x, npoints, nvars)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   s2, v = xalglib.pcabuildbasis(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          2D array/list of float
          npoints:    int
          nvars:      int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s2:         1D array/list of float
          v:          2D array/list of float

</div></pre>
<a name='sub_pcatruncatedsubspace'></a><h3 class=pageheader><code>pcatruncatedsubspace</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Principal components analysis
# 
# This function performs truncated PCA, i.e. returns just a few most important
# directions.
# 
# Internally it uses iterative eigensolver which is very efficient when only
# a minor fraction of full basis is required. Thus, if you need full  basis,
# it is better to use pcabuildbasis() function.
# 
# It should be noted that, unlike LDA, PCA does not use class labels.
# 
# INPUT PARAMETERS:
#     X           -   dataset, array[0..NPoints-1,0..NVars-1].
#                     matrix contains ONLY INDEPENDENT VARIABLES.
#     NPoints     -   dataset size, NPoints&gt;=0
#     NVars       -   number of independent variables, NVars&gt;=1
#     NNeeded     -   number of requested components, in [1,NVars] range;
#                     this function is efficient only for NNeeded&lt;&lt;NVars.
#     Eps         -   desired  precision  of  vectors  returned;  underlying
#                     solver will stop iterations as soon as absolute  error
#                     in corresponding singular values  reduces  to  roughly
#                     eps*MAX(lambda[]), with lambda[] being array of  eigen
#                     values.
#                     Zero value means that  algorithm  performs  number  of
#                     iterations  specified  by  maxits  parameter,  without
#                     paying attention to precision.
#     MaxIts      -   number of iterations performed by  subspace  iteration
#                     method. Zero value means that no  limit  on  iteration
#                     count is placed (eps-based stopping condition is used).
# 
# 
# OUTPUT PARAMETERS:
#     S2          -   array[NNeeded]. Variance values corresponding
#                     to basis vectors.
#     V           -   array[NVars,NNeeded]
#                     matrix, whose columns store basis vectors.
# 
# NOTE: passing eps=0 and maxits=0 results in small eps  being  selected  as
# stopping condition. Exact value of automatically selected eps is  version-
# -dependent.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 10.01.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s2, v = xalglib.pcatruncatedsubspace(x, npoints, nvars, nneeded, eps, maxits)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   s2, v = xalglib.pcatruncatedsubspace(x, nneeded, eps, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          2D array/list of float
          npoints:    int
          nvars:      int
          nneeded:    int
          eps:        float
          maxits:     int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s2:         1D array/list of float
          v:          2D array/list of float

</div></pre>
<a name='sub_pcatruncatedsubspacesparse'></a><h3 class=pageheader><code>pcatruncatedsubspacesparse</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sparse truncated principal components analysis
# 
# This function performs sparse truncated PCA, i.e. returns just a few  most
# important principal components for a sparse input X.
# 
# Internally it uses iterative eigensolver which is very efficient when only
# a minor fraction of full basis is required.
# 
# It should be noted that, unlike LDA, PCA does not use class labels.
# 
# INPUT PARAMETERS:
#     X           -   sparse dataset, sparse  npoints*nvars  matrix.  It  is
#                     recommended to use CRS sparse storage format;  non-CRS
#                     input will be internally converted to CRS.
#                     Matrix contains ONLY INDEPENDENT VARIABLES,  and  must
#                     be EXACTLY npoints*nvars.
#     NPoints     -   dataset size, NPoints&gt;=0
#     NVars       -   number of independent variables, NVars&gt;=1
#     NNeeded     -   number of requested components, in [1,NVars] range;
#                     this function is efficient only for NNeeded&lt;&lt;NVars.
#     Eps         -   desired  precision  of  vectors  returned;  underlying
#                     solver will stop iterations as soon as absolute  error
#                     in corresponding singular values  reduces  to  roughly
#                     eps*MAX(lambda[]), with lambda[] being array of  eigen
#                     values.
#                     Zero value means that  algorithm  performs  number  of
#                     iterations  specified  by  maxits  parameter,  without
#                     paying attention to precision.
#     MaxIts      -   number of iterations performed by  subspace  iteration
#                     method. Zero value means that no  limit  on  iteration
#                     count is placed (eps-based stopping condition is used).
# 
# 
# OUTPUT PARAMETERS:
#     S2          -   array[NNeeded]. Variance values corresponding
#                     to basis vectors.
#     V           -   array[NVars,NNeeded]
#                     matrix, whose columns store basis vectors.
# 
# NOTE: passing eps=0 and maxits=0 results in small eps  being  selected  as
#       a stopping condition. Exact value of automatically selected  eps  is
#       version-dependent.
# 
# NOTE: zero  MaxIts  is  silently  replaced  by some reasonable value which
#       prevents eternal loops (possible when inputs are degenerate and  too
#       stringent stopping criteria are specified). In  current  version  it
#       is 50+2*NVars.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB --
#      Copyright 10.01.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s2, v = xalglib.pcatruncatedsubspacesparse(x, npoints, nvars, nneeded, eps, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          class xalglib.sparsematrix
          npoints:    int
          nvars:      int
          nneeded:    int
          eps:        float
          maxits:     int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s2:         1D array/list of float
          v:          2D array/list of float

</div></pre>
<a name=unit_poissondistr></a><h2 class=pageheader><code>poissondistr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_invpoissondistribution' class=toc>invpoissondistribution</a><br>
<a href='#sub_poissoncdistribution' class=toc>poissoncdistribution</a><br>
<a href='#sub_poissondistribution' class=toc>poissondistribution</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_invpoissondistribution'></a><h3 class=pageheader><code>invpoissondistribution</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Inverse Poisson distribution
# 
# Finds the Poisson variable x such that the integral
# from 0 to x of the Poisson density is equal to the
# given probability y.
# 
# This is accomplished using the inverse gamma integral
# function and the relation
# 
#    m = igami( k+1, y ).
# 
# ACCURACY:
# 
# See inverse incomplete gamma function
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.invpoissondistribution(k, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     k:          int
          y:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_poissoncdistribution'></a><h3 class=pageheader><code>poissoncdistribution</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Complemented Poisson distribution
# 
# Returns the sum of the terms k+1 to infinity of the Poisson
# distribution:
# 
#  inf.       j
#   --   -m  m
#   &gt;   e    --
#   --       j!
#  j=k+1
# 
# The terms are not summed directly; instead the incomplete
# gamma integral is employed, according to the formula
# 
# y = pdtrc( k, m ) = igam( k+1, m ).
# 
# The arguments must both be positive.
# 
# ACCURACY:
# 
# See incomplete gamma function
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.poissoncdistribution(k, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     k:          int
          m:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_poissondistribution'></a><h3 class=pageheader><code>poissondistribution</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Poisson distribution
# 
# Returns the sum of the first k+1 terms of the Poisson
# distribution:
# 
#   k         j
#   --   -m  m
#   &gt;   e    --
#   --       j!
#  j=0
# 
# The terms are not summed directly; instead the incomplete
# gamma integral is employed, according to the relation
# 
# y = pdtr( k, m ) = igamc( k+1, m ).
# 
# The arguments must both be positive.
# ACCURACY:
# 
# See incomplete gamma function
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.poissondistribution(k, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     k:          int
          m:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_polint></a><h2 class=pageheader><code>polint</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_polynomialbar2cheb' class=toc>polynomialbar2cheb</a><br>
<a href='#sub_polynomialbar2pow' class=toc>polynomialbar2pow</a><br>
<a href='#sub_polynomialbuild' class=toc>polynomialbuild</a><br>
<a href='#sub_polynomialbuildcheb1' class=toc>polynomialbuildcheb1</a><br>
<a href='#sub_polynomialbuildcheb2' class=toc>polynomialbuildcheb2</a><br>
<a href='#sub_polynomialbuildeqdist' class=toc>polynomialbuildeqdist</a><br>
<a href='#sub_polynomialcalccheb1' class=toc>polynomialcalccheb1</a><br>
<a href='#sub_polynomialcalccheb2' class=toc>polynomialcalccheb2</a><br>
<a href='#sub_polynomialcalceqdist' class=toc>polynomialcalceqdist</a><br>
<a href='#sub_polynomialcheb2bar' class=toc>polynomialcheb2bar</a><br>
<a href='#sub_polynomialpow2bar' class=toc>polynomialpow2bar</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_polynomialbar2cheb'></a><h3 class=pageheader><code>polynomialbar2cheb</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Conversion from barycentric representation to Chebyshev basis.
# This function has O(N^2) complexity.
# 
# INPUT PARAMETERS:
#     P   -   polynomial in barycentric form
#     A,B -   base interval for Chebyshev polynomials (see below)
#             A&lt;&gt;B
# 
# OUTPUT PARAMETERS
#     T   -   coefficients of Chebyshev representation;
#             P(x) = sum { T[i]*Ti(2*(x-A)/(B-A)-1), i=0..N-1 },
#             where Ti - I-th Chebyshev polynomial.
# 
# NOTES:
#     barycentric interpolant passed as P may be either polynomial  obtained
#     from  polynomial  interpolation/ fitting or rational function which is
#     NOT polynomial. We can't distinguish between these two cases, and this
#     algorithm just tries to work assuming that P IS a polynomial.  If not,
#     algorithm will return results, but they won't have any meaning.
# 
#   -- ALGLIB --
#      Copyright 30.09.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   t = xalglib.polynomialbar2cheb(p, a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.barycentricinterpolant
          a:          float
          b:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  t:          1D array/list of float

</div></pre>
<a name='sub_polynomialbar2pow'></a><h3 class=pageheader><code>polynomialbar2pow</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Conversion from barycentric representation to power basis.
# This function has O(N^2) complexity.
# 
# INPUT PARAMETERS:
#     P   -   polynomial in barycentric form
#     C   -   offset (see below); 0.0 is used as default value.
#     S   -   scale (see below);  1.0 is used as default value. S&lt;&gt;0.
# 
# OUTPUT PARAMETERS
#     A   -   coefficients, P(x) = sum { A[i]*((X-C)/S)^i, i=0..N-1 }
#     N   -   number of coefficients (polynomial degree plus 1)
# 
# NOTES:
# 1.  this function accepts offset and scale, which can be  set  to  improve
#     numerical properties of polynomial. For example, if P was obtained  as
#     result of interpolation on [-1,+1],  you  can  set  C=0  and  S=1  and
#     represent  P  as sum of 1, x, x^2, x^3 and so on. In most cases you it
#     is exactly what you need.
# 
#     However, if your interpolation model was built on [999,1001], you will
#     see significant growth of numerical errors when using {1, x, x^2, x^3}
#     as basis. Representing P as sum of 1, (x-1000), (x-1000)^2, (x-1000)^3
#     will be better option. Such representation can be  obtained  by  using
#     1000.0 as offset C and 1.0 as scale S.
# 
# 2.  power basis is ill-conditioned and tricks described above can't  solve
#     this problem completely. This function  will  return  coefficients  in
#     any  case,  but  for  N&gt;8  they  will  become unreliable. However, N's
#     less than 5 are pretty safe.
# 
# 3.  barycentric interpolant passed as P may be either polynomial  obtained
#     from  polynomial  interpolation/ fitting or rational function which is
#     NOT polynomial. We can't distinguish between these two cases, and this
#     algorithm just tries to work assuming that P IS a polynomial.  If not,
#     algorithm will return results, but they won't have any meaning.
# 
#   -- ALGLIB --
#      Copyright 30.09.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.polynomialbar2pow(p, c, s)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.polynomialbar2pow(p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     p:          class xalglib.barycentricinterpolant
          c:          float
          s:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          1D array/list of float

</div></pre>
<a name='sub_polynomialbuild'></a><h3 class=pageheader><code>polynomialbuild</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Lagrange intepolant: generation of the model on the general grid.
# This function has O(N^2) complexity.
# 
# INPUT PARAMETERS:
#     X   -   abscissas, array[0..N-1]
#     Y   -   function values, array[0..N-1]
#     N   -   number of points, N&gt;=1
# 
# OUTPUT PARAMETERS
#     P   -   barycentric model which represents Lagrange interpolant
#             (see ratint unit info and BarycentricCalc() description for
#             more information).
# 
#   -- ALGLIB --
#      Copyright 02.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.polynomialbuild(x, y, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.polynomialbuild(x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          class xalglib.barycentricinterpolant

</div></pre>
<a name='sub_polynomialbuildcheb1'></a><h3 class=pageheader><code>polynomialbuildcheb1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Lagrange intepolant on Chebyshev grid (first kind).
# This function has O(N) complexity.
# 
# INPUT PARAMETERS:
#     A   -   left boundary of [A,B]
#     B   -   right boundary of [A,B]
#     Y   -   function values at the nodes, array[0..N-1],
#             Y[I] = Y(0.5*(B+A) + 0.5*(B-A)*Cos(PI*(2*i+1)/(2*n)))
#     N   -   number of points, N&gt;=1
#             for N=1 a constant model is constructed.
# 
# OUTPUT PARAMETERS
#     P   -   barycentric model which represents Lagrange interpolant
#             (see ratint unit info and BarycentricCalc() description for
#             more information).
# 
#   -- ALGLIB --
#      Copyright 03.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.polynomialbuildcheb1(a, b, y, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.polynomialbuildcheb1(a, b, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          float
          b:          float
          y:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          class xalglib.barycentricinterpolant

</div></pre>
<a name='sub_polynomialbuildcheb2'></a><h3 class=pageheader><code>polynomialbuildcheb2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Lagrange intepolant on Chebyshev grid (second kind).
# This function has O(N) complexity.
# 
# INPUT PARAMETERS:
#     A   -   left boundary of [A,B]
#     B   -   right boundary of [A,B]
#     Y   -   function values at the nodes, array[0..N-1],
#             Y[I] = Y(0.5*(B+A) + 0.5*(B-A)*Cos(PI*i/(n-1)))
#     N   -   number of points, N&gt;=1
#             for N=1 a constant model is constructed.
# 
# OUTPUT PARAMETERS
#     P   -   barycentric model which represents Lagrange interpolant
#             (see ratint unit info and BarycentricCalc() description for
#             more information).
# 
#   -- ALGLIB --
#      Copyright 03.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.polynomialbuildcheb2(a, b, y, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.polynomialbuildcheb2(a, b, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          float
          b:          float
          y:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          class xalglib.barycentricinterpolant

</div></pre>
<a name='sub_polynomialbuildeqdist'></a><h3 class=pageheader><code>polynomialbuildeqdist</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Lagrange intepolant: generation of the model on equidistant grid.
# This function has O(N) complexity.
# 
# INPUT PARAMETERS:
#     A   -   left boundary of [A,B]
#     B   -   right boundary of [A,B]
#     Y   -   function values at the nodes, array[0..N-1]
#     N   -   number of points, N&gt;=1
#             for N=1 a constant model is constructed.
# 
# OUTPUT PARAMETERS
#     P   -   barycentric model which represents Lagrange interpolant
#             (see ratint unit info and BarycentricCalc() description for
#             more information).
# 
#   -- ALGLIB --
#      Copyright 03.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.polynomialbuildeqdist(a, b, y, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.polynomialbuildeqdist(a, b, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          float
          b:          float
          y:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          class xalglib.barycentricinterpolant

</div></pre>
<a name='sub_polynomialcalccheb1'></a><h3 class=pageheader><code>polynomialcalccheb1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Fast polynomial interpolation function on Chebyshev points (first kind)
# with O(N) complexity.
# 
# INPUT PARAMETERS:
#     A   -   left boundary of [A,B]
#     B   -   right boundary of [A,B]
#     F   -   function values, array[0..N-1]
#     N   -   number of points on Chebyshev grid (first kind),
#             X[i] = 0.5*(B+A) + 0.5*(B-A)*Cos(PI*(2*i+1)/(2*n))
#             for N=1 a constant model is constructed.
#     T   -   position where P(x) is calculated
# 
# RESULT
#     value of the Lagrange interpolant at T
# 
# IMPORTANT
#     this function provides fast interface which is not overflow-safe
#     nor it is very precise.
#     the best option is to use  PolIntBuildCheb1()/BarycentricCalc()
#     subroutines unless you are pretty sure that your data will not result
#     in overflow.
# 
#   -- ALGLIB --
#      Copyright 02.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.polynomialcalccheb1(a, b, f, n, t)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.polynomialcalccheb1(a, b, f, t)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          float
          b:          float
          f:          1D array/list of float
          n:          int
          t:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_polynomialcalccheb2'></a><h3 class=pageheader><code>polynomialcalccheb2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Fast polynomial interpolation function on Chebyshev points (second kind)
# with O(N) complexity.
# 
# INPUT PARAMETERS:
#     A   -   left boundary of [A,B]
#     B   -   right boundary of [A,B]
#     F   -   function values, array[0..N-1]
#     N   -   number of points on Chebyshev grid (second kind),
#             X[i] = 0.5*(B+A) + 0.5*(B-A)*Cos(PI*i/(n-1))
#             for N=1 a constant model is constructed.
#     T   -   position where P(x) is calculated
# 
# RESULT
#     value of the Lagrange interpolant at T
# 
# IMPORTANT
#     this function provides fast interface which is not overflow-safe
#     nor it is very precise.
#     the best option is to use PolIntBuildCheb2()/BarycentricCalc()
#     subroutines unless you are pretty sure that your data will not result
#     in overflow.
# 
#   -- ALGLIB --
#      Copyright 02.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.polynomialcalccheb2(a, b, f, n, t)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.polynomialcalccheb2(a, b, f, t)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          float
          b:          float
          f:          1D array/list of float
          n:          int
          t:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_polynomialcalceqdist'></a><h3 class=pageheader><code>polynomialcalceqdist</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Fast equidistant polynomial interpolation function with O(N) complexity
# 
# INPUT PARAMETERS:
#     A   -   left boundary of [A,B]
#     B   -   right boundary of [A,B]
#     F   -   function values, array[0..N-1]
#     N   -   number of points on equidistant grid, N&gt;=1
#             for N=1 a constant model is constructed.
#     T   -   position where P(x) is calculated
# 
# RESULT
#     value of the Lagrange interpolant at T
# 
# IMPORTANT
#     this function provides fast interface which is not overflow-safe
#     nor it is very precise.
#     the best option is to use  PolynomialBuildEqDist()/BarycentricCalc()
#     subroutines unless you are pretty sure that your data will not result
#     in overflow.
# 
#   -- ALGLIB --
#      Copyright 02.12.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.polynomialcalceqdist(a, b, f, n, t)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.polynomialcalceqdist(a, b, f, t)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          float
          b:          float
          f:          1D array/list of float
          n:          int
          t:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_polynomialcheb2bar'></a><h3 class=pageheader><code>polynomialcheb2bar</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Conversion from Chebyshev basis to barycentric representation.
# This function has O(N^2) complexity.
# 
# INPUT PARAMETERS:
#     T   -   coefficients of Chebyshev representation;
#             P(x) = sum { T[i]*Ti(2*(x-A)/(B-A)-1), i=0..N },
#             where Ti - I-th Chebyshev polynomial.
#     N   -   number of coefficients:
#             * if given, only leading N elements of T are used
#             * if not given, automatically determined from size of T
#     A,B -   base interval for Chebyshev polynomials (see above)
#             A&lt;B
# 
# OUTPUT PARAMETERS
#     P   -   polynomial in barycentric form
# 
#   -- ALGLIB --
#      Copyright 30.09.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.polynomialcheb2bar(t, n, a, b)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.polynomialcheb2bar(t, a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     t:          1D array/list of float
          n:          int
          a:          float
          b:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          class xalglib.barycentricinterpolant

</div></pre>
<a name='sub_polynomialpow2bar'></a><h3 class=pageheader><code>polynomialpow2bar</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Conversion from power basis to barycentric representation.
# This function has O(N^2) complexity.
# 
# INPUT PARAMETERS:
#     A   -   coefficients, P(x) = sum { A[i]*((X-C)/S)^i, i=0..N-1 }
#     N   -   number of coefficients (polynomial degree plus 1)
#             * if given, only leading N elements of A are used
#             * if not given, automatically determined from size of A
#     C   -   offset (see below); 0.0 is used as default value.
#     S   -   scale (see below);  1.0 is used as default value. S&lt;&gt;0.
# 
# OUTPUT PARAMETERS
#     P   -   polynomial in barycentric form
# 
# 
# NOTES:
# 1.  this function accepts offset and scale, which can be  set  to  improve
#     numerical properties of polynomial. For example, if you interpolate on
#     [-1,+1],  you  can  set C=0 and S=1 and convert from sum of 1, x, x^2,
#     x^3 and so on. In most cases you it is exactly what you need.
# 
#     However, if your interpolation model was built on [999,1001], you will
#     see significant growth of numerical errors when using {1, x, x^2, x^3}
#     as  input  basis.  Converting  from  sum  of  1, (x-1000), (x-1000)^2,
#     (x-1000)^3 will be better option (you have to specify 1000.0 as offset
#     C and 1.0 as scale S).
# 
# 2.  power basis is ill-conditioned and tricks described above can't  solve
#     this problem completely. This function  will  return barycentric model
#     in any case, but for N&gt;8 accuracy well degrade. However, N's less than
#     5 are pretty safe.
# 
#   -- ALGLIB --
#      Copyright 30.09.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.polynomialpow2bar(a, n, c, s)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   p = xalglib.polynomialpow2bar(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          n:          int
          c:          float
          s:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  p:          class xalglib.barycentricinterpolant

</div></pre>
<a name=unit_polynomialsolver></a><h2 class=pageheader><code>polynomialsolver</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_polynomialsolve' class=toc>polynomialsolve</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_polynomialsolve'></a><h3 class=pageheader><code>polynomialsolve</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Polynomial root finding.
# 
# This function returns all roots of the polynomial
#     P(x) = a0 + a1*x + a2*x^2 + ... + an*x^n
# Both real and complex roots are returned (see below).
# 
# INPUT PARAMETERS:
#     A       -   array[N+1], polynomial coefficients:
#                 * A[0] is constant term
#                 * A[N] is a coefficient of X^N
#     N       -   polynomial degree
# 
# OUTPUT PARAMETERS:
#     X       -   array of complex roots:
#                 * for isolated real root, X[I] is strictly real: IMAGE(X[I])=0
#                 * complex roots are always returned in pairs - roots occupy
#                   positions I and I+1, with:
#                   * X[I+1]=Conj(X[I])
#                   * IMAGE(X[I]) &gt; 0
#                   * IMAGE(X[I+1]) = -IMAGE(X[I]) &lt; 0
#                 * multiple real roots may have non-zero imaginary part due
#                   to roundoff errors. There is no reliable way to distinguish
#                   real root of multiplicity 2 from two  complex  roots  in
#                   the presence of roundoff errors.
#     Rep     -   report, additional information, following fields are set:
#                 * Rep.MaxErr - max( |P(xi)| )  for  i=0..N-1.  This  field
#                   allows to quickly estimate &quot;quality&quot; of the roots  being
#                   returned.
# 
# NOTE:   this function uses companion matrix method to find roots. In  case
#         internal EVD  solver  fails  do  find  eigenvalues,  exception  is
#         generated.
# 
# NOTE:   roots are not &quot;polished&quot; and  no  matrix  balancing  is  performed
#         for them.
# 
#   -- ALGLIB --
#      Copyright 24.02.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   x, rep = xalglib.polynomialsolve(a, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  x:          1D array/list of complex
          rep:        class xalglib.polynomialsolverreport

</div></pre>
<a name=unit_psif></a><h2 class=pageheader><code>psif</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_psi' class=toc>psi</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_psi'></a><h3 class=pageheader><code>psi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Psi (digamma) function
# 
#              d      -
#   psi(x)  =  -- ln | (x)
#              dx
# 
# is the logarithmic derivative of the gamma function.
# For integer x,
#                   n-1
#                    -
# psi(n) = -EUL  +   &gt;  1/k.
#                    -
#                   k=1
# 
# This formula is used for 0 &lt; n &lt;= 10.  If x is negative, it
# is transformed to a positive argument by the reflection
# formula  psi(1-x) = psi(x) + pi cot(pi x).
# For general positive x, the argument is made greater than 10
# using the recurrence  psi(x+1) = psi(x) + 1/x.
# Then the following asymptotic expansion is applied:
# 
#                           inf.   B
#                            -      2k
# psi(x) = log(x) - 1/2x -   &gt;   -------
#                            -        2k
#                           k=1   2k x
# 
# where the B2k are Bernoulli numbers.
# 
# ACCURACY:
#    Relative error (except absolute when |psi| &lt; 1):
# arithmetic   domain     # trials      peak         rms
#    IEEE      0,30        30000       1.3e-15     1.4e-16
#    IEEE      -30,0       40000       1.5e-15     2.2e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1992, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.psi(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_ratint></a><h2 class=pageheader><code>ratint</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_barycentricbuildfloaterhormann' class=toc>barycentricbuildfloaterhormann</a><br>
<a href='#sub_barycentricbuildxyw' class=toc>barycentricbuildxyw</a><br>
<a href='#sub_barycentriccalc' class=toc>barycentriccalc</a><br>
<a href='#sub_barycentricdiff1' class=toc>barycentricdiff1</a><br>
<a href='#sub_barycentricdiff2' class=toc>barycentricdiff2</a><br>
<a href='#sub_barycentriclintransx' class=toc>barycentriclintransx</a><br>
<a href='#sub_barycentriclintransy' class=toc>barycentriclintransy</a><br>
<a href='#sub_barycentricunpack' class=toc>barycentricunpack</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_barycentricbuildfloaterhormann'></a><h3 class=pageheader><code>barycentricbuildfloaterhormann</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Rational interpolant without poles
# 
# The subroutine constructs the rational interpolating function without real
# poles  (see  'Barycentric rational interpolation with no  poles  and  high
# rates of approximation', Michael S. Floater. and  Kai  Hormann,  for  more
# information on this subject).
# 
# Input parameters:
#     X   -   interpolation nodes, array[0..N-1].
#     Y   -   function values, array[0..N-1].
#     N   -   number of nodes, N&gt;0.
#     D   -   order of the interpolation scheme, 0 &lt;= D &lt;= N-1.
#             D&lt;0 will cause an error.
#             D&gt;=N it will be replaced with D=N-1.
#             if you don't know what D to choose, use small value about 3-5.
# 
# Output parameters:
#     B   -   barycentric interpolant.
# 
# Note:
#     this algorithm always succeeds and calculates the weights  with  close
#     to machine precision.
# 
#   -- ALGLIB PROJECT --
#      Copyright 17.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   b = xalglib.barycentricbuildfloaterhormann(x, y, n, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          d:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  b:          class xalglib.barycentricinterpolant

</div></pre>
<a name='sub_barycentricbuildxyw'></a><h3 class=pageheader><code>barycentricbuildxyw</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Rational interpolant from X/Y/W arrays
# 
# F(t) = SUM(i=0,n-1,w[i]*f[i]/(t-x[i])) / SUM(i=0,n-1,w[i]/(t-x[i]))
# 
# INPUT PARAMETERS:
#     X   -   interpolation nodes, array[0..N-1]
#     F   -   function values, array[0..N-1]
#     W   -   barycentric weights, array[0..N-1]
#     N   -   nodes count, N&gt;0
# 
# OUTPUT PARAMETERS:
#     B   -   barycentric interpolant built from (X, Y, W)
# 
#   -- ALGLIB --
#      Copyright 17.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   b = xalglib.barycentricbuildxyw(x, y, w, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          w:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  b:          class xalglib.barycentricinterpolant

</div></pre>
<a name='sub_barycentriccalc'></a><h3 class=pageheader><code>barycentriccalc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Rational interpolation using barycentric formula
# 
# F(t) = SUM(i=0,n-1,w[i]*f[i]/(t-x[i])) / SUM(i=0,n-1,w[i]/(t-x[i]))
# 
# Input parameters:
#     B   -   barycentric interpolant built with one of model building
#             subroutines.
#     T   -   interpolation point
# 
# Result:
#     barycentric interpolant F(t)
# 
#   -- ALGLIB --
#      Copyright 17.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.barycentriccalc(b, t)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     b:          class xalglib.barycentricinterpolant
          t:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_barycentricdiff1'></a><h3 class=pageheader><code>barycentricdiff1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Differentiation of barycentric interpolant: first derivative.
# 
# Algorithm used in this subroutine is very robust and should not fail until
# provided with values too close to MaxRealNumber  (usually  MaxRealNumber/N
# or greater will overflow).
# 
# INPUT PARAMETERS:
#     B   -   barycentric interpolant built with one of model building
#             subroutines.
#     T   -   interpolation point
# 
# OUTPUT PARAMETERS:
#     F   -   barycentric interpolant at T
#     DF  -   first derivative
# 
# NOTE
# 
# 
#   -- ALGLIB --
#      Copyright 17.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   f, df = xalglib.barycentricdiff1(b, t)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     b:          class xalglib.barycentricinterpolant
          t:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  f:          float
          df:         float

</div></pre>
<a name='sub_barycentricdiff2'></a><h3 class=pageheader><code>barycentricdiff2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Differentiation of barycentric interpolant: first/second derivatives.
# 
# INPUT PARAMETERS:
#     B   -   barycentric interpolant built with one of model building
#             subroutines.
#     T   -   interpolation point
# 
# OUTPUT PARAMETERS:
#     F   -   barycentric interpolant at T
#     DF  -   first derivative
#     D2F -   second derivative
# 
# NOTE: this algorithm may fail due to overflow/underflor if  used  on  data
# whose values are close to MaxRealNumber or MinRealNumber.  Use more robust
# BarycentricDiff1() subroutine in such cases.
# 
# 
#   -- ALGLIB --
#      Copyright 17.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   f, df, d2f = xalglib.barycentricdiff2(b, t)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     b:          class xalglib.barycentricinterpolant
          t:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  f:          float
          df:         float
          d2f:        float

</div></pre>
<a name='sub_barycentriclintransx'></a><h3 class=pageheader><code>barycentriclintransx</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine performs linear transformation of the argument.
# 
# INPUT PARAMETERS:
#     B       -   rational interpolant in barycentric form
#     CA, CB  -   transformation coefficients: x = CA*t + CB
# 
# OUTPUT PARAMETERS:
#     B       -   transformed interpolant with X replaced by T
# 
#   -- ALGLIB PROJECT --
#      Copyright 19.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.barycentriclintransx(b, ca, cb)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     b:          class xalglib.barycentricinterpolant
          ca:         float
          cb:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_barycentriclintransy'></a><h3 class=pageheader><code>barycentriclintransy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  subroutine   performs   linear  transformation  of  the  barycentric
# interpolant.
# 
# INPUT PARAMETERS:
#     B       -   rational interpolant in barycentric form
#     CA, CB  -   transformation coefficients: B2(x) = CA*B(x) + CB
# 
# OUTPUT PARAMETERS:
#     B       -   transformed interpolant
# 
#   -- ALGLIB PROJECT --
#      Copyright 19.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.barycentriclintransy(b, ca, cb)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     b:          class xalglib.barycentricinterpolant
          ca:         float
          cb:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_barycentricunpack'></a><h3 class=pageheader><code>barycentricunpack</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Extracts X/Y/W arrays from rational interpolant
# 
# INPUT PARAMETERS:
#     B   -   barycentric interpolant
# 
# OUTPUT PARAMETERS:
#     N   -   nodes count, N&gt;0
#     X   -   interpolation nodes, array[0..N-1]
#     F   -   function values, array[0..N-1]
#     W   -   barycentric weights, array[0..N-1]
# 
#   -- ALGLIB --
#      Copyright 17.08.2009 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   n, x, y, w = xalglib.barycentricunpack(b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     b:          class xalglib.barycentricinterpolant
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  n:          int
          x:          1D array/list of float
          y:          1D array/list of float
          w:          1D array/list of float

</div></pre>
<a name=unit_rbf></a><h2 class=pageheader><code>rbf</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_rbfbuildmodel' class=toc>rbfbuildmodel</a><br>
<a href='#sub_rbfcalc' class=toc>rbfcalc</a><br>
<a href='#sub_rbfcalc1' class=toc>rbfcalc1</a><br>
<a href='#sub_rbfcalc2' class=toc>rbfcalc2</a><br>
<a href='#sub_rbfcalc3' class=toc>rbfcalc3</a><br>
<a href='#sub_rbfcalcbuf' class=toc>rbfcalcbuf</a><br>
<a href='#sub_rbfcreate' class=toc>rbfcreate</a><br>
<a href='#sub_rbfcreatecalcbuffer' class=toc>rbfcreatecalcbuffer</a><br>
<a href='#sub_rbfdiff' class=toc>rbfdiff</a><br>
<a href='#sub_rbfdiff1' class=toc>rbfdiff1</a><br>
<a href='#sub_rbfdiff2' class=toc>rbfdiff2</a><br>
<a href='#sub_rbfdiff3' class=toc>rbfdiff3</a><br>
<a href='#sub_rbfdiffbuf' class=toc>rbfdiffbuf</a><br>
<a href='#sub_rbffastcalc' class=toc>rbffastcalc</a><br>
<a href='#sub_rbfgetmodelversion' class=toc>rbfgetmodelversion</a><br>
<a href='#sub_rbfgridcalc2' class=toc>rbfgridcalc2</a><br>
<a href='#sub_rbfgridcalc2v' class=toc>rbfgridcalc2v</a><br>
<a href='#sub_rbfgridcalc2vsubset' class=toc>rbfgridcalc2vsubset</a><br>
<a href='#sub_rbfgridcalc3v' class=toc>rbfgridcalc3v</a><br>
<a href='#sub_rbfgridcalc3vsubset' class=toc>rbfgridcalc3vsubset</a><br>
<a href='#sub_rbfhess' class=toc>rbfhess</a><br>
<a href='#sub_rbfhessbuf' class=toc>rbfhessbuf</a><br>
<a href='#sub_rbfpeekprogress' class=toc>rbfpeekprogress</a><br>
<a href='#sub_rbfrequesttermination' class=toc>rbfrequesttermination</a><br>
<a href='#sub_rbfsetalgobiharmonic' class=toc>rbfsetalgobiharmonic</a><br>
<a href='#sub_rbfsetalgohierarchical' class=toc>rbfsetalgohierarchical</a><br>
<a href='#sub_rbfsetalgomultilayer' class=toc>rbfsetalgomultilayer</a><br>
<a href='#sub_rbfsetalgomultiquadricauto' class=toc>rbfsetalgomultiquadricauto</a><br>
<a href='#sub_rbfsetalgomultiquadricmanual' class=toc>rbfsetalgomultiquadricmanual</a><br>
<a href='#sub_rbfsetalgoqnn' class=toc>rbfsetalgoqnn</a><br>
<a href='#sub_rbfsetalgothinplatespline' class=toc>rbfsetalgothinplatespline</a><br>
<a href='#sub_rbfsetconstterm' class=toc>rbfsetconstterm</a><br>
<a href='#sub_rbfsetfastevaltol' class=toc>rbfsetfastevaltol</a><br>
<a href='#sub_rbfsetlinterm' class=toc>rbfsetlinterm</a><br>
<a href='#sub_rbfsetpoints' class=toc>rbfsetpoints</a><br>
<a href='#sub_rbfsetpointsandscales' class=toc>rbfsetpointsandscales</a><br>
<a href='#sub_rbfsetv2bf' class=toc>rbfsetv2bf</a><br>
<a href='#sub_rbfsetv2its' class=toc>rbfsetv2its</a><br>
<a href='#sub_rbfsetv2supportr' class=toc>rbfsetv2supportr</a><br>
<a href='#sub_rbfsetv3tol' class=toc>rbfsetv3tol</a><br>
<a href='#sub_rbfsetzeroterm' class=toc>rbfsetzeroterm</a><br>
<a href='#sub_rbftscalcbuf' class=toc>rbftscalcbuf</a><br>
<a href='#sub_rbftsdiffbuf' class=toc>rbftsdiffbuf</a><br>
<a href='#sub_rbftshessbuf' class=toc>rbftshessbuf</a><br>
<a href='#sub_rbfunpack' class=toc>rbfunpack</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_rbfbuildmodel'></a><h3 class=pageheader><code>rbfbuildmodel</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This   function  builds  RBF  model  and  returns  report  (contains  some
# information which can be used for evaluation of the algorithm properties).
# 
# Call to this function modifies RBF model by calculating its centers/radii/
# weights  and  saving  them  into  RBFModel  structure.  Initially RBFModel
# contain zero coefficients, but after call to this function  we  will  have
# coefficients which were calculated in order to fit our dataset.
# 
# After you called this function you can call RBFCalc(),  RBFGridCalc()  and
# other model calculation functions.
# 
# INPUT PARAMETERS:
#     S       -   RBF model, initialized by RBFCreate() call
#     Rep     -   report:
#                 * Rep.TerminationType:
#                   * -5 - non-distinct basis function centers were detected,
#                          interpolation  aborted;  only  QNN  returns  this
#                          error   code, other  algorithms  can  handle non-
#                          distinct nodes.
#                   * -4 - nonconvergence of the internal SVD solver
#                   * -3   incorrect model construction algorithm was chosen:
#                          QNN or RBF-ML, combined with one of the incompatible
#                          features:
#                          * NX=1 or NX&gt;3
#                          * points with per-dimension scales.
#                   *  1 - successful termination
#                   *  8 - a termination request was submitted via
#                          rbfrequesttermination() function.
# 
#                 Fields which are set only by modern RBF solvers (hierarchical
#                 or nonnegative; older solvers like QNN and ML initialize these
#                 fields by NANs):
#                 * rep.rmserror - root-mean-square error at nodes
#                 * rep.maxerror - maximum error at nodes
# 
#                 Fields are used for debugging purposes:
#                 * Rep.IterationsCount - iterations count of the LSQR solver
#                 * Rep.NMV - number of matrix-vector products
#                 * Rep.ARows - rows count for the system matrix
#                 * Rep.ACols - columns count for the system matrix
#                 * Rep.ANNZ - number of significantly non-zero elements
#                   (elements above some algorithm-determined threshold)
# 
# NOTE:  failure  to  build  model will leave current state of the structure
# unchanged.
# 
#   -- ALGLIB --
#      Copyright 13.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rep = xalglib.rbfbuildmodel(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rep:        class xalglib.rbfreport

</div></pre>
<a name='sub_rbfcalc'></a><h3 class=pageheader><code>rbfcalc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the RBF model at the given point.
# 
# This is general function which can be used for arbitrary NX (dimension  of
# the space of arguments) and NY (dimension of the function itself). However
# when  you  have  NY=1  you  may  find more convenient to use rbfcalc2() or
# rbfcalc3().
# 
# IMPORTANT: THIS FUNCTION IS THREAD-UNSAFE. It uses fields of  rbfmodel  as
#            temporary arrays, i.e. it is  impossible  to  perform  parallel
#            evaluation on the same rbfmodel object (parallel calls of  this
#            function for independent rbfmodel objects are safe).
#            If you want to perform parallel model evaluation  from multiple
#            threads, use rbftscalcbuf() with per-thread buffer object.
# 
# This function returns 0.0 when model is not initialized.
# 
# INPUT PARAMETERS:
#     S       -   RBF model
#     X       -   coordinates, array[NX].
#                 X may have more than NX elements, in this case only
#                 leading NX will be used.
# 
# OUTPUT PARAMETERS:
#     Y       -   function value, array[NY]. Y is out-parameter and
#                 reallocated after call to this function. In case you  want
#                 to reuse previously allocated Y, you may use RBFCalcBuf(),
#                 which reallocates Y only when it is too small.
# 
#   -- ALGLIB --
#      Copyright 13.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.rbfcalc(s, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_rbfcalc1'></a><h3 class=pageheader><code>rbfcalc1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the 1-dimensional RBF model with scalar
# output (NY=1) at the given point.
# 
# IMPORTANT: this function works only with modern  (hierarchical)  RBFs.  It
#            can not be used with legacy (version 1) RBFs because older  RBF
#            code does not support 1-dimensional models.
# 
# IMPORTANT: THIS FUNCTION IS THREAD-UNSAFE. It uses fields of  rbfmodel  as
#            temporary arrays, i.e. it is  impossible  to  perform  parallel
#            evaluation on the same rbfmodel object (parallel calls of  this
#            function for independent rbfmodel objects are safe).
#            If you want to perform parallel model evaluation  from multiple
#            threads, use rbftscalcbuf() with per-thread buffer object.
# 
# This function returns 0.0 when:
# * the model is not initialized
# * NX&lt;&gt;1
# * NY&lt;&gt;1
# 
# INPUT PARAMETERS:
#     S       -   RBF model
#     X0      -   X-coordinate, finite number
# 
# RESULT:
#     value of the model or 0.0 (as defined above)
# 
#   -- ALGLIB --
#      Copyright 13.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rbfcalc1(s, x0)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x0:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_rbfcalc2'></a><h3 class=pageheader><code>rbfcalc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the 2-dimensional RBF model with scalar
# output (NY=1) at the given point.
# 
# IMPORTANT: THIS FUNCTION IS THREAD-UNSAFE. It uses fields of  rbfmodel  as
#            temporary arrays, i.e. it is  impossible  to  perform  parallel
#            evaluation on the same rbfmodel object (parallel calls of  this
#            function for independent rbfmodel objects are safe).
#            If you want to perform parallel model evaluation  from multiple
#            threads, use rbftscalcbuf() with per-thread buffer object.
# 
# This function returns 0.0 when:
# * model is not initialized
# * NX&lt;&gt;2
#  *NY&lt;&gt;1
# 
# INPUT PARAMETERS:
#     S       -   RBF model
#     X0      -   first coordinate, finite number
#     X1      -   second coordinate, finite number
# 
# RESULT:
#     value of the model or 0.0 (as defined above)
# 
#   -- ALGLIB --
#      Copyright 13.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rbfcalc2(s, x0, x1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x0:         float
          x1:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_rbfcalc3'></a><h3 class=pageheader><code>rbfcalc3</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the 3-dimensional RBF model with scalar
# output (NY=1) at the given point.
# 
# IMPORTANT: THIS FUNCTION IS THREAD-UNSAFE. It uses fields of  rbfmodel  as
#            temporary arrays, i.e. it is  impossible  to  perform  parallel
#            evaluation on the same rbfmodel object (parallel calls of  this
#            function for independent rbfmodel objects are safe).
#            If you want to perform parallel model evaluation  from multiple
#            threads, use rbftscalcbuf() with per-thread buffer object.
# 
# This function returns 0.0 when:
# * model is not initialized
# * NX&lt;&gt;3
#  *NY&lt;&gt;1
# 
# INPUT PARAMETERS:
#     S       -   RBF model
#     X0      -   first coordinate, finite number
#     X1      -   second coordinate, finite number
#     X2      -   third coordinate, finite number
# 
# RESULT:
#     value of the model or 0.0 (as defined above)
# 
#   -- ALGLIB --
#      Copyright 13.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rbfcalc3(s, x0, x1, x2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x0:         float
          x1:         float
          x2:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_rbfcalcbuf'></a><h3 class=pageheader><code>rbfcalcbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the RBF model at the given point.
# 
# Same as rbfcalc(), but does not reallocate Y when in is large enough to
# store function values.
# 
# IMPORTANT: THIS FUNCTION IS THREAD-UNSAFE. It uses fields of  rbfmodel  as
#            temporary arrays, i.e. it is  impossible  to  perform  parallel
#            evaluation on the same rbfmodel object (parallel calls of  this
#            function for independent rbfmodel objects are safe).
#            If you want to perform parallel model evaluation  from multiple
#            threads, use rbftscalcbuf() with per-thread buffer object.
# 
# INPUT PARAMETERS:
#     S       -   RBF model
#     X       -   coordinates, array[NX].
#                 X may have more than NX elements, in this case only
#                 leading NX will be used.
#     Y       -   possibly preallocated array
# 
# OUTPUT PARAMETERS:
#     Y       -   function value, array[NY]. Y is not reallocated when it
#                 is larger than NY.
# 
#   -- ALGLIB --
#      Copyright 13.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.rbfcalcbuf(s, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x:          1D array/list of float
          y:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_rbfcreate'></a><h3 class=pageheader><code>rbfcreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates RBF  model  for  a  scalar (NY=1)  or  vector (NY&gt;1)
# function in a NX-dimensional space (NX&gt;=1).
# 
# Newly created model is empty. It can be used for interpolation right after
# creation, but it just returns zeros. You have to add points to the  model,
# tune interpolation settings, and then  call  model  construction  function
# rbfbuildmodel() which will update model according to your specification.
# 
# USAGE:
# 1. User creates model with rbfcreate()
# 2. User adds dataset with rbfsetpoints() or rbfsetpointsandscales()
# 3. User selects RBF solver by calling:
#    * rbfsetalgohierarchical() - for a HRBF solver,  a  hierarchical large-
#      scale Gaussian RBFs  (works  well  for  uniformly  distributed  point
#      clouds, but may fail when the data are non-uniform; use other solvers
#      below in such cases)
#    * rbfsetalgothinplatespline() - for a large-scale DDM-RBF  solver  with
#      thin plate spline basis function being used
#    * rbfsetalgobiharmonic() -  for  a  large-scale  DDM-RBF  solver   with
#      biharmonic basis function being used
#    * rbfsetalgomultiquadricauto() -  for a large-scale DDM-RBF solver with
#      multiquadric basis function being used (automatic  selection  of  the
#      scale parameter Alpha)
#    * rbfsetalgomultiquadricmanual() -  for a  large-scale  DDM-RBF  solver
#      with multiquadric basis function being used (manual selection  of the
#      scale parameter Alpha)
# 4. (OPTIONAL) User chooses polynomial term by calling:
#    * rbflinterm() to set linear term (default)
#    * rbfconstterm() to set constant term
#    * rbfzeroterm() to set zero term
# 5. User calls rbfbuildmodel() function which rebuilds model  according  to
#    the specification
# 
# INPUT PARAMETERS:
#     NX      -   dimension of the space, NX&gt;=1
#     NY      -   function dimension, NY&gt;=1
# 
# OUTPUT PARAMETERS:
#     S       -   RBF model (initially equals to zero)
# 
# NOTE 1: memory requirements. RBF models require amount of memory  which is
#         proportional  to the number of data points. Some additional memory
#         is allocated during model construction, but most of this memory is
#         freed after the model  coefficients  are   calculated.  Amount  of
#         this additional memory depends  on  model  construction  algorithm
#         being used.
# 
#   -- ALGLIB --
#      Copyright 13.12.2011, 20.06.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.rbfcreate(nx, ny)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     nx:         int
          ny:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.rbfmodel

</div></pre>
<a name='sub_rbfcreatecalcbuffer'></a><h3 class=pageheader><code>rbfcreatecalcbuffer</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates buffer  structure  which  can  be  used  to  perform
# parallel  RBF  model  evaluations  (with  one  RBF  model  instance  being
# used from multiple threads, as long as  different  threads  use  different
# instances of the buffer).
# 
# This buffer object can be used with  rbftscalcbuf()  function  (here  &quot;ts&quot;
# stands for &quot;thread-safe&quot;, &quot;buf&quot; is a suffix which denotes  function  which
# reuses previously allocated output space).
# 
# A buffer creation function (this function) is also thread-safe.  I.e.  you
# may safely create multiple buffers for the same  RBF  model  from multiple
# threads.
# 
# NOTE: the  buffer  object  is  just  a  collection of several preallocated
#       dynamic arrays and precomputed values. If you  delete  its  &quot;parent&quot;
#       RBF model when the buffer is still alive, nothing  bad  will  happen
#       (no dangling pointers or resource leaks).  The  buffer  will  simply
#       become useless.
# 
# How to use it:
# * create RBF model structure with rbfcreate()
# * load data, tune parameters
# * call rbfbuildmodel()
# * call rbfcreatecalcbuffer(), once per thread working with RBF model  (you
#   should call this function only AFTER call to rbfbuildmodel(), see  below
#   for more information)
# * call rbftscalcbuf() from different threads,  with  each  thread  working
#   with its own copy of buffer object.
# * it is recommended to reuse buffer as much  as  possible  because  buffer
#   creation involves allocation of several large dynamic arrays.  It  is  a
#   huge waste of resource to use it just once.
# 
# INPUT PARAMETERS
#     S           -   RBF model
# 
# OUTPUT PARAMETERS
#     Buf         -   external buffer.
# 
# IMPORTANT: buffer object should be used only with  RBF model object  which
#            was used to initialize buffer. Any attempt to use buffer   with
#            different object is dangerous - you may  get  memory  violation
#            error because sizes of internal arrays do not fit to dimensions
#            of RBF structure.
# 
# IMPORTANT: you  should  call  this function only for model which was built
#            with rbfbuildmodel() function, after successful  invocation  of
#            rbfbuildmodel().  Sizes   of   some   internal  structures  are
#            determined only after model is built, so buffer object  created
#            before model  construction  stage  will  be  useless  (and  any
#            attempt to use it will result in exception).
# 
#   -- ALGLIB --
#      Copyright 02.04.2016 by Sergey Bochkanov
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   buf = xalglib.rbfcreatecalcbuffer(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  buf:        class xalglib.rbfcalcbuffer

</div></pre>
<a name='sub_rbfdiff'></a><h3 class=pageheader><code>rbfdiff</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the RBF model and  its  derivatives  at
# the given point.
# 
# This is general function which can be used for arbitrary NX (dimension  of
# the space of arguments) and NY (dimension of the function itself). However
# if you have NX=3 and NY=1, you may find more convenient to use rbfdiff3().
# 
# IMPORTANT: THIS FUNCTION IS THREAD-UNSAFE. It uses fields of  rbfmodel  as
#            temporary arrays, i.e. it is  impossible  to  perform  parallel
#            evaluation on the same rbfmodel object (parallel calls of  this
#            function for independent rbfmodel objects are safe).
# 
#            If you want to perform parallel model evaluation  from multiple
#            threads, use rbftsdiffbuf() with per-thread buffer object.
# 
# This function returns 0.0 in Y and/or DY in the following cases:
# * the model is not initialized (Y=0, DY=0)
# * the gradient is undefined at the trial point. Some basis  functions have
#   discontinuous derivatives at the interpolation nodes:
#   * biharmonic splines f=r have no Hessian and no gradient at the nodes
#   In these cases only DY is set to zero (Y is still returned)
# 
# INPUT PARAMETERS:
#     S       -   RBF model
#     X       -   coordinates, array[NX].
#                 X may have more than NX elements, in this case only
#                 leading NX will be used.
# 
# OUTPUT PARAMETERS:
#     Y       -   function value, array[NY]. Y is out-parameter and
#                 reallocated after call to this function. In case you  want
#                 to reuse previously allocated Y, you may use RBFDiffBuf(),
#                 which reallocates Y only when it is too small.
#     DY      -   derivatives, array[NX*NY]:
#                 * Y[I*NX+J] with 0&lt;=I&lt;NY and 0&lt;=J&lt;NX  stores derivative of
#                   function component I with respect to input J.
#                 * for NY=1 it is simply NX-dimensional gradient of the
#                   scalar NX-dimensional function
#                 DY is out-parameter and reallocated  after  call  to  this
#                 function. In case you want to reuse  previously  allocated
#                 DY, you may use RBFDiffBuf(), which  reallocates  DY  only
#                 when it is too small to store the result.
# 
#   -- ALGLIB --
#      Copyright 13.12.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y, dy = xalglib.rbfdiff(s, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float
          dy:         1D array/list of float

</div></pre>
<a name='sub_rbfdiff1'></a><h3 class=pageheader><code>rbfdiff1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates value and derivatives of  the  1-dimensional  RBF
# model with scalar output (NY=1) at the given point.
# 
# IMPORTANT: THIS FUNCTION IS THREAD-UNSAFE. It uses fields of  rbfmodel  as
#            temporary arrays, i.e. it is  impossible  to  perform  parallel
#            evaluation on the same rbfmodel object (parallel calls of  this
#            function for independent rbfmodel objects are safe).
#            If you want to perform parallel model evaluation  from multiple
#            threads, use rbftscalcbuf() with per-thread buffer object.
# 
# This function returns 0.0 in Y and/or DY in the following cases:
# * the model is not initialized (Y=0, DY=0)
# * NX&lt;&gt;1 or NY&lt;&gt;1 (Y=0, DY=0)
# * the gradient is undefined at the trial point. Some basis  functions have
#   discontinuous derivatives at the interpolation nodes:
#   * biharmonic splines f=r have no Hessian and no gradient at the nodes
#   In these cases only DY is set to zero (Y is still returned)
# 
# INPUT PARAMETERS:
#     S       -   RBF model
#     X0      -   first coordinate, finite number
# 
# OUTPUT PARAMETERS:
#     Y       -   value of the model or 0.0 (as defined above)
#     DY0     -   derivative with respect to X0
# 
#   -- ALGLIB --
#      Copyright 13.12.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y, dy0 = xalglib.rbfdiff1(s, x0)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x0:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          float
          dy0:        float

</div></pre>
<a name='sub_rbfdiff2'></a><h3 class=pageheader><code>rbfdiff2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates value and derivatives of  the  2-dimensional  RBF
# model with scalar output (NY=1) at the given point.
# 
# IMPORTANT: THIS FUNCTION IS THREAD-UNSAFE. It uses fields of  rbfmodel  as
#            temporary arrays, i.e. it is  impossible  to  perform  parallel
#            evaluation on the same rbfmodel object (parallel calls of  this
#            function for independent rbfmodel objects are safe).
#            If you want to perform parallel model evaluation  from multiple
#            threads, use rbftscalcbuf() with per-thread buffer object.
# 
# This function returns 0.0 in Y and/or DY in the following cases:
# * the model is not initialized (Y=0, DY=0)
# * NX&lt;&gt;2 or NY&lt;&gt;1 (Y=0, DY=0)
# * the gradient is undefined at the trial point. Some basis  functions have
#   discontinuous derivatives at the interpolation nodes:
#   * biharmonic splines f=r have no Hessian and no gradient at the nodes
#   In these cases only DY is set to zero (Y is still returned)
# 
# INPUT PARAMETERS:
#     S       -   RBF model
#     X0      -   first coordinate, finite number
#     X1      -   second coordinate, finite number
# 
# OUTPUT PARAMETERS:
#     Y       -   value of the model or 0.0 (as defined above)
#     DY0     -   derivative with respect to X0
#     DY1     -   derivative with respect to X1
# 
#   -- ALGLIB --
#      Copyright 13.12.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y, dy0, dy1 = xalglib.rbfdiff2(s, x0, x1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x0:         float
          x1:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          float
          dy0:        float
          dy1:        float

</div></pre>
<a name='sub_rbfdiff3'></a><h3 class=pageheader><code>rbfdiff3</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates value and derivatives of  the  3-dimensional  RBF
# model with scalar output (NY=1) at the given point.
# 
# IMPORTANT: THIS FUNCTION IS THREAD-UNSAFE. It uses fields of  rbfmodel  as
#            temporary arrays, i.e. it is  impossible  to  perform  parallel
#            evaluation on the same rbfmodel object (parallel calls of  this
#            function for independent rbfmodel objects are safe).
#            If you want to perform parallel model evaluation  from multiple
#            threads, use rbftscalcbuf() with per-thread buffer object.
# 
# This function returns 0.0 in Y and/or DY in the following cases:
# * the model is not initialized (Y=0, DY=0)
# * NX&lt;&gt;3 or NY&lt;&gt;1 (Y=0, DY=0)
# * the gradient is undefined at the trial point. Some basis  functions have
#   discontinuous derivatives at the interpolation nodes:
#   * biharmonic splines f=r have no Hessian and no gradient at the nodes
#   In these cases only DY is set to zero (Y is still returned)
# 
# INPUT PARAMETERS:
#     S       -   RBF model
#     X0      -   first coordinate, finite number
#     X1      -   second coordinate, finite number
#     X2      -   third coordinate, finite number
# 
# OUTPUT PARAMETERS:
#     Y       -   value of the model or 0.0 (as defined above)
#     DY0     -   derivative with respect to X0
#     DY1     -   derivative with respect to X1
#     DY2     -   derivative with respect to X2
# 
#   -- ALGLIB --
#      Copyright 13.12.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y, dy0, dy1, dy2 = xalglib.rbfdiff3(s, x0, x1, x2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x0:         float
          x1:         float
          x2:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          float
          dy0:        float
          dy1:        float
          dy2:        float

</div></pre>
<a name='sub_rbfdiffbuf'></a><h3 class=pageheader><code>rbfdiffbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the RBF model and  its  derivatives  at
# the given point. It is a buffered version of the RBFDiff() which tries  to
# reuse possibly preallocated output arrays Y/DY as much as possible.
# 
# This is general function which can be used for arbitrary NX (dimension  of
# the space of arguments) and NY (dimension of the function itself). However
# if you have NX=1, 2 or 3 and NY=1, you may find  more  convenient  to  use
# rbfdiff1(), rbfdiff2() or rbfdiff3().
# 
# IMPORTANT: THIS FUNCTION IS THREAD-UNSAFE. It uses fields of  rbfmodel  as
#            temporary arrays, i.e. it is  impossible  to  perform  parallel
#            evaluation on the same rbfmodel object (parallel calls of  this
#            function for independent rbfmodel objects are safe).
# 
#            If you want to perform parallel model evaluation  from multiple
#            threads, use rbftsdiffbuf() with per-thread buffer object.
# 
# This function returns 0.0 in Y and/or DY in the following cases:
# * the model is not initialized (Y=0, DY=0)
# * the gradient is undefined at the trial point. Some basis  functions have
#   discontinuous derivatives at the interpolation nodes:
#   * biharmonic splines f=r have no Hessian and no gradient at the nodes
#   In these cases only DY is set to zero (Y is still returned)
# 
# INPUT PARAMETERS:
#     S       -   RBF model
#     X       -   coordinates, array[NX].
#                 X may have more than NX elements, in this case only
#                 leading NX will be used.
#     Y, DY   -   possibly preallocated arrays; if array size is large enough
#                 to store results, this function does not  reallocate  array
#                 to fit output size exactly.
# 
# OUTPUT PARAMETERS:
#     Y       -   function value, array[NY].
#     DY      -   derivatives, array[NX*NY]:
#                 * Y[I*NX+J] with 0&lt;=I&lt;NY and 0&lt;=J&lt;NX  stores derivative of
#                   function component I with respect to input J.
#                 * for NY=1 it is simply NX-dimensional gradient of the
#                   scalar NX-dimensional function
# 
#   -- ALGLIB --
#      Copyright 13.12.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y, dy = xalglib.rbfdiffbuf(s, x, y, dy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x:          1D array/list of float
          y:          1D array/list of float
          dy:         1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float
          dy:         1D array/list of float

</div></pre>
<a name='sub_rbffastcalc'></a><h3 class=pageheader><code>rbffastcalc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the RBF model at the given point  using
# a fast approximate algorithm whenever possible. If no  fast  algorithm  is
# available for a given model type, traditional O(N) approach is used.
# 
# Presently, fast evaluation is implemented only for biharmonic splines.
# 
# The absolute approximation accuracy is controlled by the rbfsetfastevaltol()
# function.
# 
# IMPORTANT: THIS FUNCTION IS THREAD-UNSAFE. It uses fields of  rbfmodel  as
#            temporary arrays, i.e. it is  impossible  to  perform  parallel
#            evaluation on the same rbfmodel object (parallel calls of  this
#            function for independent rbfmodel objects are safe).
#            If you want to perform parallel model evaluation  from multiple
#            threads, use rbftscalcbuf() with a per-thread buffer object.
# 
# This function returns 0.0 when model is not initialized.
# 
# INPUT PARAMETERS:
#     S       -   RBF model
#     X       -   coordinates, array[NX].
#                 X may have more than NX elements, in this case only
#                 leading NX will be used.
# 
# OUTPUT PARAMETERS:
#     Y       -   function value, array[NY]. Y is out-parameter and
#                 reallocated after call to this function. In case you  want
#                 to reuse previously allocated Y, you may use RBFCalcBuf(),
#                 which reallocates Y only when it is too small.
# 
#   -- ALGLIB --
#      Copyright 19.09.2022 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.rbffastcalc(s, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_rbfgetmodelversion'></a><h3 class=pageheader><code>rbfgetmodelversion</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns model version.
# 
# INPUT PARAMETERS:
#     S       -   RBF model
# 
# RESULT:
#     * 1 - for models created by QNN and RBF-ML algorithms,
#       compatible with ALGLIB 3.10 or earlier.
#     * 2 - for models created by HierarchicalRBF, requires
#       ALGLIB 3.11 or later
# 
#   -- ALGLIB --
#      Copyright 06.07.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rbfgetmodelversion(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_rbfgridcalc2'></a><h3 class=pageheader><code>rbfgridcalc2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is legacy function for gridded calculation of RBF model.
# 
# It is superseded by rbfgridcalc2v() and  rbfgridcalc2vsubset()  functions.
# 
#   -- ALGLIB --
#      Copyright 13.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.rbfgridcalc2(s, x0, n0, x1, n1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x0:         1D array/list of float
          n0:         int
          x1:         1D array/list of float
          n1:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          2D array/list of float

</div></pre>
<a name='sub_rbfgridcalc2v'></a><h3 class=pageheader><code>rbfgridcalc2v</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the RBF  model  at  the  regular  grid,
# which  has  N0*N1 points, with Point[I,J] = (X0[I], X1[J]).  Vector-valued
# RBF models are supported.
# 
# This function returns 0.0 when:
# * model is not initialized
# * NX&lt;&gt;2
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# NOTE: Parallel  processing  is  implemented only for modern (hierarchical)
#       RBFs. Legacy version 1 RBFs (created  by  QNN  or  RBF-ML) are still
#       processed serially.
# 
# INPUT PARAMETERS:
#     S       -   RBF model, used in read-only mode, can be  shared  between
#                 multiple   invocations  of  this  function  from  multiple
#                 threads.
# 
#     X0      -   array of grid nodes, first coordinates, array[N0].
#                 Must be ordered by ascending. Exception is generated
#                 if the array is not correctly ordered.
#     N0      -   grid size (number of nodes) in the first dimension
# 
#     X1      -   array of grid nodes, second coordinates, array[N1]
#                 Must be ordered by ascending. Exception is generated
#                 if the array is not correctly ordered.
#     N1      -   grid size (number of nodes) in the second dimension
# 
# OUTPUT PARAMETERS:
#     Y       -   function values, array[NY*N0*N1], where NY is a  number of
#                 &quot;output&quot; vector values (this  function   supports  vector-
#                 valued RBF models). Y is out-variable and  is  reallocated
#                 by this function.
#                 Y[K+NY*(I0+I1*N0)]=F_k(X0[I0],X1[I1]), for:
#                 *  K=0...NY-1
#                 * I0=0...N0-1
#                 * I1=0...N1-1
# 
# NOTE: this function supports weakly ordered grid nodes, i.e. you may  have
#       X[i]=X[i+1] for some i. It does  not  provide  you  any  performance
#       benefits  due  to   duplication  of  points,  just  convenience  and
#       flexibility.
# 
# NOTE: this  function  is  re-entrant,  i.e.  you  may  use  same  rbfmodel
#       structure in multiple threads calling  this function  for  different
#       grids.
# 
# NOTE: if you need function values on some subset  of  regular  grid, which
#       may be described as &quot;several compact and  dense  islands&quot;,  you  may
#       use rbfgridcalc2vsubset().
# 
#   -- ALGLIB --
#      Copyright 27.01.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.rbfgridcalc2v(s, x0, n0, x1, n1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x0:         1D array/list of float
          n0:         int
          x1:         1D array/list of float
          n1:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_rbfgridcalc2vsubset'></a><h3 class=pageheader><code>rbfgridcalc2vsubset</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the RBF model at some subset of regular
# grid:
# * grid has N0*N1 points, with Point[I,J] = (X0[I], X1[J])
# * only values at some subset of this grid are required
# Vector-valued RBF models are supported.
# 
# This function returns 0.0 when:
# * model is not initialized
# * NX&lt;&gt;2
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# NOTE: Parallel  processing  is  implemented only for modern (hierarchical)
#       RBFs. Legacy version 1 RBFs (created  by  QNN  or  RBF-ML) are still
#       processed serially.
# 
# INPUT PARAMETERS:
#     S       -   RBF model, used in read-only mode, can be  shared  between
#                 multiple   invocations  of  this  function  from  multiple
#                 threads.
# 
#     X0      -   array of grid nodes, first coordinates, array[N0].
#                 Must be ordered by ascending. Exception is generated
#                 if the array is not correctly ordered.
#     N0      -   grid size (number of nodes) in the first dimension
# 
#     X1      -   array of grid nodes, second coordinates, array[N1]
#                 Must be ordered by ascending. Exception is generated
#                 if the array is not correctly ordered.
#     N1      -   grid size (number of nodes) in the second dimension
# 
#     FlagY   -   array[N0*N1]:
#                 * Y[I0+I1*N0] corresponds to node (X0[I0],X1[I1])
#                 * it is a &quot;bitmap&quot; array which contains  False  for  nodes
#                   which are NOT calculated, and True for nodes  which  are
#                   required.
# 
# OUTPUT PARAMETERS:
#     Y       -   function values, array[NY*N0*N1*N2], where NY is a  number
#                 of &quot;output&quot; vector values (this function  supports vector-
#                 valued RBF models):
#                 * Y[K+NY*(I0+I1*N0)]=F_k(X0[I0],X1[I1]),
#                   for K=0...NY-1, I0=0...N0-1, I1=0...N1-1.
#                 * elements of Y[] which correspond  to  FlagY[]=True   are
#                   loaded by model values (which may be  exactly  zero  for
#                   some nodes).
#                 * elements of Y[] which correspond to FlagY[]=False MAY be
#                   initialized by zeros OR may be calculated. This function
#                   processes  grid  as  a  hierarchy  of  nested blocks and
#                   micro-rows. If just one element of micro-row is required,
#                   entire micro-row (up to 8 nodes in the current  version,
#                   but no promises) is calculated.
# 
# NOTE: this function supports weakly ordered grid nodes, i.e. you may  have
#       X[i]=X[i+1] for some i. It does  not  provide  you  any  performance
#       benefits  due  to   duplication  of  points,  just  convenience  and
#       flexibility.
# 
# NOTE: this  function  is  re-entrant,  i.e.  you  may  use  same  rbfmodel
#       structure in multiple threads calling  this function  for  different
#       grids.
# 
#   -- ALGLIB --
#      Copyright 04.03.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.rbfgridcalc2vsubset(s, x0, n0, x1, n1, flagy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x0:         1D array/list of float
          n0:         int
          x1:         1D array/list of float
          n1:         int
          flagy:      1D array/list of bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_rbfgridcalc3v'></a><h3 class=pageheader><code>rbfgridcalc3v</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the RBF  model  at  the  regular  grid,
# which  has  N0*N1*N2  points,  with  Point[I,J,K] = (X0[I], X1[J], X2[K]).
# Vector-valued RBF models are supported.
# 
# This function returns 0.0 when:
# * model is not initialized
# * NX&lt;&gt;3
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# NOTE: Parallel  processing  is  implemented only for modern (hierarchical)
#       RBFs. Legacy version 1 RBFs (created  by  QNN  or  RBF-ML) are still
#       processed serially.
# 
# INPUT PARAMETERS:
#     S       -   RBF model, used in read-only mode, can be  shared  between
#                 multiple   invocations  of  this  function  from  multiple
#                 threads.
# 
#     X0      -   array of grid nodes, first coordinates, array[N0].
#                 Must be ordered by ascending. Exception is generated
#                 if the array is not correctly ordered.
#     N0      -   grid size (number of nodes) in the first dimension
# 
#     X1      -   array of grid nodes, second coordinates, array[N1]
#                 Must be ordered by ascending. Exception is generated
#                 if the array is not correctly ordered.
#     N1      -   grid size (number of nodes) in the second dimension
# 
#     X2      -   array of grid nodes, third coordinates, array[N2]
#                 Must be ordered by ascending. Exception is generated
#                 if the array is not correctly ordered.
#     N2      -   grid size (number of nodes) in the third dimension
# 
# OUTPUT PARAMETERS:
#     Y       -   function values, array[NY*N0*N1*N2], where NY is a  number
#                 of &quot;output&quot; vector values (this function  supports vector-
#                 valued RBF models). Y is out-variable and  is  reallocated
#                 by this function.
#                 Y[K+NY*(I0+I1*N0+I2*N0*N1)]=F_k(X0[I0],X1[I1],X2[I2]), for:
#                 *  K=0...NY-1
#                 * I0=0...N0-1
#                 * I1=0...N1-1
#                 * I2=0...N2-1
# 
# NOTE: this function supports weakly ordered grid nodes, i.e. you may  have
#       X[i]=X[i+1] for some i. It does  not  provide  you  any  performance
#       benefits  due  to   duplication  of  points,  just  convenience  and
#       flexibility.
# 
# NOTE: this  function  is  re-entrant,  i.e.  you  may  use  same  rbfmodel
#       structure in multiple threads calling  this function  for  different
#       grids.
# 
# NOTE: if you need function values on some subset  of  regular  grid, which
#       may be described as &quot;several compact and  dense  islands&quot;,  you  may
#       use rbfgridcalc3vsubset().
# 
#   -- ALGLIB --
#      Copyright 04.03.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.rbfgridcalc3v(s, x0, n0, x1, n1, x2, n2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x0:         1D array/list of float
          n0:         int
          x1:         1D array/list of float
          n1:         int
          x2:         1D array/list of float
          n2:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_rbfgridcalc3vsubset'></a><h3 class=pageheader><code>rbfgridcalc3vsubset</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the RBF model at some subset of regular
# grid:
# * grid has N0*N1*N2 points, with Point[I,J,K] = (X0[I], X1[J], X2[K])
# * only values at some subset of this grid are required
# Vector-valued RBF models are supported.
# 
# This function returns 0.0 when:
# * model is not initialized
# * NX&lt;&gt;3
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# NOTE: Parallel  processing  is  implemented only for modern (hierarchical)
#       RBFs. Legacy version 1 RBFs (created  by  QNN  or  RBF-ML) are still
#       processed serially.
# 
# INPUT PARAMETERS:
#     S       -   RBF model, used in read-only mode, can be  shared  between
#                 multiple   invocations  of  this  function  from  multiple
#                 threads.
# 
#     X0      -   array of grid nodes, first coordinates, array[N0].
#                 Must be ordered by ascending. Exception is generated
#                 if the array is not correctly ordered.
#     N0      -   grid size (number of nodes) in the first dimension
# 
#     X1      -   array of grid nodes, second coordinates, array[N1]
#                 Must be ordered by ascending. Exception is generated
#                 if the array is not correctly ordered.
#     N1      -   grid size (number of nodes) in the second dimension
# 
#     X2      -   array of grid nodes, third coordinates, array[N2]
#                 Must be ordered by ascending. Exception is generated
#                 if the array is not correctly ordered.
#     N2      -   grid size (number of nodes) in the third dimension
# 
#     FlagY   -   array[N0*N1*N2]:
#                 * Y[I0+I1*N0+I2*N0*N1] corresponds to node (X0[I0],X1[I1],X2[I2])
#                 * it is a &quot;bitmap&quot; array which contains  False  for  nodes
#                   which are NOT calculated, and True for nodes  which  are
#                   required.
# 
# OUTPUT PARAMETERS:
#     Y       -   function values, array[NY*N0*N1*N2], where NY is a  number
#                 of &quot;output&quot; vector values (this function  supports vector-
#                 valued RBF models):
#                 * Y[K+NY*(I0+I1*N0+I2*N0*N1)]=F_k(X0[I0],X1[I1],X2[I2]),
#                   for K=0...NY-1, I0=0...N0-1, I1=0...N1-1, I2=0...N2-1.
#                 * elements of Y[] which correspond  to  FlagY[]=True   are
#                   loaded by model values (which may be  exactly  zero  for
#                   some nodes).
#                 * elements of Y[] which correspond to FlagY[]=False MAY be
#                   initialized by zeros OR may be calculated. This function
#                   processes  grid  as  a  hierarchy  of  nested blocks and
#                   micro-rows. If just one element of micro-row is required,
#                   entire micro-row (up to 8 nodes in the current  version,
#                   but no promises) is calculated.
# 
# NOTE: this function supports weakly ordered grid nodes, i.e. you may  have
#       X[i]=X[i+1] for some i. It does  not  provide  you  any  performance
#       benefits  due  to   duplication  of  points,  just  convenience  and
#       flexibility.
# 
# NOTE: this  function  is  re-entrant,  i.e.  you  may  use  same  rbfmodel
#       structure in multiple threads calling  this function  for  different
#       grids.
# 
#   -- ALGLIB --
#      Copyright 04.03.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.rbfgridcalc3vsubset(s, x0, n0, x1, n1, x2, n2, flagy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x0:         1D array/list of float
          n0:         int
          x1:         1D array/list of float
          n1:         int
          x2:         1D array/list of float
          n2:         int
          flagy:      1D array/list of bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_rbfhess'></a><h3 class=pageheader><code>rbfhess</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the RBF model and  its first and second
# derivatives (Hessian matrix) at the given point.
# 
# This function supports both scalar (NY=1) and vector-valued (NY&gt;1) RBFs.
# 
# IMPORTANT: THIS FUNCTION IS THREAD-UNSAFE. It uses fields of  rbfmodel  as
#            temporary arrays, i.e. it is  impossible  to  perform  parallel
#            evaluation on the same rbfmodel object (parallel calls of  this
#            function for independent rbfmodel objects are safe).
# 
#            If you want to perform parallel model evaluation  from multiple
#            threads, use rbftshessbuf() with per-thread buffer object.
# 
# This function returns 0 in Y and/or DY and/or D2Y in the following cases:
# * the model is not initialized (Y=0, DY=0, D2Y=0)
# * the gradient and/or Hessian is undefined at the trial point.  Some basis
#   functions have discontinuous derivatives at the interpolation nodes:
#   * thin plate splines have no Hessian at the nodes
#   * biharmonic splines f=r have no Hessian and no gradient at the  nodes
#   In these cases only corresponding derivative is set  to  zero,  and  the
#   rest of the derivatives is still returned.
# 
# INPUT PARAMETERS:
#     S       -   RBF model
#     X       -   coordinates, array[NX].
#                 X may have more than NX elements, in this case only
#                 leading NX will be used.
# 
# OUTPUT PARAMETERS:
#     Y       -   function value, array[NY].
#                 Y is out-parameter and  reallocated  after  call  to  this
#                 function. In case you  want to reuse previously  allocated
#                 Y, you may use RBFHessBuf(), which reallocates Y only when
#                 it is too small.
#     DY      -   first derivatives, array[NY*NX]:
#                 * Y[I*NX+J] with 0&lt;=I&lt;NY and 0&lt;=J&lt;NX  stores derivative of
#                   function component I with respect to input J.
#                 * for NY=1 it is simply NX-dimensional gradient of the
#                   scalar NX-dimensional function
#                 DY is out-parameter and reallocated  after  call  to  this
#                 function. In case you want to reuse  previously  allocated
#                 DY, you may use RBFHessBuf(), which  reallocates  DY  only
#                 when it is too small to store the result.
#     D2Y     -   second derivatives, array[NY*NX*NX]:
#                 * for NY=1 it is NX*NX array that stores  Hessian  matrix,
#                   with Y[I*NX+J]=Y[J*NX+I].
#                 * for  a  vector-valued  RBF  with  NY&gt;1  it  contains  NY
#                   subsequently stored Hessians: an element Y[K*NX*NX+I*NX+J]
#                   with  0&lt;=K&lt;NY,  0&lt;=I&lt;NX  and  0&lt;=J&lt;NX    stores   second
#                   derivative of the function #K  with  respect  to  inputs
#                   #I and #J.
#                 D2Y is out-parameter and reallocated  after  call  to this
#                 function. In case you want to reuse  previously  allocated
#                 D2Y, you may use RBFHessBuf(), which  reallocates D2Y only
#                 when it is too small to store the result.
# 
#   -- ALGLIB --
#      Copyright 13.12.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y, dy, d2y = xalglib.rbfhess(s, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float
          dy:         1D array/list of float
          d2y:        1D array/list of float

</div></pre>
<a name='sub_rbfhessbuf'></a><h3 class=pageheader><code>rbfhessbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the RBF model and  its first and second
# derivatives (Hessian matrix) at the given point. It is a buffered  version
# that reuses memory  allocated  in  output  buffers  Y/DY/D2Y  as  much  as
# possible.
# 
# This function supports both scalar (NY=1) and vector-valued (NY&gt;1) RBFs.
# 
# IMPORTANT: THIS FUNCTION IS THREAD-UNSAFE. It uses fields of  rbfmodel  as
#            temporary arrays, i.e. it is  impossible  to  perform  parallel
#            evaluation on the same rbfmodel object (parallel calls of  this
#            function for independent rbfmodel objects are safe).
# 
#            If you want to perform parallel model evaluation  from multiple
#            threads, use rbftshessbuf() with per-thread buffer object.
# 
# This function returns 0 in Y and/or DY and/or D2Y in the following cases:
# * the model is not initialized (Y=0, DY=0, D2Y=0)
# * the gradient and/or Hessian is undefined at the trial point.  Some basis
#   functions have discontinuous derivatives at the interpolation nodes:
#   * thin plate splines have no Hessian at the nodes
#   * biharmonic splines f=r have no Hessian and no gradient at the  nodes
#   In these cases only corresponding derivative is set  to  zero,  and  the
#   rest of the derivatives is still returned.
# 
# INPUT PARAMETERS:
#     S       -   RBF model
#     X       -   coordinates, array[NX].
#                 X may have more than NX elements, in this case only
#                 leading NX will be used.
#     Y,DY,D2Y-   possible preallocated output arrays. If these  arrays  are
#                 smaller than  required  to  store  the  result,  they  are
#                 automatically reallocated. If array is large enough, it is
#                 not resized.
# 
# OUTPUT PARAMETERS:
#     Y       -   function value, array[NY].
#     DY      -   first derivatives, array[NY*NX]:
#                 * Y[I*NX+J] with 0&lt;=I&lt;NY and 0&lt;=J&lt;NX  stores derivative of
#                   function component I with respect to input J.
#                 * for NY=1 it is simply NX-dimensional gradient of the
#                   scalar NX-dimensional function
#     D2Y     -   second derivatives, array[NY*NX*NX]:
#                 * for NY=1 it is NX*NX array that stores  Hessian  matrix,
#                   with Y[I*NX+J]=Y[J*NX+I].
#                 * for  a  vector-valued  RBF  with  NY&gt;1  it  contains  NY
#                   subsequently stored Hessians: an element Y[K*NX*NX+I*NX+J]
#                   with  0&lt;=K&lt;NY,  0&lt;=I&lt;NX  and  0&lt;=J&lt;NX    stores   second
#                   derivative of the function #K  with  respect  to  inputs
#                   #I and #J.
# 
#   -- ALGLIB --
#      Copyright 13.12.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y, dy, d2y = xalglib.rbfhessbuf(s, x, y, dy, d2y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          x:          1D array/list of float
          y:          1D array/list of float
          dy:         1D array/list of float
          d2y:        1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float
          dy:         1D array/list of float
          d2y:        1D array/list of float

</div></pre>
<a name='sub_rbfpeekprogress'></a><h3 class=pageheader><code>rbfpeekprogress</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is used to peek into hierarchical RBF  construction  process
# from  some  other  thread  and  get current progress indicator. It returns
# value in [0,1].
# 
# IMPORTANT: only HRBFs (hierarchical RBFs) support  peeking  into  progress
#            indicator. Legacy RBF-ML and RBF-QNN do  not  support  it.  You
#            will always get 0 value.
# 
# INPUT PARAMETERS:
#     S           -   RBF model object
# 
# RESULT:
#     progress value, in [0,1]
# 
#   -- ALGLIB --
#      Copyright 17.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rbfpeekprogress(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_rbfrequesttermination'></a><h3 class=pageheader><code>rbfrequesttermination</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function  is  used  to  submit  a  request  for  termination  of  the
# hierarchical RBF construction process from some other thread.  As  result,
# RBF construction is terminated smoothly (with proper deallocation  of  all
# necessary resources) and resultant model is filled by zeros.
# 
# A rep.terminationtype=8 will be returned upon receiving such request.
# 
# IMPORTANT: only  HRBFs  (hierarchical  RBFs) support termination requests.
#            Legacy RBF-ML and RBF-QNN do not  support  it.  An  attempt  to
#            terminate their construction will be ignored.
# 
# IMPORTANT: termination request flag is cleared when the model construction
#            starts. Thus, any pre-construction termination requests will be
#            silently ignored - only ones submitted AFTER  construction  has
#            actually began will be handled.
# 
# INPUT PARAMETERS:
#     S           -   RBF model object
# 
#   -- ALGLIB --
#      Copyright 17.11.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfrequesttermination(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetalgobiharmonic'></a><h3 class=pageheader><code>rbfsetalgobiharmonic</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  chooses  a  biharmonic DDM-RBF solver, a fast  RBF  solver
# with f(r)=r as a basis function.
# 
# This algorithm has following important features:
# * no tunable parameters
# * C0 continuous RBF model (the model has discontinuous derivatives at  the
#   interpolation nodes)
# * fast model construction algorithm with O(N) memory and O(N*logN) running
#   time requirements. Hundreds of thousands of points can be  handled  with
#   this algorithm.
# * accelerated evaluation using far field expansions  (aka  fast multipoles
#   method) is supported. See rbffastcalc() for more information.
# * controllable smoothing via optional nonlinearity penalty
# 
# INPUT PARAMETERS:
#     S       -   RBF model, initialized by rbfcreate() call
#     LambdaV -   smoothing parameter, LambdaV&gt;=0, defaults to 0.0:
#                 * LambdaV=0 means that no smoothing is applied,  i.e.  the
#                   spline tries to pass through all dataset points exactly
#                 * LambdaV&gt;0 means that a multiquadric spline is built with
#                   larger  LambdaV   corresponding   to  models  with  less
#                   nonlinearities.  Smoothing   spline   reproduces  target
#                   values at nodes with small error; from the  other  side,
#                   it is much more stable.
#                   Recommended values:
#                   * 1.0E-6 for minimal stability improving smoothing
#                   * 1.0E-3 a good value to start experiments; first results
#                     are visible
#                   * 1.0 for strong smoothing
# 
# IMPORTANT: this model construction algorithm was introduced in ALGLIB 3.19
#            and  produces  models  which  are  INCOMPATIBLE  with  previous
#            versions of ALGLIB. You can  not  unserialize  models  produced
#            with this function in ALGLIB 3.18 or earlier.
# 
# NOTE:      polyharmonic RBFs, including thin plate splines,  are  somewhat
#            slower than compactly supported RBFs built with  HRBF algorithm
#            due to the fact that non-compact basis function does not vanish
#            far away from the nodes. From the other side, polyharmonic RBFs
#            often produce much better results than HRBFs.
# 
# NOTE:      this algorithm supports specification of per-dimensional  radii
#            via scale vector, which is set by means of rbfsetpointsandscales()
#            function. This feature is useful if  you solve  spatio-temporal
#            interpolation problems where different radii are  required  for
#            spatial and temporal dimensions.
# 
#   -- ALGLIB --
#      Copyright 12.12.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetalgobiharmonic(s, lambdav)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetalgobiharmonic(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          lambdav:    float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetalgohierarchical'></a><h3 class=pageheader><code>rbfsetalgohierarchical</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function chooses HRBF solver, a 2nd version of ALGLIB RBFs.
# 
# This  algorithm is called Hierarchical RBF. It  similar  to  its  previous
# incarnation, RBF-ML, i.e.  it  also  builds  a  sequence  of  models  with
# decreasing radii. However, it uses more economical way of  building  upper
# layers (ones with large radii), which results in faster model construction
# and evaluation, as well as smaller memory footprint during construction.
# 
# This algorithm has following important features:
# * ability to handle millions of points
# * controllable smoothing via nonlinearity penalization
# * support for specification of per-dimensional  radii  via  scale  vector,
#   which is set by means of rbfsetpointsandscales() function. This  feature
#   is useful if you solve  spatio-temporal  interpolation  problems,  where
#   different radii are required for spatial and temporal dimensions.
# 
# Running times are roughly proportional to:
# * N*log(N)*NLayers - for the model construction
# * N*NLayers - for the model evaluation
# You may see that running time does not depend on search radius  or  points
# density, just on the number of layers in the hierarchy.
# 
# INPUT PARAMETERS:
#     S       -   RBF model, initialized by rbfcreate() call
#     RBase   -   RBase parameter, RBase&gt;0
#     NLayers -   NLayers parameter, NLayers&gt;0, recommended value  to  start
#                 with - about 5.
#     LambdaNS-   &gt;=0, nonlinearity penalty coefficient, negative values are
#                 not allowed. This parameter adds controllable smoothing to
#                 the problem, which may reduce noise. Specification of non-
#                 zero lambda means that in addition to fitting error solver
#                 will  also  minimize   LambdaNS*|S''(x)|^2  (appropriately
#                 generalized to multiple dimensions.
# 
#                 Specification of exactly zero value means that no  penalty
#                 is added  (we  do  not  even  evaluate  matrix  of  second
#                 derivatives which is necessary for smoothing).
# 
#                 Calculation of nonlinearity penalty is costly - it results
#                 in  several-fold  increase  of  model  construction  time.
#                 Evaluation time remains the same.
# 
#                 Optimal  lambda  is  problem-dependent and requires  trial
#                 and  error.  Good  value to  start  from  is  1e-5...1e-6,
#                 which corresponds to slightly noticeable smoothing  of the
#                 function.  Value  1e-2  usually  means  that  quite  heavy
#                 smoothing is applied.
# 
# TUNING ALGORITHM
# 
# In order to use this algorithm you have to choose three parameters:
# * initial radius RBase
# * number of layers in the model NLayers
# * penalty coefficient LambdaNS
# 
# Initial radius is easy to choose - you can pick any number  several  times
# larger  than  the  average  distance between points. Algorithm won't break
# down if you choose radius which is too large (model construction time will
# increase, but model will be built correctly).
# 
# Choose such number of layers that RLast=RBase/2^(NLayers-1)  (radius  used
# by  the  last  layer)  will  be  smaller than the typical distance between
# points.  In  case  model  error  is  too large, you can increase number of
# layers.  Having  more  layers  will make model construction and evaluation
# proportionally slower, but it will allow you to have model which precisely
# fits your data. From the other side, if you want to  suppress  noise,  you
# can DECREASE number of layers to make your model less flexible (or specify
# non-zero LambdaNS).
# 
# TYPICAL ERRORS
# 
# 1. Using too small number of layers - RBF models with large radius are not
#    flexible enough to reproduce small variations in the  target  function.
#    You  need  many  layers  with  different radii, from large to small, in
#    order to have good model.
# 
# 2. Using  initial  radius  which  is  too  small.  You will get model with
#    &quot;holes&quot; in the areas which are too far away from interpolation centers.
#    However, algorithm will work correctly (and quickly) in this case.
# 
#   -- ALGLIB --
#      Copyright 20.06.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetalgohierarchical(s, rbase, nlayers, lambdans)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          rbase:      float
          nlayers:    int
          lambdans:   float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetalgomultilayer'></a><h3 class=pageheader><code>rbfsetalgomultilayer</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# DEPRECATED: this function is deprecated. ALGLIB  includes  new  RBF  model
#             construction algorithms: DDM-RBF (since version 3.19) and HRBF
#             (since version 3.11).
# 
#   -- ALGLIB --
#      Copyright 02.03.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetalgomultilayer(s, rbase, nlayers, lambdav)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetalgomultilayer(s, rbase, nlayers)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          rbase:      float
          nlayers:    int
          lambdav:    float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetalgomultiquadricauto'></a><h3 class=pageheader><code>rbfsetalgomultiquadricauto</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function chooses a multiquadric DDM-RBF solver,  a  fast  RBF  solver
# with f(r)=sqrt(r^2+Alpha^2)  as  a  basis  function,  with   Alpha   being
# automatically determined.
# 
# This algorithm has following important features:
# * easy setup - no need to tune Alpha, good value is automatically assigned
# * C2 continuous RBF model
# * fast  model construction algorithm with O(N) memory and  O(N^2)  running
#   time requirements. Hundreds of thousands of points can be  handled  with
#   this algorithm.
# * controllable smoothing via optional nonlinearity penalty
# 
# This algorithm automatically selects Alpha  as  a  mean  distance  to  the
# nearest neighbor (ignoring neighbors that are too close).
# 
# INPUT PARAMETERS:
#     S       -   RBF model, initialized by rbfcreate() call
#     LambdaV -   smoothing parameter, LambdaV&gt;=0, defaults to 0.0:
#                 * LambdaV=0 means that no smoothing is applied,  i.e.  the
#                   spline tries to pass through all dataset points exactly
#                 * LambdaV&gt;0 means that a multiquadric spline is built with
#                   larger  LambdaV   corresponding   to  models  with  less
#                   nonlinearities.  Smoothing   spline   reproduces  target
#                   values at nodes with small error; from the  other  side,
#                   it is much more stable.
#                   Recommended values:
#                   * 1.0E-6 for minimal stability improving smoothing
#                   * 1.0E-3 a good value to start experiments; first results
#                     are visible
#                   * 1.0 for strong smoothing
# 
# IMPORTANT: this model construction algorithm was introduced in ALGLIB 3.19
#            and  produces  models  which  are  INCOMPATIBLE  with  previous
#            versions of ALGLIB. You can  not  unserialize  models  produced
#            with this function in ALGLIB 3.18 or earlier.
# 
# NOTE:      polyharmonic RBFs, including thin plate splines,  are  somewhat
#            slower than compactly supported RBFs built with  HRBF algorithm
#            due to the fact that non-compact basis function does not vanish
#            far away from the nodes. From the other side, polyharmonic RBFs
#            often produce much better results than HRBFs.
# 
# NOTE:      this algorithm supports specification of per-dimensional  radii
#            via scale vector, which is set by means of rbfsetpointsandscales()
#            function. This feature is useful if  you solve  spatio-temporal
#            interpolation problems where different radii are  required  for
#            spatial and temporal dimensions.
# 
#   -- ALGLIB --
#      Copyright 12.12.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetalgomultiquadricauto(s, lambdav)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetalgomultiquadricauto(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          lambdav:    float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetalgomultiquadricmanual'></a><h3 class=pageheader><code>rbfsetalgomultiquadricmanual</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function chooses a multiquadric DDM-RBF solver,  a  fast  RBF  solver
# with f(r)=sqrt(r^2+Alpha^2) as a basis function,  with  manual  choice  of
# the scale parameter Alpha.
# 
# This algorithm has following important features:
# * C2 continuous RBF model (when Alpha&gt;0 is used; for Alpha=0 the model  is
#   merely C0 continuous)
# * fast  model construction algorithm with O(N) memory and  O(N^2)  running
#   time requirements. Hundreds of thousands of points can be  handled  with
#   this algorithm.
# * controllable smoothing via optional nonlinearity penalty
# 
# One important point is that  this  algorithm  includes  tunable  parameter
# Alpha, which should be carefully chosen. Selecting too  large  value  will
# result in extremely badly  conditioned  problems  (interpolation  accuracy
# may degrade up to complete breakdown) whilst selecting too small value may
# produce models that are precise but nearly nonsmooth at the nodes.
# 
# Good value to  start  from  is  mean  distance  between  nodes. Generally,
# choosing too small Alpha is better than choosing too large - in the former
# case you still have model that reproduces target values at the nodes.
# 
# In most cases, better option is to choose good Alpha automatically - it is
# done by another version of the same algorithm that is activated by calling
# rbfsetalgomultiquadricauto() method.
# 
# INPUT PARAMETERS:
#     S       -   RBF model, initialized by rbfcreate() call
#     Alpha   -   basis function parameter, Alpha&gt;=0:
#                 * Alpha&gt;0  means that multiquadric algorithm is used which
#                   produces C2-continuous RBF model
#                 * Alpha=0  means that the multiquadric kernel  effectively
#                   becomes a biharmonic one: f=r. As a  result,  the  model
#                   becomes nonsmooth at nodes, and hence is C0 continuous
#     LambdaV -   smoothing parameter, LambdaV&gt;=0, defaults to 0.0:
#                 * LambdaV=0 means that no smoothing is applied,  i.e.  the
#                   spline tries to pass through all dataset points exactly
#                 * LambdaV&gt;0 means that a multiquadric spline is built with
#                   larger  LambdaV   corresponding   to  models  with  less
#                   nonlinearities.  Smoothing   spline   reproduces  target
#                   values at nodes with small error; from the  other  side,
#                   it is much more stable.
#                   Recommended values:
#                   * 1.0E-6 for minimal stability improving smoothing
#                   * 1.0E-3 a good value to start experiments; first results
#                     are visible
#                   * 1.0 for strong smoothing
# 
# IMPORTANT: this model construction algorithm was introduced in ALGLIB 3.19
#            and  produces  models  which  are  INCOMPATIBLE  with  previous
#            versions of ALGLIB. You can  not  unserialize  models  produced
#            with this function in ALGLIB 3.18 or earlier.
# 
# NOTE:      polyharmonic RBFs, including thin plate splines,  are  somewhat
#            slower than compactly supported RBFs built with  HRBF algorithm
#            due to the fact that non-compact basis function does not vanish
#            far away from the nodes. From the other side, polyharmonic RBFs
#            often produce much better results than HRBFs.
# 
# NOTE:      this algorithm supports specification of per-dimensional  radii
#            via scale vector, which is set by means of rbfsetpointsandscales()
#            function. This feature is useful if  you solve  spatio-temporal
#            interpolation problems where different radii are  required  for
#            spatial and temporal dimensions.
# 
#   -- ALGLIB --
#      Copyright 12.12.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetalgomultiquadricmanual(s, alpha, lambdav)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetalgomultiquadricmanual(s, alpha)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          alpha:      float
          lambdav:    float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetalgoqnn'></a><h3 class=pageheader><code>rbfsetalgoqnn</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# DEPRECATED: this function is deprecated. ALGLIB  includes  new  RBF  model
#             construction algorithms: DDM-RBF (since version 3.19) and HRBF
#             (since version 3.11).
# 
#   -- ALGLIB --
#      Copyright 13.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetalgoqnn(s, q, z)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetalgoqnn(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          q:          float
          z:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetalgothinplatespline'></a><h3 class=pageheader><code>rbfsetalgothinplatespline</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function chooses a thin plate  spline  DDM-RBF  solver,  a  fast  RBF
# solver with f(r)=r^2*ln(r) basis function.
# 
# This algorithm has following important features:
# * easy setup - no tunable parameters
# * C1 continuous RBF model (gradient is defined everywhere, but Hessian  is
#   undefined at nodes), high-quality interpolation
# * fast  model construction algorithm with O(N) memory and  O(N^2)  running
#   time requirements. Hundreds of thousands of points can be  handled  with
#   this algorithm.
# * controllable smoothing via optional nonlinearity penalty
# 
# INPUT PARAMETERS:
#     S       -   RBF model, initialized by rbfcreate() call
#     LambdaV -   smoothing parameter, LambdaV&gt;=0, defaults to 0.0:
#                 * LambdaV=0 means that no smoothing is applied,  i.e.  the
#                   spline tries to pass through all dataset points exactly
#                 * LambdaV&gt;0 means that a smoothing thin  plate  spline  is
#                   built, with larger LambdaV corresponding to models  with
#                   less nonlinearities. Smoothing spline reproduces  target
#                   values at nodes with small error; from the  other  side,
#                   it is much more stable.
#                   Recommended values:
#                   * 1.0E-6 for minimal stability improving smoothing
#                   * 1.0E-3 a good value to start experiments; first results
#                     are visible
#                   * 1.0 for strong smoothing
# 
# IMPORTANT: this model construction algorithm was introduced in ALGLIB 3.19
#            and  produces  models  which  are  INCOMPATIBLE  with  previous
#            versions of ALGLIB. You can  not  unserialize  models  produced
#            with this function in ALGLIB 3.18 or earlier.
# 
# NOTE:      polyharmonic RBFs, including thin plate splines,  are  somewhat
#            slower than compactly supported RBFs built with  HRBF algorithm
#            due to the fact that non-compact basis function does not vanish
#            far away from the nodes. From the other side, polyharmonic RBFs
#            often produce much better results than HRBFs.
# 
# NOTE:      this algorithm supports specification of per-dimensional  radii
#            via scale vector, which is set by means of rbfsetpointsandscales()
#            function. This feature is useful if  you solve  spatio-temporal
#            interpolation problems where different radii are  required  for
#            spatial and temporal dimensions.
# 
#   -- ALGLIB --
#      Copyright 12.12.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetalgothinplatespline(s, lambdav)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetalgothinplatespline(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          lambdav:    float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetconstterm'></a><h3 class=pageheader><code>rbfsetconstterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets constant term (model is a sum of radial basis functions
# plus constant).  This  function  won't  have  effect  until  next  call to
# RBFBuildModel().
# 
# IMPORTANT: thin plate splines require  polynomial term to be  linear,  not
#            constant,  in  order  to  provide   interpolation   guarantees.
#            Although  failures  are  exceptionally  rare,  some  small  toy
#            problems may result in degenerate linear systems. Thus,  it  is
#            advised to use linear term when one fits data with TPS.
# 
# INPUT PARAMETERS:
#     S       -   RBF model, initialized by RBFCreate() call
# 
#   -- ALGLIB --
#      Copyright 13.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetconstterm(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetfastevaltol'></a><h3 class=pageheader><code>rbfsetfastevaltol</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets absolute accuracy of a  fast evaluation  algorithm used
# by rbffastcalc() and other fast evaluation functions.
# 
# A fast evaluation algorithm is model-dependent and is available  only  for
# some RBF models. Usually it utilizes far field expansions (a generalization
# of the fast multipoles  method).  If  no  approximate  fast  evaluator  is
# available for the  current RBF model type, this function has no effect.
# 
# NOTE: this function can be called before or after the model was built. The
#       result will be the same.
# 
# NOTE: this  function  has  O(N) running time, where N is a  points  count.
#       Most fast evaluators work by aggregating influence of  point groups,
#       i.e. by computing so called far field. Changing evaluator  tolerance
#       means that far field radii have to  be  recomputed  for  each  point
#       cluster, and we have O(N) such clusters.
# 
#       This function is still very fast, but  it  should  not be called too
#       often, e.g. every time you call rbffastcalc() in a loop.
# 
# NOTE: the tolerance  set  by this function is an accuracy of an  evaluator
#       which computes the value of the model. It is  NOT  accuracy  of  the
#       model itself.
# 
#       E.g., if you set evaluation accuracy to 1E-12, the model value  will
#       be computed with required precision. However, the model itself is an
#       approximation of the target (the default requirement is to fit model
#       with ~6 digits of precision) and THIS accuracy can  not  be  changed
#       after the model was built.
# 
# IMPORTANT: THIS FUNCTION IS THREAD-UNSAFE. Calling it while another thread
#            tries to use rbffastcalc() is unsafe because it means that  the
#            accuracy requirements will change in the middle of computations.
#            The algorithm may behave unpredictably.
# 
# INPUT PARAMETERS:
#     S       -   RBF model
#     TOL     -   TOL&gt;0, desired evaluation tolerance:
#                 * should be somewhere between 1E-3 and 1E-6
#                 * values outside of this range will cause no problems (the
#                   evaluator will do the job anyway). However,  too  strict
#                   precision requirements may mean  that  no  approximation
#                   speed-up will be achieved.
# 
#   -- ALGLIB --
#      Copyright 19.09.2022 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetfastevaltol(s, tol)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          tol:        float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetlinterm'></a><h3 class=pageheader><code>rbfsetlinterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets linear term (model is a sum of radial  basis  functions
# plus linear polynomial). This function won't have effect until  next  call
# to RBFBuildModel().
# 
# Using linear term is a default option and it is the best one - it provides
# best convergence guarantees for all RBF model  types: legacy  RBF-QNN  and
# RBF-ML, Gaussian HRBFs and all types of DDM-RBF models.
# 
# Other options, like constant or zero term, work for HRBFs,  almost  always
# work for DDM-RBFs but provide no stability  guarantees  in the latter case
# (e.g. the solver may fail on some carefully prepared problems).
# 
# INPUT PARAMETERS:
#     S       -   RBF model, initialized by RBFCreate() call
# 
#   -- ALGLIB --
#      Copyright 13.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetlinterm(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetpoints'></a><h3 class=pageheader><code>rbfsetpoints</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function adds dataset.
# 
# This function overrides results of the previous calls, i.e. multiple calls
# of this function will result in only the last set being added.
# 
# IMPORTANT: ALGLIB version 3.11 and later allows you to specify  a  set  of
#            per-dimension scales. Interpolation radii are multiplied by the
#            scale vector. It may be useful if you have mixed spatio-temporal
#            data (say, a set of 3D slices recorded at different times).
#            You should call rbfsetpointsandscales() function  to  use  this
#            feature.
# 
# INPUT PARAMETERS:
#     S       -   RBF model, initialized by rbfcreate() call.
#     XY      -   points, array[N,NX+NY]. One row corresponds to  one  point
#                 in the dataset. First NX elements  are  coordinates,  next
#                 NY elements are function values. Array may  be larger than
#                 specified, in  this  case  only leading [N,NX+NY] elements
#                 will be used.
#     N       -   number of points in the dataset
# 
# After you've added dataset and (optionally) tuned algorithm  settings  you
# should call rbfbuildmodel() in order to build a model for you.
# 
# NOTE: dataset added by this function is not saved during model serialization.
#       MODEL ITSELF is serialized, but data used to build it are not.
# 
#       So, if you 1) add dataset to  empty  RBF  model,  2)  serialize  and
#       unserialize it, then you will get an empty RBF model with no dataset
#       being attached.
# 
#       From the other side, if you call rbfbuildmodel() between (1) and (2),
#       then after (2) you will get your fully constructed RBF model  -  but
#       again with no dataset attached, so subsequent calls to rbfbuildmodel()
#       will produce empty model.
# 
# 
#   -- ALGLIB --
#      Copyright 13.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetpoints(s, xy, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetpoints(s, xy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          xy:         2D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetpointsandscales'></a><h3 class=pageheader><code>rbfsetpointsandscales</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function adds dataset and a vector of per-dimension scales.
# 
# It may be useful if you have mixed spatio-temporal data - say, a set of 3D
# slices recorded at different times. Such data typically require  different
# RBF radii for spatial and temporal dimensions. ALGLIB solves this  problem
# by specifying single RBF radius, which is (optionally) multiplied  by  the
# scale vector.
# 
# This function overrides results of the previous calls, i.e. multiple calls
# of this function will result in only the last set being added.
# 
# IMPORTANT: only modern RBF algorithms  support  variable  scaling.  Legacy
#            algorithms like RBF-ML or QNN algorithms  will  result  in   -3
#            completion code being returned (incorrect algorithm).
# 
# INPUT PARAMETERS:
#     R       -   RBF model, initialized by rbfcreate() call.
#     XY      -   points, array[N,NX+NY]. One row corresponds to  one  point
#                 in the dataset. First NX elements  are  coordinates,  next
#                 NY elements are function values. Array may  be larger than
#                 specified, in  this  case  only leading [N,NX+NY] elements
#                 will be used.
#     N       -   number of points in the dataset
#     S       -   array[NX], scale vector, S[i]&gt;0.
# 
# After you've added dataset and (optionally) tuned algorithm  settings  you
# should call rbfbuildmodel() in order to build a model for you.
# 
# NOTE: dataset added by this function is not saved during model serialization.
#       MODEL ITSELF is serialized, but data used to build it are not.
# 
#       So, if you 1) add dataset to  empty  RBF  model,  2)  serialize  and
#       unserialize it, then you will get an empty RBF model with no dataset
#       being attached.
# 
#       From the other side, if you call rbfbuildmodel() between (1) and (2),
#       then after (2) you will get your fully constructed RBF model  -  but
#       again with no dataset attached, so subsequent calls to rbfbuildmodel()
#       will produce empty model.
# 
# 
#   -- ALGLIB --
#      Copyright 20.06.2016 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetpointsandscales(r, xy, n, s)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetpointsandscales(r, xy, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     r:          class xalglib.rbfmodel
          xy:         2D array/list of float
          n:          int
          s:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> r
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetv2bf'></a><h3 class=pageheader><code>rbfsetv2bf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets basis function type, which can be:
# * 0 for classic Gaussian
# * 1 for fast and compact bell-like basis function, which  becomes  exactly
#   zero at distance equal to 3*R (default option).
# 
# INPUT PARAMETERS:
#     S       -   RBF model, initialized by RBFCreate() call
#     BF      -   basis function type:
#                 * 0 - classic Gaussian
#                 * 1 - fast and compact one
# 
#   -- ALGLIB --
#      Copyright 01.02.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetv2bf(s, bf)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          bf:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetv2its'></a><h3 class=pageheader><code>rbfsetv2its</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets stopping criteria of the underlying linear  solver  for
# hierarchical (version 2) RBF constructor.
# 
# INPUT PARAMETERS:
#     S       -   RBF model, initialized by RBFCreate() call
#     MaxIts  -   this criterion will stop algorithm after MaxIts iterations.
#                 Typically a few hundreds iterations is required,  with 400
#                 being a good default value to start experimentation.
#                 Zero value means that default value will be selected.
# 
#   -- ALGLIB --
#      Copyright 01.02.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetv2its(s, maxits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          maxits:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetv2supportr'></a><h3 class=pageheader><code>rbfsetv2supportr</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets support radius parameter  of  hierarchical  (version 2)
# RBF constructor.
# 
# Hierarchical RBF model achieves great speed-up  by removing from the model
# excessive (too dense) nodes. Say, if you have RBF radius equal to 1 meter,
# and two nodes are just 1 millimeter apart, you  may  remove  one  of  them
# without reducing model quality.
# 
# Support radius parameter is used to justify which points need removal, and
# which do not. If two points are less than  SUPPORT_R*CUR_RADIUS  units  of
# distance apart, one of them is removed from the model. The larger  support
# radius  is, the faster model  construction  AND  evaluation are.  However,
# too large values result in &quot;bumpy&quot; models.
# 
# INPUT PARAMETERS:
#     S       -   RBF model, initialized by RBFCreate() call
#     R       -   support radius coefficient, &gt;=0.
#                 Recommended values are [0.1,0.4] range, with 0.1 being
#                 default value.
# 
#   -- ALGLIB --
#      Copyright 01.02.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetv2supportr(s, r)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          r:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetv3tol'></a><h3 class=pageheader><code>rbfsetv3tol</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets desired accuracy for a version 3 RBF model.
# 
# As of ALGLIB 3.20.0, version 3 models include biharmonic RBFs, thin  plate
# splines, multiquadrics.
# 
# Version 3 models are fit  with  specialized  domain  decomposition  method
# which splits problem into smaller  chunks.  Models  with  size  less  than
# the DDM chunk size are computed nearly exactly in one step. Larger  models
# are built with an iterative linear solver. This function controls accuracy
# of the solver.
# 
# INPUT PARAMETERS:
#     S       -   RBF model, initialized by RBFCreate() call
#     TOL     -   desired precision:
#                 * must be non-negative
#                 * should be somewhere between 0.001 and 0.000001
#                 * values higher than 0.001 make little sense   -  you  may
#                   lose a lot of precision with no performance gains.
#                 * values below 1E-6 usually require too much time to converge,
#                   so they are silenly replaced by a 1E-6 cutoff value. Thus,
#                   zero can be used to denote 'maximum precision'.
# 
#   -- ALGLIB --
#      Copyright 01.10.2022 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetv3tol(s, tol)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          tol:        float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbfsetzeroterm'></a><h3 class=pageheader><code>rbfsetzeroterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  sets  zero  term (model is a sum of radial basis functions
# without polynomial term). This function won't have effect until next  call
# to RBFBuildModel().
# 
# IMPORTANT: only  Gaussian  RBFs  (HRBF  algorithm)  provide  interpolation
#            guarantees when no polynomial term is used.  Most  other  RBFs,
#            including   biharmonic  splines,   thin   plate   splines   and
#            multiquadrics, require at least constant term  (biharmonic  and
#            multiquadric) or linear one (thin plate splines)  in  order  to
#            guarantee non-degeneracy of linear systems being solved.
# 
#            Although  failures  are  exceptionally  rare,  some  small  toy
#            problems still may result in degenerate linear systems. Thus,it
#            is advised to use constant/linear term, unless one is 100% sure
#            that he needs zero term.
# 
# INPUT PARAMETERS:
#     S       -   RBF model, initialized by RBFCreate() call
# 
#   -- ALGLIB --
#      Copyright 13.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.rbfsetzeroterm(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_rbftscalcbuf'></a><h3 class=pageheader><code>rbftscalcbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the RBF model at the given point, using
# external  buffer  object  (internal  temporaries  of  RBF  model  are  not
# modified).
# 
# This function allows to use same RBF model object  in  different  threads,
# assuming  that  different   threads  use  different  instances  of  buffer
# structure.
# 
# INPUT PARAMETERS:
#     S       -   RBF model, may be shared between different threads
#     Buf     -   buffer object created for this particular instance of  RBF
#                 model with rbfcreatecalcbuffer().
#     X       -   coordinates, array[NX].
#                 X may have more than NX elements, in this case only
#                 leading NX will be used.
#     Y       -   possibly preallocated array
# 
# OUTPUT PARAMETERS:
#     Y       -   function value, array[NY]. Y is not reallocated when it
#                 is larger than NY.
# 
#   -- ALGLIB --
#      Copyright 13.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.rbftscalcbuf(s, buf, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          buf:        class xalglib.rbfcalcbuffer
          x:          1D array/list of float
          y:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> buf
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_rbftsdiffbuf'></a><h3 class=pageheader><code>rbftsdiffbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the RBF model and  its  derivatives  at
# the given point, using external buffer object (internal temporaries of the
# RBF model are not modified).
# 
# This function allows to use same RBF model object  in  different  threads,
# assuming  that  different   threads  use different instances of the buffer
# structure.
# 
# This function returns 0.0 in Y and/or DY in the following cases:
# * the model is not initialized (Y=0, DY=0)
# * the gradient is undefined at the trial point. Some basis  functions have
#   discontinuous derivatives at the interpolation nodes:
#   * biharmonic splines f=r have no Hessian and no gradient at the nodes
#   In these cases only DY is set to zero (Y is still returned)
# 
# INPUT PARAMETERS:
#     S       -   RBF model, may be shared between different threads
#     Buf     -   buffer object created for this particular instance of  RBF
#                 model with rbfcreatecalcbuffer().
#     X       -   coordinates, array[NX].
#                 X may have more than NX elements, in this case only
#                 leading NX will be used.
#     Y, DY   -   possibly preallocated arrays; if array size is large enough
#                 to store results, this function does not  reallocate  array
#                 to fit output size exactly.
# 
# OUTPUT PARAMETERS:
#     Y       -   function value, array[NY].
#     DY      -   derivatives, array[NX*NY]:
#                 * Y[I*NX+J] with 0&lt;=I&lt;NY and 0&lt;=J&lt;NX  stores derivative of
#                   function component I with respect to input J.
#                 * for NY=1 it is simply NX-dimensional gradient of the
#                   scalar NX-dimensional function
#                 Zero is returned when the first derivative is undefined.
# 
#   -- ALGLIB --
#      Copyright 13.12.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y, dy = xalglib.rbftsdiffbuf(s, buf, x, y, dy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          buf:        class xalglib.rbfcalcbuffer
          x:          1D array/list of float
          y:          1D array/list of float
          dy:         1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> buf
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float
          dy:         1D array/list of float

</div></pre>
<a name='sub_rbftshessbuf'></a><h3 class=pageheader><code>rbftshessbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates values of the RBF model and  its first and second
# derivatives (Hessian matrix) at the given  point,  using  external  buffer
# object (internal temporaries of the RBF  model  are  not  modified).
# 
# This function allows to use same RBF model object  in  different  threads,
# assuming  that  different   threads  use different instances of the buffer
# structure.
# 
# This function returns 0 in Y and/or DY and/or D2Y in the following cases:
# * the model is not initialized (Y=0, DY=0, D2Y=0)
# * the gradient and/or Hessian is undefined at the trial point.  Some basis
#   functions have discontinuous derivatives at the interpolation nodes:
#   * thin plate splines have no Hessian at the nodes
#   * biharmonic splines f=r have no Hessian and no gradient at the  nodes
#   In these cases only corresponding derivative is set  to  zero,  and  the
#   rest of the derivatives is still returned.
# 
# INPUT PARAMETERS:
#     S       -   RBF model, may be shared between different threads
#     Buf     -   buffer object created for this particular instance of  RBF
#                 model with rbfcreatecalcbuffer().
#     X       -   coordinates, array[NX].
#                 X may have more than NX elements, in this case only
#                 leading NX will be used.
#     Y,DY,D2Y-   possible preallocated output arrays. If these  arrays  are
#                 smaller than  required  to  store  the  result,  they  are
#                 automatically reallocated. If array is large enough, it is
#                 not resized.
# 
# OUTPUT PARAMETERS:
#     Y       -   function value, array[NY].
#     DY      -   first derivatives, array[NY*NX]:
#                 * Y[I*NX+J] with 0&lt;=I&lt;NY and 0&lt;=J&lt;NX  stores derivative of
#                   function component I with respect to input J.
#                 * for NY=1 it is simply NX-dimensional gradient of the
#                   scalar NX-dimensional function
#                 Zero is returned when the first derivative is undefined.
#     D2Y     -   second derivatives, array[NY*NX*NX]:
#                 * for NY=1 it is NX*NX array that stores  Hessian  matrix,
#                   with Y[I*NX+J]=Y[J*NX+I].
#                 * for  a  vector-valued  RBF  with  NY&gt;1  it  contains  NY
#                   subsequently stored Hessians: an element Y[K*NX*NX+I*NX+J]
#                   with  0&lt;=K&lt;NY,  0&lt;=I&lt;NX  and  0&lt;=J&lt;NX    stores   second
#                   derivative of the function #K  with  respect  to  inputs
#                   #I and #J.
#                 Zero is returned when the second derivative is undefined.
# 
#   -- ALGLIB --
#      Copyright 13.12.2021 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y, dy, d2y = xalglib.rbftshessbuf(s, buf, x, y, dy, d2y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
          buf:        class xalglib.rbfcalcbuffer
          x:          1D array/list of float
          y:          1D array/list of float
          dy:         1D array/list of float
          d2y:        1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> buf
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float
          dy:         1D array/list of float
          d2y:        1D array/list of float

</div></pre>
<a name='sub_rbfunpack'></a><h3 class=pageheader><code>rbfunpack</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function &quot;unpacks&quot; RBF model by extracting its coefficients.
# 
# INPUT PARAMETERS:
#     S       -   RBF model
# 
# OUTPUT PARAMETERS:
#     NX      -   dimensionality of argument
#     NY      -   dimensionality of the target function
#     XWR     -   model  information ,  2D  array.  One  row  of  the  array
#                 corresponds to one basis function.
# 
#                 For ModelVersion=1 we have NX+NY+1 columns:
#                 * first NX columns  - coordinates of the center
#                 * next  NY columns  - weights, one per dimension of the
#                                       function being modeled
#                 * last column       - radius, same for all dimensions of
#                                       the function being modeled
# 
#                 For ModelVersion=2 we have NX+NY+NX columns:
#                 * first NX columns  - coordinates of the center
#                 * next  NY columns  - weights, one per dimension of the
#                                       function being modeled
#                 * last NX columns   - radii, one per dimension
# 
#                 For ModelVersion=3 we have NX+NY+NX+3 columns:
#                 * first NX columns  - coordinates of the center
#                 * next  NY columns  - weights, one per dimension of the
#                                       function being modeled
#                 * next NX columns   - radii, one per dimension
#                 * next column       - basis function type:
#                                       * 1  for f=r
#                                       * 2  for f=r^2*ln(r)
#                                       * 10 for multiquadric f=sqrt(r^2+alpha^2)
#                 * next column       - basis function parameter:
#                                       * alpha, for basis function type 10
#                                       * ignored (zero) for other basis function types
#                 * next column       - point index in the original dataset,
#                                       or -1 for an artificial node created
#                                       by the solver. The algorithm may reorder
#                                       the nodes, drop some nodes or add
#                                       artificial nodes. Thus, one parsing
#                                       this column should expect all these
#                                       kinds of alterations in the dataset.
# 
#     NC      -   number of the centers
#     V       -   polynomial  term , array[NY,NX+1]. One row per one
#                 dimension of the function being modelled. First NX
#                 elements are linear coefficients, V[NX] is equal to the
#                 constant part.
#     ModelVersion-version of the RBF model:
#                 * 1 - for models created by QNN and RBF-ML algorithms,
#                   compatible with ALGLIB 3.10 or earlier.
#                 * 2 - for models created by HierarchicalRBF, requires
#                   ALGLIB 3.11 or later
#                 * 3 - for models created by DDM-RBF, requires
#                   ALGLIB 3.19 or later
# 
#   -- ALGLIB --
#      Copyright 13.12.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   nx, ny, xwr, nc, v, modelversion = xalglib.rbfunpack(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.rbfmodel
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  nx:         int
          ny:         int
          xwr:        2D array/list of float
          nc:         int
          v:          2D array/list of float
          modelversion: int

</div></pre>
<a name=unit_rcond></a><h2 class=pageheader><code>rcond</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cmatrixlurcond1' class=toc>cmatrixlurcond1</a><br>
<a href='#sub_cmatrixlurcondinf' class=toc>cmatrixlurcondinf</a><br>
<a href='#sub_cmatrixrcond1' class=toc>cmatrixrcond1</a><br>
<a href='#sub_cmatrixrcondinf' class=toc>cmatrixrcondinf</a><br>
<a href='#sub_cmatrixtrrcond1' class=toc>cmatrixtrrcond1</a><br>
<a href='#sub_cmatrixtrrcondinf' class=toc>cmatrixtrrcondinf</a><br>
<a href='#sub_hpdmatrixcholeskyrcond' class=toc>hpdmatrixcholeskyrcond</a><br>
<a href='#sub_hpdmatrixrcond' class=toc>hpdmatrixrcond</a><br>
<a href='#sub_rmatrixlurcond1' class=toc>rmatrixlurcond1</a><br>
<a href='#sub_rmatrixlurcondinf' class=toc>rmatrixlurcondinf</a><br>
<a href='#sub_rmatrixrcond1' class=toc>rmatrixrcond1</a><br>
<a href='#sub_rmatrixrcond2' class=toc>rmatrixrcond2</a><br>
<a href='#sub_rmatrixrcond2rect' class=toc>rmatrixrcond2rect</a><br>
<a href='#sub_rmatrixrcondinf' class=toc>rmatrixrcondinf</a><br>
<a href='#sub_rmatrixtrrcond1' class=toc>rmatrixtrrcond1</a><br>
<a href='#sub_rmatrixtrrcond2' class=toc>rmatrixtrrcond2</a><br>
<a href='#sub_rmatrixtrrcondinf' class=toc>rmatrixtrrcondinf</a><br>
<a href='#sub_spdmatrixcholeskyrcond' class=toc>spdmatrixcholeskyrcond</a><br>
<a href='#sub_spdmatrixrcond' class=toc>spdmatrixrcond</a><br>
<a href='#sub_spdmatrixrcond2' class=toc>spdmatrixrcond2</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_cmatrixlurcond1'></a><h3 class=pageheader><code>cmatrixlurcond1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Estimate of the condition number of a matrix given by its LU decomposition (1-norm)
# 
# The algorithm calculates a lower bound of the condition number. In this case,
# the algorithm does not return a lower bound of the condition number, but an
# inverse number (to avoid an overflow in case of a singular matrix).
# 
# Input parameters:
#     LUA         -   LU decomposition of a matrix in compact form. Output of
#                     the CMatrixLU subroutine.
#     N           -   size of matrix A.
# 
# Result: 1/LowerBound(cond(A))
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixlurcond1(lua, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lua:        2D array/list of complex
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_cmatrixlurcondinf'></a><h3 class=pageheader><code>cmatrixlurcondinf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Estimate of the condition number of a matrix given by its LU decomposition
# (infinity norm).
# 
# The algorithm calculates a lower bound of the condition number. In this case,
# the algorithm does not return a lower bound of the condition number, but an
# inverse number (to avoid an overflow in case of a singular matrix).
# 
# Input parameters:
#     LUA     -   LU decomposition of a matrix in compact form. Output of
#                 the CMatrixLU subroutine.
#     N       -   size of matrix A.
# 
# Result: 1/LowerBound(cond(A))
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixlurcondinf(lua, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lua:        2D array/list of complex
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_cmatrixrcond1'></a><h3 class=pageheader><code>cmatrixrcond1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Estimate of a matrix condition number (1-norm)
# 
# The algorithm calculates a lower bound of the condition number. In this case,
# the algorithm does not return a lower bound of the condition number, but an
# inverse number (to avoid an overflow in case of a singular matrix).
# 
# Input parameters:
#     A   -   matrix. Array whose indexes range within [0..N-1, 0..N-1].
#     N   -   size of matrix A.
# 
# Result: 1/LowerBound(cond(A))
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixrcond1(a, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_cmatrixrcondinf'></a><h3 class=pageheader><code>cmatrixrcondinf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Estimate of a matrix condition number (infinity-norm).
# 
# The algorithm calculates a lower bound of the condition number. In this case,
# the algorithm does not return a lower bound of the condition number, but an
# inverse number (to avoid an overflow in case of a singular matrix).
# 
# Input parameters:
#     A   -   matrix. Array whose indexes range within [0..N-1, 0..N-1].
#     N   -   size of matrix A.
# 
# Result: 1/LowerBound(cond(A))
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixrcondinf(a, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_cmatrixtrrcond1'></a><h3 class=pageheader><code>cmatrixtrrcond1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Triangular matrix: estimate of a condition number (1-norm)
# 
# The algorithm calculates a lower bound of the condition number. In this case,
# the algorithm does not return a lower bound of the condition number, but an
# inverse number (to avoid an overflow in case of a singular matrix).
# 
# Input parameters:
#     A       -   matrix. Array[0..N-1, 0..N-1].
#     N       -   size of A.
#     IsUpper -   True, if the matrix is upper triangular.
#     IsUnit  -   True, if the matrix has a unit diagonal.
# 
# Result: 1/LowerBound(cond(A))
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixtrrcond1(a, n, isupper, isunit)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          isupper:    bool
          isunit:     bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_cmatrixtrrcondinf'></a><h3 class=pageheader><code>cmatrixtrrcondinf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Triangular matrix: estimate of a matrix condition number (infinity-norm).
# 
# The algorithm calculates a lower bound of the condition number. In this case,
# the algorithm does not return a lower bound of the condition number, but an
# inverse number (to avoid an overflow in case of a singular matrix).
# 
# Input parameters:
#     A   -   matrix. Array whose indexes range within [0..N-1, 0..N-1].
#     N   -   size of matrix A.
#     IsUpper -   True, if the matrix is upper triangular.
#     IsUnit  -   True, if the matrix has a unit diagonal.
# 
# Result: 1/LowerBound(cond(A))
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.cmatrixtrrcondinf(a, n, isupper, isunit)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          isupper:    bool
          isunit:     bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_hpdmatrixcholeskyrcond'></a><h3 class=pageheader><code>hpdmatrixcholeskyrcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Condition number estimate of a Hermitian positive definite matrix given by
# Cholesky decomposition.
# 
# The algorithm calculates a lower bound of the condition number. In this
# case, the algorithm does not return a lower bound of the condition number,
# but an inverse number (to avoid an overflow in case of a singular matrix).
# 
# It should be noted that 1-norm and inf-norm condition numbers of symmetric
# matrices are equal, so the algorithm doesn't take into account the
# differences between these types of norms.
# 
# Input parameters:
#     CD  - Cholesky decomposition of matrix A,
#           output of SMatrixCholesky subroutine.
#     N   - size of matrix A.
# 
# Result: 1/LowerBound(cond(A))
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hpdmatrixcholeskyrcond(a, n, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_hpdmatrixrcond'></a><h3 class=pageheader><code>hpdmatrixrcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Condition number estimate of a Hermitian positive definite matrix.
# 
# The algorithm calculates a lower bound of the condition number. In this case,
# the algorithm does not return a lower bound of the condition number, but an
# inverse number (to avoid an overflow in case of a singular matrix).
# 
# It should be noted that 1-norm and inf-norm of condition numbers of symmetric
# matrices are equal, so the algorithm doesn't take into account the
# differences between these types of norms.
# 
# Input parameters:
#     A       -   Hermitian positive definite matrix which is given by its
#                 upper or lower triangle depending on the value of
#                 IsUpper. Array with elements [0..N-1, 0..N-1].
#     N       -   size of matrix A.
#     IsUpper -   storage format.
# 
# Result:
#     1/LowerBound(cond(A)), if matrix A is positive definite,
#    -1, if matrix A is not positive definite, and its condition number
#     could not be found by this algorithm.
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hpdmatrixrcond(a, n, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_rmatrixlurcond1'></a><h3 class=pageheader><code>rmatrixlurcond1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Estimate of the condition number of a matrix given by its LU decomposition (1-norm)
# 
# The algorithm calculates a lower bound of the condition number. In this case,
# the algorithm does not return a lower bound of the condition number, but an
# inverse number (to avoid an overflow in case of a singular matrix).
# 
# Input parameters:
#     LUA         -   LU decomposition of a matrix in compact form. Output of
#                     the RMatrixLU subroutine.
#     N           -   size of matrix A.
# 
# Result: 1/LowerBound(cond(A))
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixlurcond1(lua, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lua:        2D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_rmatrixlurcondinf'></a><h3 class=pageheader><code>rmatrixlurcondinf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Estimate of the condition number of a matrix given by its LU decomposition
# (infinity norm).
# 
# The algorithm calculates a lower bound of the condition number. In this case,
# the algorithm does not return a lower bound of the condition number, but an
# inverse number (to avoid an overflow in case of a singular matrix).
# 
# Input parameters:
#     LUA     -   LU decomposition of a matrix in compact form. Output of
#                 the RMatrixLU subroutine.
#     N       -   size of matrix A.
# 
# Result: 1/LowerBound(cond(A))
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixlurcondinf(lua, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     lua:        2D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_rmatrixrcond1'></a><h3 class=pageheader><code>rmatrixrcond1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Estimate of a matrix condition number (1-norm)
# 
# The algorithm calculates a lower bound of the condition number. In this case,
# the algorithm does not return a lower bound of the condition number, but an
# inverse number (to avoid an overflow in case of a singular matrix).
# 
# Input parameters:
#     A   -   matrix. Array whose indexes range within [0..N-1, 0..N-1].
#     N   -   size of matrix A.
# 
# Result: 1/LowerBound(cond(A))
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixrcond1(a, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_rmatrixrcond2'></a><h3 class=pageheader><code>rmatrixrcond2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Estimate of a matrix condition number (2-norm)
# 
# The algorithm calculates exact 2-norm reciprocal condition number using SVD.
# 
# Input parameters:
#     A   -   matrix. Array whose indexes range within [0..N-1, 0..N-1].
#     N   -   size of matrix A.
# 
# Result: 1/cond2(A)
# 
# NOTE:
#     if k(A) is very large, then the matrix is  assumed to be degenerate,
#     k(A)=INF, 0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixrcond2(a, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_rmatrixrcond2rect'></a><h3 class=pageheader><code>rmatrixrcond2rect</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Estimate of a matrix condition number (2-norm) for a rectangular matrix.
# 
# The algorithm calculates exact 2-norm reciprocal condition number using SVD.
# 
# Input parameters:
#     A   -   matrix. Array[M,N]
#     M, N-   rows and columns count, &gt;=1
# 
# Result: 1/cond2(A)
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixrcond2rect(a, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_rmatrixrcondinf'></a><h3 class=pageheader><code>rmatrixrcondinf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Estimate of a matrix condition number (infinity-norm).
# 
# The algorithm calculates a lower bound of the condition number. In this case,
# the algorithm does not return a lower bound of the condition number, but an
# inverse number (to avoid an overflow in case of a singular matrix).
# 
# Input parameters:
#     A   -   matrix. Array whose indexes range within [0..N-1, 0..N-1].
#     N   -   size of matrix A.
# 
# Result: 1/LowerBound(cond(A))
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixrcondinf(a, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_rmatrixtrrcond1'></a><h3 class=pageheader><code>rmatrixtrrcond1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Triangular matrix: estimate of a condition number (1-norm)
# 
# The algorithm calculates a lower bound of the condition number. In this case,
# the algorithm does not return a lower bound of the condition number, but an
# inverse number (to avoid an overflow in case of a singular matrix).
# 
# Input parameters:
#     A       -   matrix. Array[0..N-1, 0..N-1].
#     N       -   size of A.
#     IsUpper -   True, if the matrix is upper triangular.
#     IsUnit  -   True, if the matrix has a unit diagonal.
# 
# Result: 1/LowerBound(cond(A))
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixtrrcond1(a, n, isupper, isunit)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
          isunit:     bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_rmatrixtrrcond2'></a><h3 class=pageheader><code>rmatrixtrrcond2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Triangular matrix: reciprocal 2-norm condition number
# 
# The algorithm calculates a reciprocal 2-norm condition number using SVD.
# 
# Input parameters:
#     A       -   matrix. Array[0..N-1, 0..N-1].
#     N       -   size of A.
#     IsUpper -   True, if the matrix is upper triangular.
#     IsUnit  -   True, if the matrix has a unit diagonal.
# 
# Result: 1/cond(A)
# 
# NOTE:
#     if k(A) is very large, then matrix is assumed to be degenerate,
#     k(A)=INF, 0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixtrrcond2(a, n, isupper, isunit)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
          isunit:     bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_rmatrixtrrcondinf'></a><h3 class=pageheader><code>rmatrixtrrcondinf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Triangular matrix: estimate of a matrix condition number (infinity-norm).
# 
# The algorithm calculates a lower bound of the condition number. In this case,
# the algorithm does not return a lower bound of the condition number, but an
# inverse number (to avoid an overflow in case of a singular matrix).
# 
# Input parameters:
#     A   -   matrix. Array whose indexes range within [0..N-1, 0..N-1].
#     N   -   size of matrix A.
#     IsUpper -   True, if the matrix is upper triangular.
#     IsUnit  -   True, if the matrix has a unit diagonal.
# 
# Result: 1/LowerBound(cond(A))
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.rmatrixtrrcondinf(a, n, isupper, isunit)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
          isunit:     bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_spdmatrixcholeskyrcond'></a><h3 class=pageheader><code>spdmatrixcholeskyrcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Condition number estimate of a symmetric positive definite matrix given by
# Cholesky decomposition.
# 
# The algorithm calculates a lower bound of the condition number. In this
# case, the algorithm does not return a lower bound of the condition number,
# but an inverse number (to avoid an overflow in case of a singular matrix).
# 
# It should be noted that 1-norm and inf-norm condition numbers of symmetric
# matrices are equal, so the algorithm doesn't take into account the
# differences between these types of norms.
# 
# Input parameters:
#     CD  - Cholesky decomposition of matrix A,
#           output of SMatrixCholesky subroutine.
#     N   - size of matrix A.
# 
# Result: 1/LowerBound(cond(A))
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixcholeskyrcond(a, n, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_spdmatrixrcond'></a><h3 class=pageheader><code>spdmatrixrcond</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Condition number estimate of a symmetric positive definite matrix.
# 
# The algorithm calculates a lower bound of the condition number. In this case,
# the algorithm does not return a lower bound of the condition number, but an
# inverse number (to avoid an overflow in case of a singular matrix).
# 
# It should be noted that 1-norm and inf-norm of condition numbers of symmetric
# matrices are equal, so the algorithm doesn't take into account the
# differences between these types of norms.
# 
# Input parameters:
#     A       -   symmetric positive definite matrix which is given by its
#                 upper or lower triangle depending on the value of
#                 IsUpper. Array with elements [0..N-1, 0..N-1].
#     N       -   size of matrix A.
#     IsUpper -   storage format.
# 
# Result:
#     1/LowerBound(cond(A)), if matrix A is positive definite,
#    -1, if matrix A is not positive definite, and its condition number
#     could not be found by this algorithm.
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixrcond(a, n, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_spdmatrixrcond2'></a><h3 class=pageheader><code>spdmatrixrcond2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# 2-norm condition number of a symmetric positive definite matrix using EVD.
# 
# Input parameters:
#     A       -   symmetric positive definite matrix which is given by its
#                 upper or lower triangle depending on the value of
#                 IsUpper. Array[N,N]
#     N       -   size of matrix A.
#     IsUpper -   storage format.
# 
# Result:
#     1/cond(A), if matrix A is positive definite,
#     0, if matrix A is not positive definite
# 
# NOTE:
#     if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
#     0.0 is returned in such cases.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixrcond2(a, n, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_schur></a><h2 class=pageheader><code>schur</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_rmatrixschur' class=toc>rmatrixschur</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_rmatrixschur'></a><h3 class=pageheader><code>rmatrixschur</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Subroutine performing the Schur decomposition of a general matrix by using
# the QR algorithm with multiple shifts.
# 
# COMMERCIAL EDITION OF ALGLIB:
# 
#   ! Commercial version of ALGLIB includes one  important  improvement   of
#   ! this function, which can be used from C++ and C#:
#   ! * Intel MKL support (lightweight Intel MKL is shipped with ALGLIB)
#   !
#   ! Intel MKL gives approximately constant  (with  respect  to  number  of
#   ! worker threads) acceleration factor which depends on CPU  being  used,
#   ! problem  size  and  &quot;baseline&quot;  ALGLIB  edition  which  is  used   for
#   ! comparison.
#   !
#   ! Multithreaded acceleration is NOT supported for this function.
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# The source matrix A is represented as S'*A*S = T, where S is an orthogonal
# matrix (Schur vectors), T - upper quasi-triangular matrix (with blocks of
# sizes 1x1 and 2x2 on the main diagonal).
# 
# Input parameters:
#     A   -   matrix to be decomposed.
#             Array whose indexes range within [0..N-1, 0..N-1].
#     N   -   size of A, N&gt;=0.
# 
# 
# Output parameters:
#     A   -   contains matrix T.
#             Array whose indexes range within [0..N-1, 0..N-1].
#     S   -   contains Schur vectors.
#             Array whose indexes range within [0..N-1, 0..N-1].
# 
# Note 1:
#     The block structure of matrix T can be easily recognized: since all
#     the elements below the blocks are zeros, the elements a[i+1,i] which
#     are equal to 0 show the block border.
# 
# Note 2:
#     The algorithm performance depends on the value of the internal parameter
#     NS of the InternalSchurDecomposition subroutine which defines the number
#     of shifts in the QR algorithm (similarly to the block width in block-matrix
#     algorithms in linear algebra). If you require maximum performance on
#     your machine, it is recommended to adjust this parameter manually.
# 
# Result:
#     True,
#         if the algorithm has converged and parameters A and S contain the result.
#     False,
#         if the algorithm has not converged.
# 
# Algorithm implemented on the basis of the DHSEQR subroutine (LAPACK 3.0 library).
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, s = xalglib.rmatrixschur(a, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          s:          2D array/list of float

</div></pre>
<a name=unit_sparse></a><h2 class=pageheader><code>sparse</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_sparseadd' class=toc>sparseadd</a><br>
<a href='#sub_sparseappendcompressedrow' class=toc>sparseappendcompressedrow</a><br>
<a href='#sub_sparseappendelement' class=toc>sparseappendelement</a><br>
<a href='#sub_sparseappendemptyrow' class=toc>sparseappendemptyrow</a><br>
<a href='#sub_sparseappendmatrix' class=toc>sparseappendmatrix</a><br>
<a href='#sub_sparseconvertto' class=toc>sparseconvertto</a><br>
<a href='#sub_sparseconverttocrs' class=toc>sparseconverttocrs</a><br>
<a href='#sub_sparseconverttohash' class=toc>sparseconverttohash</a><br>
<a href='#sub_sparseconverttosks' class=toc>sparseconverttosks</a><br>
<a href='#sub_sparsecopy' class=toc>sparsecopy</a><br>
<a href='#sub_sparsecopybuf' class=toc>sparsecopybuf</a><br>
<a href='#sub_sparsecopytobuf' class=toc>sparsecopytobuf</a><br>
<a href='#sub_sparsecopytocrs' class=toc>sparsecopytocrs</a><br>
<a href='#sub_sparsecopytocrsbuf' class=toc>sparsecopytocrsbuf</a><br>
<a href='#sub_sparsecopytohash' class=toc>sparsecopytohash</a><br>
<a href='#sub_sparsecopytohashbuf' class=toc>sparsecopytohashbuf</a><br>
<a href='#sub_sparsecopytosks' class=toc>sparsecopytosks</a><br>
<a href='#sub_sparsecopytosksbuf' class=toc>sparsecopytosksbuf</a><br>
<a href='#sub_sparsecopytransposecrs' class=toc>sparsecopytransposecrs</a><br>
<a href='#sub_sparsecopytransposecrsbuf' class=toc>sparsecopytransposecrsbuf</a><br>
<a href='#sub_sparsecreate' class=toc>sparsecreate</a><br>
<a href='#sub_sparsecreatebuf' class=toc>sparsecreatebuf</a><br>
<a href='#sub_sparsecreatecrs' class=toc>sparsecreatecrs</a><br>
<a href='#sub_sparsecreatecrsbuf' class=toc>sparsecreatecrsbuf</a><br>
<a href='#sub_sparsecreatecrsempty' class=toc>sparsecreatecrsempty</a><br>
<a href='#sub_sparsecreatecrsemptybuf' class=toc>sparsecreatecrsemptybuf</a><br>
<a href='#sub_sparsecreatecrsfromdense' class=toc>sparsecreatecrsfromdense</a><br>
<a href='#sub_sparsecreatecrsfromdensebuf' class=toc>sparsecreatecrsfromdensebuf</a><br>
<a href='#sub_sparsecreatecrsfromdensev' class=toc>sparsecreatecrsfromdensev</a><br>
<a href='#sub_sparsecreatecrsfromdensevbuf' class=toc>sparsecreatecrsfromdensevbuf</a><br>
<a href='#sub_sparsecreatesks' class=toc>sparsecreatesks</a><br>
<a href='#sub_sparsecreatesksband' class=toc>sparsecreatesksband</a><br>
<a href='#sub_sparsecreatesksbandbuf' class=toc>sparsecreatesksbandbuf</a><br>
<a href='#sub_sparsecreatesksbuf' class=toc>sparsecreatesksbuf</a><br>
<a href='#sub_sparseenumerate' class=toc>sparseenumerate</a><br>
<a href='#sub_sparseexists' class=toc>sparseexists</a><br>
<a href='#sub_sparsefree' class=toc>sparsefree</a><br>
<a href='#sub_sparsegemv' class=toc>sparsegemv</a><br>
<a href='#sub_sparseget' class=toc>sparseget</a><br>
<a href='#sub_sparsegetcompressedrow' class=toc>sparsegetcompressedrow</a><br>
<a href='#sub_sparsegetdiagonal' class=toc>sparsegetdiagonal</a><br>
<a href='#sub_sparsegetlowercount' class=toc>sparsegetlowercount</a><br>
<a href='#sub_sparsegetmatrixtype' class=toc>sparsegetmatrixtype</a><br>
<a href='#sub_sparsegetncols' class=toc>sparsegetncols</a><br>
<a href='#sub_sparsegetnrows' class=toc>sparsegetnrows</a><br>
<a href='#sub_sparsegetrow' class=toc>sparsegetrow</a><br>
<a href='#sub_sparsegetuppercount' class=toc>sparsegetuppercount</a><br>
<a href='#sub_sparseiscrs' class=toc>sparseiscrs</a><br>
<a href='#sub_sparseishash' class=toc>sparseishash</a><br>
<a href='#sub_sparseissks' class=toc>sparseissks</a><br>
<a href='#sub_sparsemm' class=toc>sparsemm</a><br>
<a href='#sub_sparsemm2' class=toc>sparsemm2</a><br>
<a href='#sub_sparsemtm' class=toc>sparsemtm</a><br>
<a href='#sub_sparsemtv' class=toc>sparsemtv</a><br>
<a href='#sub_sparsemultiplycolsby' class=toc>sparsemultiplycolsby</a><br>
<a href='#sub_sparsemultiplyrowsby' class=toc>sparsemultiplyrowsby</a><br>
<a href='#sub_sparsemv' class=toc>sparsemv</a><br>
<a href='#sub_sparsemv2' class=toc>sparsemv2</a><br>
<a href='#sub_sparseresizematrix' class=toc>sparseresizematrix</a><br>
<a href='#sub_sparserewriteexisting' class=toc>sparserewriteexisting</a><br>
<a href='#sub_sparsescale' class=toc>sparsescale</a><br>
<a href='#sub_sparseset' class=toc>sparseset</a><br>
<a href='#sub_sparsesmm' class=toc>sparsesmm</a><br>
<a href='#sub_sparsesmv' class=toc>sparsesmv</a><br>
<a href='#sub_sparseswap' class=toc>sparseswap</a><br>
<a href='#sub_sparsesymmpermtbl' class=toc>sparsesymmpermtbl</a><br>
<a href='#sub_sparsesymmpermtblbuf' class=toc>sparsesymmpermtblbuf</a><br>
<a href='#sub_sparsesymmpermtbltranspose' class=toc>sparsesymmpermtbltranspose</a><br>
<a href='#sub_sparsesymmpermtbltransposebuf' class=toc>sparsesymmpermtbltransposebuf</a><br>
<a href='#sub_sparsetransposecrs' class=toc>sparsetransposecrs</a><br>
<a href='#sub_sparsetransposesks' class=toc>sparsetransposesks</a><br>
<a href='#sub_sparsetrmv' class=toc>sparsetrmv</a><br>
<a href='#sub_sparsetrsv' class=toc>sparsetrsv</a><br>
<a href='#sub_sparsevsmv' class=toc>sparsevsmv</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_sparseadd'></a><h3 class=pageheader><code>sparseadd</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function adds value to S[i,j] - element of the sparse matrix. Matrix
# must be in a Hash-Table mode.
# 
# In case S[i,j] already exists in the table, V i added to  its  value.  In
# case  S[i,j]  is  non-existent,  it  is  inserted  in  the  table.  Table
# automatically grows when necessary.
# 
# INPUT PARAMETERS
#     S           -   sparse M*N matrix in Hash-Table representation.
#                     Exception will be thrown for CRS matrix.
#     I           -   row index of the element to modify, 0&lt;=I&lt;M
#     J           -   column index of the element to modify, 0&lt;=J&lt;N
#     V           -   value to add, must be finite number
# 
# OUTPUT PARAMETERS
#     S           -   modified matrix
# 
# NOTE 1:  when  S[i,j]  is exactly zero after modification, it is  deleted
# from the table.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparseadd(s, i, j, v)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          i:          int
          j:          int
          v:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparseappendcompressedrow'></a><h3 class=pageheader><code>sparseappendcompressedrow</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends a compressed sparse row to a CRS matrix,  increasing
# its row count by 1.
# 
# INPUT PARAMETERS:
#     S           -   sparse M*N matrix in CRS format, including one created
#                     with sparsecreatecrsempty().
#     ColIdx      -   array[NZ], column indexes, values  in  [0,N-1]  range.
#                     ColIdx[] can store non-distinct  values;  elements  of
#                     Vals[] corresponding to duplicate column indexes  will
#                     be summed up.
#     Vals        -   array[NZ], element values.
#     NZ          -   nonzeros count, NZ&gt;=0. Both ColIdx[]  and  Vals[]  can
#                     be longer than NZ, in   which  case  only  leading  NZ
#                     elements are used.
# 
# OUTPUT PARAMETERS:
#     S           -   (M+1)*N matrix in the CRS format.
# 
# NOTE: this function has amortized O(NZ*logNZ) cost.
# 
#   -- ALGLIB PROJECT --
#      Copyright 2024.02.19 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparseappendcompressedrow(s, colidx, vals, nz)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          colidx:     1D array/list of int
          vals:       1D array/list of float
          nz:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparseappendelement'></a><h3 class=pageheader><code>sparseappendelement</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends an element to the last row  of  a  CRS  matrix.  New
# elements can be added ONLY from left to right (column indexes are strictly
# increasing).
# 
# INPUT PARAMETERS:
#     S           -   a fully initialized sparse M*N matrix in CRS format, M&gt;0
#     K           -   column index, 0&lt;=K&lt;N, must be  strictly  greater  than
#                     the last element in the last row.
#     V           -   element value
# 
# OUTPUT PARAMETERS:
#     S           -   M*N matrix in the CRS format.
# 
#   -- ALGLIB PROJECT --
#      Copyright 2024.02.19 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparseappendelement(s, k, v)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          k:          int
          v:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparseappendemptyrow'></a><h3 class=pageheader><code>sparseappendemptyrow</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends an empty row to a CRS matrix,  increasing  its  rows
# count by 1. The newly added row can be modified with sparseappendelement().
# The matrix is a valid CRS matrix at any moment of the process.
# 
# INPUT PARAMETERS:
#     S           -   sparse M*N matrix in CRS format, including one created
#                     with sparsecreatecrsempty().
# 
# OUTPUT PARAMETERS:
#     S           -   (M+1)*N matrix in the CRS format.
# 
#   -- ALGLIB PROJECT --
#      Copyright 2024.02.19 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparseappendemptyrow(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparseappendmatrix'></a><h3 class=pageheader><code>sparseappendmatrix</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends from below a  sparse  CRS-based  matrix  to  another
# sparse CRS-based matrix. The matrix  being  appended  must  be  completely
# initialized CRS matrix.
# 
# INPUT PARAMETERS:
#     SDst        -   sparse X*N matrix in CRS format, including one created
#                     with sparsecreatecrsempty (in the latter case, X=0).
#     SSrc        -   sparse M*N matrix in the CRS format
# 
# OUTPUT PARAMETERS:
#     SDst        -   (X+M)*N matrix in the CRS format, SSrc appended from
#                     below
# 
# NOTE: this  function  has  amortized  O(MSrc+NZCnt) cost, where NZCnt is a
#       total number of nonzero elements in SSrc.
# 
#   -- ALGLIB PROJECT --
#      Copyright 2024.03.23 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparseappendmatrix(sdst, ssrc)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     sdst:       class xalglib.sparsematrix
          ssrc:       class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> sdst
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparseconvertto'></a><h3 class=pageheader><code>sparseconvertto</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  performs  in-place  conversion  to  desired sparse storage
# format.
# 
# INPUT PARAMETERS
#     S0      -   sparse matrix in any format.
#     Fmt     -   desired storage format  of  the  output,  as  returned  by
#                 SparseGetMatrixType() function:
#                 * 0 for hash-based storage
#                 * 1 for CRS
#                 * 2 for SKS
# 
# OUTPUT PARAMETERS
#     S0          -   sparse matrix in requested format.
# 
# NOTE: in-place conversion wastes a lot of memory which is  used  to  store
#       temporaries.  If  you  perform  a  lot  of  repeated conversions, we
#       recommend to use out-of-place buffered  conversion  functions,  like
#       SparseCopyToBuf(), which can reuse already allocated memory.
# 
#   -- ALGLIB PROJECT --
#      Copyright 16.01.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparseconvertto(s0, fmt)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s0:         class xalglib.sparsematrix
          fmt:        int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s0
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparseconverttocrs'></a><h3 class=pageheader><code>sparseconverttocrs</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function converts matrix to CRS format.
# 
# Some  algorithms  (linear  algebra ones, for example) require matrices in
# CRS format. This function allows to perform in-place conversion.
# 
# INPUT PARAMETERS
#     S           -   sparse M*N matrix in any format
# 
# OUTPUT PARAMETERS
#     S           -   matrix in CRS format
# 
# NOTE: this   function  has  no  effect  when  called with matrix which is
#       already in CRS mode.
# 
# NOTE: this function allocates temporary memory to store a   copy  of  the
#       matrix. If you perform a lot of repeated conversions, we  recommend
#       you  to  use  SparseCopyToCRSBuf()  function,   which   can   reuse
#       previously allocated memory.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparseconverttocrs(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparseconverttohash'></a><h3 class=pageheader><code>sparseconverttohash</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function performs in-place conversion to Hash table storage.
# 
# INPUT PARAMETERS
#     S           -   sparse matrix in CRS format.
# 
# OUTPUT PARAMETERS
#     S           -   sparse matrix in Hash table format.
# 
# NOTE: this  function  has   no  effect  when  called with matrix which  is
#       already in Hash table mode.
# 
# NOTE: in-place conversion involves allocation of temporary arrays. If  you
#       perform a lot of repeated in- place  conversions,  it  may  lead  to
#       memory fragmentation. Consider using out-of-place SparseCopyToHashBuf()
#       function in this case.
# 
#   -- ALGLIB PROJECT --
#      Copyright 20.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparseconverttohash(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparseconverttosks'></a><h3 class=pageheader><code>sparseconverttosks</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function performs in-place conversion to SKS format.
# 
# INPUT PARAMETERS
#     S           -   sparse matrix in any format.
# 
# OUTPUT PARAMETERS
#     S           -   sparse matrix in SKS format.
# 
# NOTE: this  function  has   no  effect  when  called with matrix which  is
#       already in SKS mode.
# 
# NOTE: in-place conversion involves allocation of temporary arrays. If  you
#       perform a lot of repeated in- place  conversions,  it  may  lead  to
#       memory fragmentation. Consider using out-of-place SparseCopyToSKSBuf()
#       function in this case.
# 
#   -- ALGLIB PROJECT --
#      Copyright 15.01.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparseconverttosks(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsecopy'></a><h3 class=pageheader><code>sparsecopy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function copies S0 to S1.
# This function completely deallocates memory owned by S1 before creating a
# copy of S0. If you want to reuse memory, use SparseCopyBuf.
# 
# NOTE:  this  function  does  not verify its arguments, it just copies all
# fields of the structure.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s1 = xalglib.sparsecopy(s0)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s0:         class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s1:         class xalglib.sparsematrix

</div></pre>
<a name='sub_sparsecopybuf'></a><h3 class=pageheader><code>sparsecopybuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function copies S0 to S1.
# Memory already allocated in S1 is reused as much as possible.
# 
# NOTE:  this  function  does  not verify its arguments, it just copies all
# fields of the structure.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsecopybuf(s0, s1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s0:         class xalglib.sparsematrix
          s1:         class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s1
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsecopytobuf'></a><h3 class=pageheader><code>sparsecopytobuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  performs out-of-place conversion to desired sparse storage
# format. S0 is copied to S1 and converted on-the-fly. Memory  allocated  in
# S1 is reused to maximum extent possible.
# 
# INPUT PARAMETERS
#     S0      -   sparse matrix in any format.
#     Fmt     -   desired storage format  of  the  output,  as  returned  by
#                 SparseGetMatrixType() function:
#                 * 0 for hash-based storage
#                 * 1 for CRS
#                 * 2 for SKS
# 
# OUTPUT PARAMETERS
#     S1          -   sparse matrix in requested format.
# 
#   -- ALGLIB PROJECT --
#      Copyright 16.01.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsecopytobuf(s0, fmt, s1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s0:         class xalglib.sparsematrix
          fmt:        int
          s1:         class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s1
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsecopytocrs'></a><h3 class=pageheader><code>sparsecopytocrs</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  performs  out-of-place  conversion  to  CRS format.  S0 is
# copied to S1 and converted on-the-fly.
# 
# INPUT PARAMETERS
#     S0          -   sparse matrix in any format.
# 
# OUTPUT PARAMETERS
#     S1          -   sparse matrix in CRS format.
# 
# NOTE: if S0 is stored as CRS, it is just copied without conversion.
# 
# NOTE: this function de-allocates memory occupied by S1 before starting CRS
#       conversion. If you perform a lot of repeated CRS conversions, it may
#       lead to memory fragmentation. In this case we recommend you  to  use
#       SparseCopyToCRSBuf() function which re-uses memory in S1 as much  as
#       possible.
# 
#   -- ALGLIB PROJECT --
#      Copyright 20.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s1 = xalglib.sparsecopytocrs(s0)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s0:         class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s1:         class xalglib.sparsematrix

</div></pre>
<a name='sub_sparsecopytocrsbuf'></a><h3 class=pageheader><code>sparsecopytocrsbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  performs  out-of-place  conversion  to  CRS format.  S0 is
# copied to S1 and converted on-the-fly. Memory allocated in S1 is reused to
# maximum extent possible.
# 
# INPUT PARAMETERS
#     S0          -   sparse matrix in any format.
#     S1          -   matrix which may contain some pre-allocated memory, or
#                     can be just uninitialized structure.
# 
# OUTPUT PARAMETERS
#     S1          -   sparse matrix in CRS format.
# 
# NOTE: if S0 is stored as CRS, it is just copied without conversion.
# 
#   -- ALGLIB PROJECT --
#      Copyright 20.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsecopytocrsbuf(s0, s1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s0:         class xalglib.sparsematrix
          s1:         class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s1
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsecopytohash'></a><h3 class=pageheader><code>sparsecopytohash</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  performs  out-of-place  conversion  to  Hash table storage
# format. S0 is copied to S1 and converted on-the-fly.
# 
# INPUT PARAMETERS
#     S0          -   sparse matrix in any format.
# 
# OUTPUT PARAMETERS
#     S1          -   sparse matrix in Hash table format.
# 
# NOTE: if S0 is stored as Hash-table, it is just copied without conversion.
# 
# NOTE: this function de-allocates memory  occupied  by  S1 before  starting
#       conversion. If you perform a  lot  of  repeated  conversions, it may
#       lead to memory fragmentation. In this case we recommend you  to  use
#       SparseCopyToHashBuf() function which re-uses memory in S1 as much as
#       possible.
# 
#   -- ALGLIB PROJECT --
#      Copyright 20.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s1 = xalglib.sparsecopytohash(s0)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s0:         class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s1:         class xalglib.sparsematrix

</div></pre>
<a name='sub_sparsecopytohashbuf'></a><h3 class=pageheader><code>sparsecopytohashbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  performs  out-of-place  conversion  to  Hash table storage
# format. S0 is copied to S1 and converted on-the-fly. Memory  allocated  in
# S1 is reused to maximum extent possible.
# 
# INPUT PARAMETERS
#     S0          -   sparse matrix in any format.
# 
# OUTPUT PARAMETERS
#     S1          -   sparse matrix in Hash table format.
# 
# NOTE: if S0 is stored as Hash-table, it is just copied without conversion.
# 
#   -- ALGLIB PROJECT --
#      Copyright 20.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsecopytohashbuf(s0, s1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s0:         class xalglib.sparsematrix
          s1:         class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s1
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsecopytosks'></a><h3 class=pageheader><code>sparsecopytosks</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  performs  out-of-place  conversion  to SKS storage format.
# S0 is copied to S1 and converted on-the-fly.
# 
# INPUT PARAMETERS
#     S0          -   sparse matrix in any format.
# 
# OUTPUT PARAMETERS
#     S1          -   sparse matrix in SKS format.
# 
# NOTE: if S0 is stored as SKS, it is just copied without conversion.
# 
# NOTE: this function de-allocates memory  occupied  by  S1 before  starting
#       conversion. If you perform a  lot  of  repeated  conversions, it may
#       lead to memory fragmentation. In this case we recommend you  to  use
#       SparseCopyToSKSBuf() function which re-uses memory in S1 as much  as
#       possible.
# 
#   -- ALGLIB PROJECT --
#      Copyright 20.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s1 = xalglib.sparsecopytosks(s0)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s0:         class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s1:         class xalglib.sparsematrix

</div></pre>
<a name='sub_sparsecopytosksbuf'></a><h3 class=pageheader><code>sparsecopytosksbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  performs  out-of-place  conversion  to SKS format.  S0  is
# copied to S1 and converted on-the-fly. Memory  allocated  in S1 is  reused
# to maximum extent possible.
# 
# INPUT PARAMETERS
#     S0          -   sparse matrix in any format.
# 
# OUTPUT PARAMETERS
#     S1          -   sparse matrix in SKS format.
# 
# NOTE: if S0 is stored as SKS, it is just copied without conversion.
# 
#   -- ALGLIB PROJECT --
#      Copyright 20.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsecopytosksbuf(s0, s1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s0:         class xalglib.sparsematrix
          s1:         class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s1
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsecopytransposecrs'></a><h3 class=pageheader><code>sparsecopytransposecrs</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function performs copying with transposition of CRS matrix.
# 
# INPUT PARAMETERS
#     S0      -   sparse matrix in CRS format.
# 
# OUTPUT PARAMETERS
#     S1      -   sparse matrix, transposed
# 
#   -- ALGLIB PROJECT --
#      Copyright 23.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s1 = xalglib.sparsecopytransposecrs(s0)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s0:         class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s1:         class xalglib.sparsematrix

</div></pre>
<a name='sub_sparsecopytransposecrsbuf'></a><h3 class=pageheader><code>sparsecopytransposecrsbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function performs copying with transposition of CRS matrix  (buffered
# version which reuses memory already allocated by  the  target as  much  as
# possible).
# 
# INPUT PARAMETERS
#     S0      -   sparse matrix in CRS format.
# 
# OUTPUT PARAMETERS
#     S1      -   sparse matrix, transposed; previously allocated memory  is
#                 reused if possible.
# 
#   -- ALGLIB PROJECT --
#      Copyright 23.07.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsecopytransposecrsbuf(s0, s1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s0:         class xalglib.sparsematrix
          s1:         class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s1
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsecreate'></a><h3 class=pageheader><code>sparsecreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates sparse matrix in a Hash-Table format.
# 
# This function creates Hast-Table matrix, which can be  converted  to  CRS
# format after its initialization is over. Typical  usage  scenario  for  a
# sparse matrix is:
# 1. creation in a Hash-Table format
# 2. insertion of the matrix elements
# 3. conversion to the CRS representation
# 4. matrix is passed to some linear algebra algorithm
# 
# Some  information  about  different matrix formats can be found below, in
# the &quot;NOTES&quot; section.
# 
# INPUT PARAMETERS
#     M           -   number of rows in a matrix, M&gt;=1
#     N           -   number of columns in a matrix, N&gt;=1
#     K           -   K&gt;=0, expected number of non-zero elements in a matrix.
#                     K can be inexact approximation, can be less than actual
#                     number  of  elements  (table will grow when needed) or
#                     even zero).
#                     It is important to understand that although hash-table
#                     may grow automatically, it is better to  provide  good
#                     estimate of data size.
# 
# OUTPUT PARAMETERS
#     S           -   sparse M*N matrix in Hash-Table representation.
#                     All elements of the matrix are zero.
# 
# NOTE 1
# 
# Hash-tables use memory inefficiently, and they have to keep  some  amount
# of the &quot;spare memory&quot; in order to have good performance. Hash  table  for
# matrix with K non-zero elements will  need  C*K*(8+2*sizeof(int))  bytes,
# where C is a small constant, about 1.5-2 in magnitude.
# 
# CRS storage, from the other side, is  more  memory-efficient,  and  needs
# just K*(8+sizeof(int))+M*sizeof(int) bytes, where M is a number  of  rows
# in a matrix.
# 
# When you convert from the Hash-Table to CRS  representation, all unneeded
# memory will be freed.
# 
# NOTE 2
# 
# Comments of SparseMatrix structure outline  information  about  different
# sparse storage formats. We recommend you to read them before starting  to
# use ALGLIB sparse matrices.
# 
# NOTE 3
# 
# This function completely  overwrites S with new sparse matrix. Previously
# allocated storage is NOT reused. If you  want  to reuse already allocated
# memory, call SparseCreateBuf function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.sparsecreate(m, n, k)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.sparsecreate(m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          k:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.sparsematrix

</div></pre>
<a name='sub_sparsecreatebuf'></a><h3 class=pageheader><code>sparsecreatebuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This version of SparseCreate function creates sparse matrix in Hash-Table
# format, reusing previously allocated storage as much  as  possible.  Read
# comments for SparseCreate() for more information.
# 
# INPUT PARAMETERS
#     M           -   number of rows in a matrix, M&gt;=1
#     N           -   number of columns in a matrix, N&gt;=1
#     K           -   K&gt;=0, expected number of non-zero elements in a matrix.
#                     K can be inexact approximation, can be less than actual
#                     number  of  elements  (table will grow when needed) or
#                     even zero).
#                     It is important to understand that although hash-table
#                     may grow automatically, it is better to  provide  good
#                     estimate of data size.
#     S           -   SparseMatrix structure which MAY contain some  already
#                     allocated storage.
# 
# OUTPUT PARAMETERS
#     S           -   sparse M*N matrix in Hash-Table representation.
#                     All elements of the matrix are zero.
#                     Previously allocated storage is reused, if  its  size
#                     is compatible with expected number of non-zeros K.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.01.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsecreatebuf(m, n, k, s)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsecreatebuf(m, n, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          k:          int
          s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsecreatecrs'></a><h3 class=pageheader><code>sparsecreatecrs</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates sparse matrix in a CRS format - the least  flexible
# but the most efficient format implemented in ALGLIB.
# 
# This function creates CRS matrix. Typical usage scenario for a CRS matrix
# is:
# 1. creation (you have to tell the number of non-zero elements at each row
#    at this moment)
# 2. initialization of the matrix elements (row by row, from left to right)
# 3. the matrix is passed to some linear algebra algorithm
# 
# This function is a memory-efficient alternative to SparseCreate(), but it
# is more complex because it requires you to know in advance how large your
# matrix is. Some  information about  different matrix formats can be found
# in comments on SparseMatrix structure.  We recommend  you  to  read  them
# before starting to use ALGLIB sparse matrices.
# 
# INPUT PARAMETERS
#     M           -   number of rows in a matrix, M&gt;=1
#     N           -   number of columns in a matrix, N&gt;=1
#     NER         -   number of elements at each row, array[M], NER[I]&gt;=0
# 
# OUTPUT PARAMETERS
#     S           -   sparse M*N matrix in CRS representation.
#                     You have to fill ALL non-zero elements by calling
#                     SparseSet() BEFORE you try to use this matrix.
# 
# NOTE: this function completely  overwrites  S  with  new  sparse  matrix.
#       Previously allocated storage is NOT reused. If you  want  to  reuse
#       already allocated memory, call SparseCreateCRSBuf function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.sparsecreatecrs(m, n, ner)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          ner:        1D array/list of int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.sparsematrix

</div></pre>
<a name='sub_sparsecreatecrsbuf'></a><h3 class=pageheader><code>sparsecreatecrsbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates sparse matrix in a CRS format (expert function  for
# situations when you are running out  of  memory).  This  version  of  CRS
# matrix creation function may reuse memory already allocated in S.
# 
# This function creates CRS matrix. Typical usage scenario for a CRS matrix
# is:
# 1. creation (you have to tell number of non-zero elements at each row  at
#    this moment)
# 2. insertion of the matrix elements (row by row, from left to right)
# 3. matrix is passed to some linear algebra algorithm
# 
# This function is a memory-efficient alternative to SparseCreate(), but it
# is more complex because it requires you to know in advance how large your
# matrix is. Some  information about  different matrix formats can be found
# in comments on SparseMatrix structure.  We recommend  you  to  read  them
# before starting to use ALGLIB sparse matrices..
# 
# INPUT PARAMETERS
#     M           -   number of rows in a matrix, M&gt;=1
#     N           -   number of columns in a matrix, N&gt;=1
#     NER         -   number of elements at each row, array[M], NER[I]&gt;=0
#     S           -   sparse matrix structure with possibly preallocated
#                     memory.
# 
# OUTPUT PARAMETERS
#     S           -   sparse M*N matrix in CRS representation.
#                     You have to fill ALL non-zero elements by calling
#                     SparseSet() BEFORE you try to use this matrix.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsecreatecrsbuf(m, n, ner, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          ner:        1D array/list of int
          s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsecreatecrsempty'></a><h3 class=pageheader><code>sparsecreatecrsempty</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates an EMPTY sparse matrix stored in the CRS format.
# 
# The empty matrix is a degenerate 0*N-dimensional matrix which can be used
# ONLY for:
# * appending rows with sparseappendcompressedrow()
# * appending non-degenerate CRS matrices with sparseappendmatrix()
# Before the first row is appended, the matrix is in a special intermediate
# state. After the first append it becomes a standard CRS matrix.
# 
# The main purpose of this function is to simplify step-by-step initialization
# of CRS matrices.
# 
# INPUT PARAMETERS
#     N           -   number of columns in a matrix, N&gt;=1
# 
# OUTPUT PARAMETERS
#     S           -   sparse 0*N matrix in a partially initialized state
# 
# NOTE: this function completely  overwrites  S  with  new  sparse  matrix.
#       Previously allocated storage is NOT reused. If you  want  to  reuse
#       already allocated memory, call SparseCreateCRSEmptyBuf function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 20.02.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.sparsecreatecrsempty(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.sparsematrix

</div></pre>
<a name='sub_sparsecreatecrsemptybuf'></a><h3 class=pageheader><code>sparsecreatecrsemptybuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates an EMPTY sparse matrix stored in the CRS format. It
# is a buffered version of the function which  reuses  previosly  allocated
# space as much as possible.
# 
# INPUT PARAMETERS
#     N           -   number of columns in a matrix, N&gt;=1
# 
# OUTPUT PARAMETERS
#     S           -   sparse 0*N matrix in a partially initialized state
# 
#   -- ALGLIB PROJECT --
#      Copyright 20.02.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsecreatecrsemptybuf(n, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
          s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsecreatecrsfromdense'></a><h3 class=pageheader><code>sparsecreatecrsfromdense</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates a CRS-based sparse matrix from  the  dense  matrix.
# 
# This function is intended for situations when you already  have  a  dense
# matrix and need a convenient way of converting it to the CRS format.
# 
# INPUT PARAMETERS
#     A           -   array[M,N]. If larger, only leading MxN submatrix
#                     will be used.
#     M           -   number of rows in a matrix, M&gt;=1
#     N           -   number of columns in a matrix, N&gt;=1
# 
# OUTPUT PARAMETERS
#     S           -   sparse M*N matrix A in the CRS format
# 
# NOTE: this function completely  overwrites  S  with  new  sparse  matrix.
#       Previously allocated storage is NOT reused. If you  want  to  reuse
#       already allocated memory, call SparseCreateCRSFromDenseBuf function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 16.06.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.sparsecreatecrsfromdense(a, m, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.sparsecreatecrsfromdense(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.sparsematrix

</div></pre>
<a name='sub_sparsecreatecrsfromdensebuf'></a><h3 class=pageheader><code>sparsecreatecrsfromdensebuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates a CRS-based sparse matrix from  the  dense  matrix.
# A buffered version which reused memory already allocated in S as much  as
# possible.
# 
# This function is intended for situations when you already  have  a  dense
# matrix and need a convenient way of converting it to the CRS format.
# 
# INPUT PARAMETERS
#     A           -   array[M,N]. If larger, only leading MxN submatrix
#                     will be used.
#     M           -   number of rows in a matrix, M&gt;=1
#     N           -   number of columns in a matrix, N&gt;=1
#     S           -   an already allocated structure; if it already has
#                     enough memory to store the matrix, no new memory
#                     will be allocated.
# 
# OUTPUT PARAMETERS
#     S           -   sparse M*N matrix A in the CRS format.
# 
#   -- ALGLIB PROJECT --
#      Copyright 16.06.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsecreatecrsfromdensebuf(a, m, n, s)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsecreatecrsfromdensebuf(a, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          m:          int
          n:          int
          s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsecreatecrsfromdensev'></a><h3 class=pageheader><code>sparsecreatecrsfromdensev</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates a  CRS-based  sparse  matrix  from  a  dense  vector
# which stores a dense 1-dimensional representation of a dense M*N matrix.
# 
# This function is intended for situations when you already  have  a  dense
# vector and need a convenient way of converting it to the CRS format.
# 
# INPUT PARAMETERS
#     A           -   array[M*N]. If larger, only leading M*N elements
#                     will be used.
#     M           -   number of rows in a matrix, M&gt;=1
#     N           -   number of columns in a matrix, N&gt;=1
# 
# OUTPUT PARAMETERS
#     S           -   sparse M*N matrix A in the CRS format
# 
# NOTE: this function completely  overwrites  S  with  new  sparse  matrix.
#       Previously allocated storage is NOT reused. If you  want  to  reuse
#       already allocated memory, call SparseCreateCRSFromDenseBuf function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 17.02.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.sparsecreatecrsfromdensev(a, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.sparsematrix

</div></pre>
<a name='sub_sparsecreatecrsfromdensevbuf'></a><h3 class=pageheader><code>sparsecreatecrsfromdensevbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates a  CRS-based  sparse  matrix  from  a  dense vector
# which stores a dense 1-dimensional representation of a dense M*N  matrix.
# A buffered version which reused memory already allocated in S as much  as
# possible.
# 
# This function is intended for situations when you already  have  a  dense
# vector and need a convenient way of converting it to the CRS format.
# 
# INPUT PARAMETERS
#     A           -   array[M*N]. If larger, only leading M*N elements
#                     will be used.
#     M           -   number of rows in a matrix, M&gt;=1
#     N           -   number of columns in a matrix, N&gt;=1
#     S           -   an already allocated structure; if it already has
#                     enough memory to store the matrix, no new memory
#                     will be allocated.
# 
# OUTPUT PARAMETERS
#     S           -   sparse M*N matrix A in the CRS format.
# 
#   -- ALGLIB PROJECT --
#      Copyright 16.06.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsecreatecrsfromdensevbuf(a, m, n, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          m:          int
          n:          int
          s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsecreatesks'></a><h3 class=pageheader><code>sparsecreatesks</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates sparse matrix in  a  SKS  format  (skyline  storage
# format). In most cases you do not need this function - CRS format  better
# suits most use cases.
# 
# INPUT PARAMETERS
#     M, N        -   number of rows(M) and columns (N) in a matrix:
#                     * M=N (as for now, ALGLIB supports only square SKS)
#                     * N&gt;=1
#                     * M&gt;=1
#     D           -   &quot;bottom&quot; bandwidths, array[M], D[I]&gt;=0.
#                     I-th element stores number of non-zeros at I-th  row,
#                     below the diagonal (diagonal itself is not  included)
#     U           -   &quot;top&quot; bandwidths, array[N], U[I]&gt;=0.
#                     I-th element stores number of non-zeros  at I-th row,
#                     above the diagonal (diagonal itself  is not included)
# 
# OUTPUT PARAMETERS
#     S           -   sparse M*N matrix in SKS representation.
#                     All elements are filled by zeros.
#                     You may use sparseset() to change their values.
# 
# NOTE: this function completely  overwrites  S  with  new  sparse  matrix.
#       Previously allocated storage is NOT reused. If you  want  to  reuse
#       already allocated memory, call SparseCreateSKSBuf function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 13.01.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.sparsecreatesks(m, n, d, u)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          d:          1D array/list of int
          u:          1D array/list of int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.sparsematrix

</div></pre>
<a name='sub_sparsecreatesksband'></a><h3 class=pageheader><code>sparsecreatesksband</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates sparse matrix in  a  SKS  format  (skyline  storage
# format). Unlike more general  sparsecreatesks(),  this  function  creates
# sparse matrix with constant bandwidth.
# 
# You may want to use this function instead of sparsecreatesks() when  your
# matrix has  constant  or  nearly-constant  bandwidth,  and  you  want  to
# simplify source code.
# 
# INPUT PARAMETERS
#     M, N        -   number of rows(M) and columns (N) in a matrix:
#                     * M=N (as for now, ALGLIB supports only square SKS)
#                     * N&gt;=1
#                     * M&gt;=1
#     BW          -   matrix bandwidth, BW&gt;=0
# 
# OUTPUT PARAMETERS
#     S           -   sparse M*N matrix in SKS representation.
#                     All elements are filled by zeros.
#                     You may use sparseset() to  change  their values.
# 
# NOTE: this function completely  overwrites  S  with  new  sparse  matrix.
#       Previously allocated storage is NOT reused. If you  want  to  reuse
#       already allocated memory, call sparsecreatesksbandbuf function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 25.12.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.sparsecreatesksband(m, n, bw)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          bw:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.sparsematrix

</div></pre>
<a name='sub_sparsecreatesksbandbuf'></a><h3 class=pageheader><code>sparsecreatesksbandbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is &quot;buffered&quot; version  of  sparsecreatesksband() which reuses memory
# previously allocated in S (of course, memory is reallocated if needed).
# 
# You may want to use this function instead  of  sparsecreatesksbuf()  when
# your matrix has  constant or nearly-constant  bandwidth,  and you want to
# simplify source code.
# 
# INPUT PARAMETERS
#     M, N        -   number of rows(M) and columns (N) in a matrix:
#                     * M=N (as for now, ALGLIB supports only square SKS)
#                     * N&gt;=1
#                     * M&gt;=1
#     BW          -   bandwidth, BW&gt;=0
# 
# OUTPUT PARAMETERS
#     S           -   sparse M*N matrix in SKS representation.
#                     All elements are filled by zeros.
#                     You may use sparseset() to change their values.
# 
#   -- ALGLIB PROJECT --
#      Copyright 13.01.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsecreatesksbandbuf(m, n, bw, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          bw:         int
          s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsecreatesksbuf'></a><h3 class=pageheader><code>sparsecreatesksbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is &quot;buffered&quot;  version  of  SparseCreateSKS()  which  reuses  memory
# previously allocated in S (of course, memory is reallocated if needed).
# 
# This function creates sparse matrix in  a  SKS  format  (skyline  storage
# format). In most cases you do not need this function - CRS format  better
# suits most use cases.
# 
# INPUT PARAMETERS
#     M, N        -   number of rows(M) and columns (N) in a matrix:
#                     * M=N (as for now, ALGLIB supports only square SKS)
#                     * N&gt;=1
#                     * M&gt;=1
#     D           -   &quot;bottom&quot; bandwidths, array[M], 0&lt;=D[I]&lt;=I.
#                     I-th element stores number of non-zeros at I-th row,
#                     below the diagonal (diagonal itself is not included)
#     U           -   &quot;top&quot; bandwidths, array[N], 0&lt;=U[I]&lt;=I.
#                     I-th element stores number of non-zeros at I-th row,
#                     above the diagonal (diagonal itself is not included)
# 
# OUTPUT PARAMETERS
#     S           -   sparse M*N matrix in SKS representation.
#                     All elements are filled by zeros.
#                     You may use sparseset() to change their values.
# 
#   -- ALGLIB PROJECT --
#      Copyright 13.01.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsecreatesksbuf(m, n, d, u, s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          d:          1D array/list of int
          u:          1D array/list of int
          s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparseenumerate'></a><h3 class=pageheader><code>sparseenumerate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  is  used  to enumerate all elements of the sparse matrix.
# Before  first  call  user  initializes  T0 and T1 counters by zero. These
# counters are used to remember current position in a  matrix;  after  each
# call they are updated by the function.
# 
# Subsequent calls to this function return non-zero elements of the  sparse
# matrix, one by one. If you enumerate CRS matrix, matrix is traversed from
# left to right, from top to bottom. In case you enumerate matrix stored as
# Hash table, elements are returned in random order.
# 
# EXAMPLE
#     &gt; T0=0
#     &gt; T1=0
#     &gt; while SparseEnumerate(S,T0,T1,I,J,V) do
#     &gt;     ....do something with I,J,V
# 
# INPUT PARAMETERS
#     S           -   sparse M*N matrix in Hash-Table or CRS representation.
#     T0          -   internal counter
#     T1          -   internal counter
# 
# OUTPUT PARAMETERS
#     T0          -   new value of the internal counter
#     T1          -   new value of the internal counter
#     I           -   row index of non-zero element, 0&lt;=I&lt;M.
#     J           -   column index of non-zero element, 0&lt;=J&lt;N
#     V           -   value of the T-th element
# 
# RESULT
#     True in case of success (next non-zero element was retrieved)
#     False in case all non-zero elements were enumerated
# 
# NOTE: you may call SparseRewriteExisting() during enumeration, but it  is
#       THE  ONLY  matrix  modification  function  you  can  call!!!  Other
#       matrix modification functions should not be called during enumeration!
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.03.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, t0, t1, i, j, v = xalglib.sparseenumerate(s, t0, t1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          t0:         int
          t1:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          t0:         int
          t1:         int
          i:          int
          j:          int
          v:          float

</div></pre>
<a name='sub_sparseexists'></a><h3 class=pageheader><code>sparseexists</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function checks whether S[i,j] is present in the sparse  matrix.  It
# returns True even for elements  that  are  numerically  zero  (but  still
# have place allocated for them).
# 
# The matrix  can be in any mode (Hash-Table, CRS, SKS), but this  function
# is less efficient for CRS matrices. Hash-Table and SKS matrices can  find
# element in O(1) time, while  CRS  matrices need O(log(RS)) time, where RS
# is an number of non-zero elements in a row.
# 
# INPUT PARAMETERS
#     S           -   sparse M*N matrix
#     I           -   row index of the element to modify, 0&lt;=I&lt;M
#     J           -   column index of the element to modify, 0&lt;=J&lt;N
# 
# RESULT
#     whether S[I,J] is present in the data structure or not
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2020 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sparseexists(s, i, j)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          i:          int
          j:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_sparsefree'></a><h3 class=pageheader><code>sparsefree</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# The function frees all memory occupied by  sparse  matrix.  Sparse  matrix
# structure becomes unusable after this call.
# 
# OUTPUT PARAMETERS
#     S   -   sparse matrix to delete
# 
#   -- ALGLIB PROJECT --
#      Copyright 24.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.sparsefree()
<span style='font-weight: bold; color: navy;'>ARGS:</span>     
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.sparsematrix

</div></pre>
<a name='sub_sparsegemv'></a><h3 class=pageheader><code>sparsegemv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates generalized sparse matrix-vector product
# 
#     y := alpha*op(S)*x + beta*y
# 
# Matrix S must be stored in CRS or SKS format (exception  will  be  thrown
# otherwise). op(S) can be either S or S^T.
# 
# NOTE: this  function  expects  Y  to  be  large enough to store result. No
#       automatic preallocation happens for smaller arrays.
# 
# INPUT PARAMETERS
#     S           -   sparse matrix in CRS or SKS format.
#     Alpha       -   source coefficient
#     OpS         -   operation type:
#                     * OpS=0     =&gt;  op(S) = S
#                     * OpS=1     =&gt;  op(S) = S^T
#     X           -   input vector, must have at least Cols(op(S))+IX elements
#     IX          -   subvector offset
#     Beta        -   destination coefficient
#     Y           -   preallocated output array, must have at least Rows(op(S))+IY elements
#     IY          -   subvector offset
# 
# OUTPUT PARAMETERS
#     Y           -   elements [IY...IY+Rows(op(S))-1] are replaced by result,
#                     other elements are not modified
# 
# HANDLING OF SPECIAL CASES:
# * below M=Rows(op(S)) and N=Cols(op(S)). Although current  ALGLIB  version
#   does not allow you to  create  zero-sized  sparse  matrices,  internally
#   ALGLIB  can  deal  with  such matrices. So, comments for M or N equal to
#   zero are for internal use only.
# * if M=0, then subroutine does nothing. It does not even touch arrays.
# * if N=0 or Alpha=0.0, then:
#   * if Beta=0, then Y is filled by zeros. S and X are  not  referenced  at
#     all. Initial values of Y are ignored (we do not  multiply  Y by  zero,
#     we just rewrite it by zeros)
#   * if Beta&lt;&gt;0, then Y is replaced by Beta*Y
# * if M&gt;0, N&gt;0, Alpha&lt;&gt;0, but  Beta=0, then  Y is replaced by alpha*op(S)*x
#   initial state of Y  is ignored (rewritten without initial multiplication
#   by zeros).
# 
# NOTE: this function throws exception when called for non-CRS/SKS  matrix.
# You must convert your matrix with SparseConvertToCRS/SKS()  before  using
# this function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 10.12.2019 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsegemv(s, alpha, ops, x, ix, beta, y, iy)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          alpha:      float
          ops:        int
          x:          1D array/list of float
          ix:         int
          beta:       float
          y:          1D array/list of float
          iy:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> y
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparseget'></a><h3 class=pageheader><code>sparseget</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns S[i,j] - element of the sparse matrix.  Matrix  can
# be in any mode (Hash-Table, CRS, SKS), but this function is less efficient
# for CRS matrices. Hash-Table and SKS matrices can find  element  in  O(1)
# time, while  CRS  matrices need O(log(RS)) time, where RS is an number of
# non-zero elements in a row.
# 
# INPUT PARAMETERS
#     S           -   sparse M*N matrix
#     I           -   row index of the element to modify, 0&lt;=I&lt;M
#     J           -   column index of the element to modify, 0&lt;=J&lt;N
# 
# RESULT
#     value of S[I,J] or zero (in case no element with such index is found)
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sparseget(s, i, j)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          i:          int
          j:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_sparsegetcompressedrow'></a><h3 class=pageheader><code>sparsegetcompressedrow</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns I-th row of the sparse matrix IN COMPRESSED FORMAT -
# only non-zero elements are returned (with their indexes). Matrix  must  be
# stored in CRS or SKS format.
# 
# INPUT PARAMETERS:
#     S           -   sparse M*N matrix in CRS format
#     I           -   row index, 0&lt;=I&lt;M
#     ColIdx      -   output buffer for column indexes, can be preallocated.
#                     In case buffer size is too small to store I-th row, it
#                     is automatically reallocated.
#     Vals        -   output buffer for values, can be preallocated. In case
#                     buffer size is too small to  store  I-th  row,  it  is
#                     automatically reallocated.
# 
# OUTPUT PARAMETERS:
#     ColIdx      -   column   indexes   of  non-zero  elements,  sorted  by
#                     ascending. Symbolically non-zero elements are  counted
#                     (i.e. if you allocated place for element, but  it  has
#                     zero numerical value - it is counted).
#     Vals        -   values. Vals[K] stores value of  matrix  element  with
#                     indexes (I,ColIdx[K]). Symbolically non-zero  elements
#                     are counted (i.e. if you allocated place for  element,
#                     but it has zero numerical value - it is counted).
#     NZCnt       -   number of symbolically non-zero elements per row.
# 
# NOTE: when  incorrect  I  (outside  of  [0,M-1]) or  matrix (non  CRS/SKS)
#       is passed, this function throws exception.
# 
# NOTE: this function may allocate additional, unnecessary place for  ColIdx
#       and Vals arrays. It is dictated by  performance  reasons  -  on  SKS
#       matrices it is faster  to  allocate  space  at  the  beginning  with
#       some &quot;extra&quot;-space, than performing two passes over matrix  -  first
#       time to calculate exact space required for data, second  time  -  to
#       store data itself.
# 
#   -- ALGLIB PROJECT --
#      Copyright 10.12.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   colidx, vals, nzcnt = xalglib.sparsegetcompressedrow(s, i, colidx, vals)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          i:          int
          colidx:     1D array/list of int
          vals:       1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  colidx:     1D array/list of int
          vals:       1D array/list of float
          nzcnt:      int

</div></pre>
<a name='sub_sparsegetdiagonal'></a><h3 class=pageheader><code>sparsegetdiagonal</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns I-th diagonal element of the sparse matrix.
# 
# Matrix can be in any mode (Hash-Table or CRS storage), but this  function
# is most efficient for CRS matrices - it requires less than 50 CPU  cycles
# to extract diagonal element. For Hash-Table matrices we still  have  O(1)
# query time, but function is many times slower.
# 
# INPUT PARAMETERS
#     S           -   sparse M*N matrix in Hash-Table representation.
#                     Exception will be thrown for CRS matrix.
#     I           -   index of the element to modify, 0&lt;=I&lt;min(M,N)
# 
# RESULT
#     value of S[I,I] or zero (in case no element with such index is found)
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sparsegetdiagonal(s, i)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          i:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_sparsegetlowercount'></a><h3 class=pageheader><code>sparsegetlowercount</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# The function returns number of strictly lower triangular non-zero elements
# in  the  matrix.  It  counts  SYMBOLICALLY non-zero elements, i.e. entries
# in the sparse matrix data structure. If some element  has  zero  numerical
# value, it is still counted.
# 
# This function has different cost for different types of matrices:
# * for hash-based matrices it involves complete pass over entire hash-table
#   with O(NNZ) cost, where NNZ is number of non-zero elements
# * for CRS and SKS matrix types cost of counting is O(N) (N - matrix size).
# 
# RESULT: number of non-zero elements strictly below main diagonal
# 
#   -- ALGLIB PROJECT --
#      Copyright 12.02.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sparsegetlowercount(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_sparsegetmatrixtype'></a><h3 class=pageheader><code>sparsegetmatrixtype</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns type of the matrix storage format.
# 
# INPUT PARAMETERS:
#     S           -   sparse matrix.
# 
# RESULT:
#     sparse storage format used by matrix:
#         0   -   Hash-table
#         1   -   CRS (compressed row storage)
#         2   -   SKS (skyline)
# 
# NOTE: future  versions  of  ALGLIB  may  include additional sparse storage
#       formats.
# 
# 
#   -- ALGLIB PROJECT --
#      Copyright 20.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sparsegetmatrixtype(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_sparsegetncols'></a><h3 class=pageheader><code>sparsegetncols</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# The function returns number of columns of a sparse matrix.
# 
# RESULT: number of columns of a sparse matrix.
# 
#   -- ALGLIB PROJECT --
#      Copyright 23.08.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sparsegetncols(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_sparsegetnrows'></a><h3 class=pageheader><code>sparsegetnrows</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# The function returns number of rows of a sparse matrix.
# 
# RESULT: number of rows of a sparse matrix.
# 
#   -- ALGLIB PROJECT --
#      Copyright 23.08.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sparsegetnrows(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_sparsegetrow'></a><h3 class=pageheader><code>sparsegetrow</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns I-th row of the sparse matrix. Matrix must be stored
# in CRS or SKS format.
# 
# INPUT PARAMETERS:
#     S           -   sparse M*N matrix in CRS format
#     I           -   row index, 0&lt;=I&lt;M
#     IRow        -   output buffer, can be  preallocated.  In  case  buffer
#                     size  is  too  small  to  store  I-th   row,   it   is
#                     automatically reallocated.
# 
# OUTPUT PARAMETERS:
#     IRow        -   array[M], I-th row.
# 
# NOTE: this function has O(N) running time, where N is a  column  count. It
#       allocates and fills N-element  array,  even  although  most  of  its
#       elemets are zero.
# 
# NOTE: If you have O(non-zeros-per-row) time and memory  requirements,  use
#       SparseGetCompressedRow() function. It  returns  data  in  compressed
#       format.
# 
# NOTE: when  incorrect  I  (outside  of  [0,M-1]) or  matrix (non  CRS/SKS)
#       is passed, this function throws exception.
# 
#   -- ALGLIB PROJECT --
#      Copyright 10.12.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   irow = xalglib.sparsegetrow(s, i, irow)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          i:          int
          irow:       1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  irow:       1D array/list of float

</div></pre>
<a name='sub_sparsegetuppercount'></a><h3 class=pageheader><code>sparsegetuppercount</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# The function returns number of strictly upper triangular non-zero elements
# in  the  matrix.  It  counts  SYMBOLICALLY non-zero elements, i.e. entries
# in the sparse matrix data structure. If some element  has  zero  numerical
# value, it is still counted.
# 
# This function has different cost for different types of matrices:
# * for hash-based matrices it involves complete pass over entire hash-table
#   with O(NNZ) cost, where NNZ is number of non-zero elements
# * for CRS and SKS matrix types cost of counting is O(N) (N - matrix size).
# 
# RESULT: number of non-zero elements strictly above main diagonal
# 
#   -- ALGLIB PROJECT --
#      Copyright 12.02.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sparsegetuppercount(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_sparseiscrs'></a><h3 class=pageheader><code>sparseiscrs</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function checks matrix storage format and returns True when matrix is
# stored using CRS representation.
# 
# INPUT PARAMETERS:
#     S   -   sparse matrix.
# 
# RESULT:
#     True if matrix type is CRS
#     False if matrix type is not CRS
# 
#   -- ALGLIB PROJECT --
#      Copyright 20.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sparseiscrs(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_sparseishash'></a><h3 class=pageheader><code>sparseishash</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function checks matrix storage format and returns True when matrix is
# stored using Hash table representation.
# 
# INPUT PARAMETERS:
#     S   -   sparse matrix.
# 
# RESULT:
#     True if matrix type is Hash table
#     False if matrix type is not Hash table
# 
#   -- ALGLIB PROJECT --
#      Copyright 20.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sparseishash(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_sparseissks'></a><h3 class=pageheader><code>sparseissks</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function checks matrix storage format and returns True when matrix is
# stored using SKS representation.
# 
# INPUT PARAMETERS:
#     S   -   sparse matrix.
# 
# RESULT:
#     True if matrix type is SKS
#     False if matrix type is not SKS
# 
#   -- ALGLIB PROJECT --
#      Copyright 20.07.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sparseissks(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_sparsemm'></a><h3 class=pageheader><code>sparsemm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates matrix-matrix product  S*A.  Matrix  S  must  be
# stored in CRS or SKS format (exception will be thrown otherwise).
# 
# INPUT PARAMETERS
#     S           -   sparse M*N matrix in CRS or SKS format.
#     A           -   array[N][K], input dense matrix. For  performance reasons
#                     we make only quick checks - we check that array size
#                     is at least N, but we do not check for NAN's or INF's.
#     K           -   number of columns of matrix (A).
#     B           -   output buffer, possibly preallocated. In case  buffer
#                     size is too small to store  result,  this  buffer  is
#                     automatically resized.
# 
# OUTPUT PARAMETERS
#     B           -   array[M][K], S*A
# 
# NOTE: this function throws exception when called for non-CRS/SKS  matrix.
# You must convert your matrix with SparseConvertToCRS/SKS()  before  using
# this function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   b = xalglib.sparsemm(s, a, k, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          a:          2D array/list of float
          k:          int
          b:          2D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  b:          2D array/list of float

</div></pre>
<a name='sub_sparsemm2'></a><h3 class=pageheader><code>sparsemm2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function simultaneously calculates two matrix-matrix products:
#     S*A and S^T*A.
# S  must  be  square (non-rectangular) matrix stored in CRS or  SKS  format
# (exception will be thrown otherwise).
# 
# INPUT PARAMETERS
#     S           -   sparse N*N matrix in CRS or SKS format.
#     A           -   array[N][K], input dense matrix. For performance reasons
#                     we make only quick checks - we check that array size  is
#                     at least N, but we do not check for NAN's or INF's.
#     K           -   number of columns of matrix (A).
#     B0          -   output buffer, possibly preallocated. In case  buffer
#                     size is too small to store  result,  this  buffer  is
#                     automatically resized.
#     B1          -   output buffer, possibly preallocated. In case  buffer
#                     size is too small to store  result,  this  buffer  is
#                     automatically resized.
# 
# OUTPUT PARAMETERS
#     B0          -   array[N][K], S*A
#     B1          -   array[N][K], S^T*A
# 
# NOTE: this function throws exception when called for non-CRS/SKS  matrix.
# You must convert your matrix with SparseConvertToCRS/SKS()  before  using
# this function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   b0, b1 = xalglib.sparsemm2(s, a, k, b0, b1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          a:          2D array/list of float
          k:          int
          b0:         2D array/list of float
          b1:         2D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  b0:         2D array/list of float
          b1:         2D array/list of float

</div></pre>
<a name='sub_sparsemtm'></a><h3 class=pageheader><code>sparsemtm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates matrix-matrix product  S^T*A. Matrix S  must  be
# stored in CRS or SKS format (exception will be thrown otherwise).
# 
# INPUT PARAMETERS
#     S           -   sparse M*N matrix in CRS or SKS format.
#     A           -   array[M][K], input dense matrix. For performance reasons
#                     we make only quick checks - we check that array size  is
#                     at least M, but we do not check for NAN's or INF's.
#     K           -   number of columns of matrix (A).
#     B           -   output buffer, possibly preallocated. In case  buffer
#                     size is too small to store  result,  this  buffer  is
#                     automatically resized.
# 
# OUTPUT PARAMETERS
#     B           -   array[N][K], S^T*A
# 
# NOTE: this function throws exception when called for non-CRS/SKS  matrix.
# You must convert your matrix with SparseConvertToCRS/SKS()  before  using
# this function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   b = xalglib.sparsemtm(s, a, k, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          a:          2D array/list of float
          k:          int
          b:          2D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  b:          2D array/list of float

</div></pre>
<a name='sub_sparsemtv'></a><h3 class=pageheader><code>sparsemtv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates matrix-vector product  S^T*x. Matrix S  must  be
# stored in CRS or SKS format (exception will be thrown otherwise).
# 
# INPUT PARAMETERS
#     S           -   sparse M*N matrix in CRS or SKS format.
#     X           -   array[M], input vector. For  performance  reasons  we
#                     make only quick checks - we check that array size  is
#                     at least M, but we do not check for NAN's or INF's.
#     Y           -   output buffer, possibly preallocated. In case  buffer
#                     size is too small to store  result,  this  buffer  is
#                     automatically resized.
# 
# OUTPUT PARAMETERS
#     Y           -   array[N], S^T*x
# 
# NOTE: this function throws exception when called for non-CRS/SKS  matrix.
# You must convert your matrix with SparseConvertToCRS/SKS()  before  using
# this function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.sparsemtv(s, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          x:          1D array/list of float
          y:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_sparsemultiplycolsby'></a><h3 class=pageheader><code>sparsemultiplycolsby</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function perform in-place multiplication of the matrix columns by  a
# user-supplied vector X. The matrix S must be stored in CRS format.
# 
# INPUT PARAMETERS
#     S           -   sparse M*N matrix in CRS format.
#     X           -   array[N], coefficients vector.
# 
# OUTPUT PARAMETERS
#     S           -   in-place multiplied by diag(X) from the right
# 
# NOTE: this function throws exception when called for  a  non-CRS  matrix.
# You must convert your matrix with SparseConvertToCRS() before using  this
# function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 17.02.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsemultiplycolsby(s, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsemultiplyrowsby'></a><h3 class=pageheader><code>sparsemultiplyrowsby</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function perform in-place multiplication of the matrix rows by  a
# user-supplied vector X. The matrix S must be stored in CRS format.
# 
# INPUT PARAMETERS
#     S           -   sparse M*N matrix in CRS format.
#     X           -   array[M], coefficients vector.
# 
# OUTPUT PARAMETERS
#     S           -   in-place multiplied by diag(X) from the left
# 
# NOTE: this function throws exception when called for  a  non-CRS  matrix.
# You must convert your matrix with SparseConvertToCRS() before using  this
# function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 17.02.2024 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsemultiplyrowsby(s, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsemv'></a><h3 class=pageheader><code>sparsemv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates matrix-vector product  S*x.  Matrix  S  must  be
# stored in CRS or SKS format (exception will be thrown otherwise).
# 
# INPUT PARAMETERS
#     S           -   sparse M*N matrix in CRS or SKS format.
#     X           -   array[N], input vector. For  performance  reasons  we
#                     make only quick checks - we check that array size  is
#                     at least N, but we do not check for NAN's or INF's.
#     Y           -   output buffer, possibly preallocated. In case  buffer
#                     size is too small to store  result,  this  buffer  is
#                     automatically resized.
# 
# OUTPUT PARAMETERS
#     Y           -   array[M], S*x
# 
# NOTE: this function throws exception when called for non-CRS/SKS  matrix.
# You must convert your matrix with SparseConvertToCRS/SKS()  before  using
# this function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.sparsemv(s, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          x:          1D array/list of float
          y:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_sparsemv2'></a><h3 class=pageheader><code>sparsemv2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function simultaneously calculates two matrix-vector products:
#     S*x and S^T*x.
# S must be square (non-rectangular) matrix stored in  CRS  or  SKS  format
# (exception will be thrown otherwise).
# 
# INPUT PARAMETERS
#     S           -   sparse N*N matrix in CRS or SKS format.
#     X           -   array[N], input vector. For  performance  reasons  we
#                     make only quick checks - we check that array size  is
#                     at least N, but we do not check for NAN's or INF's.
#     Y0          -   output buffer, possibly preallocated. In case  buffer
#                     size is too small to store  result,  this  buffer  is
#                     automatically resized.
#     Y1          -   output buffer, possibly preallocated. In case  buffer
#                     size is too small to store  result,  this  buffer  is
#                     automatically resized.
# 
# OUTPUT PARAMETERS
#     Y0          -   array[N], S*x
#     Y1          -   array[N], S^T*x
# 
# NOTE: this function throws exception when called for non-CRS/SKS  matrix.
# You must convert your matrix with SparseConvertToCRS/SKS()  before  using
# this function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y0, y1 = xalglib.sparsemv2(s, x, y0, y1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          x:          1D array/list of float
          y0:         1D array/list of float
          y1:         1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y0:         1D array/list of float
          y1:         1D array/list of float

</div></pre>
<a name='sub_sparseresizematrix'></a><h3 class=pageheader><code>sparseresizematrix</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This procedure resizes Hash-Table matrix. It can be called when you  have
# deleted too many elements from the matrix, and you want to  free unneeded
# memory.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparseresizematrix(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparserewriteexisting'></a><h3 class=pageheader><code>sparserewriteexisting</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function rewrites existing (non-zero) element. It  returns  True   if
# element  exists  or  False,  when  it  is  called for non-existing  (zero)
# element.
# 
# This function works with any kind of the matrix.
# 
# The purpose of this function is to provide convenient thread-safe  way  to
# modify  sparse  matrix.  Such  modification  (already  existing element is
# rewritten) is guaranteed to be thread-safe without any synchronization, as
# long as different threads modify different elements.
# 
# INPUT PARAMETERS
#     S           -   sparse M*N matrix in any kind of representation
#                     (Hash, SKS, CRS).
#     I           -   row index of non-zero element to modify, 0&lt;=I&lt;M
#     J           -   column index of non-zero element to modify, 0&lt;=J&lt;N
#     V           -   value to rewrite, must be finite number
# 
# OUTPUT PARAMETERS
#     S           -   modified matrix
# RESULT
#     True in case when element exists
#     False in case when element doesn't exist or it is zero
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.03.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sparserewriteexisting(s, i, j, v)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          i:          int
          j:          int
          v:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_sparsescale'></a><h3 class=pageheader><code>sparsescale</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function performs an in-place matrix conditioning scaling  such  that
# 
#     A = R*Z*C
# 
# where A is an original matrix, R and C are diagonal scaling  matrices, and
# Z is a scaled matrix. Z replaces A, R and C are returned as 1D arrays.
# 
# INPUT PARAMETERS
#     S           -   sparse M*N matrix in CRS format.
#     SclType     -   scaling type:
#                     * 0     for automatically chosen scaling
#                     * 1     for equilibration scaling
#     ScaleRows   -   if False, rows are not scaled (R=identity)
#     ScaleCols   -   if False, cols are not scaled (C=identity)
#     ColsFirst   -   scale columns first. If False, rows are  scaled  prior
#                     to scaling columns. Ignored for ScaleCols=False.
# 
# OUTPUT PARAMETERS
#     R           -   array[M], row scales, R[i]&gt;0
#     C           -   array[N], col scales, C[i]&gt;0
# 
# NOTE: this function throws exception when called  for  a  non-CRS  matrix.
#       You must convert your matrix with SparseConvertToCRS()  before using
#       this function.
# 
# NOTE: this  function  works  with  general  (nonsymmetric)  matrices.  See
#       sparsesymmscale() for a symmetric version. See sparsescalebuf()  for
#       a version which reuses space already present in output arrays R/C.
# 
# NOTE: if both ScaleRows=False and ScaleCols=False, this  function  returns
#       an identity scaling.
# 
# NOTE: R[] and C[] are guaranteed to be strictly positive. When the  matrix
#       has zero rows/cols, corresponding elements of R/C are set to 1.
# 
#   -- ALGLIB PROJECT --
#      Copyright 12.11.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   r, c = xalglib.sparsescale(s, scltype, scalerows, scalecols, colsfirst)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          scltype:    int
          scalerows:  bool
          scalecols:  bool
          colsfirst:  bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  r:          1D array/list of float
          c:          1D array/list of float

</div></pre>
<a name='sub_sparseset'></a><h3 class=pageheader><code>sparseset</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function modifies S[i,j] - element of the sparse matrix.
# 
# For Hash-based storage format:
# * this function can be called at any moment - during matrix initialization
#   or later
# * new value can be zero or non-zero.  In case new value of S[i,j] is zero,
#   this element is deleted from the table.
# * this  function  has  no  effect when called with zero V for non-existent
#   element.
# 
# For CRS-bases storage format:
# * this function can be called ONLY DURING MATRIX INITIALIZATION
# * zero values are stored in the matrix similarly to non-zero ones
# * elements must be initialized in correct order -  from top row to bottom,
#   within row - from left to right.
# 
# For SKS storage:
# * this function can be called at any moment - during matrix initialization
#   or later
# * zero values are stored in the matrix similarly to non-zero ones
# * this function CAN NOT be called for non-existent (outside  of  the  band
#   specified during SKS matrix creation) elements. Say, if you created  SKS
#   matrix  with  bandwidth=2  and  tried to call sparseset(s,0,10,VAL),  an
#   exception will be generated.
# 
# INPUT PARAMETERS
#     S           -   sparse M*N matrix in Hash-Table, SKS or CRS format.
#     I           -   row index of the element to modify, 0&lt;=I&lt;M
#     J           -   column index of the element to modify, 0&lt;=J&lt;N
#     V           -   value to set, must be finite number, can be zero
# 
# OUTPUT PARAMETERS
#     S           -   modified matrix
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparseset(s, i, j, v)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          i:          int
          j:          int
          v:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsesmm'></a><h3 class=pageheader><code>sparsesmm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates matrix-matrix product  S*A, when S  is  symmetric
# matrix. Matrix S must be stored in CRS or SKS format  (exception  will  be
# thrown otherwise).
# 
# INPUT PARAMETERS
#     S           -   sparse M*M matrix in CRS or SKS format.
#     IsUpper     -   whether upper or lower triangle of S is given:
#                     * if upper triangle is given,  only   S[i,j] for j&gt;=i
#                       are used, and lower triangle is ignored (it can  be
#                       empty - these elements are not referenced at all).
#                     * if lower triangle is given,  only   S[i,j] for j&lt;=i
#                       are used, and upper triangle is ignored.
#     A           -   array[N][K], input dense matrix. For performance reasons
#                     we make only quick checks - we check that array size is
#                     at least N, but we do not check for NAN's or INF's.
#     K           -   number of columns of matrix (A).
#     B           -   output buffer, possibly preallocated. In case  buffer
#                     size is too small to store  result,  this  buffer  is
#                     automatically resized.
# 
# OUTPUT PARAMETERS
#     B           -   array[M][K], S*A
# 
# NOTE: this function throws exception when called for non-CRS/SKS  matrix.
# You must convert your matrix with SparseConvertToCRS/SKS()  before  using
# this function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   b = xalglib.sparsesmm(s, isupper, a, k, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          isupper:    bool
          a:          2D array/list of float
          k:          int
          b:          2D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  b:          2D array/list of float

</div></pre>
<a name='sub_sparsesmv'></a><h3 class=pageheader><code>sparsesmv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates matrix-vector product  S*x, when S is  symmetric
# matrix. Matrix S  must be stored in CRS or SKS format  (exception will be
# thrown otherwise).
# 
# INPUT PARAMETERS
#     S           -   sparse M*M matrix in CRS or SKS format.
#     IsUpper     -   whether upper or lower triangle of S is given:
#                     * if upper triangle is given,  only   S[i,j] for j&gt;=i
#                       are used, and lower triangle is ignored (it can  be
#                       empty - these elements are not referenced at all).
#                     * if lower triangle is given,  only   S[i,j] for j&lt;=i
#                       are used, and upper triangle is ignored.
#     X           -   array[N], input vector. For  performance  reasons  we
#                     make only quick checks - we check that array size  is
#                     at least N, but we do not check for NAN's or INF's.
#     Y           -   output buffer, possibly preallocated. In case  buffer
#                     size is too small to store  result,  this  buffer  is
#                     automatically resized.
# 
# OUTPUT PARAMETERS
#     Y           -   array[M], S*x
# 
# NOTE: this function throws exception when called for non-CRS/SKS  matrix.
# You must convert your matrix with SparseConvertToCRS/SKS()  before  using
# this function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 14.10.2011 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.sparsesmv(s, isupper, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          isupper:    bool
          x:          1D array/list of float
          y:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_sparseswap'></a><h3 class=pageheader><code>sparseswap</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function efficiently swaps contents of S0 and S1.
# 
#   -- ALGLIB PROJECT --
#      Copyright 16.01.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparseswap(s0, s1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s0:         class xalglib.sparsematrix
          s1:         class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s0, s1
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsesymmpermtbl'></a><h3 class=pageheader><code>sparsesymmpermtbl</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function applies permutation given by permutation table P (as opposed
# to product form of permutation) to sparse symmetric  matrix  A,  given  by
# either upper or lower triangle: B := P*A*P'.
# 
# This function allocates completely new instance of B. Use buffered version
# SparseSymmPermTblBuf() if you want to reuse already allocated structure.
# 
# INPUT PARAMETERS
#     A           -   sparse square matrix in CRS format.
#     IsUpper     -   whether upper or lower triangle of A is used:
#                     * if upper triangle is given,  only   A[i,j] for  j&gt;=i
#                       are used, and lower triangle is  ignored (it can  be
#                       empty - these elements are not referenced at all).
#                     * if lower triangle is given,  only   A[i,j] for  j&lt;=i
#                       are used, and upper triangle is ignored.
#     P           -   array[N] which stores permutation table;  P[I]=J means
#                     that I-th row/column of matrix  A  is  moved  to  J-th
#                     position. For performance reasons we do NOT check that
#                     P[] is  a   correct   permutation  (that there  is  no
#                     repetitions, just that all its elements  are  in [0,N)
#                     range.
# 
# OUTPUT PARAMETERS
#     B           -   permuted matrix.  Permutation  is  applied  to A  from
#                     the both sides, only upper or lower triangle (depending
#                     on IsUpper) is stored.
# 
# NOTE: this function throws exception when called for non-CRS  matrix.  You
#       must convert your matrix with SparseConvertToCRS() before using this
#       function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 05.10.2020 by Bochkanov Sergey.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   b = xalglib.sparsesymmpermtbl(a, isupper, p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          isupper:    bool
          p:          1D array/list of int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  b:          class xalglib.sparsematrix

</div></pre>
<a name='sub_sparsesymmpermtblbuf'></a><h3 class=pageheader><code>sparsesymmpermtblbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function is a buffered version  of  SparseSymmPermTbl()  that  reuses
# previously allocated storage in B as much as possible.
# 
# This function applies permutation given by permutation table P (as opposed
# to product form of permutation) to sparse symmetric  matrix  A,  given  by
# either upper or lower triangle: B := P*A*P'.
# 
# INPUT PARAMETERS
#     A           -   sparse square matrix in CRS format.
#     IsUpper     -   whether upper or lower triangle of A is used:
#                     * if upper triangle is given,  only   A[i,j] for  j&gt;=i
#                       are used, and lower triangle is  ignored (it can  be
#                       empty - these elements are not referenced at all).
#                     * if lower triangle is given,  only   A[i,j] for  j&lt;=i
#                       are used, and upper triangle is ignored.
#     P           -   array[N] which stores permutation table;  P[I]=J means
#                     that I-th row/column of matrix  A  is  moved  to  J-th
#                     position. For performance reasons we do NOT check that
#                     P[] is  a   correct   permutation  (that there  is  no
#                     repetitions, just that all its elements  are  in [0,N)
#                     range.
#     B           -   sparse matrix object that will hold the result.
#                     Previously allocated memory will be reused as much  as
#                     possible.
# 
# OUTPUT PARAMETERS
#     B           -   permuted matrix.  Permutation  is  applied  to A  from
#                     the both sides, only upper or lower triangle (depending
#                     on IsUpper) is stored.
# 
# NOTE: this function throws exception when called for non-CRS  matrix.  You
#       must convert your matrix with SparseConvertToCRS() before using this
#       function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 05.10.2020 by Bochkanov Sergey.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsesymmpermtblbuf(a, isupper, p, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          isupper:    bool
          p:          1D array/list of int
          b:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsesymmpermtbltranspose'></a><h3 class=pageheader><code>sparsesymmpermtbltranspose</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function applies permutation given by permutation table P (as opposed
# to product form of permutation) to sparse symmetric  matrix  A,  given  by
# either upper or lower triangle: B := P*A*P'.
# 
# It outputs TRANSPOSED matrix, i.e. if A is given  by  the  lower  triangle
# then B is given by the upper one, and vice versa.
# 
# This function allocates completely new instance of B. Use buffered version
# SparseSymmPermTblTransposeBuf() if you want to reuse an already  allocated
# structure.
# 
# INPUT PARAMETERS
#     A           -   sparse square matrix in CRS format.
#     IsUpper     -   whether upper or lower triangle of A is used:
#                     * if upper triangle is given,  only   A[i,j] for  j&gt;=i
#                       are used, and lower triangle is  ignored (it can  be
#                       empty - these elements are not referenced at all).
#                     * if lower triangle is given,  only   A[i,j] for  j&lt;=i
#                       are used, and upper triangle is ignored.
#     P           -   array[N] which stores permutation table;  P[I]=J means
#                     that I-th row/column of matrix  A  is  moved  to  J-th
#                     position. For performance reasons we do NOT check that
#                     P[] is  a   correct   permutation  (that there  is  no
#                     repetitions, just that all its elements  are  in [0,N)
#                     range.
# 
# OUTPUT PARAMETERS
#     B           -   permuted matrix.  Permutation  is  applied  to A  from
#                     the both sides, only triangle OPPOSITE to that of A is
#                     returned: a lower one if IsUpper=True,  and  an  upper
#                     one otherwise.
# 
# NOTE: this function throws exception when called for non-CRS  matrix.  You
#       must convert your matrix with SparseConvertToCRS() before using this
#       function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 24.080.2024 by Bochkanov Sergey.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   b = xalglib.sparsesymmpermtbltranspose(a, isupper, p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          isupper:    bool
          p:          1D array/list of int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  b:          class xalglib.sparsematrix

</div></pre>
<a name='sub_sparsesymmpermtbltransposebuf'></a><h3 class=pageheader><code>sparsesymmpermtbltransposebuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function applies permutation given by permutation table P (as opposed
# to product form of permutation) to sparse symmetric  matrix  A,  given  by
# either upper or lower triangle: B := P*A*P'.
# 
# It outputs TRANSPOSED matrix, i.e. if A is given  by  the  lower  triangle
# then B is given by the upper one, and vice versa.
# 
# This function reuses memory already allocated in B as much as possible.
# 
# INPUT PARAMETERS
#     A           -   sparse square matrix in CRS format.
#     IsUpper     -   whether upper or lower triangle of A is used:
#                     * if upper triangle is given,  only   A[i,j] for  j&gt;=i
#                       are used, and lower triangle is  ignored (it can  be
#                       empty - these elements are not referenced at all).
#                     * if lower triangle is given,  only   A[i,j] for  j&lt;=i
#                       are used, and upper triangle is ignored.
#     P           -   array[N] which stores permutation table;  P[I]=J means
#                     that I-th row/column of matrix  A  is  moved  to  J-th
#                     position. For performance reasons we do NOT check that
#                     P[] is  a   correct   permutation  (that there  is  no
#                     repetitions, just that all its elements  are  in [0,N)
#                     range.
#     B           -   sparse matrix object that will hold the result.
#                     Previously allocated memory will be reused as much  as
#                     possible.
# 
# OUTPUT PARAMETERS
#     B           -   permuted matrix.  Permutation  is  applied  to A  from
#                     the both sides, only triangle OPPOSITE to that of A is
#                     returned: a lower one if IsUpper=True,  and  an  upper
#                     one otherwise.
# 
# NOTE: this function throws exception when called for non-CRS  matrix.  You
#       must convert your matrix with SparseConvertToCRS() before using this
#       function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 24.080.2024 by Bochkanov Sergey.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsesymmpermtbltransposebuf(a, isupper, p, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          isupper:    bool
          p:          1D array/list of int
          b:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> b
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsetransposecrs'></a><h3 class=pageheader><code>sparsetransposecrs</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function performs transpose of CRS matrix.
# 
# INPUT PARAMETERS
#     S       -   sparse matrix in CRS format.
# 
# OUTPUT PARAMETERS
#     S           -   sparse matrix, transposed.
# 
# NOTE: internal  temporary  copy  is  allocated   for   the   purposes   of
#       transposition. It is deallocated after transposition.
# 
#   -- ALGLIB PROJECT --
#      Copyright 30.01.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsetransposecrs(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsetransposesks'></a><h3 class=pageheader><code>sparsetransposesks</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function performs efficient in-place  transpose  of  SKS  matrix.  No
# additional memory is allocated during transposition.
# 
# This function supports only skyline storage format (SKS).
# 
# INPUT PARAMETERS
#     S       -   sparse matrix in SKS format.
# 
# OUTPUT PARAMETERS
#     S           -   sparse matrix, transposed.
# 
#   -- ALGLIB PROJECT --
#      Copyright 16.01.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsetransposesks(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsetrmv'></a><h3 class=pageheader><code>sparsetrmv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates matrix-vector product op(S)*x, when x is  vector,
# S is symmetric triangular matrix, op(S) is transposition or no  operation.
# Matrix S must be stored in CRS or SKS format  (exception  will  be  thrown
# otherwise).
# 
# INPUT PARAMETERS
#     S           -   sparse square matrix in CRS or SKS format.
#     IsUpper     -   whether upper or lower triangle of S is used:
#                     * if upper triangle is given,  only   S[i,j] for  j&gt;=i
#                       are used, and lower triangle is  ignored (it can  be
#                       empty - these elements are not referenced at all).
#                     * if lower triangle is given,  only   S[i,j] for  j&lt;=i
#                       are used, and upper triangle is ignored.
#     IsUnit      -   unit or non-unit diagonal:
#                     * if True, diagonal elements of triangular matrix  are
#                       considered equal to 1.0. Actual elements  stored  in
#                       S are not referenced at all.
#                     * if False, diagonal stored in S is used
#     OpType      -   operation type:
#                     * if 0, S*x is calculated
#                     * if 1, (S^T)*x is calculated (transposition)
#     X           -   array[N] which stores input  vector.  For  performance
#                     reasons we make only quick  checks  -  we  check  that
#                     array  size  is  at  least  N, but we do not check for
#                     NAN's or INF's.
#     Y           -   possibly  preallocated  input   buffer.  Automatically
#                     resized if its size is too small.
# 
# OUTPUT PARAMETERS
#     Y           -   array[N], op(S)*x
# 
# NOTE: this function throws exception when called for non-CRS/SKS  matrix.
# You must convert your matrix with SparseConvertToCRS/SKS()  before  using
# this function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 20.01.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y = xalglib.sparsetrmv(s, isupper, isunit, optype, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          isupper:    bool
          isunit:     bool
          optype:     int
          x:          1D array/list of float
          y:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> x
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y:          1D array/list of float

</div></pre>
<a name='sub_sparsetrsv'></a><h3 class=pageheader><code>sparsetrsv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function solves linear system op(S)*y=x  where  x  is  vector,  S  is
# symmetric  triangular  matrix,  op(S)  is  transposition  or no operation.
# Matrix S must be stored in CRS or SKS format  (exception  will  be  thrown
# otherwise).
# 
# INPUT PARAMETERS
#     S           -   sparse square matrix in CRS or SKS format.
#     IsUpper     -   whether upper or lower triangle of S is used:
#                     * if upper triangle is given,  only   S[i,j] for  j&gt;=i
#                       are used, and lower triangle is  ignored (it can  be
#                       empty - these elements are not referenced at all).
#                     * if lower triangle is given,  only   S[i,j] for  j&lt;=i
#                       are used, and upper triangle is ignored.
#     IsUnit      -   unit or non-unit diagonal:
#                     * if True, diagonal elements of triangular matrix  are
#                       considered equal to 1.0. Actual elements  stored  in
#                       S are not referenced at all.
#                     * if False, diagonal stored in S is used. It  is  your
#                       responsibility  to  make  sure  that   diagonal   is
#                       non-zero.
#     OpType      -   operation type:
#                     * if 0, S*x is calculated
#                     * if 1, (S^T)*x is calculated (transposition)
#     X           -   array[N] which stores input  vector.  For  performance
#                     reasons we make only quick  checks  -  we  check  that
#                     array  size  is  at  least  N, but we do not check for
#                     NAN's or INF's.
# 
# OUTPUT PARAMETERS
#     X           -   array[N], inv(op(S))*x
# 
# NOTE: this function throws exception when called for  non-CRS/SKS  matrix.
#       You must convert your matrix  with  SparseConvertToCRS/SKS()  before
#       using this function.
# 
# NOTE: no assertion or tests are done during algorithm  operation.   It  is
#       your responsibility to provide invertible matrix to algorithm.
# 
#   -- ALGLIB PROJECT --
#      Copyright 20.01.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsetrsv(s, isupper, isunit, optype, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          isupper:    bool
          isunit:     bool
          optype:     int
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> x
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsevsmv'></a><h3 class=pageheader><code>sparsevsmv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function calculates vector-matrix-vector product x'*S*x, where  S is
# symmetric matrix. Matrix S must be stored in CRS or SKS format (exception
# will be thrown otherwise).
# 
# INPUT PARAMETERS
#     S           -   sparse M*M matrix in CRS or SKS format.
#     IsUpper     -   whether upper or lower triangle of S is given:
#                     * if upper triangle is given,  only   S[i,j] for j&gt;=i
#                       are used, and lower triangle is ignored (it can  be
#                       empty - these elements are not referenced at all).
#                     * if lower triangle is given,  only   S[i,j] for j&lt;=i
#                       are used, and upper triangle is ignored.
#     X           -   array[N], input vector. For  performance  reasons  we
#                     make only quick checks - we check that array size  is
#                     at least N, but we do not check for NAN's or INF's.
# 
# RESULT
#     x'*S*x
# 
# NOTE: this function throws exception when called for non-CRS/SKS  matrix.
# You must convert your matrix with SparseConvertToCRS/SKS()  before  using
# this function.
# 
#   -- ALGLIB PROJECT --
#      Copyright 27.01.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sparsevsmv(s, isupper, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.sparsematrix
          isupper:    bool
          x:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_spdgevd></a><h2 class=pageheader><code>spdgevd</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_smatrixgevd' class=toc>smatrixgevd</a><br>
<a href='#sub_smatrixgevdreduce' class=toc>smatrixgevdreduce</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_smatrixgevd'></a><h3 class=pageheader><code>smatrixgevd</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Algorithm for solving the following generalized symmetric positive-definite
# eigenproblem:
#     A*x = lambda*B*x (1) or
#     A*B*x = lambda*x (2) or
#     B*A*x = lambda*x (3).
# where A is a symmetric matrix, B - symmetric positive-definite matrix.
# The problem is solved by reducing it to an ordinary  symmetric  eigenvalue
# problem.
# 
# Input parameters:
#     A           -   symmetric matrix which is given by its upper or lower
#                     triangular part.
#                     Array whose indexes range within [0..N-1, 0..N-1].
#     N           -   size of matrices A and B.
#     IsUpperA    -   storage format of matrix A.
#     B           -   symmetric positive-definite matrix which is given by
#                     its upper or lower triangular part.
#                     Array whose indexes range within [0..N-1, 0..N-1].
#     IsUpperB    -   storage format of matrix B.
#     ZNeeded     -   if ZNeeded is equal to:
#                      * 0, the eigenvectors are not returned;
#                      * 1, the eigenvectors are returned.
#     ProblemType -   if ProblemType is equal to:
#                      * 1, the following problem is solved: A*x = lambda*B*x;
#                      * 2, the following problem is solved: A*B*x = lambda*x;
#                      * 3, the following problem is solved: B*A*x = lambda*x.
# 
# Output parameters:
#     D           -   eigenvalues in ascending order.
#                     Array whose index ranges within [0..N-1].
#     Z           -   if ZNeeded is equal to:
#                      * 0, Z hasn't changed;
#                      * 1, Z contains eigenvectors.
#                     Array whose indexes range within [0..N-1, 0..N-1].
#                     The eigenvectors are stored in matrix columns. It should
#                     be noted that the eigenvectors in such problems do not
#                     form an orthogonal system.
# 
# Result:
#     True, if the problem was solved successfully.
#     False, if the error occurred during the Cholesky decomposition of matrix
#     B (the matrix isn't positive-definite) or during the work of the iterative
#     algorithm for solving the symmetric eigenproblem.
# 
# See also the GeneralizedSymmetricDefiniteEVDReduce subroutine.
# 
#   -- ALGLIB --
#      Copyright 1.28.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, d, z = xalglib.smatrixgevd(a, n, isuppera, b, isupperb, zneeded, problemtype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isuppera:   bool
          b:          2D array/list of float
          isupperb:   bool
          zneeded:    int
          problemtype: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          d:          1D array/list of float
          z:          2D array/list of float

</div></pre>
<a name='sub_smatrixgevdreduce'></a><h3 class=pageheader><code>smatrixgevdreduce</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Algorithm for reduction of the following generalized symmetric positive-
# definite eigenvalue problem:
#     A*x = lambda*B*x (1) or
#     A*B*x = lambda*x (2) or
#     B*A*x = lambda*x (3)
# to the symmetric eigenvalues problem C*y = lambda*y (eigenvalues of this and
# the given problems are the same, and the eigenvectors of the given problem
# could be obtained by multiplying the obtained eigenvectors by the
# transformation matrix x = R*y).
# 
# Here A is a symmetric matrix, B - symmetric positive-definite matrix.
# 
# Input parameters:
#     A           -   symmetric matrix which is given by its upper or lower
#                     triangular part.
#                     Array whose indexes range within [0..N-1, 0..N-1].
#     N           -   size of matrices A and B.
#     IsUpperA    -   storage format of matrix A.
#     B           -   symmetric positive-definite matrix which is given by
#                     its upper or lower triangular part.
#                     Array whose indexes range within [0..N-1, 0..N-1].
#     IsUpperB    -   storage format of matrix B.
#     ProblemType -   if ProblemType is equal to:
#                      * 1, the following problem is solved: A*x = lambda*B*x;
#                      * 2, the following problem is solved: A*B*x = lambda*x;
#                      * 3, the following problem is solved: B*A*x = lambda*x.
# 
# Output parameters:
#     A           -   symmetric matrix which is given by its upper or lower
#                     triangle depending on IsUpperA. Contains matrix C.
#                     Array whose indexes range within [0..N-1, 0..N-1].
#     R           -   upper triangular or low triangular transformation matrix
#                     which is used to obtain the eigenvectors of a given problem
#                     as the product of eigenvectors of C (from the right) and
#                     matrix R (from the left). If the matrix is upper
#                     triangular, the elements below the main diagonal
#                     are equal to 0 (and vice versa). Thus, we can perform
#                     the multiplication without taking into account the
#                     internal structure (which is an easier though less
#                     effective way).
#                     Array whose indexes range within [0..N-1, 0..N-1].
#     IsUpperR    -   type of matrix R (upper or lower triangular).
# 
# Result:
#     True, if the problem was reduced successfully.
#     False, if the error occurred during the Cholesky decomposition of
#         matrix B (the matrix is not positive-definite).
# 
#   -- ALGLIB --
#      Copyright 1.28.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, r, isupperr = xalglib.smatrixgevdreduce(a, n, isuppera, b, isupperb, problemtype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isuppera:   bool
          b:          2D array/list of float
          isupperb:   bool
          problemtype: int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          r:          2D array/list of float
          isupperr:   bool

</div></pre>
<a name=unit_spline1d></a><h2 class=pageheader><code>spline1d</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_spline1dbuildakima' class=toc>spline1dbuildakima</a><br>
<a href='#sub_spline1dbuildakimamod' class=toc>spline1dbuildakimamod</a><br>
<a href='#sub_spline1dbuildcatmullrom' class=toc>spline1dbuildcatmullrom</a><br>
<a href='#sub_spline1dbuildcubic' class=toc>spline1dbuildcubic</a><br>
<a href='#sub_spline1dbuildhermite' class=toc>spline1dbuildhermite</a><br>
<a href='#sub_spline1dbuildhermitebuf' class=toc>spline1dbuildhermitebuf</a><br>
<a href='#sub_spline1dbuildlinear' class=toc>spline1dbuildlinear</a><br>
<a href='#sub_spline1dbuildlinearbuf' class=toc>spline1dbuildlinearbuf</a><br>
<a href='#sub_spline1dbuildmonotone' class=toc>spline1dbuildmonotone</a><br>
<a href='#sub_spline1dcalc' class=toc>spline1dcalc</a><br>
<a href='#sub_spline1dconvcubic' class=toc>spline1dconvcubic</a><br>
<a href='#sub_spline1dconvdiff2cubic' class=toc>spline1dconvdiff2cubic</a><br>
<a href='#sub_spline1dconvdiffcubic' class=toc>spline1dconvdiffcubic</a><br>
<a href='#sub_spline1ddiff' class=toc>spline1ddiff</a><br>
<a href='#sub_spline1dfit' class=toc>spline1dfit</a><br>
<a href='#sub_spline1dgriddiff2cubic' class=toc>spline1dgriddiff2cubic</a><br>
<a href='#sub_spline1dgriddiffcubic' class=toc>spline1dgriddiffcubic</a><br>
<a href='#sub_spline1dintegrate' class=toc>spline1dintegrate</a><br>
<a href='#sub_spline1dlintransx' class=toc>spline1dlintransx</a><br>
<a href='#sub_spline1dlintransy' class=toc>spline1dlintransy</a><br>
<a href='#sub_spline1dunpack' class=toc>spline1dunpack</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_spline1dbuildakima'></a><h3 class=pageheader><code>spline1dbuildakima</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds Akima spline interpolant
# 
# INPUT PARAMETERS:
#     X           -   spline nodes, array[0..N-1]
#     Y           -   function values, array[0..N-1]
#     N           -   points count (optional):
#                     * N&gt;=2
#                     * if given, only first N points are used to build spline
#                     * if not given, automatically detected from X/Y sizes
#                       (len(X) must be equal to len(Y))
# 
# OUTPUT PARAMETERS:
#     C           -   spline interpolant
# 
# 
# ORDER OF POINTS
# 
# Subroutine automatically sorts points, so caller may pass unsorted array.
# 
#   -- ALGLIB PROJECT --
#      Copyright 24.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline1dbuildakima(x, y, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline1dbuildakima(x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          class xalglib.spline1dinterpolant

</div></pre>
<a name='sub_spline1dbuildakimamod'></a><h3 class=pageheader><code>spline1dbuildakimamod</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds modified Akima spline interpolant, with weights
# 
#     W[i]=|Delta[I]-Delta[I-1]|
# 
# replaced by
# 
#     W[i]=|Delta[I]-Delta[I-1]|+0.5*|Delta[I]+Delta[I-1]|
# 
# INPUT PARAMETERS:
#     X           -   spline nodes, array[0..N-1]
#     Y           -   function values, array[0..N-1]
#     N           -   points count (optional):
#                     * N&gt;=2
#                     * if given, only first N points are used to build spline
#                     * if not given, automatically detected from X/Y sizes
#                       (len(X) must be equal to len(Y))
# 
# OUTPUT PARAMETERS:
#     C           -   spline interpolant
# 
# 
# ORDER OF POINTS
# 
# Subroutine automatically sorts points, so caller may pass unsorted array.
# 
#   -- ALGLIB PROJECT --
#      Copyright 24.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline1dbuildakimamod(x, y, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline1dbuildakimamod(x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          class xalglib.spline1dinterpolant

</div></pre>
<a name='sub_spline1dbuildcatmullrom'></a><h3 class=pageheader><code>spline1dbuildcatmullrom</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds Catmull-Rom spline interpolant.
# 
# INPUT PARAMETERS:
#     X           -   spline nodes, array[0..N-1].
#     Y           -   function values, array[0..N-1].
# 
# OPTIONAL PARAMETERS:
#     N           -   points count:
#                     * N&gt;=2
#                     * if given, only first N points are used to build spline
#                     * if not given, automatically detected from X/Y sizes
#                       (len(X) must be equal to len(Y))
#     BoundType   -   boundary condition type:
#                     * -1 for periodic boundary condition
#                     *  0 for parabolically terminated spline (default)
#     Tension     -   tension parameter:
#                     * tension=0   corresponds to classic Catmull-Rom spline (default)
#                     * 0&lt;tension&lt;1 corresponds to more general form - cardinal spline
# 
# OUTPUT PARAMETERS:
#     C           -   spline interpolant
# 
# 
# ORDER OF POINTS
# 
# Subroutine automatically sorts points, so caller may pass unsorted array.
# 
# PROBLEMS WITH PERIODIC BOUNDARY CONDITIONS:
# 
# Problems with periodic boundary conditions have Y[first_point]=Y[last_point].
# However, this subroutine doesn't require you to specify equal  values  for
# the first and last points - it automatically forces them  to  be  equal by
# copying  Y[first_point]  (corresponds  to the leftmost,  minimal  X[])  to
# Y[last_point]. However it is recommended to pass consistent values of Y[],
# i.e. to make Y[first_point]=Y[last_point].
# 
#   -- ALGLIB PROJECT --
#      Copyright 23.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline1dbuildcatmullrom(x, y, n, boundtype, tension)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline1dbuildcatmullrom(x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          boundtype:  int
          tension:    float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          class xalglib.spline1dinterpolant

</div></pre>
<a name='sub_spline1dbuildcubic'></a><h3 class=pageheader><code>spline1dbuildcubic</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds cubic spline interpolant.
# 
# INPUT PARAMETERS:
#     X           -   spline nodes, array[0..N-1].
#     Y           -   function values, array[0..N-1].
# 
# OPTIONAL PARAMETERS:
#     N           -   points count:
#                     * N&gt;=2
#                     * if given, only first N points are used to build spline
#                     * if not given, automatically detected from X/Y sizes
#                       (len(X) must be equal to len(Y))
#     BoundLType  -   boundary condition type for the left boundary
#     BoundL      -   left boundary condition (first or second derivative,
#                     depending on the BoundLType)
#     BoundRType  -   boundary condition type for the right boundary
#     BoundR      -   right boundary condition (first or second derivative,
#                     depending on the BoundRType)
# 
# OUTPUT PARAMETERS:
#     C           -   spline interpolant
# 
# ORDER OF POINTS
# 
# Subroutine automatically sorts points, so caller may pass unsorted array.
# 
# SETTING BOUNDARY VALUES:
# 
# The BoundLType/BoundRType parameters can have the following values:
#     * -1, which corresonds to the periodic (cyclic) boundary conditions.
#           In this case:
#           * both BoundLType and BoundRType must be equal to -1.
#           * BoundL/BoundR are ignored
#           * Y[last] is ignored (it is assumed to be equal to Y[first]).
#     *  0, which  corresponds  to  the  parabolically   terminated  spline
#           (BoundL and/or BoundR are ignored).
#     *  1, which corresponds to the first derivative boundary condition
#     *  2, which corresponds to the second derivative boundary condition
#     *  by default, BoundType=0 is used
# 
# PROBLEMS WITH PERIODIC BOUNDARY CONDITIONS:
# 
# Problems with periodic boundary conditions have Y[first_point]=Y[last_point].
# However, this subroutine doesn't require you to specify equal  values  for
# the first and last points - it automatically forces them  to  be  equal by
# copying  Y[first_point]  (corresponds  to the leftmost,  minimal  X[])  to
# Y[last_point]. However it is recommended to pass consistent values of Y[],
# i.e. to make Y[first_point]=Y[last_point].
# 
#   -- ALGLIB PROJECT --
#      Copyright 23.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline1dbuildcubic(x, y, n, boundltype, boundl, boundrtype, boundr)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline1dbuildcubic(x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          boundltype: int
          boundl:     float
          boundrtype: int
          boundr:     float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          class xalglib.spline1dinterpolant

</div></pre>
<a name='sub_spline1dbuildhermite'></a><h3 class=pageheader><code>spline1dbuildhermite</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds Hermite spline interpolant.
# 
# INPUT PARAMETERS:
#     X           -   spline nodes, array[0..N-1]
#     Y           -   function values, array[0..N-1]
#     D           -   derivatives, array[0..N-1]
#     N           -   points count (optional):
#                     * N&gt;=2
#                     * if given, only first N points are used to build spline
#                     * if not given, automatically detected from X/Y sizes
#                       (len(X) must be equal to len(Y))
# 
# OUTPUT PARAMETERS:
#     C           -   spline interpolant.
# 
# 
# ORDER OF POINTS
# 
# Subroutine automatically sorts points, so caller may pass unsorted array.
# 
#   -- ALGLIB PROJECT --
#      Copyright 23.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline1dbuildhermite(x, y, d, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline1dbuildhermite(x, y, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          d:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          class xalglib.spline1dinterpolant

</div></pre>
<a name='sub_spline1dbuildhermitebuf'></a><h3 class=pageheader><code>spline1dbuildhermitebuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds Hermite spline interpolant.
# 
# Buffered version which reuses memory previously allocated in C as much  as
# possible.
# 
#   -- ALGLIB PROJECT --
#      Copyright 23.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline1dbuildhermitebuf(x, y, d, n, c)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline1dbuildhermitebuf(x, y, d, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          d:          1D array/list of float
          n:          int
          c:          class xalglib.spline1dinterpolant
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline1dbuildlinear'></a><h3 class=pageheader><code>spline1dbuildlinear</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds linear spline interpolant
# 
# INPUT PARAMETERS:
#     X   -   spline nodes, array[0..N-1]
#     Y   -   function values, array[0..N-1]
#     N   -   points count (optional):
#             * N&gt;=2
#             * if given, only first N points are used to build spline
#             * if not given, automatically detected from X/Y sizes
#               (len(X) must be equal to len(Y))
# 
# OUTPUT PARAMETERS:
#     C   -   spline interpolant
# 
# 
# ORDER OF POINTS
# 
# Subroutine automatically sorts points, so caller may pass unsorted array.
# 
#   -- ALGLIB PROJECT --
#      Copyright 24.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline1dbuildlinear(x, y, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline1dbuildlinear(x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          class xalglib.spline1dinterpolant

</div></pre>
<a name='sub_spline1dbuildlinearbuf'></a><h3 class=pageheader><code>spline1dbuildlinearbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds linear spline interpolant.
# 
# Buffered version of Spline1DBuildLinear() which reused  memory  previously
# allocated in C as much as possible.
# 
#   -- ALGLIB PROJECT --
#      Copyright 24.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline1dbuildlinearbuf(x, y, n, c)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline1dbuildlinearbuf(x, y, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          c:          class xalglib.spline1dinterpolant
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline1dbuildmonotone'></a><h3 class=pageheader><code>spline1dbuildmonotone</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function builds monotone cubic Hermite interpolant. This interpolant
# is monotonic in [x(0),x(n-1)] and is constant outside of this interval.
# 
# In  case  y[]  form  non-monotonic  sequence,  interpolant  is  piecewise
# monotonic.  Say, for x=(0,1,2,3,4)  and  y=(0,1,2,1,0)  interpolant  will
# monotonically grow at [0..2] and monotonically decrease at [2..4].
# 
# INPUT PARAMETERS:
#     X           -   spline nodes, array[0..N-1]. Subroutine automatically
#                     sorts points, so caller may pass unsorted array.
#     Y           -   function values, array[0..N-1]
#     N           -   the number of points(N&gt;=2).
# 
# OUTPUT PARAMETERS:
#     C           -   spline interpolant.
# 
#  -- ALGLIB PROJECT --
#      Copyright 21.06.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline1dbuildmonotone(x, y, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline1dbuildmonotone(x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          class xalglib.spline1dinterpolant

</div></pre>
<a name='sub_spline1dcalc'></a><h3 class=pageheader><code>spline1dcalc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates the value of the spline at the given point X.
# 
# INPUT PARAMETERS:
#     C   -   spline interpolant
#     X   -   point
# 
# Result:
#     S(x)
# 
#   -- ALGLIB PROJECT --
#      Copyright 23.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spline1dcalc(c, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline1dinterpolant
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_spline1dconvcubic'></a><h3 class=pageheader><code>spline1dconvcubic</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function solves following problem: given table y[] of function values
# at old nodes x[]  and new nodes  x2[],  it calculates and returns table of
# function values y2[] (calculated at x2[]).
# 
# This function yields same result as Spline1DBuildCubic() call followed  by
# sequence of Spline1DCalc() calls, but it  can  be  several  times  faster,
# whilst still having the same O(N*logN) running time.
# 
# When called for ordered X[], this function has O(N) running  time  instead
# of O(N*logN).
# 
# INPUT PARAMETERS:
#     X           -   old spline nodes
#     Y           -   function values
#     X2           -  new spline nodes
# 
# OPTIONAL PARAMETERS:
#     N           -   points count:
#                     * N&gt;=2
#                     * if given, only first N points from X/Y are used
#                     * if not given, automatically detected from X/Y sizes
#                       (len(X) must be equal to len(Y))
#     BoundLType  -   boundary condition type for the left boundary
#     BoundL      -   left boundary condition (first or second derivative,
#                     depending on the BoundLType)
#     BoundRType  -   boundary condition type for the right boundary
#     BoundR      -   right boundary condition (first or second derivative,
#                     depending on the BoundRType)
#     N2          -   new points count:
#                     * N2&gt;=2
#                     * if given, only first N2 points from X2 are used
#                     * if not given, automatically detected from X2 size
# 
# OUTPUT PARAMETERS:
#     F2          -   function values at X2[]
# 
# ORDER OF POINTS
# 
# Subroutine automatically sorts points, so caller  may pass unsorted array.
# Function  values  are correctly reordered on  return, so F2[I]  is  always
# equal to S(X2[I]) independently of points order.
# 
# SETTING BOUNDARY VALUES:
# 
# The BoundLType/BoundRType parameters can have the following values:
#     * -1, which corresonds to the periodic (cyclic) boundary conditions.
#           In this case:
#           * both BoundLType and BoundRType must be equal to -1.
#           * BoundL/BoundR are ignored
#           * Y[last] is ignored (it is assumed to be equal to Y[first]).
#     *  0, which  corresponds  to  the  parabolically   terminated  spline
#           (BoundL and/or BoundR are ignored).
#     *  1, which corresponds to the first derivative boundary condition
#     *  2, which corresponds to the second derivative boundary condition
#     *  by default, BoundType=0 is used
# 
# PROBLEMS WITH PERIODIC BOUNDARY CONDITIONS:
# 
# Problems with periodic boundary conditions have Y[first_point]=Y[last_point].
# However, this subroutine doesn't require you to specify equal  values  for
# the first and last points - it automatically forces them  to  be  equal by
# copying  Y[first_point]  (corresponds  to the leftmost,  minimal  X[])  to
# Y[last_point]. However it is recommended to pass consistent values of Y[],
# i.e. to make Y[first_point]=Y[last_point].
# 
#   -- ALGLIB PROJECT --
#      Copyright 03.09.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y2 = xalglib.spline1dconvcubic(x, y, n, boundltype, boundl, boundrtype, boundr, x2, n2)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   y2 = xalglib.spline1dconvcubic(x, y, x2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          boundltype: int
          boundl:     float
          boundrtype: int
          boundr:     float
          x2:         1D array/list of float
          n2:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y2:         1D array/list of float

</div></pre>
<a name='sub_spline1dconvdiff2cubic'></a><h3 class=pageheader><code>spline1dconvdiff2cubic</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function solves following problem: given table y[] of function values
# at old nodes x[]  and new nodes  x2[],  it calculates and returns table of
# function  values  y2[],  first  and  second  derivatives  d2[]  and  dd2[]
# (calculated at x2[]).
# 
# This function yields same result as Spline1DBuildCubic() call followed  by
# sequence of Spline1DDiff2() calls, but it  can  be  several  times faster,
# whilst still having the same O(N*logN) running time.
# 
# When called for ordered X[], this function has O(N) running  time  instead
# of O(N*logN).
# 
# INPUT PARAMETERS:
#     X           -   old spline nodes
#     Y           -   function values
#     X2           -  new spline nodes
# 
# OPTIONAL PARAMETERS:
#     N           -   points count:
#                     * N&gt;=2
#                     * if given, only first N points from X/Y are used
#                     * if not given, automatically detected from X/Y sizes
#                       (len(X) must be equal to len(Y))
#     BoundLType  -   boundary condition type for the left boundary
#     BoundL      -   left boundary condition (first or second derivative,
#                     depending on the BoundLType)
#     BoundRType  -   boundary condition type for the right boundary
#     BoundR      -   right boundary condition (first or second derivative,
#                     depending on the BoundRType)
#     N2          -   new points count:
#                     * N2&gt;=2
#                     * if given, only first N2 points from X2 are used
#                     * if not given, automatically detected from X2 size
# 
# OUTPUT PARAMETERS:
#     F2          -   function values at X2[]
#     D2          -   first derivatives at X2[]
#     DD2         -   second derivatives at X2[]
# 
# ORDER OF POINTS
# 
# Subroutine automatically sorts points, so caller  may pass unsorted array.
# Function  values  are correctly reordered on  return, so F2[I]  is  always
# equal to S(X2[I]) independently of points order.
# 
# SETTING BOUNDARY VALUES:
# 
# The BoundLType/BoundRType parameters can have the following values:
#     * -1, which corresonds to the periodic (cyclic) boundary conditions.
#           In this case:
#           * both BoundLType and BoundRType must be equal to -1.
#           * BoundL/BoundR are ignored
#           * Y[last] is ignored (it is assumed to be equal to Y[first]).
#     *  0, which  corresponds  to  the  parabolically   terminated  spline
#           (BoundL and/or BoundR are ignored).
#     *  1, which corresponds to the first derivative boundary condition
#     *  2, which corresponds to the second derivative boundary condition
#     *  by default, BoundType=0 is used
# 
# PROBLEMS WITH PERIODIC BOUNDARY CONDITIONS:
# 
# Problems with periodic boundary conditions have Y[first_point]=Y[last_point].
# However, this subroutine doesn't require you to specify equal  values  for
# the first and last points - it automatically forces them  to  be  equal by
# copying  Y[first_point]  (corresponds  to the leftmost,  minimal  X[])  to
# Y[last_point]. However it is recommended to pass consistent values of Y[],
# i.e. to make Y[first_point]=Y[last_point].
# 
#   -- ALGLIB PROJECT --
#      Copyright 03.09.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y2, d2, dd2 = xalglib.spline1dconvdiff2cubic(x, y, n, boundltype, boundl, boundrtype, boundr, x2, n2)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   y2, d2, dd2 = xalglib.spline1dconvdiff2cubic(x, y, x2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          boundltype: int
          boundl:     float
          boundrtype: int
          boundr:     float
          x2:         1D array/list of float
          n2:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y2:         1D array/list of float
          d2:         1D array/list of float
          dd2:        1D array/list of float

</div></pre>
<a name='sub_spline1dconvdiffcubic'></a><h3 class=pageheader><code>spline1dconvdiffcubic</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function solves following problem: given table y[] of function values
# at old nodes x[]  and new nodes  x2[],  it calculates and returns table of
# function values y2[] and derivatives d2[] (calculated at x2[]).
# 
# This function yields same result as Spline1DBuildCubic() call followed  by
# sequence of Spline1DDiff() calls, but it  can  be  several  times  faster,
# whilst still having the same O(N*logN) running time.
# 
# When called for ordered X[], this function has O(N) running  time  instead
# of O(N*logN).
# 
# INPUT PARAMETERS:
#     X           -   old spline nodes
#     Y           -   function values
#     X2           -  new spline nodes
# 
# OPTIONAL PARAMETERS:
#     N           -   points count:
#                     * N&gt;=2
#                     * if given, only first N points from X/Y are used
#                     * if not given, automatically detected from X/Y sizes
#                       (len(X) must be equal to len(Y))
#     BoundLType  -   boundary condition type for the left boundary
#     BoundL      -   left boundary condition (first or second derivative,
#                     depending on the BoundLType)
#     BoundRType  -   boundary condition type for the right boundary
#     BoundR      -   right boundary condition (first or second derivative,
#                     depending on the BoundRType)
#     N2          -   new points count:
#                     * N2&gt;=2
#                     * if given, only first N2 points from X2 are used
#                     * if not given, automatically detected from X2 size
# 
# OUTPUT PARAMETERS:
#     F2          -   function values at X2[]
#     D2          -   first derivatives at X2[]
# 
# ORDER OF POINTS
# 
# Subroutine automatically sorts points, so caller  may pass unsorted array.
# Function  values  are correctly reordered on  return, so F2[I]  is  always
# equal to S(X2[I]) independently of points order.
# 
# SETTING BOUNDARY VALUES:
# 
# The BoundLType/BoundRType parameters can have the following values:
#     * -1, which corresonds to the periodic (cyclic) boundary conditions.
#           In this case:
#           * both BoundLType and BoundRType must be equal to -1.
#           * BoundL/BoundR are ignored
#           * Y[last] is ignored (it is assumed to be equal to Y[first]).
#     *  0, which  corresponds  to  the  parabolically   terminated  spline
#           (BoundL and/or BoundR are ignored).
#     *  1, which corresponds to the first derivative boundary condition
#     *  2, which corresponds to the second derivative boundary condition
#     *  by default, BoundType=0 is used
# 
# PROBLEMS WITH PERIODIC BOUNDARY CONDITIONS:
# 
# Problems with periodic boundary conditions have Y[first_point]=Y[last_point].
# However, this subroutine doesn't require you to specify equal  values  for
# the first and last points - it automatically forces them  to  be  equal by
# copying  Y[first_point]  (corresponds  to the leftmost,  minimal  X[])  to
# Y[last_point]. However it is recommended to pass consistent values of Y[],
# i.e. to make Y[first_point]=Y[last_point].
# 
#   -- ALGLIB PROJECT --
#      Copyright 03.09.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   y2, d2 = xalglib.spline1dconvdiffcubic(x, y, n, boundltype, boundl, boundrtype, boundr, x2, n2)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   y2, d2 = xalglib.spline1dconvdiffcubic(x, y, x2)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          boundltype: int
          boundl:     float
          boundrtype: int
          boundr:     float
          x2:         1D array/list of float
          n2:         int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  y2:         1D array/list of float
          d2:         1D array/list of float

</div></pre>
<a name='sub_spline1ddiff'></a><h3 class=pageheader><code>spline1ddiff</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine differentiates the spline.
# 
# INPUT PARAMETERS:
#     C   -   spline interpolant.
#     X   -   point
# 
# Result:
#     S   -   S(x)
#     DS  -   S'(x)
#     D2S -   S''(x)
# 
#   -- ALGLIB PROJECT --
#      Copyright 24.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s, ds, d2s = xalglib.spline1ddiff(c, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline1dinterpolant
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          float
          ds:         float
          d2s:        float

</div></pre>
<a name='sub_spline1dfit'></a><h3 class=pageheader><code>spline1dfit</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Fitting by the smoothing (penalized) cubic spline.
# 
# This function approximates N scattered points (some of X[] may be equal to
# each other) by the cubic spline with M equidistant nodes spanning interval
# [min(x),max(x)].
# 
# The problem is regularized by adding nonlinearity  penalty  to  the  usual
# least squares penalty function:
# 
#     MERIT_FUNC = F_LS + F_NL
# 
# where F_LS is a least squares error  term,  and  F_NL  is  a  nonlinearity
# penalty which is roughly proportional to LambdaNS*integral{ S''(x)^2*dx }.
# Algorithm applies automatic renormalization of F_NL  which  makes  penalty
# term roughly invariant to scaling of X[] and changes in M.
# 
# This function is a new edition  of  penalized  regression  spline fitting,
# a fast and compact one which needs much less resources that  its  previous
# version: just O(maxMN) memory and O(maxMN) time.
# 
# NOTE: it is OK to run this function with both M&lt;&lt;N and M&gt;&gt;N;  say,  it  is
#       possible to process 100 points with 1000-node spline.
# 
# INPUT PARAMETERS:
#     X           -   points, array[0..N-1].
#     Y           -   function values, array[0..N-1].
#     N           -   number of points (optional):
#                     * N&gt;0
#                     * if given, only first N elements of X/Y are processed
#                     * if not given, automatically determined from lengths
#     M           -   number of basis functions ( = number_of_nodes), M&gt;=4.
#     LambdaNS    -   LambdaNS&gt;=0, regularization  constant  passed by user.
#                     It penalizes nonlinearity in the regression spline.
#                     Possible values to start from are 0.00001, 0.1, 1
# 
# OUTPUT PARAMETERS:
#     S   -   spline interpolant.
#     Rep -   Following fields are set:
#             * TerminationType set to 1
#             * RMSError      rms error on the (X,Y).
#             * AvgError      average error on the (X,Y).
#             * AvgRelError   average relative error on the non-zero Y
#             * MaxError      maximum error
# 
#   -- ALGLIB PROJECT --
#      Copyright 10.04.2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s, rep = xalglib.spline1dfit(x, y, n, m, lambdans)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   s, rep = xalglib.spline1dfit(x, y, m, lambdans)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          m:          int
          lambdans:   float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.spline1dinterpolant
          rep:        class xalglib.spline1dfitreport

</div></pre>
<a name='sub_spline1dgriddiff2cubic'></a><h3 class=pageheader><code>spline1dgriddiff2cubic</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function solves following problem: given table y[] of function values
# at  nodes  x[],  it  calculates  and  returns  tables  of first and second
# function derivatives d1[] and d2[] (calculated at the same nodes x[]).
# 
# This function yields same result as Spline1DBuildCubic() call followed  by
# sequence of Spline1DDiff2() calls, but it  can  be  several  times faster,
# whilst still having the same O(N*logN) running time.
# 
# When called for ordered X[], this function has O(N) running  time  instead
# of O(N*logN).
# 
# 
# INPUT PARAMETERS:
#     X           -   spline nodes
#     Y           -   function values
# 
# OPTIONAL PARAMETERS:
#     N           -   points count:
#                     * N&gt;=2
#                     * if given, only first N points are used
#                     * if not given, automatically detected from X/Y sizes
#                       (len(X) must be equal to len(Y))
#     BoundLType  -   boundary condition type for the left boundary
#     BoundL      -   left boundary condition (first or second derivative,
#                     depending on the BoundLType)
#     BoundRType  -   boundary condition type for the right boundary
#     BoundR      -   right boundary condition (first or second derivative,
#                     depending on the BoundRType)
# 
# OUTPUT PARAMETERS:
#     D1          -   S' values at X[]
#     D2          -   S'' values at X[]
# 
# ORDER OF POINTS
# 
# Subroutine automatically sorts points, so caller may pass unsorted array.
# Derivative values are correctly reordered on return, so  D[I]  is  always
# equal to S'(X[I]) independently of points order.
# 
# SETTING BOUNDARY VALUES:
# 
# The BoundLType/BoundRType parameters can have the following values:
#     * -1, which corresonds to the periodic (cyclic) boundary conditions.
#           In this case:
#           * both BoundLType and BoundRType must be equal to -1.
#           * BoundL/BoundR are ignored
#           * Y[last] is ignored (it is assumed to be equal to Y[first]).
#     *  0, which  corresponds  to  the  parabolically   terminated  spline
#           (BoundL and/or BoundR are ignored).
#     *  1, which corresponds to the first derivative boundary condition
#     *  2, which corresponds to the second derivative boundary condition
#     *  by default, BoundType=0 is used
# 
# PROBLEMS WITH PERIODIC BOUNDARY CONDITIONS:
# 
# Problems with periodic boundary conditions have Y[first_point]=Y[last_point].
# However, this subroutine doesn't require you to specify equal  values  for
# the first and last points - it automatically forces them  to  be  equal by
# copying  Y[first_point]  (corresponds  to the leftmost,  minimal  X[])  to
# Y[last_point]. However it is recommended to pass consistent values of Y[],
# i.e. to make Y[first_point]=Y[last_point].
# 
#   -- ALGLIB PROJECT --
#      Copyright 03.09.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   d1, d2 = xalglib.spline1dgriddiff2cubic(x, y, n, boundltype, boundl, boundrtype, boundr)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   d1, d2 = xalglib.spline1dgriddiff2cubic(x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          boundltype: int
          boundl:     float
          boundrtype: int
          boundr:     float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  d1:         1D array/list of float
          d2:         1D array/list of float

</div></pre>
<a name='sub_spline1dgriddiffcubic'></a><h3 class=pageheader><code>spline1dgriddiffcubic</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function solves following problem: given table y[] of function values
# at nodes x[], it calculates and returns table of function derivatives  d[]
# (calculated at the same nodes x[]).
# 
# This function yields same result as Spline1DBuildCubic() call followed  by
# sequence of Spline1DDiff() calls, but it  can  be  several  times  faster,
# whilst still having the same O(N*logN) running time.
# 
# When called for ordered X[], this function has O(N) running  time  instead
# of O(N*logN).
# 
# INPUT PARAMETERS:
#     X           -   spline nodes
#     Y           -   function values
# 
# OPTIONAL PARAMETERS:
#     N           -   points count:
#                     * N&gt;=2
#                     * if given, only first N points are used
#                     * if not given, automatically detected from X/Y sizes
#                       (len(X) must be equal to len(Y))
#     BoundLType  -   boundary condition type for the left boundary
#     BoundL      -   left boundary condition (first or second derivative,
#                     depending on the BoundLType)
#     BoundRType  -   boundary condition type for the right boundary
#     BoundR      -   right boundary condition (first or second derivative,
#                     depending on the BoundRType)
# 
# OUTPUT PARAMETERS:
#     D           -   derivative values at X[]
# 
# ORDER OF POINTS
# 
# Subroutine automatically sorts points, so caller may pass unsorted array.
# Derivative values are correctly reordered on return, so  D[I]  is  always
# equal to S'(X[I]) independently of points order.
# 
# SETTING BOUNDARY VALUES:
# 
# The BoundLType/BoundRType parameters can have the following values:
#     * -1, which corresonds to the periodic (cyclic) boundary conditions.
#           In this case:
#           * both BoundLType and BoundRType must be equal to -1.
#           * BoundL/BoundR are ignored
#           * Y[last] is ignored (it is assumed to be equal to Y[first]).
#     *  0, which  corresponds  to  the  parabolically   terminated  spline
#           (BoundL and/or BoundR are ignored).
#     *  1, which corresponds to the first derivative boundary condition
#     *  2, which corresponds to the second derivative boundary condition
#     *  by default, BoundType=0 is used
# 
# PROBLEMS WITH PERIODIC BOUNDARY CONDITIONS:
# 
# Problems with periodic boundary conditions have Y[first_point]=Y[last_point].
# However, this subroutine doesn't require you to specify equal  values  for
# the first and last points - it automatically forces them  to  be  equal by
# copying  Y[first_point]  (corresponds  to the leftmost,  minimal  X[])  to
# Y[last_point]. However it is recommended to pass consistent values of Y[],
# i.e. to make Y[first_point]=Y[last_point].
# 
#   -- ALGLIB PROJECT --
#      Copyright 03.09.2010 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   d = xalglib.spline1dgriddiffcubic(x, y, n, boundltype, boundl, boundrtype, boundr)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   d = xalglib.spline1dgriddiffcubic(x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          n:          int
          boundltype: int
          boundl:     float
          boundrtype: int
          boundr:     float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  d:          1D array/list of float

</div></pre>
<a name='sub_spline1dintegrate'></a><h3 class=pageheader><code>spline1dintegrate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine integrates the spline.
# 
# INPUT PARAMETERS:
#     C   -   spline interpolant.
#     X   -   right bound of the integration interval [a, x],
#             here 'a' denotes min(x[])
# Result:
#     integral(S(t)dt,a,x)
# 
#   -- ALGLIB PROJECT --
#      Copyright 23.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spline1dintegrate(c, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline1dinterpolant
          x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_spline1dlintransx'></a><h3 class=pageheader><code>spline1dlintransx</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine performs linear transformation of the spline argument.
# 
# INPUT PARAMETERS:
#     C   -   spline interpolant.
#     A, B-   transformation coefficients: x = A*t + B
# Result:
#     C   -   transformed spline
# 
#   -- ALGLIB PROJECT --
#      Copyright 30.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline1dlintransx(c, a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline1dinterpolant
          a:          float
          b:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline1dlintransy'></a><h3 class=pageheader><code>spline1dlintransy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine performs linear transformation of the spline.
# 
# INPUT PARAMETERS:
#     C   -   spline interpolant.
#     A, B-   transformation coefficients: S2(x) = A*S(x) + B
# Result:
#     C   -   transformed spline
# 
#   -- ALGLIB PROJECT --
#      Copyright 30.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline1dlintransy(c, a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline1dinterpolant
          a:          float
          b:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline1dunpack'></a><h3 class=pageheader><code>spline1dunpack</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine unpacks the spline into the coefficients table.
# 
# INPUT PARAMETERS:
#     C   -   spline interpolant.
#     X   -   point
# 
# OUTPUT PARAMETERS:
#     Tbl -   coefficients table, unpacked format, array[0..N-2, 0..5].
#             For I = 0...N-2:
#                 Tbl[I,0] = X[i]
#                 Tbl[I,1] = X[i+1]
#                 Tbl[I,2] = C0
#                 Tbl[I,3] = C1
#                 Tbl[I,4] = C2
#                 Tbl[I,5] = C3
#             On [x[i], x[i+1]] spline is equals to:
#                 S(x) = C0 + C1*t + C2*t^2 + C3*t^3
#                 t = x-x[i]
# 
# NOTE:
#     You  can rebuild spline with  Spline1DBuildHermite()  function,  which
#     accepts as inputs function values and derivatives at nodes, which  are
#     easy to calculate when you have coefficients.
# 
#   -- ALGLIB PROJECT --
#      Copyright 29.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   n, tbl = xalglib.spline1dunpack(c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline1dinterpolant
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  n:          int
          tbl:        2D array/list of float

</div></pre>
<a name=unit_spline2d></a><h2 class=pageheader><code>spline2d</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_spline2dbuildbicubic' class=toc>spline2dbuildbicubic</a><br>
<a href='#sub_spline2dbuildbicubicmissing' class=toc>spline2dbuildbicubicmissing</a><br>
<a href='#sub_spline2dbuildbicubicmissingbuf' class=toc>spline2dbuildbicubicmissingbuf</a><br>
<a href='#sub_spline2dbuildbicubicv' class=toc>spline2dbuildbicubicv</a><br>
<a href='#sub_spline2dbuildbicubicvbuf' class=toc>spline2dbuildbicubicvbuf</a><br>
<a href='#sub_spline2dbuildbilinear' class=toc>spline2dbuildbilinear</a><br>
<a href='#sub_spline2dbuildbilinearmissing' class=toc>spline2dbuildbilinearmissing</a><br>
<a href='#sub_spline2dbuildbilinearmissingbuf' class=toc>spline2dbuildbilinearmissingbuf</a><br>
<a href='#sub_spline2dbuildbilinearv' class=toc>spline2dbuildbilinearv</a><br>
<a href='#sub_spline2dbuildbilinearvbuf' class=toc>spline2dbuildbilinearvbuf</a><br>
<a href='#sub_spline2dbuildclampedv' class=toc>spline2dbuildclampedv</a><br>
<a href='#sub_spline2dbuildercreate' class=toc>spline2dbuildercreate</a><br>
<a href='#sub_spline2dbuildersetalgoblocklls' class=toc>spline2dbuildersetalgoblocklls</a><br>
<a href='#sub_spline2dbuildersetalgofastddm' class=toc>spline2dbuildersetalgofastddm</a><br>
<a href='#sub_spline2dbuildersetalgonaivells' class=toc>spline2dbuildersetalgonaivells</a><br>
<a href='#sub_spline2dbuildersetarea' class=toc>spline2dbuildersetarea</a><br>
<a href='#sub_spline2dbuildersetareaauto' class=toc>spline2dbuildersetareaauto</a><br>
<a href='#sub_spline2dbuildersetconstterm' class=toc>spline2dbuildersetconstterm</a><br>
<a href='#sub_spline2dbuildersetgrid' class=toc>spline2dbuildersetgrid</a><br>
<a href='#sub_spline2dbuildersetlinterm' class=toc>spline2dbuildersetlinterm</a><br>
<a href='#sub_spline2dbuildersetpoints' class=toc>spline2dbuildersetpoints</a><br>
<a href='#sub_spline2dbuildersetuserterm' class=toc>spline2dbuildersetuserterm</a><br>
<a href='#sub_spline2dbuildersetzeroterm' class=toc>spline2dbuildersetzeroterm</a><br>
<a href='#sub_spline2dbuildhermitev' class=toc>spline2dbuildhermitev</a><br>
<a href='#sub_spline2dcalc' class=toc>spline2dcalc</a><br>
<a href='#sub_spline2dcalcv' class=toc>spline2dcalcv</a><br>
<a href='#sub_spline2dcalcvbuf' class=toc>spline2dcalcvbuf</a><br>
<a href='#sub_spline2dcalcvi' class=toc>spline2dcalcvi</a><br>
<a href='#sub_spline2dcopy' class=toc>spline2dcopy</a><br>
<a href='#sub_spline2ddiff' class=toc>spline2ddiff</a><br>
<a href='#sub_spline2ddiff2' class=toc>spline2ddiff2</a><br>
<a href='#sub_spline2ddiff2vi' class=toc>spline2ddiff2vi</a><br>
<a href='#sub_spline2ddiffvi' class=toc>spline2ddiffvi</a><br>
<a href='#sub_spline2dfit' class=toc>spline2dfit</a><br>
<a href='#sub_spline2dlintransf' class=toc>spline2dlintransf</a><br>
<a href='#sub_spline2dlintransxy' class=toc>spline2dlintransxy</a><br>
<a href='#sub_spline2dresamplebicubic' class=toc>spline2dresamplebicubic</a><br>
<a href='#sub_spline2dresamplebilinear' class=toc>spline2dresamplebilinear</a><br>
<a href='#sub_spline2dunpack' class=toc>spline2dunpack</a><br>
<a href='#sub_spline2dunpackv' class=toc>spline2dunpackv</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_spline2dbuildbicubic'></a><h3 class=pageheader><code>spline2dbuildbicubic</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine was deprecated in ALGLIB 3.6.0
# 
# We recommend you to switch  to  Spline2DBuildBicubicV(),  which  is  more
# flexible and accepts its arguments in more convenient order.
# 
#   -- ALGLIB PROJECT --
#      Copyright 05.07.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline2dbuildbicubic(x, y, f, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          f:          2D array/list of float
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          class xalglib.spline2dinterpolant

</div></pre>
<a name='sub_spline2dbuildbicubicmissing'></a><h3 class=pageheader><code>spline2dbuildbicubicmissing</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  subroutine builds bicubic vector-valued  spline,  with  some  spline
# cells being missing due to missing nodes.
# 
# This function produces C2-continuous spline, i.e. the has smooth first and
# second derivatives both inside spline cells and at the boundaries.
# 
# When the node (i,j) is missing, it means that: a) we don't  have  function
# value at this point (elements of F[] are ignored), and  b)  we  don't need
# spline value at cells adjacent to the node (i,j), i.e. up to 4 spline cells
# will be dropped. An attempt to compute spline value at  the  missing  cell
# will return NAN.
# 
# It is important to  understand  that  this  subroutine  does  NOT  support
# interpolation on scattered grids. It allows us to drop some nodes, but  at
# the cost of making a &quot;hole in the spline&quot; around this point. If  you  want
# function  that   can   &quot;fill  the  gap&quot;,  use  RBF  or  another  scattered
# interpolation method.
# 
# The  intended  usage  for  this  subroutine  are  regularly  sampled,  but
# non-rectangular datasets.
# 
# Input parameters:
#     X   -   spline abscissas, array[0..N-1]
#     Y   -   spline ordinates, array[0..M-1]
#     F   -   function values, array[0..M*N*D-1]:
#             * first D elements store D values at (X[0],Y[0])
#             * next D elements store D values at (X[1],Y[0])
#             * general form - D function values at (X[i],Y[j]) are stored
#               at F[D*(J*N+I)...D*(J*N+I)+D-1].
#             * missing values are ignored
#     Missing array[M*N], Missing[J*N+I]=True means that corresponding entries
#             of F[] are missing nodes.
#     M,N -   grid size, M&gt;=2, N&gt;=2
#     D   -   vector dimension, D&gt;=1
# 
# Output parameters:
#     C   -   spline interpolant
# 
#   -- ALGLIB PROJECT --
#      Copyright 27.06.2022 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline2dbuildbicubicmissing(x, n, y, m, f, missing, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          y:          1D array/list of float
          m:          int
          f:          1D array/list of float
          missing:    1D array/list of bool
          d:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          class xalglib.spline2dinterpolant

</div></pre>
<a name='sub_spline2dbuildbicubicmissingbuf'></a><h3 class=pageheader><code>spline2dbuildbicubicmissingbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  subroutine builds bicubic vector-valued  spline,  with  some  spline
# cells being missing due to missing nodes.
# 
# Buffered version  of  Spline2DBuildBicubicMissing()  which  reuses  memory
# previously allocated in C as much as possible.
# 
#   -- ALGLIB PROJECT --
#      Copyright 27.06.2022 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dbuildbicubicmissingbuf(x, n, y, m, f, missing, d, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          y:          1D array/list of float
          m:          int
          f:          1D array/list of float
          missing:    1D array/list of bool
          d:          int
          c:          class xalglib.spline2dinterpolant
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dbuildbicubicv'></a><h3 class=pageheader><code>spline2dbuildbicubicv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds a bicubic vector-valued spline using  parabolically
# terminated end conditions.
# 
# This function produces a C2-continuous spline, i.e. the  spline has smooth
# first and second  derivatives  both  inside  spline  cells  and  at  their
# boundaries.
# 
# INPUT PARAMETERS:
#     X   -   spline abscissas, array[N]
#     N   -   N&gt;=2:
#             * if not given, automatically determined as len(X)
#             * if given, only leading N elements of X are used
#     Y   -   spline ordinates, array[M]
#     M   -   M&gt;=2:
#             * if not given, automatically determined as len(Y)
#             * if given, only leading M elements of Y are used
#     F   -   function values, array[M*N*D]:
#             * first D elements store D values at (X[0],Y[0])
#             * next D elements store D values at (X[1],Y[0])
#             * general form - D function values at (X[i],Y[j]) are stored
#               at F[D*(J*N+I)...D*(J*N+I)+D-1].
#     D   -   vector dimension, D&gt;=1:
#             * D=1 means scalar-valued bicubic spline
#             * D&gt;1 means vector-valued bicubic spline
# 
# OUTPUT PARAMETERS:
#     C   -   spline interpolant
# 
#   -- ALGLIB PROJECT --
#      Copyright 2012-2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline2dbuildbicubicv(x, n, y, m, f, d)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline2dbuildbicubicv(x, y, f, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          y:          1D array/list of float
          m:          int
          f:          1D array/list of float
          d:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          class xalglib.spline2dinterpolant

</div></pre>
<a name='sub_spline2dbuildbicubicvbuf'></a><h3 class=pageheader><code>spline2dbuildbicubicvbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds bicubic vector-valued spline.
# 
# Buffered version of Spline2DBuildBicubicV() which reuses memory previously
# allocated in C as much as possible.
# 
#   -- ALGLIB PROJECT --
#      Copyright 16.04.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dbuildbicubicvbuf(x, n, y, m, f, d, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          y:          1D array/list of float
          m:          int
          f:          1D array/list of float
          d:          int
          c:          class xalglib.spline2dinterpolant
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dbuildbilinear'></a><h3 class=pageheader><code>spline2dbuildbilinear</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine was deprecated in ALGLIB 3.6.0
# 
# We recommend you to switch  to  Spline2DBuildBilinearV(),  which  is  more
# flexible and accepts its arguments in more convenient order.
# 
#   -- ALGLIB PROJECT --
#      Copyright 05.07.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline2dbuildbilinear(x, y, f, m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          y:          1D array/list of float
          f:          2D array/list of float
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          class xalglib.spline2dinterpolant

</div></pre>
<a name='sub_spline2dbuildbilinearmissing'></a><h3 class=pageheader><code>spline2dbuildbilinearmissing</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds bilinear vector-valued  spline,  with  some  spline
# cells being missing due to missing nodes.
# 
# This function produces C0-continuous spline, i.e.  the  spline  itself  is
# continuous, however its first and second  derivatives have discontinuities
# at the spline cell boundaries.
# 
# When the node (i,j) is missing, it means that: a) we don't  have  function
# value at this point (elements of F[] are ignored), and  b)  we  don't need
# spline value at cells adjacent to the node (i,j), i.e. up to 4 spline cells
# will be dropped. An attempt to compute spline value at  the  missing  cell
# will return NAN.
# 
# It is important to  understand  that  this  subroutine  does  NOT  support
# interpolation on scattered grids. It allows us to drop some nodes, but  at
# the cost of making a &quot;hole in the spline&quot; around this point. If  you  want
# function  that   can   &quot;fill  the  gap&quot;,  use  RBF  or  another  scattered
# interpolation method.
# 
# The  intended  usage  for  this  subroutine  are  regularly  sampled,  but
# non-rectangular datasets.
# 
# Input parameters:
#     X   -   spline abscissas, array[0..N-1]
#     Y   -   spline ordinates, array[0..M-1]
#     F   -   function values, array[0..M*N*D-1]:
#             * first D elements store D values at (X[0],Y[0])
#             * next D elements store D values at (X[1],Y[0])
#             * general form - D function values at (X[i],Y[j]) are stored
#               at F[D*(J*N+I)...D*(J*N+I)+D-1].
#             * missing values are ignored
#     Missing array[M*N], Missing[J*N+I]=True means that corresponding entries
#             of F[] are missing nodes.
#     M,N -   grid size, M&gt;=2, N&gt;=2
#     D   -   vector dimension, D&gt;=1
# 
# Output parameters:
#     C   -   spline interpolant
# 
#   -- ALGLIB PROJECT --
#      Copyright 27.06.2022 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline2dbuildbilinearmissing(x, n, y, m, f, missing, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          y:          1D array/list of float
          m:          int
          f:          1D array/list of float
          missing:    1D array/list of bool
          d:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          class xalglib.spline2dinterpolant

</div></pre>
<a name='sub_spline2dbuildbilinearmissingbuf'></a><h3 class=pageheader><code>spline2dbuildbilinearmissingbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds bilinear vector-valued  spline,  with  some  spline
# cells being missing due to missing nodes.
# 
# Buffered version of  Spline2DBuildBilinearMissing()  which  reuses  memory
# previously allocated in C as much as possible.
# 
#   -- ALGLIB PROJECT --
#      Copyright 27.06.2022 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dbuildbilinearmissingbuf(x, n, y, m, f, missing, d, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          y:          1D array/list of float
          m:          int
          f:          1D array/list of float
          missing:    1D array/list of bool
          d:          int
          c:          class xalglib.spline2dinterpolant
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dbuildbilinearv'></a><h3 class=pageheader><code>spline2dbuildbilinearv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds bilinear vector-valued spline.
# 
# This function produces C0-continuous spline, i.e.  the  spline  itself  is
# continuous, however its first and second  derivatives have discontinuities
# at the spline cell boundaries.
# 
# Input parameters:
#     X   -   spline abscissas, array[0..N-1]
#     Y   -   spline ordinates, array[0..M-1]
#     F   -   function values, array[0..M*N*D-1]:
#             * first D elements store D values at (X[0],Y[0])
#             * next D elements store D values at (X[1],Y[0])
#             * general form - D function values at (X[i],Y[j]) are stored
#               at F[D*(J*N+I)...D*(J*N+I)+D-1].
#     M,N -   grid size, M&gt;=2, N&gt;=2
#     D   -   vector dimension, D&gt;=1
# 
# Output parameters:
#     C   -   spline interpolant
# 
#   -- ALGLIB PROJECT --
#      Copyright 16.04.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline2dbuildbilinearv(x, n, y, m, f, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          y:          1D array/list of float
          m:          int
          f:          1D array/list of float
          d:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          class xalglib.spline2dinterpolant

</div></pre>
<a name='sub_spline2dbuildbilinearvbuf'></a><h3 class=pageheader><code>spline2dbuildbilinearvbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds bilinear vector-valued spline.
# 
# Buffered version of Spline2DBuildBilinearV() which reuses memory previously
# allocated in C as much as possible.
# 
#   -- ALGLIB PROJECT --
#      Copyright 16.04.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dbuildbilinearvbuf(x, n, y, m, f, d, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          y:          1D array/list of float
          m:          int
          f:          1D array/list of float
          d:          int
          c:          class xalglib.spline2dinterpolant
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dbuildclampedv'></a><h3 class=pageheader><code>spline2dbuildclampedv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine  builds  a  bicubic  vector-valued  spline  using  clamped
# boundary conditions:
# * spline values at the grid nodes are specified
# * boundary conditions for  first,  second  derivatives  or  for  parabolic
#   termination at four boundaries (bottom  y=min(Y[]), top y=max(Y[]), left
#   x=min(X[]), right x=max(X[])) are specified
# * mixed derivatives at corners are specified
# * it is possible to  have  different  boundary  conditions  for  different
#   boundaries (first derivatives along  one  boundary,  second  derivatives
#   along other one, parabolic termination along the rest and so on)
# * it is possible to have either a scalar (D=1) or a vector-valued spline
# 
# This function produces a C2-continuous spline, i.e. the  spline has smooth
# first and second  derivatives  both  inside  spline  cells  and  at  their
# boundaries.
# 
# INPUT PARAMETERS:
#     X           -   spline  abscissas,  array[N].  Can  be  unsorted,  the
#                     function will sort it together with boundary conditions
#                     and F[] array (the same set of  permutations  will  be
#                     applied to X[] and F[]).
#     N           -   N&gt;=2:
#                     * if not given, automatically determined as len(X)
#                     * if given, only leading N elements of X are used
#     Y           -   spline ordinates, array[M].  Can   be   unsorted,  the
#                     function will sort it together with boundary conditions
#                     and F[] array (the same set of  permutations  will  be
#                     applied to X[] and F[]).
#     M           -   M&gt;=2:
#                     * if not given, automatically determined as len(Y)
#                     * if given, only leading M elements of Y are used
#     BndBtm      -   array[D*N], boundary conditions at the bottom boundary
#                     of the interpolation area  (corresponds to y=min(Y[]):
#                     * if  BndTypeBtm=0,  the  spline  has   a   'parabolic
#                       termination' boundary condition across that specific
#                       boundary. In this case BndBtm is not even referenced
#                       by the function and can be unallocated.
#                     * otherwise contains derivatives with respect to X
#                     * if BndTypeBtm=1, first derivatives are given
#                     * if BndTypeBtm=2, second derivatives are given
#                     * first D entries store derivatives at x=X[0], y=minY,
#                       subsequent D entries store  derivatives  at  x=X[1],
#                       y=minY and so on
#     BndTop      -   array[D*N],  boundary  conditions  at the top boundary
#                     of the interpolation area  (corresponds to y=max(Y[]):
#                     * if  BndTypeTop=0,  the  spline  has   a   'parabolic
#                       termination' boundary condition across that specific
#                       boundary. In this case BndTop is not even referenced
#                       by the function and can be unallocated.
#                     * otherwise contains derivatives with respect to X
#                     * if BndTypeTop=1, first derivatives are given
#                     * if BndTypeTop=2, second derivatives are given
#                     * first D entries store derivatives at x=X[0], y=maxY,
#                       subsequent D entries store  derivatives  at  x=X[1],
#                       y=maxY and so on
#     BndLft      -   array[D*M], boundary conditions at  the  left boundary
#                     of the  interpolation area (corresponds to x=min(X[]):
#                     * if  BndTypeLft=0,  the  spline  has   a   'parabolic
#                       termination' boundary condition across that specific
#                       boundary. In this case BndLft is not even referenced
#                       by the function and can be unallocated.
#                     * otherwise contains derivatives with respect to Y
#                     * if BndTypeLft=1, first derivatives are given
#                     * if BndTypeLft=2, second derivatives are given
#                     * first D entries store derivatives at x=minX, y=Y[0],
#                       subsequent D entries store  derivatives  at  x=minX,
#                       y=Y[1] and so on
#     BndRgt      -   array[D*M], boundary conditions at  the right boundary
#                     of the  interpolation area (corresponds to x=max(X[]):
#                     * if  BndTypeRgt=0,  the  spline  has   a   'parabolic
#                       termination' boundary condition across that specific
#                       boundary. In this case BndRgt is not even referenced
#                       by the function and can be unallocated.
#                     * otherwise contains derivatives with respect to Y
#                     * if BndTypeRgt=1, first derivatives are given
#                     * if BndTypeRgt=2, second derivatives are given
#                     * first D entries store derivatives at x=maxX, y=Y[0],
#                       subsequent D entries store  derivatives  at  x=maxX,
#                       y=Y[1] and so on
#     MixedD      -   array[D*4], mixed derivatives  at  4  corners  of  the
#                     interpolation area:
#                     * derivative order depends on the order  of   boundary
#                       conditions (bottom/top and left/right)  intersecting
#                       at that corner:
#                       **  for BndType(Btm|Top)=BndType(Lft|Rgt)=1 user has
#                           to provide d2S/dXdY
#                       **  for BndType(Btm|Top)=BndType(Lft|Rgt)=2 user has
#                           to provide d4S/(dX^2*dY^2)
#                       **  for BndType(Btm|Top)=1, BndType(Lft|Rgt)=2  user
#                           has to provide d3S/(dX^2*dY)
#                       **  for BndType(Btm|Top)=2, BndType(Lft|Rgt)=1  user
#                           has to provide d3S/(dX*dY^2)
#                       **  if one of the intersecting bounds has 'parabolic
#                           termination'  condition,   this  specific  mixed
#                           derivative is not used
#                     * first D entries store derivatives at the bottom left
#                       corner x=min(X[]), y=min(Y[])
#                     * subsequent D entries store derivatives at the bottom
#                       right corner x=max(X[]), y=min(Y[])
#                     * subsequent D entries store derivatives  at  the  top
#                       left corner  x=min(X[]), y=max(Y[])
#                     * subsequent D entries store derivatives  at  the  top
#                       right corner x=max(X[]), y=max(Y[])
#                     * if all bounds have 'parabolic termination' condition,
#                       MixedD[]  is  not  referenced  at  all  and  can  be
#                       unallocated.
#     F           -   function values, array[M*N*D]:
#                     * first D elements store D values at (X[0],Y[0])
#                     * next D elements store D values at (X[1],Y[0])
#                     * general form - D function values at (X[i],Y[j])  are
#                       stored at F[D*(J*N+I)...D*(J*N+I)+D-1].
#     D           -   vector dimension, D&gt;=1:
#                     * D=1 means scalar-valued bicubic spline
#                     * D&gt;1 means vector-valued bicubic spline
# 
# OUTPUT PARAMETERS:
#     C   -   spline interpolant
# 
#   -- ALGLIB PROJECT --
#      Copyright 2012-2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline2dbuildclampedv(x, n, y, m, bndbtm, bndtypebtm, bndtop, bndtypetop, bndlft, bndtypelft, bndrgt, bndtypergt, mixedd, f, d)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline2dbuildclampedv(x, y, bndbtm, bndtypebtm, bndtop, bndtypetop, bndlft, bndtypelft, bndrgt, bndtypergt, mixedd, f, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          y:          1D array/list of float
          m:          int
          bndbtm:     1D array/list of float
          bndtypebtm: int
          bndtop:     1D array/list of float
          bndtypetop: int
          bndlft:     1D array/list of float
          bndtypelft: int
          bndrgt:     1D array/list of float
          bndtypergt: int
          mixedd:     1D array/list of float
          f:          1D array/list of float
          d:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          class xalglib.spline2dinterpolant

</div></pre>
<a name='sub_spline2dbuildercreate'></a><h3 class=pageheader><code>spline2dbuildercreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine creates least squares solver used to  fit  2D  splines  to
# irregularly sampled (scattered) data.
# 
# Solver object is used to perform spline fits as follows:
# * solver object is created with spline2dbuildercreate() function
# * dataset is added with spline2dbuildersetpoints() function
# * fit area is chosen:
#   * spline2dbuildersetarea()     - for user-defined area
#   * spline2dbuildersetareaauto() - for automatically chosen area
# * number of grid nodes is chosen with spline2dbuildersetgrid()
# * prior term is chosen with one of the following functions:
#   * spline2dbuildersetlinterm()   to set linear prior
#   * spline2dbuildersetconstterm() to set constant prior
#   * spline2dbuildersetzeroterm()  to set zero prior
#   * spline2dbuildersetuserterm()  to set user-defined constant prior
# * solver algorithm is chosen with either:
#   * spline2dbuildersetalgoblocklls() - BlockLLS algorithm, medium-scale problems
#   * spline2dbuildersetalgofastddm()  - FastDDM algorithm, large-scale problems
# * finally, fitting itself is performed with spline2dfit() function.
# 
# Most of the steps above can be omitted,  solver  is  configured with  good
# defaults. The minimum is to call:
# * spline2dbuildercreate() to create solver object
# * spline2dbuildersetpoints() to specify dataset
# * spline2dbuildersetgrid() to tell how many nodes you need
# * spline2dfit() to perform fit
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     D   -   positive number, number of Y-components: D=1 for simple scalar
#             fit, D&gt;1 for vector-valued spline fitting.
# 
# OUTPUT PARAMETERS:
#     S   -   solver object
# 
#   -- ALGLIB PROJECT --
#      Copyright 29.01.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   state = xalglib.spline2dbuildercreate(d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     d:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  state:      class xalglib.spline2dbuilder

</div></pre>
<a name='sub_spline2dbuildersetalgoblocklls'></a><h3 class=pageheader><code>spline2dbuildersetalgoblocklls</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  allows  you to choose least squares solver used to perform
# fitting. This function sets solver algorithm to &quot;BlockLLS&quot;, which performs
# least squares fitting  with  fast  sparse  direct  solver,  with  optional
# nonsmoothness penalty being applied.
# 
# This solver produces C2-continuous spline.
# 
# Nonlinearity penalty has the following form:
# 
#                           [                                            ]
#     P() ~ Lambda* integral[ (d2S/dx2)^2 + 2*(d2S/dxdy)^2 + (d2S/dy2)^2 ]dxdy
#                           [                                            ]
# 
# here integral is calculated over entire grid, and &quot;~&quot; means &quot;proportional&quot;
# because integral is normalized after calcilation. Extremely  large  values
# of Lambda result in linear fit being performed.
# 
# NOTE: this algorithm is the most robust and controllable one,  but  it  is
#       limited by 512x512 grids and (say) up to 1.000.000 points.  However,
#       ALGLIB has one more  spline  solver:  FastDDM  algorithm,  which  is
#       intended for really large-scale problems (in 10M-100M range). FastDDM
#       algorithm also has better parallelism properties.
# 
# More information on BlockLLS solver:
# * memory requirements: ~[32*K^3+256*NPoints]  bytes  for  KxK  grid   with
#   NPoints-sized dataset
# * serial running time: O(K^4+NPoints)
# * parallelism potential: limited. You may get some sublinear gain when
#   working with large grids (K's in 256..512 range)
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     S       -   spline 2D builder object
#     LambdaNS-   non-negative value:
#                 * positive value means that some smoothing is applied
#                 * zero value means  that  no  smoothing  is  applied,  and
#                   corresponding entries of design matrix  are  numerically
#                   zero and dropped from consideration.
# 
#   -- ALGLIB --
#      Copyright 05.02.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dbuildersetalgoblocklls(state, lambdans)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.spline2dbuilder
          lambdans:   float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dbuildersetalgofastddm'></a><h3 class=pageheader><code>spline2dbuildersetalgofastddm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  allows  you to choose least squares solver used to perform
# fitting. This function sets solver algorithm to &quot;FastDDM&quot;, which  performs
# fast parallel fitting by splitting problem into smaller chunks and merging
# results together.
# 
# Unlike BlockLLS, this solver produces merely C1 continuous models  because
# domain decomposition part disrupts C2 continuity.
# 
# This solver is optimized for large-scale problems, starting  from  256x256
# grids, and up to 10000x10000 grids. Of course, it will  work  for  smaller
# grids too.
# 
# More detailed description of the algorithm is given below:
# * algorithm generates hierarchy  of  nested  grids,  ranging  from  ~16x16
#   (topmost &quot;layer&quot; of the model) to ~KX*KY one (final layer). Upper layers
#   model global behavior of the function, lower layers are  used  to  model
#   fine details. Moving from layer to layer doubles grid density.
# * fitting  is  started  from  topmost  layer, subsequent layers are fitted
#   using residuals from previous ones.
# * user may choose to skip generation of upper layers and generate  only  a
#   few bottom ones, which  will  result  in  much  better  performance  and
#   parallelization efficiency, at the cost of algorithm inability to &quot;patch&quot;
#   large holes in the dataset.
# * every layer is regularized using progressively increasing regularization
#   coefficient; thus, increasing  LambdaV  penalizes  fine  details  first,
#   leaving lower frequencies almost intact for a while.
# * after fitting is done, all layers are merged together into  one  bicubic
#   spline
# 
# IMPORTANT: regularization coefficient used by  this  solver  is  different
#            from the one used by  BlockLLS.  Latter  utilizes  nonlinearity
#            penalty,  which  is  global  in  nature  (large  regularization
#            results in global linear trend being  extracted);  this  solver
#            uses another, localized form of penalty, which is suitable  for
#            parallel processing.
# 
# Notes on memory and performance:
# * memory requirements: most memory is consumed  during  modeling   of  the
#   higher layers; ~[512*NPoints] bytes is required for a  model  with  full
#   hierarchy of grids being generated. However, if you skip a  few  topmost
#   layers, you will get nearly constant (wrt. points count and  grid  size)
#   memory consumption.
# * serial running time: O(K*K)+O(NPoints) for a KxK grid
# * parallelism potential: good. You may get  nearly  linear  speed-up  when
#   performing fitting with just a few layers. Adding more layers results in
#   model becoming more global, which somewhat  reduces  efficiency  of  the
#   parallel code.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     S       -   spline 2D builder object
#     NLayers -   number of layers in the model:
#                 * NLayers&gt;=1 means that up  to  chosen  number  of  bottom
#                   layers is fitted
#                 * NLayers=0 means that maximum number of layers is  chosen
#                   (according to current grid size)
#                 * NLayers&lt;=-1 means that up to |NLayers| topmost layers is
#                   skipped
#                 Recommendations:
#                 * good &quot;default&quot; value is 2 layers
#                 * you may need  more  layers,  if  your  dataset  is  very
#                   irregular and you want to &quot;patch&quot;  large  holes.  For  a
#                   grid step H (equal to AreaWidth/GridSize) you may expect
#                   that last layer reproduces variations at distance H (and
#                   can patch holes that wide); that higher  layers  operate
#                   at distances 2*H, 4*H, 8*H and so on.
#                 * good value for &quot;bullletproof&quot; mode is  NLayers=0,  which
#                   results in complete hierarchy of layers being generated.
#     LambdaV -   regularization coefficient, chosen in such a way  that  it
#                 penalizes bottom layers (fine details) first.
#                 LambdaV&gt;=0, zero value means that no penalty is applied.
# 
#   -- ALGLIB --
#      Copyright 05.02.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dbuildersetalgofastddm(state, nlayers, lambdav)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.spline2dbuilder
          nlayers:    int
          lambdav:    float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dbuildersetalgonaivells'></a><h3 class=pageheader><code>spline2dbuildersetalgonaivells</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  allows  you to choose least squares solver used to perform
# fitting. This function sets solver algorithm to &quot;NaiveLLS&quot;.
# 
# IMPORTANT: NaiveLLS is NOT intended to be used in  real  life  code!  This
#            algorithm solves problem by generated dense (K^2)x(K^2+NPoints)
#            matrix and solves  linear  least  squares  problem  with  dense
#            solver.
# 
#            It is here just  to  test  BlockLLS  against  reference  solver
#            (and maybe for someone trying to compare well optimized  solver
#            against straightforward approach to the LLS problem).
# 
# More information on naive LLS solver:
# * memory requirements: ~[8*K^4+256*NPoints] bytes for KxK grid.
# * serial running time: O(K^6+NPoints) for KxK grid
# * when compared with BlockLLS,  NaiveLLS  has ~K  larger memory demand and
#   ~K^2  larger running time.
# 
# INPUT PARAMETERS:
#     S       -   spline 2D builder object
#     LambdaNS-   nonsmoothness penalty
# 
#   -- ALGLIB --
#      Copyright 05.02.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dbuildersetalgonaivells(state, lambdans)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.spline2dbuilder
          lambdans:   float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dbuildersetarea'></a><h3 class=pageheader><code>spline2dbuildersetarea</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  sets  area  where  2D  spline  interpolant  is   built  to
# user-defined one: [XA,XB]*[YA,YB]
# 
# INPUT PARAMETERS:
#     S       -   spline 2D builder object
#     XA,XB   -   spatial extent in the first (X) dimension, XA&lt;XB
#     YA,YB   -   spatial extent in the second (Y) dimension, YA&lt;YB
# 
#   -- ALGLIB --
#      Copyright 05.02.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dbuildersetarea(state, xa, xb, ya, yb)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.spline2dbuilder
          xa:         float
          xb:         float
          ya:         float
          yb:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dbuildersetareaauto'></a><h3 class=pageheader><code>spline2dbuildersetareaauto</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets area where 2D spline interpolant is built. &quot;Auto&quot; means
# that area extent is determined automatically from dataset extent.
# 
# INPUT PARAMETERS:
#     S       -   spline 2D builder object
# 
#   -- ALGLIB --
#      Copyright 05.02.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dbuildersetareaauto(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.spline2dbuilder
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dbuildersetconstterm'></a><h3 class=pageheader><code>spline2dbuildersetconstterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets constant prior term (model is a sum of  bicubic  spline
# and global prior, which can be linear, constant, user-defined  constant or
# zero).
# 
# Constant prior term is determined by least squares fitting.
# 
# INPUT PARAMETERS:
#     S       -   spline builder
# 
#   -- ALGLIB --
#      Copyright 01.02.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dbuildersetconstterm(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.spline2dbuilder
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dbuildersetgrid'></a><h3 class=pageheader><code>spline2dbuildersetgrid</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  sets  nodes  count  for  2D spline interpolant. Fitting is
# performed on area defined with one of the &quot;setarea&quot;  functions;  this  one
# sets number of nodes placed upon the fitting area.
# 
# INPUT PARAMETERS:
#     S       -   spline 2D builder object
#     KX      -   nodes count for the first (X) dimension; fitting  interval
#                 [XA,XB] is separated into KX-1 subintervals, with KX nodes
#                 created at the boundaries.
#     KY      -   nodes count for the first (Y) dimension; fitting  interval
#                 [YA,YB] is separated into KY-1 subintervals, with KY nodes
#                 created at the boundaries.
# 
# NOTE: at  least  4  nodes  is  created in each dimension, so KX and KY are
#       silently increased if needed.
# 
#   -- ALGLIB --
#      Copyright 05.02.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dbuildersetgrid(state, kx, ky)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.spline2dbuilder
          kx:         int
          ky:         int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dbuildersetlinterm'></a><h3 class=pageheader><code>spline2dbuildersetlinterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets linear prior term (model is a sum of bicubic spline and
# global  prior,  which  can  be  linear, constant, user-defined constant or
# zero).
# 
# Linear prior term is determined by least squares fitting.
# 
# INPUT PARAMETERS:
#     S       -   spline builder
# 
#   -- ALGLIB --
#      Copyright 01.02.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dbuildersetlinterm(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.spline2dbuilder
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dbuildersetpoints'></a><h3 class=pageheader><code>spline2dbuildersetpoints</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function adds dataset to the builder object.
# 
# This function overrides results of the previous calls, i.e. multiple calls
# of this function will result in only the last set being added.
# 
# INPUT PARAMETERS:
#     S       -   spline 2D builder object
#     XY      -   points, array[N,2+D]. One  row  corresponds to  one  point
#                 in the dataset. First 2  elements  are  coordinates,  next
#                 D  elements are function values. Array may  be larger than
#                 specified, in  this  case  only leading [N,NX+NY] elements
#                 will be used.
#     N       -   number of points in the dataset
# 
#   -- ALGLIB --
#      Copyright 05.02.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dbuildersetpoints(state, xy, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.spline2dbuilder
          xy:         2D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dbuildersetuserterm'></a><h3 class=pageheader><code>spline2dbuildersetuserterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets constant prior term (model is a sum of  bicubic  spline
# and global prior, which can be linear, constant, user-defined  constant or
# zero).
# 
# Constant prior term is determined by least squares fitting.
# 
# INPUT PARAMETERS:
#     S       -   spline builder
#     V       -   value for user-defined prior
# 
#   -- ALGLIB --
#      Copyright 01.02.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dbuildersetuserterm(state, v)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.spline2dbuilder
          v:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dbuildersetzeroterm'></a><h3 class=pageheader><code>spline2dbuildersetzeroterm</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets zero prior term (model is a sum of bicubic  spline  and
# global  prior,  which  can  be  linear, constant, user-defined constant or
# zero).
# 
# INPUT PARAMETERS:
#     S       -   spline builder
# 
#   -- ALGLIB --
#      Copyright 01.02.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dbuildersetzeroterm(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.spline2dbuilder
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dbuildhermitev'></a><h3 class=pageheader><code>spline2dbuildhermitev</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds a Hermite bicubic vector-valued spline.
# 
# This function produces merely C1-continuous spline, i.e. the   spline  has
# smooth first derivatives.
# 
# INPUT PARAMETERS:
#     X   -   spline abscissas, array[N]
#     N   -   N&gt;=2:
#             * if not given, automatically determined as len(X)
#             * if given, only leading N elements of X are used
#     Y   -   spline ordinates, array[M]
#     M   -   M&gt;=2:
#             * if not given, automatically determined as len(Y)
#             * if given, only leading M elements of Y are used
#     F   -   function values, array[M*N*D]:
#             * first D elements store D values at (X[0],Y[0])
#             * next D elements store D values at (X[1],Y[0])
#             * general form - D function values at (X[i],Y[j]) are stored
#               at F[D*(J*N+I)...D*(J*N+I)+D-1].
#     dFdX-   spline derivatives with respect to X, array[M*N*D]:
#             * first D elements store D values at (X[0],Y[0])
#             * next D elements store D values at (X[1],Y[0])
#             * general form - D function values at (X[i],Y[j]) are stored
#               at F[D*(J*N+I)...D*(J*N+I)+D-1].
#     dFdY-   spline derivatives with respect to Y, array[M*N*D]:
#             * first D elements store D values at (X[0],Y[0])
#             * next D elements store D values at (X[1],Y[0])
#             * general form - D function values at (X[i],Y[j]) are stored
#               at F[D*(J*N+I)...D*(J*N+I)+D-1].
#     d2FdXdY-mixed derivatives with respect to X and Y, array[M*N*D]:
#             * first D elements store D values at (X[0],Y[0])
#             * next D elements store D values at (X[1],Y[0])
#             * general form - D function values at (X[i],Y[j]) are stored
#               at F[D*(J*N+I)...D*(J*N+I)+D-1].
#     D   -   vector dimension, D&gt;=1:
#             * D=1 means scalar-valued bicubic spline
#             * D&gt;1 means vector-valued bicubic spline
# 
# OUTPUT PARAMETERS:
#     C   -   spline interpolant
# 
#   -- ALGLIB PROJECT --
#      Copyright 2012-2023 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline2dbuildhermitev(x, n, y, m, f, dfdx, dfdy, d2fdxdy, d)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline2dbuildhermitev(x, y, f, dfdx, dfdy, d2fdxdy, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          y:          1D array/list of float
          m:          int
          f:          1D array/list of float
          dfdx:       1D array/list of float
          dfdy:       1D array/list of float
          d2fdxdy:    1D array/list of float
          d:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          class xalglib.spline2dinterpolant

</div></pre>
<a name='sub_spline2dcalc'></a><h3 class=pageheader><code>spline2dcalc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates the value of the bilinear or bicubic spline  at
# the given point X.
# 
# Input parameters:
#     C   -   2D spline object.
#             Built by spline2dbuildbilinearv or spline2dbuildbicubicv.
#     X, Y-   point
# 
# Result:
#     S(x,y)
# 
#   -- ALGLIB PROJECT --
#      Copyright 05.07.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spline2dcalc(c, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline2dinterpolant
          x:          float
          y:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_spline2dcalcv'></a><h3 class=pageheader><code>spline2dcalcv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates bilinear or bicubic vector-valued spline at the
# given point (X,Y).
# 
# INPUT PARAMETERS:
#     C   -   spline interpolant.
#     X, Y-   point
# 
# OUTPUT PARAMETERS:
#     F   -   array[D] which stores function values.  F is out-parameter and
#             it  is  reallocated  after  call to this function. In case you
#             want  to    reuse  previously  allocated  F,   you   may   use
#             Spline2DCalcVBuf(),  which  reallocates  F only when it is too
#             small.
# 
#   -- ALGLIB PROJECT --
#      Copyright 16.04.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   f = xalglib.spline2dcalcv(c, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline2dinterpolant
          x:          float
          y:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  f:          1D array/list of float

</div></pre>
<a name='sub_spline2dcalcvbuf'></a><h3 class=pageheader><code>spline2dcalcvbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates bilinear or bicubic vector-valued spline at the
# given point (X,Y).
# 
# If you need just some specific component of vector-valued spline, you  can
# use spline2dcalcvi() function.
# 
# INPUT PARAMETERS:
#     C   -   spline interpolant.
#     X, Y-   point
#     F   -   output buffer, possibly preallocated array. In case array size
#             is large enough to store result, it is not reallocated.  Array
#             which is too short will be reallocated
# 
# OUTPUT PARAMETERS:
#     F   -   array[D] (or larger) which stores function values
# 
#   -- ALGLIB PROJECT --
#      Copyright 01.02.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   f = xalglib.spline2dcalcvbuf(c, x, y, f)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline2dinterpolant
          x:          float
          y:          float
          f:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  f:          1D array/list of float

</div></pre>
<a name='sub_spline2dcalcvi'></a><h3 class=pageheader><code>spline2dcalcvi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates specific component of vector-valued bilinear or
# bicubic spline at the given point (X,Y).
# 
# INPUT PARAMETERS:
#     C   -   spline interpolant.
#     X, Y-   point
#     I   -   component index, in [0,D). An exception is generated for out
#             of range values.
# 
# RESULT:
#     value of I-th component
# 
#   -- ALGLIB PROJECT --
#      Copyright 01.02.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spline2dcalcvi(c, x, y, i)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline2dinterpolant
          x:          float
          y:          float
          i:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_spline2dcopy'></a><h3 class=pageheader><code>spline2dcopy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine makes the copy of the spline model.
# 
# Input parameters:
#     C   -   spline interpolant
# 
# Output parameters:
#     CC  -   spline copy
# 
#   -- ALGLIB PROJECT --
#      Copyright 29.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   cc = xalglib.spline2dcopy(c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline2dinterpolant
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  cc:         class xalglib.spline2dinterpolant

</div></pre>
<a name='sub_spline2ddiff'></a><h3 class=pageheader><code>spline2ddiff</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates the value of a bilinear or bicubic spline   and
# its derivatives.
# 
# Use Spline2DDiff2() if you need second derivatives Sxx and Syy.
# 
# Input parameters:
#     C   -   spline interpolant.
#     X, Y-   point
# 
# Output parameters:
#     F   -   S(x,y)
#     FX  -   dS(x,y)/dX
#     FY  -   dS(x,y)/dY
# 
#   -- ALGLIB PROJECT --
#      Copyright 05.07.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   f, fx, fy = xalglib.spline2ddiff(c, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline2dinterpolant
          x:          float
          y:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  f:          float
          fx:         float
          fy:         float

</div></pre>
<a name='sub_spline2ddiff2'></a><h3 class=pageheader><code>spline2ddiff2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates the value of a bilinear or bicubic spline   and
# its second derivatives.
# 
# Input parameters:
#     C   -   spline interpolant.
#     X, Y-   point
# 
# Output parameters:
#     F   -   S(x,y)
#     FX  -   dS(x,y)/dX
#     FY  -   dS(x,y)/dY
#     FXX -   d2S(x,y)/dXdX
#     FXY -   d2S(x,y)/dXdY
#     FYY -   d2S(x,y)/dYdY
# 
#   -- ALGLIB PROJECT --
#      Copyright 17.04.2023 by Bochkanov Sergey.
# 
#      The second derivatives code was contributed by  Horst  Greiner  under
#      public domain terms.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   f, fx, fy, fxx, fxy, fyy = xalglib.spline2ddiff2(c, x, y)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline2dinterpolant
          x:          float
          y:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  f:          float
          fx:         float
          fy:         float
          fxx:        float
          fxy:        float
          fyy:        float

</div></pre>
<a name='sub_spline2ddiff2vi'></a><h3 class=pageheader><code>spline2ddiff2vi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates the value and the derivatives of I-th component
# of a vector-valued bilinear or bicubic spline.
# 
# Input parameters:
#     C   -   spline interpolant.
#     X, Y-   point
#     I   -   component index, in [0,D)
# 
# Output parameters:
#     F   -   S(x,y)
#     FX  -   dS(x,y)/dX
#     FY  -   dS(x,y)/dY
#     FXX -   d2S(x,y)/dXdX
#     FXY -   d2S(x,y)/dXdY
#     FYY -   d2S(x,y)/dYdY
# 
#   -- ALGLIB PROJECT --
#      Copyright 17.04.2023 by Bochkanov Sergey.
# 
#      The second derivatives code was contributed by  Horst  Greiner  under
#      public domain terms.
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   f, fx, fy, fxx, fxy, fyy = xalglib.spline2ddiff2vi(c, x, y, i)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline2dinterpolant
          x:          float
          y:          float
          i:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  f:          float
          fx:         float
          fy:         float
          fxx:        float
          fxy:        float
          fyy:        float

</div></pre>
<a name='sub_spline2ddiffvi'></a><h3 class=pageheader><code>spline2ddiffvi</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates the value and the derivatives of I-th component
# of a  vector-valued bilinear or bicubic spline.
# 
# Input parameters:
#     C   -   spline interpolant.
#     X, Y-   point
#     I   -   component index, in [0,D)
# 
# Output parameters:
#     F   -   S(x,y)
#     FX  -   dS(x,y)/dX
#     FY  -   dS(x,y)/dY
# 
#   -- ALGLIB PROJECT --
#      Copyright 05.07.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   f, fx, fy = xalglib.spline2ddiffvi(c, x, y, i)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline2dinterpolant
          x:          float
          y:          float
          i:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  f:          float
          fx:         float
          fy:         float

</div></pre>
<a name='sub_spline2dfit'></a><h3 class=pageheader><code>spline2dfit</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function fits bicubic spline to current dataset, using current  area/
# grid and current LLS solver.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# INPUT PARAMETERS:
#     State   -   spline 2D builder object
# 
# OUTPUT PARAMETERS:
#     S       -   2D spline, fit result
#     Rep     -   fitting report, which provides some additional info  about
#                 errors, R2 coefficient and so on.
# 
#   -- ALGLIB --
#      Copyright 05.02.2018 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s, rep = xalglib.spline2dfit(state)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     state:      class xalglib.spline2dbuilder
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> state
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.spline2dinterpolant
          rep:        class xalglib.spline2dfitreport

</div></pre>
<a name='sub_spline2dlintransf'></a><h3 class=pageheader><code>spline2dlintransf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine performs linear transformation of the spline.
# 
# Input parameters:
#     C   -   spline interpolant.
#     A, B-   transformation coefficients: S2(x,y) = A*S(x,y) + B
# 
# Output parameters:
#     C   -   transformed spline
# 
#   -- ALGLIB PROJECT --
#      Copyright 30.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dlintransf(c, a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline2dinterpolant
          a:          float
          b:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dlintransxy'></a><h3 class=pageheader><code>spline2dlintransxy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine performs linear transformation of the spline argument.
# 
# Input parameters:
#     C       -   spline interpolant
#     AX, BX  -   transformation coefficients: x = A*t + B
#     AY, BY  -   transformation coefficients: y = A*u + B
# Result:
#     C   -   transformed spline
# 
#   -- ALGLIB PROJECT --
#      Copyright 30.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline2dlintransxy(c, ax, bx, ay, by)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline2dinterpolant
          ax:         float
          bx:         float
          ay:         float
          by:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline2dresamplebicubic'></a><h3 class=pageheader><code>spline2dresamplebicubic</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Bicubic spline resampling
# 
# Input parameters:
#     A           -   function values at the old grid,
#                     array[0..OldHeight-1, 0..OldWidth-1]
#     OldHeight   -   old grid height, OldHeight&gt;1
#     OldWidth    -   old grid width, OldWidth&gt;1
#     NewHeight   -   new grid height, NewHeight&gt;1
#     NewWidth    -   new grid width, NewWidth&gt;1
# 
# Output parameters:
#     B           -   function values at the new grid,
#                     array[0..NewHeight-1, 0..NewWidth-1]
# 
#   -- ALGLIB routine --
#      15 May, 2007
#      Copyright by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   b = xalglib.spline2dresamplebicubic(a, oldheight, oldwidth, newheight, newwidth)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          oldheight:  int
          oldwidth:   int
          newheight:  int
          newwidth:   int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  b:          2D array/list of float

</div></pre>
<a name='sub_spline2dresamplebilinear'></a><h3 class=pageheader><code>spline2dresamplebilinear</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Bilinear spline resampling
# 
# Input parameters:
#     A           -   function values at the old grid,
#                     array[0..OldHeight-1, 0..OldWidth-1]
#     OldHeight   -   old grid height, OldHeight&gt;1
#     OldWidth    -   old grid width, OldWidth&gt;1
#     NewHeight   -   new grid height, NewHeight&gt;1
#     NewWidth    -   new grid width, NewWidth&gt;1
# 
# Output parameters:
#     B           -   function values at the new grid,
#                     array[0..NewHeight-1, 0..NewWidth-1]
# 
#   -- ALGLIB routine --
#      09.07.2007
#      Copyright by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   b = xalglib.spline2dresamplebilinear(a, oldheight, oldwidth, newheight, newwidth)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          oldheight:  int
          oldwidth:   int
          newheight:  int
          newwidth:   int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  b:          2D array/list of float

</div></pre>
<a name='sub_spline2dunpack'></a><h3 class=pageheader><code>spline2dunpack</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine was deprecated in ALGLIB 3.6.0
# 
# We recommend you to switch  to  Spline2DUnpackV(),  which is more flexible
# and accepts its arguments in more convenient order.
# 
#   -- ALGLIB PROJECT --
#      Copyright 29.06.2007 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   m, n, tbl = xalglib.spline2dunpack(c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline2dinterpolant
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  m:          int
          n:          int
          tbl:        2D array/list of float

</div></pre>
<a name='sub_spline2dunpackv'></a><h3 class=pageheader><code>spline2dunpackv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine unpacks two-dimensional spline into the coefficients table
# 
# Input parameters:
#     C   -   spline interpolant.
# 
# Result:
#     M, N-   grid size (x-axis and y-axis)
#     D   -   number of components
#     Tbl -   coefficients table, unpacked format,
#             D - components: [0..(N-1)*(M-1)*D-1, 0..20].
#             For T=0..D-1 (component index), I = 0...N-2 (x index),
#             J=0..M-2 (y index):
#                 K :=  T + I*D + J*D*(N-1)
# 
#                 K-th row stores decomposition for T-th component of the
#                 vector-valued function
# 
#                 Tbl[K,0] = X[i]
#                 Tbl[K,1] = X[i+1]
#                 Tbl[K,2] = Y[j]
#                 Tbl[K,3] = Y[j+1]
#                 Tbl[K,4] = C00
#                 Tbl[K,5] = C01
#                 Tbl[K,6] = C02
#                 Tbl[K,7] = C03
#                 Tbl[K,8] = C10
#                 Tbl[K,9] = C11
#                 ...
#                 Tbl[K,19] = C33
#                 Tbl[K,20] = 1 if the cell is present, 0 if the cell is missing.
#                             In the latter case Tbl[4..19] are exactly zero.
#             On each grid square spline is equals to:
#                 S(x) = SUM(c[i,j]*(t^i)*(u^j), i=0..3, j=0..3)
#                 t = x-x[j]
#                 u = y-y[i]
# 
#   -- ALGLIB PROJECT --
#      Copyright 16.04.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   m, n, d, tbl = xalglib.spline2dunpackv(c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline2dinterpolant
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  m:          int
          n:          int
          d:          int
          tbl:        2D array/list of float

</div></pre>
<a name=unit_spline3d></a><h2 class=pageheader><code>spline3d</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_spline3dbuildtrilinearv' class=toc>spline3dbuildtrilinearv</a><br>
<a href='#sub_spline3dbuildtrilinearvbuf' class=toc>spline3dbuildtrilinearvbuf</a><br>
<a href='#sub_spline3dcalc' class=toc>spline3dcalc</a><br>
<a href='#sub_spline3dcalcv' class=toc>spline3dcalcv</a><br>
<a href='#sub_spline3dcalcvbuf' class=toc>spline3dcalcvbuf</a><br>
<a href='#sub_spline3dlintransf' class=toc>spline3dlintransf</a><br>
<a href='#sub_spline3dlintransxyz' class=toc>spline3dlintransxyz</a><br>
<a href='#sub_spline3dresampletrilinear' class=toc>spline3dresampletrilinear</a><br>
<a href='#sub_spline3dunpackv' class=toc>spline3dunpackv</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_spline3dbuildtrilinearv'></a><h3 class=pageheader><code>spline3dbuildtrilinearv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds trilinear vector-valued spline.
# 
# INPUT PARAMETERS:
#     X   -   spline abscissas,  array[0..N-1]
#     Y   -   spline ordinates,  array[0..M-1]
#     Z   -   spline applicates, array[0..L-1]
#     F   -   function values, array[0..M*N*L*D-1]:
#             * first D elements store D values at (X[0],Y[0],Z[0])
#             * next D elements store D values at (X[1],Y[0],Z[0])
#             * next D elements store D values at (X[2],Y[0],Z[0])
#             * ...
#             * next D elements store D values at (X[0],Y[1],Z[0])
#             * next D elements store D values at (X[1],Y[1],Z[0])
#             * next D elements store D values at (X[2],Y[1],Z[0])
#             * ...
#             * next D elements store D values at (X[0],Y[0],Z[1])
#             * next D elements store D values at (X[1],Y[0],Z[1])
#             * next D elements store D values at (X[2],Y[0],Z[1])
#             * ...
#             * general form - D function values at (X[i],Y[j]) are stored
#               at F[D*(N*(M*K+J)+I)...D*(N*(M*K+J)+I)+D-1].
#     M,N,
#     L   -   grid size, M&gt;=2, N&gt;=2, L&gt;=2
#     D   -   vector dimension, D&gt;=1
# 
# OUTPUT PARAMETERS:
#     C   -   spline interpolant
# 
#   -- ALGLIB PROJECT --
#      Copyright 26.04.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   c = xalglib.spline3dbuildtrilinearv(x, n, y, m, z, l, f, d)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          y:          1D array/list of float
          m:          int
          z:          1D array/list of float
          l:          int
          f:          1D array/list of float
          d:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  c:          class xalglib.spline3dinterpolant

</div></pre>
<a name='sub_spline3dbuildtrilinearvbuf'></a><h3 class=pageheader><code>spline3dbuildtrilinearvbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine builds trilinear vector-valued spline.
# 
# Buffered  version   of   Spline3DBuildTrilinearV()  which  reuses   memory
# previously allocated in C as much as possible.
# 
#   -- ALGLIB PROJECT --
#      Copyright 26.04.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline3dbuildtrilinearvbuf(x, n, y, m, z, l, f, d, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          y:          1D array/list of float
          m:          int
          z:          1D array/list of float
          l:          int
          f:          1D array/list of float
          d:          int
          c:          class xalglib.spline3dinterpolant
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline3dcalc'></a><h3 class=pageheader><code>spline3dcalc</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates the value of the trilinear or tricubic spline at
# the given point (X,Y,Z).
# 
# INPUT PARAMETERS:
#     C   -   coefficients table.
#             Built by BuildBilinearSpline or BuildBicubicSpline.
#     X, Y,
#     Z   -   point
# 
# Result:
#     S(x,y,z)
# 
#   -- ALGLIB PROJECT --
#      Copyright 26.04.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spline3dcalc(c, x, y, z)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline3dinterpolant
          x:          float
          y:          float
          z:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_spline3dcalcv'></a><h3 class=pageheader><code>spline3dcalcv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates trilinear or tricubic vector-valued spline at the
# given point (X,Y,Z).
# 
# INPUT PARAMETERS:
#     C   -   spline interpolant.
#     X, Y,
#     Z   -   point
# 
# OUTPUT PARAMETERS:
#     F   -   array[D] which stores function values.  F is out-parameter and
#             it  is  reallocated  after  call to this function. In case you
#             want  to    reuse  previously  allocated  F,   you   may   use
#             Spline2DCalcVBuf(),  which  reallocates  F only when it is too
#             small.
# 
#   -- ALGLIB PROJECT --
#      Copyright 26.04.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   f = xalglib.spline3dcalcv(c, x, y, z)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline3dinterpolant
          x:          float
          y:          float
          z:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  f:          1D array/list of float

</div></pre>
<a name='sub_spline3dcalcvbuf'></a><h3 class=pageheader><code>spline3dcalcvbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine calculates bilinear or bicubic vector-valued spline at the
# given point (X,Y,Z).
# 
# INPUT PARAMETERS:
#     C   -   spline interpolant.
#     X, Y,
#     Z   -   point
#     F   -   output buffer, possibly preallocated array. In case array size
#             is large enough to store result, it is not reallocated.  Array
#             which is too short will be reallocated
# 
# OUTPUT PARAMETERS:
#     F   -   array[D] (or larger) which stores function values
# 
#   -- ALGLIB PROJECT --
#      Copyright 26.04.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   f = xalglib.spline3dcalcvbuf(c, x, y, z, f)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline3dinterpolant
          x:          float
          y:          float
          z:          float
          f:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  f:          1D array/list of float

</div></pre>
<a name='sub_spline3dlintransf'></a><h3 class=pageheader><code>spline3dlintransf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine performs linear transformation of the spline.
# 
# INPUT PARAMETERS:
#     C   -   spline interpolant.
#     A, B-   transformation coefficients: S2(x,y) = A*S(x,y,z) + B
# 
# OUTPUT PARAMETERS:
#     C   -   transformed spline
# 
#   -- ALGLIB PROJECT --
#      Copyright 26.04.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline3dlintransf(c, a, b)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline3dinterpolant
          a:          float
          b:          float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline3dlintransxyz'></a><h3 class=pageheader><code>spline3dlintransxyz</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine performs linear transformation of the spline argument.
# 
# INPUT PARAMETERS:
#     C       -   spline interpolant
#     AX, BX  -   transformation coefficients: x = A*u + B
#     AY, BY  -   transformation coefficients: y = A*v + B
#     AZ, BZ  -   transformation coefficients: z = A*w + B
# 
# OUTPUT PARAMETERS:
#     C   -   transformed spline
# 
#   -- ALGLIB PROJECT --
#      Copyright 26.04.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spline3dlintransxyz(c, ax, bx, ay, by, az, bz)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline3dinterpolant
          ax:         float
          bx:         float
          ay:         float
          by:         float
          az:         float
          bz:         float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> c
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spline3dresampletrilinear'></a><h3 class=pageheader><code>spline3dresampletrilinear</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Trilinear spline resampling
# 
# INPUT PARAMETERS:
#     A           -   array[0..OldXCount*OldYCount*OldZCount-1], function
#                     values at the old grid, :
#                         A[0]        x=0,y=0,z=0
#                         A[1]        x=1,y=0,z=0
#                         A[..]       ...
#                         A[..]       x=oldxcount-1,y=0,z=0
#                         A[..]       x=0,y=1,z=0
#                         A[..]       ...
#                         ...
#     OldZCount   -   old Z-count, OldZCount&gt;1
#     OldYCount   -   old Y-count, OldYCount&gt;1
#     OldXCount   -   old X-count, OldXCount&gt;1
#     NewZCount   -   new Z-count, NewZCount&gt;1
#     NewYCount   -   new Y-count, NewYCount&gt;1
#     NewXCount   -   new X-count, NewXCount&gt;1
# 
# OUTPUT PARAMETERS:
#     B           -   array[0..NewXCount*NewYCount*NewZCount-1], function
#                     values at the new grid:
#                         B[0]        x=0,y=0,z=0
#                         B[1]        x=1,y=0,z=0
#                         B[..]       ...
#                         B[..]       x=newxcount-1,y=0,z=0
#                         B[..]       x=0,y=1,z=0
#                         B[..]       ...
#                         ...
# 
#   -- ALGLIB routine --
#      26.04.2012
#      Copyright by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   b = xalglib.spline3dresampletrilinear(a, oldzcount, oldycount, oldxcount, newzcount, newycount, newxcount)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
          oldzcount:  int
          oldycount:  int
          oldxcount:  int
          newzcount:  int
          newycount:  int
          newxcount:  int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  b:          1D array/list of float

</div></pre>
<a name='sub_spline3dunpackv'></a><h3 class=pageheader><code>spline3dunpackv</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This subroutine unpacks tri-dimensional spline into the coefficients table
# 
# INPUT PARAMETERS:
#     C   -   spline interpolant.
# 
# Result:
#     N   -   grid size (X)
#     M   -   grid size (Y)
#     L   -   grid size (Z)
#     D   -   number of components
#     SType-  spline type. Currently, only one spline type is supported:
#             trilinear spline, as indicated by SType=1.
#     Tbl -   spline coefficients: [0..(N-1)*(M-1)*(L-1)*D-1, 0..13].
#             For T=0..D-1 (component index), I = 0...N-2 (x index),
#             J=0..M-2 (y index), K=0..L-2 (z index):
#                 Q := T + I*D + J*D*(N-1) + K*D*(N-1)*(M-1),
# 
#                 Q-th row stores decomposition for T-th component of the
#                 vector-valued function
# 
#                 Tbl[Q,0] = X[i]
#                 Tbl[Q,1] = X[i+1]
#                 Tbl[Q,2] = Y[j]
#                 Tbl[Q,3] = Y[j+1]
#                 Tbl[Q,4] = Z[k]
#                 Tbl[Q,5] = Z[k+1]
# 
#                 Tbl[Q,6] = C000
#                 Tbl[Q,7] = C100
#                 Tbl[Q,8] = C010
#                 Tbl[Q,9] = C110
#                 Tbl[Q,10]= C001
#                 Tbl[Q,11]= C101
#                 Tbl[Q,12]= C011
#                 Tbl[Q,13]= C111
#             On each grid square spline is equals to:
#                 S(x) = SUM(c[i,j,k]*(x^i)*(y^j)*(z^k), i=0..1, j=0..1, k=0..1)
#                 t = x-x[j]
#                 u = y-y[i]
#                 v = z-z[k]
# 
#             NOTE: format of Tbl is given for SType=1. Future versions of
#                   ALGLIB can use different formats for different values of
#                   SType.
# 
#   -- ALGLIB PROJECT --
#      Copyright 26.04.2012 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   n, m, l, d, stype, tbl = xalglib.spline3dunpackv(c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     c:          class xalglib.spline3dinterpolant
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  n:          int
          m:          int
          l:          int
          d:          int
          stype:      int
          tbl:        2D array/list of float

</div></pre>
<a name=unit_ssa></a><h2 class=pageheader><code>ssa</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_ssaaddsequence' class=toc>ssaaddsequence</a><br>
<a href='#sub_ssaanalyzelast' class=toc>ssaanalyzelast</a><br>
<a href='#sub_ssaanalyzelastwindow' class=toc>ssaanalyzelastwindow</a><br>
<a href='#sub_ssaanalyzesequence' class=toc>ssaanalyzesequence</a><br>
<a href='#sub_ssaappendpointandupdate' class=toc>ssaappendpointandupdate</a><br>
<a href='#sub_ssaappendsequenceandupdate' class=toc>ssaappendsequenceandupdate</a><br>
<a href='#sub_ssacleardata' class=toc>ssacleardata</a><br>
<a href='#sub_ssacreate' class=toc>ssacreate</a><br>
<a href='#sub_ssaforecastavglast' class=toc>ssaforecastavglast</a><br>
<a href='#sub_ssaforecastavgsequence' class=toc>ssaforecastavgsequence</a><br>
<a href='#sub_ssaforecastlast' class=toc>ssaforecastlast</a><br>
<a href='#sub_ssaforecastsequence' class=toc>ssaforecastsequence</a><br>
<a href='#sub_ssagetbasis' class=toc>ssagetbasis</a><br>
<a href='#sub_ssagetlrr' class=toc>ssagetlrr</a><br>
<a href='#sub_ssasetalgoprecomputed' class=toc>ssasetalgoprecomputed</a><br>
<a href='#sub_ssasetalgotopkdirect' class=toc>ssasetalgotopkdirect</a><br>
<a href='#sub_ssasetalgotopkrealtime' class=toc>ssasetalgotopkrealtime</a><br>
<a href='#sub_ssasetmemorylimit' class=toc>ssasetmemorylimit</a><br>
<a href='#sub_ssasetpoweruplength' class=toc>ssasetpoweruplength</a><br>
<a href='#sub_ssasetseed' class=toc>ssasetseed</a><br>
<a href='#sub_ssasetwindow' class=toc>ssasetwindow</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_ssaaddsequence'></a><h3 class=pageheader><code>ssaaddsequence</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function adds data sequence to SSA  model.  Only   single-dimensional
# sequences are supported.
# 
# What is a sequences? Following definitions/requirements apply:
# * a sequence  is  an  array of  values  measured  in  subsequent,  equally
#   separated time moments (ticks).
# * you may have many sequences  in your  dataset;  say,  one  sequence  may
#   correspond to one trading session.
# * sequence length should be larger  than current  window  length  (shorter
#   sequences will be ignored during analysis).
# * analysis is performed within a  sequence; different  sequences  are  NOT
#   stacked together to produce one large contiguous stream of data.
# * analysis is performed for all  sequences at once, i.e. same set of basis
#   vectors is computed for all sequences
# 
# INCREMENTAL ANALYSIS
# 
# This function is non intended for  incremental updates of previously found
# SSA basis. Calling it invalidates  all previous analysis results (basis is
# reset and will be recalculated from zero during next analysis).
# 
# If  you  want  to  perform   incremental/real-time  SSA,  consider   using
# following functions:
# * ssaappendpointandupdate() for appending one point
# * ssaappendsequenceandupdate() for appending new sequence
# 
# INPUT PARAMETERS:
#     S               -   SSA model created with ssacreate()
#     X               -   array[N], data, can be larger (additional values
#                         are ignored)
#     N               -   data length, can be automatically determined from
#                         the array length. N&gt;=0.
# 
# OUTPUT PARAMETERS:
#     S               -   SSA model, updated
# 
# NOTE: you can clear dataset with ssacleardata()
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.ssaaddsequence(s, x, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.ssaaddsequence(s, x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
          x:          1D array/list of float
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_ssaanalyzelast'></a><h3 class=pageheader><code>ssaanalyzelast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function:
# * builds SSA basis using internally stored (entire) dataset
# * returns reconstruction for the last NTicks of the last sequence
# 
# If you want to analyze some other sequence, use ssaanalyzesequence().
# 
# Reconstruction phase involves  generation  of  NTicks-WindowWidth  sliding
# windows, their decomposition using empirical orthogonal functions found by
# SSA, followed by averaging of each data point across  several  overlapping
# windows. Thus, every point in the output trend is reconstructed  using  up
# to WindowWidth overlapping  windows  (WindowWidth windows exactly  in  the
# inner points, just one window at the extremal points).
# 
# IMPORTANT: due to averaging this function returns  different  results  for
#            different values of NTicks. It is expected and not a bug.
# 
#            For example:
#            * Trend[NTicks-1] is always same because it is not averaged  in
#              any case (same applies to Trend[0]).
#            * Trend[NTicks-2] has different values  for  NTicks=WindowWidth
#              and NTicks=WindowWidth+1 because former  case  means that  no
#              averaging is performed, and latter  case means that averaging
#              using two sliding windows  is  performed.  Larger  values  of
#              NTicks produce same results as NTicks=WindowWidth+1.
#            * ...and so on...
# 
# PERFORMANCE: this  function has O((NTicks-WindowWidth)*WindowWidth*NBasis)
#              running time. If you work  in  time-constrained  setting  and
#              have to analyze just a few last ticks, choosing NTicks  equal
#              to WindowWidth+SmoothingLen, with SmoothingLen=1...WindowWidth
#              will result in good compromise between noise cancellation and
#              analysis speed.
# 
# INPUT PARAMETERS:
#     S               -   SSA model
#     NTicks          -   number of ticks to analyze, Nticks&gt;=1.
#                         * special case of NTicks&lt;=WindowWidth  is  handled
#                           by analyzing last window and  returning   NTicks
#                           last ticks.
#                         * special case NTicks&gt;LastSequenceLen  is  handled
#                           by prepending result with NTicks-LastSequenceLen
#                           zeros.
# 
# OUTPUT PARAMETERS:
#     Trend           -   array[NTicks], reconstructed trend line
#     Noise           -   array[NTicks], the rest of the signal;
#                         it holds that ActualData = Trend+Noise.
# 
# 
# CACHING/REUSE OF THE BASIS
# 
# Caching/reuse of previous results is performed:
# * first call performs full run of SSA; basis is stored in the cache
# * subsequent calls reuse previously cached basis
# * if you call any function which changes model properties (window  length,
#   algorithm, dataset), internal basis will be invalidated.
# * the only calls which do NOT invalidate basis are listed below:
#   a) ssasetwindow() with same window length
#   b) ssaappendpointandupdate()
#   c) ssaappendsequenceandupdate()
#   d) ssasetalgotopk...() with exactly same K
#   Calling these functions will result in reuse of previously found basis.
# 
# In  any  case,  only  basis  is  reused. Reconstruction is performed  from
# scratch every time you call this function.
# 
# 
# HANDLING OF DEGENERATE CASES
# 
# Following degenerate cases may happen:
# * dataset is empty (no analysis can be done)
# * all sequences are shorter than the window length,no analysis can be done
# * no algorithm is specified (no analysis can be done)
# * last sequence is shorter than the window length (analysis  can  be done,
#   but we can not perform reconstruction on the last sequence)
# 
# Calling this function in degenerate cases returns following result:
# * in any case, NTicks ticks is returned
# * trend is assumed to be zero
# * noise is initialized by the last sequence; if last sequence  is  shorter
#   than the window size, it is moved to  the  end  of  the  array, and  the
#   beginning of the noise array is filled by zeros
# 
# No analysis is performed in degenerate cases (we immediately return  dummy
# values, no basis is constructed).
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   trend, noise = xalglib.ssaanalyzelast(s, nticks)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
          nticks:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  trend:      1D array/list of float
          noise:      1D array/list of float

</div></pre>
<a name='sub_ssaanalyzelastwindow'></a><h3 class=pageheader><code>ssaanalyzelastwindow</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  executes  SSA  on  internally  stored  dataset and returns
# analysis  for  the  last  window  of  the  last sequence. Such analysis is
# an lightweight alternative for full scale reconstruction (see below).
# 
# Typical use case for this function is  real-time  setting,  when  you  are
# interested in quick-and-dirty (very quick and very  dirty)  processing  of
# just a few last ticks of the trend.
# 
# IMPORTANT: full  scale  SSA  involves  analysis  of  the  ENTIRE  dataset,
#            with reconstruction being done for  all  positions  of  sliding
#            window with subsequent hankelization  (diagonal  averaging)  of
#            the resulting matrix.
# 
#            Such analysis requires O((DataLen-Window)*Window*NBasis)  FLOPs
#            and can be quite costly. However, it has  nice  noise-canceling
#            effects due to averaging.
# 
#            This function performs REDUCED analysis of the last window.  It
#            is much faster - just O(Window*NBasis),  but  its  results  are
#            DIFFERENT from that of ssaanalyzelast(). In  particular,  first
#            few points of the trend are much more prone to noise.
# 
# INPUT PARAMETERS:
#     S               -   SSA model
# 
# OUTPUT PARAMETERS:
#     Trend           -   array[WindowSize], reconstructed trend line
#     Noise           -   array[WindowSize], the rest of the signal;
#                         it holds that ActualData = Trend+Noise.
#     NTicks          -   current WindowSize
# 
# 
# CACHING/REUSE OF THE BASIS
# 
# Caching/reuse of previous results is performed:
# * first call performs full run of SSA; basis is stored in the cache
# * subsequent calls reuse previously cached basis
# * if you call any function which changes model properties (window  length,
#   algorithm, dataset), internal basis will be invalidated.
# * the only calls which do NOT invalidate basis are listed below:
#   a) ssasetwindow() with same window length
#   b) ssaappendpointandupdate()
#   c) ssaappendsequenceandupdate()
#   d) ssasetalgotopk...() with exactly same K
#   Calling these functions will result in reuse of previously found basis.
# 
# In  any  case,  only  basis  is  reused. Reconstruction is performed  from
# scratch every time you call this function.
# 
# 
# HANDLING OF DEGENERATE CASES
# 
# Following degenerate cases may happen:
# * dataset is empty (no analysis can be done)
# * all sequences are shorter than the window length,no analysis can be done
# * no algorithm is specified (no analysis can be done)
# * last sequence is shorter than the window length (analysis can  be  done,
#   but we can not perform reconstruction on the last sequence)
# 
# Calling this function in degenerate cases returns following result:
# * in any case, WindowWidth ticks is returned
# * trend is assumed to be zero
# * noise is initialized by the last sequence; if last sequence  is  shorter
#   than the window size, it is moved to  the  end  of  the  array, and  the
#   beginning of the noise array is filled by zeros
# 
# No analysis is performed in degenerate cases (we immediately return  dummy
# values, no basis is constructed).
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   trend, noise, nticks = xalglib.ssaanalyzelastwindow(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  trend:      1D array/list of float
          noise:      1D array/list of float
          nticks:     int

</div></pre>
<a name='sub_ssaanalyzesequence'></a><h3 class=pageheader><code>ssaanalyzesequence</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function:
# * builds SSA basis using internally stored (entire) dataset
# * returns reconstruction for the sequence being passed to this function
# 
# If  you  want  to  analyze  last  sequence  stored  in   the   model,  use
# ssaanalyzelast().
# 
# Reconstruction phase involves  generation  of  NTicks-WindowWidth  sliding
# windows, their decomposition using empirical orthogonal functions found by
# SSA, followed by averaging of each data point across  several  overlapping
# windows. Thus, every point in the output trend is reconstructed  using  up
# to WindowWidth overlapping  windows  (WindowWidth windows exactly  in  the
# inner points, just one window at the extremal points).
# 
# PERFORMANCE: this  function has O((NTicks-WindowWidth)*WindowWidth*NBasis)
#              running time. If you work  in  time-constrained  setting  and
#              have to analyze just a few last ticks, choosing NTicks  equal
#              to WindowWidth+SmoothingLen, with SmoothingLen=1...WindowWidth
#              will result in good compromise between noise cancellation and
#              analysis speed.
# 
# INPUT PARAMETERS:
#     S               -   SSA model
#     Data            -   array[NTicks], can be larger (only NTicks  leading
#                         elements will be used)
#     NTicks          -   number of ticks to analyze, Nticks&gt;=1.
#                         * special case of NTicks&lt;WindowWidth  is   handled
#                           by returning zeros as trend, and signal as noise
# 
# OUTPUT PARAMETERS:
#     Trend           -   array[NTicks], reconstructed trend line
#     Noise           -   array[NTicks], the rest of the signal;
#                         it holds that ActualData = Trend+Noise.
# 
# 
# CACHING/REUSE OF THE BASIS
# 
# Caching/reuse of previous results is performed:
# * first call performs full run of SSA; basis is stored in the cache
# * subsequent calls reuse previously cached basis
# * if you call any function which changes model properties (window  length,
#   algorithm, dataset), internal basis will be invalidated.
# * the only calls which do NOT invalidate basis are listed below:
#   a) ssasetwindow() with same window length
#   b) ssaappendpointandupdate()
#   c) ssaappendsequenceandupdate()
#   d) ssasetalgotopk...() with exactly same K
#   Calling these functions will result in reuse of previously found basis.
# 
# In  any  case,  only  basis  is  reused. Reconstruction is performed  from
# scratch every time you call this function.
# 
# 
# HANDLING OF DEGENERATE CASES
# 
# Following degenerate cases may happen:
# * dataset is empty (no analysis can be done)
# * all sequences are shorter than the window length,no analysis can be done
# * no algorithm is specified (no analysis can be done)
# * sequence being passed is shorter than the window length
# 
# Calling this function in degenerate cases returns following result:
# * in any case, NTicks ticks is returned
# * trend is assumed to be zero
# * noise is initialized by the sequence.
# 
# No analysis is performed in degenerate cases (we immediately return  dummy
# values, no basis is constructed).
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   trend, noise = xalglib.ssaanalyzesequence(s, data, nticks)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   trend, noise = xalglib.ssaanalyzesequence(s, data)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
          data:       1D array/list of float
          nticks:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  trend:      1D array/list of float
          noise:      1D array/list of float

</div></pre>
<a name='sub_ssaappendpointandupdate'></a><h3 class=pageheader><code>ssaappendpointandupdate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends single point to last data sequence stored in the SSA
# model and tries to update model in the  incremental  manner  (if  possible
# with current algorithm).
# 
# If you want to add more than one point at once:
# * if you want to add M points to the same sequence, perform M-1 calls with
#   UpdateIts parameter set to 0.0, and last call with non-zero UpdateIts.
# * if you want to add new sequence, use ssaappendsequenceandupdate()
# 
# Running time of this function does NOT depend on  dataset  size,  only  on
# window width and number of singular vectors. Depending on algorithm  being
# used, incremental update has complexity:
# * for top-K real time   - O(UpdateIts*K*Width^2), with fractional UpdateIts
# * for top-K direct      - O(Width^3) for any non-zero UpdateIts
# * for precomputed basis - O(1), no update is performed
# 
# INPUT PARAMETERS:
#     S               -   SSA model created with ssacreate()
#     X               -   new point
#     UpdateIts       -   &gt;=0,  floating  point (!)  value,  desired  update
#                         frequency:
#                         * zero value means that point is  stored,  but  no
#                           update is performed
#                         * integer part of the value means  that  specified
#                           number of iterations is always performed
#                         * fractional part of  the  value  means  that  one
#                           iteration is performed with this probability.
# 
#                         Recommended value: 0&lt;UpdateIts&lt;=1.  Values  larger
#                         than 1 are VERY seldom  needed.  If  your  dataset
#                         changes slowly, you can set it  to  0.1  and  skip
#                         90% of updates.
# 
#                         In any case, no information is lost even with zero
#                         value of UpdateIts! It will be  incorporated  into
#                         model, sooner or later.
# 
# OUTPUT PARAMETERS:
#     S               -   SSA model, updated
# 
# NOTE: this function uses internal  RNG  to  handle  fractional  values  of
#       UpdateIts. By default it  is  initialized  with  fixed  seed  during
#       initial calculation of basis. Thus subsequent calls to this function
#       will result in the same sequence of pseudorandom decisions.
# 
#       However, if  you  have  several  SSA  models  which  are  calculated
#       simultaneously, and if you want to reduce computational  bottlenecks
#       by performing random updates at random moments, then fixed  seed  is
#       not an option - all updates will fire at same moments.
# 
#       You may change it with ssasetseed() function.
# 
# NOTE: this function throws an exception if called for empty dataset (there
#       is no &quot;last&quot; sequence to modify).
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.ssaappendpointandupdate(s, x, updateits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
          x:          float
          updateits:  float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_ssaappendsequenceandupdate'></a><h3 class=pageheader><code>ssaappendsequenceandupdate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function appends new sequence to dataset stored in the SSA  model and
# tries to update model in the incremental manner (if possible  with current
# algorithm).
# 
# Notes:
# * if you want to add M sequences at once, perform M-1 calls with UpdateIts
#   parameter set to 0.0, and last call with non-zero UpdateIts.
# * if you want to add just one point, use ssaappendpointandupdate()
# 
# Running time of this function does NOT depend on  dataset  size,  only  on
# sequence length, window width and number of singular vectors. Depending on
# algorithm being used, incremental update has complexity:
# * for top-K real time   - O(UpdateIts*K*Width^2+(NTicks-Width)*Width^2)
# * for top-K direct      - O(Width^3+(NTicks-Width)*Width^2)
# * for precomputed basis - O(1), no update is performed
# 
# INPUT PARAMETERS:
#     S               -   SSA model created with ssacreate()
#     X               -   new sequence, array[NTicks] or larget
#     NTicks          -   &gt;=1, number of ticks in the sequence
#     UpdateIts       -   &gt;=0,  floating  point (!)  value,  desired  update
#                         frequency:
#                         * zero value means that point is  stored,  but  no
#                           update is performed
#                         * integer part of the value means  that  specified
#                           number of iterations is always performed
#                         * fractional part of  the  value  means  that  one
#                           iteration is performed with this probability.
# 
#                         Recommended value: 0&lt;UpdateIts&lt;=1.  Values  larger
#                         than 1 are VERY seldom  needed.  If  your  dataset
#                         changes slowly, you can set it  to  0.1  and  skip
#                         90% of updates.
# 
#                         In any case, no information is lost even with zero
#                         value of UpdateIts! It will be  incorporated  into
#                         model, sooner or later.
# 
# OUTPUT PARAMETERS:
#     S               -   SSA model, updated
# 
# NOTE: this function uses internal  RNG  to  handle  fractional  values  of
#       UpdateIts. By default it  is  initialized  with  fixed  seed  during
#       initial calculation of basis. Thus subsequent calls to this function
#       will result in the same sequence of pseudorandom decisions.
# 
#       However, if  you  have  several  SSA  models  which  are  calculated
#       simultaneously, and if you want to reduce computational  bottlenecks
#       by performing random updates at random moments, then fixed  seed  is
#       not an option - all updates will fire at same moments.
# 
#       You may change it with ssasetseed() function.
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.ssaappendsequenceandupdate(s, x, nticks, updateits)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.ssaappendsequenceandupdate(s, x, updateits)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
          x:          1D array/list of float
          nticks:     int
          updateits:  float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_ssacleardata'></a><h3 class=pageheader><code>ssacleardata</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function clears all data stored in the  model  and  invalidates  all
# basis components found so far.
# 
# INPUT PARAMETERS:
#     S               -   SSA model created with ssacreate()
# 
# OUTPUT PARAMETERS:
#     S               -   SSA model, updated
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.ssacleardata(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_ssacreate'></a><h3 class=pageheader><code>ssacreate</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function creates SSA model object.  Right after creation model is  in
# &quot;dummy&quot; mode - you can add data,  but   analyzing/prediction  will  return
# just zeros (it assumes that basis is empty).
# 
# HOW TO USE SSA MODEL:
# 
# 1. create model with ssacreate()
# 2. add data with one/many ssaaddsequence() calls
# 3. choose SSA algorithm with one of ssasetalgo...() functions:
#    * ssasetalgotopkdirect() for direct one-run analysis
#    * ssasetalgotopkrealtime() for algorithm optimized for many  subsequent
#      runs with warm-start capabilities
#    * ssasetalgoprecomputed() for user-supplied basis
# 4. set window width with ssasetwindow()
# 5. perform one of the analysis-related activities:
#    a) call ssagetbasis() to get basis
#    b) call ssaanalyzelast() ssaanalyzesequence() or ssaanalyzelastwindow()
#       to perform analysis (trend/noise separation)
#    c) call  one  of   the   forecasting   functions  (ssaforecastlast() or
#       ssaforecastsequence()) to perform prediction; alternatively, you can
#       extract linear recurrence coefficients with ssagetlrr().
#    SSA analysis will be performed during first  call  to  analysis-related
#    function. SSA model is smart enough to track all changes in the dataset
#    and  model  settings,  to  cache  previously  computed  basis  and   to
#    re-evaluate basis only when necessary.
# 
# Additionally, if your setting involves constant stream  of  incoming data,
# you can perform quick update already calculated  model  with  one  of  the
# incremental   append-and-update   functions:  ssaappendpointandupdate() or
# ssaappendsequenceandupdate().
# 
# NOTE: steps (2), (3), (4) can be performed in arbitrary order.
# 
# INPUT PARAMETERS:
#     none
# 
# OUTPUT PARAMETERS:
#     S               -   structure which stores model state
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   s = xalglib.ssacreate()
<span style='font-weight: bold; color: navy;'>ARGS:</span>     
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  s:          class xalglib.ssamodel

</div></pre>
<a name='sub_ssaforecastavglast'></a><h3 class=pageheader><code>ssaforecastavglast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function builds SSA basis and performs forecasting  for  a  specified
# number of ticks, returning value of trend.
# 
# Forecast is performed as follows:
# * SSA  trend  extraction  is  applied to last  M  sliding windows  of  the
#   internally stored dataset
# * for each of M sliding windows, M predictions are built
# * average value of M predictions is returned
# 
# This function has following running time:
# * O(NBasis*WindowWidth*M) for trend extraction phase (always performed)
# * O(WindowWidth*NTicks*M) for forecast phase
# 
# NOTE: noise reduction is ALWAYS applied by this algorithm; if you want  to
#       apply recurrence relation  to  raw  unprocessed  data,  use  another
#       function - ssaforecastsequence() which allows to  turn  on  and  off
#       noise reduction phase.
# 
# NOTE: combination of several predictions results in lesser sensitivity  to
#       noise, but it may produce undesirable discontinuities  between  last
#       point of the trend and first point of the prediction. The reason  is
#       that  last  point  of  the  trend is usually corrupted by noise, but
#       average  value of  several  predictions  is less sensitive to noise,
#       thus discontinuity appears. It is not a bug.
# 
# INPUT PARAMETERS:
#     S               -   SSA model
#     M               -   number  of  sliding  windows  to combine, M&gt;=1. If
#                         your dataset has less than M sliding windows, this
#                         parameter will be silently reduced.
#     NTicks          -   number of ticks to forecast, NTicks&gt;=1
# 
# OUTPUT PARAMETERS:
#     Trend           -   array[NTicks], predicted trend line
# 
# 
# CACHING/REUSE OF THE BASIS
# 
# Caching/reuse of previous results is performed:
# * first call performs full run of SSA; basis is stored in the cache
# * subsequent calls reuse previously cached basis
# * if you call any function which changes model properties (window  length,
#   algorithm, dataset), internal basis will be invalidated.
# * the only calls which do NOT invalidate basis are listed below:
#   a) ssasetwindow() with same window length
#   b) ssaappendpointandupdate()
#   c) ssaappendsequenceandupdate()
#   d) ssasetalgotopk...() with exactly same K
#   Calling these functions will result in reuse of previously found basis.
# 
# 
# HANDLING OF DEGENERATE CASES
# 
# Following degenerate cases may happen:
# * dataset is empty (no analysis can be done)
# * all sequences are shorter than the window length,no analysis can be done
# * no algorithm is specified (no analysis can be done)
# * last sequence is shorter than the WindowWidth   (analysis  can  be done,
#   but we can not perform forecasting on the last sequence)
# * window lentgh is 1 (impossible to use for forecasting)
# * SSA analysis algorithm is  configured  to  extract  basis  whose size is
#   equal to window length (impossible to use for  forecasting;  only  basis
#   whose size is less than window length can be used).
# 
# Calling this function in degenerate cases returns following result:
# * NTicks  copies  of  the  last  value is returned for non-empty task with
#   large enough dataset, but with overcomplete  basis  (window  width=1  or
#   basis size is equal to window width)
# * zero trend with length=NTicks is returned for empty task
# 
# No analysis is performed in degenerate cases (we immediately return  dummy
# values, no basis is ever constructed).
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   trend = xalglib.ssaforecastavglast(s, m, nticks)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
          m:          int
          nticks:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  trend:      1D array/list of float

</div></pre>
<a name='sub_ssaforecastavgsequence'></a><h3 class=pageheader><code>ssaforecastavgsequence</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function builds SSA  basis  and  performs  forecasting  for  a  user-
# specified sequence, returning value of trend.
# 
# Forecasting is done in two stages:
# * first,  we  extract  trend  from M last sliding windows of the sequence.
#   This stage is optional, you can  turn  it  off  if  you  pass data which
#   are already processed with SSA. Of course, you  can  turn  it  off  even
#   for raw data, but it is not recommended  -  noise  suppression  is  very
#   important for correct prediction.
# * then, we apply LRR independently for M sliding windows
# * average of M predictions is returned
# 
# This function has following running time:
# * O(NBasis*WindowWidth*M) for trend extraction phase
# * O(WindowWidth*NTicks*M) for forecast phase
# 
# NOTE: combination of several predictions results in lesser sensitivity  to
#       noise, but it may produce undesirable discontinuities  between  last
#       point of the trend and first point of the prediction. The reason  is
#       that  last  point  of  the  trend is usually corrupted by noise, but
#       average  value of  several  predictions  is less sensitive to noise,
#       thus discontinuity appears. It is not a bug.
# 
# INPUT PARAMETERS:
#     S               -   SSA model
#     Data            -   array[NTicks], data to forecast
#     DataLen         -   number of ticks in the data, DataLen&gt;=1
#     M               -   number  of  sliding  windows  to combine, M&gt;=1. If
#                         your dataset has less than M sliding windows, this
#                         parameter will be silently reduced.
#     ForecastLen     -   number of ticks to predict, ForecastLen&gt;=1
#     ApplySmoothing  -   whether to apply smoothing trend extraction or not.
#                         if you do not know what to specify, pass true.
# 
# OUTPUT PARAMETERS:
#     Trend           -   array[ForecastLen], forecasted trend
# 
# 
# CACHING/REUSE OF THE BASIS
# 
# Caching/reuse of previous results is performed:
# * first call performs full run of SSA; basis is stored in the cache
# * subsequent calls reuse previously cached basis
# * if you call any function which changes model properties (window  length,
#   algorithm, dataset), internal basis will be invalidated.
# * the only calls which do NOT invalidate basis are listed below:
#   a) ssasetwindow() with same window length
#   b) ssaappendpointandupdate()
#   c) ssaappendsequenceandupdate()
#   d) ssasetalgotopk...() with exactly same K
#   Calling these functions will result in reuse of previously found basis.
# 
# 
# HANDLING OF DEGENERATE CASES
# 
# Following degenerate cases may happen:
# * dataset is empty (no analysis can be done)
# * all sequences are shorter than the window length,no analysis can be done
# * no algorithm is specified (no analysis can be done)
# * data sequence is shorter than the WindowWidth   (analysis  can  be done,
#   but we can not perform forecasting on the last sequence)
# * window lentgh is 1 (impossible to use for forecasting)
# * SSA analysis algorithm is  configured  to  extract  basis  whose size is
#   equal to window length (impossible to use for  forecasting;  only  basis
#   whose size is less than window length can be used).
# 
# Calling this function in degenerate cases returns following result:
# * ForecastLen copies of the last value is returned for non-empty task with
#   large enough dataset, but with overcomplete  basis  (window  width=1  or
#   basis size is equal to window width)
# * zero trend with length=ForecastLen is returned for empty task
# 
# No analysis is performed in degenerate cases (we immediately return  dummy
# values, no basis is ever constructed).
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   trend = xalglib.ssaforecastavgsequence(s, data, datalen, m, forecastlen, applysmoothing)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   trend = xalglib.ssaforecastavgsequence(s, data, m, forecastlen)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
          data:       1D array/list of float
          datalen:    int
          m:          int
          forecastlen: int
          applysmoothing: bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  trend:      1D array/list of float

</div></pre>
<a name='sub_ssaforecastlast'></a><h3 class=pageheader><code>ssaforecastlast</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function builds SSA basis and performs forecasting  for  a  specified
# number of ticks, returning value of trend.
# 
# Forecast is performed as follows:
# * SSA  trend  extraction  is  applied  to last WindowWidth elements of the
#   internally stored dataset; this step is basically a noise reduction.
# * linear recurrence relation is applied to extracted trend
# 
# This function has following running time:
# * O(NBasis*WindowWidth) for trend extraction phase (always performed)
# * O(WindowWidth*NTicks) for forecast phase
# 
# NOTE: noise reduction is ALWAYS applied by this algorithm; if you want  to
#       apply recurrence relation  to  raw  unprocessed  data,  use  another
#       function - ssaforecastsequence() which allows to  turn  on  and  off
#       noise reduction phase.
# 
# NOTE: this algorithm performs prediction using only one - last  -  sliding
#       window.  Predictions  produced   by   such   approach   are   smooth
#       continuations of the reconstructed  trend  line,  but  they  can  be
#       easily corrupted by noise. If you need  noise-resistant  prediction,
#       use ssaforecastavglast() function, which averages predictions  built
#       using several sliding windows.
# 
# INPUT PARAMETERS:
#     S               -   SSA model
#     NTicks          -   number of ticks to forecast, NTicks&gt;=1
# 
# OUTPUT PARAMETERS:
#     Trend           -   array[NTicks], predicted trend line
# 
# 
# CACHING/REUSE OF THE BASIS
# 
# Caching/reuse of previous results is performed:
# * first call performs full run of SSA; basis is stored in the cache
# * subsequent calls reuse previously cached basis
# * if you call any function which changes model properties (window  length,
#   algorithm, dataset), internal basis will be invalidated.
# * the only calls which do NOT invalidate basis are listed below:
#   a) ssasetwindow() with same window length
#   b) ssaappendpointandupdate()
#   c) ssaappendsequenceandupdate()
#   d) ssasetalgotopk...() with exactly same K
#   Calling these functions will result in reuse of previously found basis.
# 
# 
# HANDLING OF DEGENERATE CASES
# 
# Following degenerate cases may happen:
# * dataset is empty (no analysis can be done)
# * all sequences are shorter than the window length,no analysis can be done
# * no algorithm is specified (no analysis can be done)
# * last sequence is shorter than the WindowWidth   (analysis  can  be done,
#   but we can not perform forecasting on the last sequence)
# * window lentgh is 1 (impossible to use for forecasting)
# * SSA analysis algorithm is  configured  to  extract  basis  whose size is
#   equal to window length (impossible to use for  forecasting;  only  basis
#   whose size is less than window length can be used).
# 
# Calling this function in degenerate cases returns following result:
# * NTicks  copies  of  the  last  value is returned for non-empty task with
#   large enough dataset, but with overcomplete  basis  (window  width=1  or
#   basis size is equal to window width)
# * zero trend with length=NTicks is returned for empty task
# 
# No analysis is performed in degenerate cases (we immediately return  dummy
# values, no basis is ever constructed).
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   trend = xalglib.ssaforecastlast(s, nticks)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
          nticks:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  trend:      1D array/list of float

</div></pre>
<a name='sub_ssaforecastsequence'></a><h3 class=pageheader><code>ssaforecastsequence</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function builds SSA  basis  and  performs  forecasting  for  a  user-
# specified sequence, returning value of trend.
# 
# Forecasting is done in two stages:
# * first,  we  extract  trend  from the WindowWidth  last  elements of  the
#   sequence. This stage is optional, you  can  turn  it  off  if  you  pass
#   data which are already processed with SSA. Of course, you  can  turn  it
#   off even for raw data, but it is not recommended - noise suppression  is
#   very important for correct prediction.
# * then, we apply LRR for last  WindowWidth-1  elements  of  the  extracted
#   trend.
# 
# This function has following running time:
# * O(NBasis*WindowWidth) for trend extraction phase
# * O(WindowWidth*NTicks) for forecast phase
# 
# NOTE: this algorithm performs prediction using only one - last  -  sliding
#       window.  Predictions  produced   by   such   approach   are   smooth
#       continuations of the reconstructed  trend  line,  but  they  can  be
#       easily corrupted by noise. If you need  noise-resistant  prediction,
#       use ssaforecastavgsequence() function,  which  averages  predictions
#       built using several sliding windows.
# 
# INPUT PARAMETERS:
#     S               -   SSA model
#     Data            -   array[NTicks], data to forecast
#     DataLen         -   number of ticks in the data, DataLen&gt;=1
#     ForecastLen     -   number of ticks to predict, ForecastLen&gt;=1
#     ApplySmoothing  -   whether to apply smoothing trend extraction or not;
#                         if you do not know what to specify, pass True.
# 
# OUTPUT PARAMETERS:
#     Trend           -   array[ForecastLen], forecasted trend
# 
# 
# CACHING/REUSE OF THE BASIS
# 
# Caching/reuse of previous results is performed:
# * first call performs full run of SSA; basis is stored in the cache
# * subsequent calls reuse previously cached basis
# * if you call any function which changes model properties (window  length,
#   algorithm, dataset), internal basis will be invalidated.
# * the only calls which do NOT invalidate basis are listed below:
#   a) ssasetwindow() with same window length
#   b) ssaappendpointandupdate()
#   c) ssaappendsequenceandupdate()
#   d) ssasetalgotopk...() with exactly same K
#   Calling these functions will result in reuse of previously found basis.
# 
# 
# HANDLING OF DEGENERATE CASES
# 
# Following degenerate cases may happen:
# * dataset is empty (no analysis can be done)
# * all sequences are shorter than the window length,no analysis can be done
# * no algorithm is specified (no analysis can be done)
# * data sequence is shorter than the WindowWidth   (analysis  can  be done,
#   but we can not perform forecasting on the last sequence)
# * window lentgh is 1 (impossible to use for forecasting)
# * SSA analysis algorithm is  configured  to  extract  basis  whose size is
#   equal to window length (impossible to use for  forecasting;  only  basis
#   whose size is less than window length can be used).
# 
# Calling this function in degenerate cases returns following result:
# * ForecastLen copies of the last value is returned for non-empty task with
#   large enough dataset, but with overcomplete  basis  (window  width=1  or
#   basis size is equal to window width)
# * zero trend with length=ForecastLen is returned for empty task
# 
# No analysis is performed in degenerate cases (we immediately return  dummy
# values, no basis is ever constructed).
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   trend = xalglib.ssaforecastsequence(s, data, datalen, forecastlen, applysmoothing)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   trend = xalglib.ssaforecastsequence(s, data, forecastlen)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
          data:       1D array/list of float
          datalen:    int
          forecastlen: int
          applysmoothing: bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  trend:      1D array/list of float

</div></pre>
<a name='sub_ssagetbasis'></a><h3 class=pageheader><code>ssagetbasis</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function executes SSA on internally stored dataset and returns  basis
# found by current method.
# 
# INPUT PARAMETERS:
#     S               -   SSA model
# 
# OUTPUT PARAMETERS:
#     A               -   array[WindowWidth,NBasis],   basis;  vectors  are
#                         stored in matrix columns, by descreasing variance
#     SV              -   array[NBasis]:
#                         * zeros - for model initialized with SSASetAlgoPrecomputed()
#                         * singular values - for other algorithms
#     WindowWidth     -   current window
#     NBasis          -   basis size
# 
# 
# CACHING/REUSE OF THE BASIS
# 
# Caching/reuse of previous results is performed:
# * first call performs full run of SSA; basis is stored in the cache
# * subsequent calls reuse previously cached basis
# * if you call any function which changes model properties (window  length,
#   algorithm, dataset), internal basis will be invalidated.
# * the only calls which do NOT invalidate basis are listed below:
#   a) ssasetwindow() with same window length
#   b) ssaappendpointandupdate()
#   c) ssaappendsequenceandupdate()
#   d) ssasetalgotopk...() with exactly same K
#   Calling these functions will result in reuse of previously found basis.
# 
# 
# HANDLING OF DEGENERATE CASES
# 
# Calling  this  function  in  degenerate  cases  (no  data  or all data are
# shorter than window size; no algorithm is specified)  returns  basis  with
# just one zero vector.
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a, sv, windowwidth, nbasis = xalglib.ssagetbasis(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of float
          sv:         1D array/list of float
          windowwidth: int
          nbasis:     int

</div></pre>
<a name='sub_ssagetlrr'></a><h3 class=pageheader><code>ssagetlrr</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function returns linear recurrence relation (LRR) coefficients  found
# by current SSA algorithm.
# 
# INPUT PARAMETERS:
#     S               -   SSA model
# 
# OUTPUT PARAMETERS:
#     A               -   array[WindowWidth-1]. Coefficients  of  the
#                         linear recurrence of the form:
#                         X[W-1] = X[W-2]*A[W-2] + X[W-3]*A[W-3] + ... + X[0]*A[0].
#                         Empty array for WindowWidth=1.
#     WindowWidth     -   current window width
# 
# 
# CACHING/REUSE OF THE BASIS
# 
# Caching/reuse of previous results is performed:
# * first call performs full run of SSA; basis is stored in the cache
# * subsequent calls reuse previously cached basis
# * if you call any function which changes model properties (window  length,
#   algorithm, dataset), internal basis will be invalidated.
# * the only calls which do NOT invalidate basis are listed below:
#   a) ssasetwindow() with same window length
#   b) ssaappendpointandupdate()
#   c) ssaappendsequenceandupdate()
#   d) ssasetalgotopk...() with exactly same K
#   Calling these functions will result in reuse of previously found basis.
# 
# 
# HANDLING OF DEGENERATE CASES
# 
# Calling  this  function  in  degenerate  cases  (no  data  or all data are
# shorter than window size; no algorithm is specified) returns zeros.
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a, windowwidth = xalglib.ssagetlrr(s)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          1D array/list of float
          windowwidth: int

</div></pre>
<a name='sub_ssasetalgoprecomputed'></a><h3 class=pageheader><code>ssasetalgoprecomputed</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function sets SSA algorithm to &quot;precomputed vectors&quot; algorithm.
# 
# This  algorithm  uses  precomputed  set  of  orthonormal  (orthogonal  AND
# normalized) basis vectors supplied by user. Thus, basis calculation  phase
# is not performed -  we  already  have  our  basis  -  and  only  analysis/
# forecasting phase requires actual calculations.
# 
# This algorithm may handle &quot;append&quot; requests which add just  one/few  ticks
# to the end of the last sequence in O(1) time.
# 
# NOTE: this algorithm accepts both basis and window  width,  because  these
#       two parameters are naturally aligned.  Calling  this  function  sets
#       window width; if you call ssasetwindow() with  other  window  width,
#       then during analysis stage algorithm will detect conflict and  reset
#       to zero basis.
# 
# INPUT PARAMETERS:
#     S               -   SSA model
#     A               -   array[WindowWidth,NBasis], orthonormalized  basis;
#                         this function does NOT control  orthogonality  and
#                         does NOT perform any kind of  renormalization.  It
#                         is your responsibility to provide it with  correct
#                         basis.
#     WindowWidth     -   window width, &gt;=1
#     NBasis          -   number of basis vectors, 1&lt;=NBasis&lt;=WindowWidth
# 
# OUTPUT PARAMETERS:
#     S               -   updated model
# 
# NOTE: calling this function invalidates basis in all cases.
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.ssasetalgoprecomputed(s, a, windowwidth, nbasis)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.ssasetalgoprecomputed(s, a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
          a:          2D array/list of float
          windowwidth: int
          nbasis:     int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_ssasetalgotopkdirect'></a><h3 class=pageheader><code>ssasetalgotopkdirect</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function sets SSA algorithm to &quot;direct top-K&quot; algorithm.
# 
# &quot;Direct top-K&quot; algorithm performs full  SVD  of  the  N*WINDOW  trajectory
# matrix (hence its name - direct solver  is  used),  then  extracts  top  K
# components. Overall running time is O(N*WINDOW^2), where N is a number  of
# ticks in the dataset, WINDOW is window width.
# 
# This algorithm may handle &quot;append&quot; requests which add just  one/few  ticks
# to the end of the last sequence in O(WINDOW^3) time,  which  is  ~N/WINDOW
# times faster than re-computing everything from scratch.
# 
# INPUT PARAMETERS:
#     S               -   SSA model
#     TopK            -   number of components to analyze; TopK&gt;=1.
# 
# OUTPUT PARAMETERS:
#     S               -   updated model
# 
# 
# NOTE: TopK&gt;WindowWidth is silently decreased to WindowWidth during analysis
#       phase
# 
# NOTE: calling this function invalidates basis, except  for  the  situation
#       when this algorithm was already set with same parameters.
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.ssasetalgotopkdirect(s, topk)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
          topk:       int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_ssasetalgotopkrealtime'></a><h3 class=pageheader><code>ssasetalgotopkrealtime</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets SSA algorithm to &quot;top-K real time algorithm&quot;. This algo
# extracts K components with largest singular values.
# 
# It  is  real-time  version  of  top-K  algorithm  which  is  optimized for
# incremental processing and  fast  start-up. Internally  it  uses  subspace
# eigensolver for truncated SVD. It results  in  ability  to  perform  quick
# updates of the basis when only a few points/sequences is added to dataset.
# 
# Performance profile of the algorithm is given below:
# * O(K*WindowWidth^2) running time for incremental update  of  the  dataset
#   with one of the &quot;append-and-update&quot; functions (ssaappendpointandupdate()
#   or ssaappendsequenceandupdate()).
# * O(N*WindowWidth^2) running time for initial basis evaluation (N=size  of
#   dataset)
# * ability  to  split  costly  initialization  across  several  incremental
#   updates of the basis (so called &quot;Power-Up&quot; functionality,  activated  by
#   ssasetpoweruplength() function)
# 
# INPUT PARAMETERS:
#     S               -   SSA model
#     TopK            -   number of components to analyze; TopK&gt;=1.
# 
# OUTPUT PARAMETERS:
#     S               -   updated model
# 
# NOTE: this  algorithm  is  optimized  for  large-scale  tasks  with  large
#       datasets. On toy problems with just  5-10 points it can return basis
#       which is slightly different from that returned by  direct  algorithm
#       (ssasetalgotopkdirect() function). However, the  difference  becomes
#       negligible as dataset grows.
# 
# NOTE: TopK&gt;WindowWidth is silently decreased to WindowWidth during analysis
#       phase
# 
# NOTE: calling this function invalidates basis, except  for  the  situation
#       when this algorithm was already set with same parameters.
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.ssasetalgotopkrealtime(s, topk)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
          topk:       int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_ssasetmemorylimit'></a><h3 class=pageheader><code>ssasetmemorylimit</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets memory limit of SSA analysis.
# 
# Straightforward SSA with sequence length T and window width W needs O(T*W)
# memory. It is possible to reduce memory consumption by splitting task into
# smaller chunks.
# 
# Thus function allows you to specify approximate memory limit (measured  in
# double precision numbers used for buffers). Actual memory consumption will
# be comparable to the number specified by you.
# 
# Default memory limit is 50.000.000 (400Mbytes) in current version.
# 
# INPUT PARAMETERS:
#     S       -   SSA model
#     MemLimit-   memory limit, &gt;=0. Zero value means no limit.
# 
#   -- ALGLIB --
#      Copyright 20.12.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.ssasetmemorylimit(s, memlimit)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
          memlimit:   int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_ssasetpoweruplength'></a><h3 class=pageheader><code>ssasetpoweruplength</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets length of power-up cycle for real-time algorithm.
# 
# By default, this algorithm performs costly O(N*WindowWidth^2)  init  phase
# followed by full run of truncated  EVD.  However,  if  you  are  ready  to
# live with a bit lower-quality basis during first few iterations,  you  can
# split this O(N*WindowWidth^2) initialization  between  several  subsequent
# append-and-update rounds. It results in better latency of the algorithm.
# 
# This function invalidates basis/solver, next analysis call will result  in
# full recalculation of everything.
# 
# INPUT PARAMETERS:
#     S       -   SSA model
#     PWLen   -   length of the power-up stage:
#                 * 0 means that no power-up is requested
#                 * 1 is the same as 0
#                 * &gt;1 means that delayed power-up is performed
# 
#   -- ALGLIB --
#      Copyright 03.11.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.ssasetpoweruplength(s, pwlen)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
          pwlen:      int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_ssasetseed'></a><h3 class=pageheader><code>ssasetseed</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This  function  sets  seed  which  is used to initialize internal RNG when
# we make pseudorandom decisions on model updates.
# 
# By default, deterministic seed is used - which results in same sequence of
# pseudorandom decisions every time you run SSA model. If you  specify  non-
# deterministic seed value, then SSA  model  may  return  slightly different
# results after each run.
# 
# This function can be useful when you have several SSA models updated  with
# sseappendpointandupdate() called with 0&lt;UpdateIts&lt;1 (fractional value) and
# due to performance limitations want them to perform updates  at  different
# moments.
# 
# INPUT PARAMETERS:
#     S       -   SSA model
#     Seed    -   seed:
#                 * positive values = use deterministic seed for each run of
#                   algorithms which depend on random initialization
#                 * zero or negative values = use non-deterministic seed
# 
#   -- ALGLIB --
#      Copyright 03.11.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.ssasetseed(s, seed)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
          seed:       int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_ssasetwindow'></a><h3 class=pageheader><code>ssasetwindow</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This function sets window width for SSA model. You should call  it  before
# analysis phase. Default window width is 1 (not for real use).
# 
# Special notes:
# * this function call can be performed at any moment before  first call  to
#   analysis-related functions
# * changing window width invalidates internally stored basis; if you change
#   window width AFTER you call analysis-related  function,  next  analysis
#   phase will require re-calculation of  the  basis  according  to  current
#   algorithm.
# * calling this function with exactly  same window width as current one has
#   no effect
# * if you specify window width larger  than any data sequence stored in the
#   model, analysis will return zero basis.
# 
# INPUT PARAMETERS:
#     S               -   SSA model created with ssacreate()
#     WindowWidth     -   &gt;=1, new window width
# 
# OUTPUT PARAMETERS:
#     S               -   SSA model, updated
# 
#   -- ALGLIB --
#      Copyright 30.10.2017 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.ssasetwindow(s, windowwidth)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     s:          class xalglib.ssamodel
          windowwidth: int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> s
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name=unit_stest></a><h2 class=pageheader><code>stest</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_onesamplesigntest' class=toc>onesamplesigntest</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_onesamplesigntest'></a><h3 class=pageheader><code>onesamplesigntest</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sign test
# 
# This test checks three hypotheses about the median of  the  given  sample.
# The following tests are performed:
#     * two-tailed test (null hypothesis - the median is equal to the  given
#       value)
#     * left-tailed test (null hypothesis - the median is  greater  than  or
#       equal to the given value)
#     * right-tailed test (null hypothesis - the  median  is  less  than  or
#       equal to the given value)
# 
# Requirements:
#     * the scale of measurement should be ordinal, interval or ratio  (i.e.
#       the test could not be applied to nominal variables).
# 
# The test is non-parametric and doesn't require distribution X to be normal
# 
# Input parameters:
#     X       -   sample. Array whose index goes from 0 to N-1.
#     N       -   size of the sample.
#     Median  -   assumed median value.
# 
# Output parameters:
#     BothTails   -   p-value for two-tailed test.
#                     If BothTails is less than the given significance level
#                     the null hypothesis is rejected.
#     LeftTail    -   p-value for left-tailed test.
#                     If LeftTail is less than the given significance level,
#                     the null hypothesis is rejected.
#     RightTail   -   p-value for right-tailed test.
#                     If RightTail is less than the given significance level
#                     the null hypothesis is rejected.
# 
# While   calculating   p-values   high-precision   binomial    distribution
# approximation is used, so significance levels have about 15 exact digits.
# 
#   -- ALGLIB --
#      Copyright 08.09.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   bothtails, lefttail, righttail = xalglib.onesamplesigntest(x, n, median)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          median:     float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  bothtails:  float
          lefttail:   float
          righttail:  float

</div></pre>
<a name=unit_studenttdistr></a><h2 class=pageheader><code>studenttdistr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_invstudenttdistribution' class=toc>invstudenttdistribution</a><br>
<a href='#sub_studenttdistribution' class=toc>studenttdistribution</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_invstudenttdistribution'></a><h3 class=pageheader><code>invstudenttdistribution</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Functional inverse of Student's t distribution
# 
# Given probability p, finds the argument t such that stdtr(k,t)
# is equal to p.
# 
# ACCURACY:
# 
# Tested at random 1 &lt;= k &lt;= 100.  The &quot;domain&quot; refers to p:
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE    .001,.999     25000       5.7e-15     8.0e-16
#    IEEE    10^-6,.001    25000       2.0e-12     2.9e-14
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.invstudenttdistribution(k, p)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     k:          int
          p:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_studenttdistribution'></a><h3 class=pageheader><code>studenttdistribution</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Student's t distribution
# 
# Computes the integral from minus infinity to t of the Student
# t distribution with integer k &gt; 0 degrees of freedom:
# 
#                                      t
#                                      -
#                                     | |
#              -                      |         2   -(k+1)/2
#             | ( (k+1)/2 )           |  (     x   )
#       ----------------------        |  ( 1 + --- )        dx
#                     -               |  (      k  )
#       sqrt( k pi ) | ( k/2 )        |
#                                   | |
#                                    -
#                                   -inf.
# 
# Relation to incomplete beta integral:
# 
#        1 - stdtr(k,t) = 0.5 * incbet( k/2, 1/2, z )
# where
#        z = k/(k + t**2).
# 
# For t &lt; -2, this is the method of computation.  For higher t,
# a direct method is derived from integration by parts.
# Since the function is symmetric about t=0, the area under the
# right tail of the density is found by calling the function
# with -t instead of t.
# 
# ACCURACY:
# 
# Tested at random 1 &lt;= k &lt;= 25.  The &quot;domain&quot; refers to t.
#                      Relative error:
# arithmetic   domain     # trials      peak         rms
#    IEEE     -100,-2      50000       5.9e-15     1.4e-15
#    IEEE     -2,100      500000       2.7e-15     4.9e-17
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.studenttdistribution(k, t)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     k:          int
          t:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name=unit_studentttests></a><h2 class=pageheader><code>studentttests</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_studentttest1' class=toc>studentttest1</a><br>
<a href='#sub_studentttest2' class=toc>studentttest2</a><br>
<a href='#sub_unequalvariancettest' class=toc>unequalvariancettest</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_studentttest1'></a><h3 class=pageheader><code>studentttest1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# One-sample t-test
# 
# This test checks three hypotheses about the mean of the given sample.  The
# following tests are performed:
#     * two-tailed test (null hypothesis - the mean is equal  to  the  given
#       value)
#     * left-tailed test (null hypothesis - the  mean  is  greater  than  or
#       equal to the given value)
#     * right-tailed test (null hypothesis - the mean is less than or  equal
#       to the given value).
# 
# The test is based on the assumption that  a  given  sample  has  a  normal
# distribution and  an  unknown  dispersion.  If  the  distribution  sharply
# differs from normal, the test will work incorrectly.
# 
# INPUT PARAMETERS:
#     X       -   sample. Array whose index goes from 0 to N-1.
#     N       -   size of sample, N&gt;=0
#     Mean    -   assumed value of the mean.
# 
# OUTPUT PARAMETERS:
#     BothTails   -   p-value for two-tailed test.
#                     If BothTails is less than the given significance level
#                     the null hypothesis is rejected.
#     LeftTail    -   p-value for left-tailed test.
#                     If LeftTail is less than the given significance level,
#                     the null hypothesis is rejected.
#     RightTail   -   p-value for right-tailed test.
#                     If RightTail is less than the given significance level
#                     the null hypothesis is rejected.
# 
# NOTE: this function correctly handles degenerate cases:
#       * when N=0, all p-values are set to 1.0
#       * when variance of X[] is exactly zero, p-values are set
#         to 1.0 or 0.0, depending on difference between sample mean and
#         value of mean being tested.
# 
# 
#   -- ALGLIB --
#      Copyright 08.09.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   bothtails, lefttail, righttail = xalglib.studentttest1(x, n, mean)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          mean:       float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  bothtails:  float
          lefttail:   float
          righttail:  float

</div></pre>
<a name='sub_studentttest2'></a><h3 class=pageheader><code>studentttest2</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Two-sample pooled test
# 
# This test checks three hypotheses about the mean of the given samples. The
# following tests are performed:
#     * two-tailed test (null hypothesis - the means are equal)
#     * left-tailed test (null hypothesis - the mean of the first sample  is
#       greater than or equal to the mean of the second sample)
#     * right-tailed test (null hypothesis - the mean of the first sample is
#       less than or equal to the mean of the second sample).
# 
# Test is based on the following assumptions:
#     * given samples have normal distributions
#     * dispersions are equal
#     * samples are independent.
# 
# Input parameters:
#     X       -   sample 1. Array whose index goes from 0 to N-1.
#     N       -   size of sample.
#     Y       -   sample 2. Array whose index goes from 0 to M-1.
#     M       -   size of sample.
# 
# Output parameters:
#     BothTails   -   p-value for two-tailed test.
#                     If BothTails is less than the given significance level
#                     the null hypothesis is rejected.
#     LeftTail    -   p-value for left-tailed test.
#                     If LeftTail is less than the given significance level,
#                     the null hypothesis is rejected.
#     RightTail   -   p-value for right-tailed test.
#                     If RightTail is less than the given significance level
#                     the null hypothesis is rejected.
# 
# NOTE: this function correctly handles degenerate cases:
#       * when N=0 or M=0, all p-values are set to 1.0
#       * when both samples has exactly zero variance, p-values are set
#         to 1.0 or 0.0, depending on difference between means.
# 
#   -- ALGLIB --
#      Copyright 18.09.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   bothtails, lefttail, righttail = xalglib.studentttest2(x, n, y, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          y:          1D array/list of float
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  bothtails:  float
          lefttail:   float
          righttail:  float

</div></pre>
<a name='sub_unequalvariancettest'></a><h3 class=pageheader><code>unequalvariancettest</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Two-sample unpooled test
# 
# This test checks three hypotheses about the mean of the given samples. The
# following tests are performed:
#     * two-tailed test (null hypothesis - the means are equal)
#     * left-tailed test (null hypothesis - the mean of the first sample  is
#       greater than or equal to the mean of the second sample)
#     * right-tailed test (null hypothesis - the mean of the first sample is
#       less than or equal to the mean of the second sample).
# 
# Test is based on the following assumptions:
#     * given samples have normal distributions
#     * samples are independent.
# Equality of variances is NOT required.
# 
# Input parameters:
#     X - sample 1. Array whose index goes from 0 to N-1.
#     N - size of the sample.
#     Y - sample 2. Array whose index goes from 0 to M-1.
#     M - size of the sample.
# 
# Output parameters:
#     BothTails   -   p-value for two-tailed test.
#                     If BothTails is less than the given significance level
#                     the null hypothesis is rejected.
#     LeftTail    -   p-value for left-tailed test.
#                     If LeftTail is less than the given significance level,
#                     the null hypothesis is rejected.
#     RightTail   -   p-value for right-tailed test.
#                     If RightTail is less than the given significance level
#                     the null hypothesis is rejected.
# 
# NOTE: this function correctly handles degenerate cases:
#       * when N=0 or M=0, all p-values are set to 1.0
#       * when both samples has zero variance, p-values are set
#         to 1.0 or 0.0, depending on difference between means.
#       * when only one sample has zero variance, test reduces to 1-sample
#         version.
# 
#   -- ALGLIB --
#      Copyright 18.09.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   bothtails, lefttail, righttail = xalglib.unequalvariancettest(x, n, y, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          y:          1D array/list of float
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  bothtails:  float
          lefttail:   float
          righttail:  float

</div></pre>
<a name=unit_svd></a><h2 class=pageheader><code>svd</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_rmatrixsvd' class=toc>rmatrixsvd</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_rmatrixsvd'></a><h3 class=pageheader><code>rmatrixsvd</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Singular value decomposition of a rectangular matrix.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
# The algorithm calculates the singular value decomposition of a matrix of
# size MxN: A = U * S * V^T
# 
# The algorithm finds the singular values and, optionally, matrices U and V^T.
# The algorithm can find both first min(M,N) columns of matrix U and rows of
# matrix V^T (singular vectors), and matrices U and V^T wholly (of sizes MxM
# and NxN respectively).
# 
# Take into account that the subroutine does not return matrix V but V^T.
# 
# Input parameters:
#     A           -   matrix to be decomposed.
#                     Array whose indexes range within [0..M-1, 0..N-1].
#     M           -   number of rows in matrix A.
#     N           -   number of columns in matrix A.
#     UNeeded     -   0, 1 or 2. See the description of the parameter U.
#     VTNeeded    -   0, 1 or 2. See the description of the parameter VT.
#     AdditionalMemory -
#                     If the parameter:
#                      * equals 0, the algorithm doesn't use additional
#                        memory (lower requirements, lower performance).
#                      * equals 1, the algorithm uses additional
#                        memory of size min(M,N)*min(M,N) of real numbers.
#                        It often speeds up the algorithm.
#                      * equals 2, the algorithm uses additional
#                        memory of size M*min(M,N) of real numbers.
#                        It allows to get a maximum performance.
#                     The recommended value of the parameter is 2.
# 
# Output parameters:
#     W           -   contains singular values in descending order.
#     U           -   if UNeeded=0, U isn't changed, the left singular vectors
#                     are not calculated.
#                     if Uneeded=1, U contains left singular vectors (first
#                     min(M,N) columns of matrix U). Array whose indexes range
#                     within [0..M-1, 0..Min(M,N)-1].
#                     if UNeeded=2, U contains matrix U wholly. Array whose
#                     indexes range within [0..M-1, 0..M-1].
#     VT          -   if VTNeeded=0, VT isn't changed, the right singular vectors
#                     are not calculated.
#                     if VTNeeded=1, VT contains right singular vectors (first
#                     min(M,N) rows of matrix V^T). Array whose indexes range
#                     within [0..min(M,N)-1, 0..N-1].
#                     if VTNeeded=2, VT contains matrix V^T wholly. Array whose
#                     indexes range within [0..N-1, 0..N-1].
# 
#   -- ALGLIB --
#      Copyright 2005 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, w, u, vt = xalglib.rmatrixsvd(a, m, n, uneeded, vtneeded, additionalmemory)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          m:          int
          n:          int
          uneeded:    int
          vtneeded:   int
          additionalmemory: int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          w:          1D array/list of float
          u:          2D array/list of float
          vt:         2D array/list of float

</div></pre>
<a name=unit_trfac></a><h2 class=pageheader><code>trfac</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cmatrixlu' class=toc>cmatrixlu</a><br>
<a href='#sub_hpdmatrixcholesky' class=toc>hpdmatrixcholesky</a><br>
<a href='#sub_rmatrixlu' class=toc>rmatrixlu</a><br>
<a href='#sub_sparsecholesky' class=toc>sparsecholesky</a><br>
<a href='#sub_sparsecholeskyanalyze' class=toc>sparsecholeskyanalyze</a><br>
<a href='#sub_sparsecholeskyfactorize' class=toc>sparsecholeskyfactorize</a><br>
<a href='#sub_sparsecholeskyp' class=toc>sparsecholeskyp</a><br>
<a href='#sub_sparsecholeskyreload' class=toc>sparsecholeskyreload</a><br>
<a href='#sub_sparsecholeskyskyline' class=toc>sparsecholeskyskyline</a><br>
<a href='#sub_sparselu' class=toc>sparselu</a><br>
<a href='#sub_spdmatrixcholesky' class=toc>spdmatrixcholesky</a><br>
<a href='#sub_spdmatrixcholeskyupdateadd1' class=toc>spdmatrixcholeskyupdateadd1</a><br>
<a href='#sub_spdmatrixcholeskyupdateadd1buf' class=toc>spdmatrixcholeskyupdateadd1buf</a><br>
<a href='#sub_spdmatrixcholeskyupdatefix' class=toc>spdmatrixcholeskyupdatefix</a><br>
<a href='#sub_spdmatrixcholeskyupdatefixbuf' class=toc>spdmatrixcholeskyupdatefixbuf</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_cmatrixlu'></a><h3 class=pageheader><code>cmatrixlu</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# LU decomposition of a general complex matrix with row pivoting
# 
# A is represented as A = P*L*U, where:
# * L is lower unitriangular matrix
# * U is upper triangular matrix
# * P = P0*P1*...*PK, K=min(M,N)-1,
#   Pi - permutation matrix for I and Pivots[I]
# 
# INPUT PARAMETERS:
#     A       -   array[0..M-1, 0..N-1].
#     M       -   number of rows in matrix A.
#     N       -   number of columns in matrix A.
# 
# 
# OUTPUT PARAMETERS:
#     A       -   matrices L and U in compact form:
#                 * L is stored under main diagonal
#                 * U is stored on and above main diagonal
#     Pivots  -   permutation matrix in compact form.
#                 array[0..Min(M-1,N-1)].
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      10.01.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   pivots = xalglib.cmatrixlu(a, m, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   pivots = xalglib.cmatrixlu(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  pivots:     1D array/list of int

</div></pre>
<a name='sub_hpdmatrixcholesky'></a><h3 class=pageheader><code>hpdmatrixcholesky</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Cache-oblivious Cholesky decomposition
# 
# The algorithm computes Cholesky decomposition  of  a  Hermitian  positive-
# definite matrix. The result of an algorithm is a representation  of  A  as
# A=U'*U  or A=L*L' (here X' denotes conj(X^T)).
# 
# INPUT PARAMETERS:
#     A       -   upper or lower triangle of a factorized matrix.
#                 array with elements [0..N-1, 0..N-1].
#     N       -   size of matrix A.
#     IsUpper -   if IsUpper=True, then A contains an upper triangle of
#                 a symmetric matrix, otherwise A contains a lower one.
# 
# OUTPUT PARAMETERS:
#     A       -   the result of factorization. If IsUpper=True, then
#                 the upper triangle contains matrix U, so that A = U'*U,
#                 and the elements below the main diagonal are not modified.
#                 Similarly, if IsUpper = False.
# 
# RESULT:
#     If  the  matrix  is  positive-definite,  the  function  returns  True.
#     Otherwise, the function returns False. Contents of A is not determined
#     in such case.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      15.12.2009-22.01.2018
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hpdmatrixcholesky(a, n, isupper)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.hpdmatrixcholesky(a, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
          n:          int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_rmatrixlu'></a><h3 class=pageheader><code>rmatrixlu</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# LU decomposition of a general real matrix with row pivoting
# 
# A is represented as A = P*L*U, where:
# * L is lower unitriangular matrix
# * U is upper triangular matrix
# * P = P0*P1*...*PK, K=min(M,N)-1,
#   Pi - permutation matrix for I and Pivots[I]
# 
# INPUT PARAMETERS:
#     A       -   array[0..M-1, 0..N-1].
#     M       -   number of rows in matrix A.
#     N       -   number of columns in matrix A.
# 
# 
# OUTPUT PARAMETERS:
#     A       -   matrices L and U in compact form:
#                 * L is stored under main diagonal
#                 * U is stored on and above main diagonal
#     Pivots  -   permutation matrix in compact form.
#                 array[0..Min(M-1,N-1)].
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      10.01.2010
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   pivots = xalglib.rmatrixlu(a, m, n)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   pivots = xalglib.rmatrixlu(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  pivots:     1D array/list of int

</div></pre>
<a name='sub_sparsecholesky'></a><h3 class=pageheader><code>sparsecholesky</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sparse Cholesky decomposition for a matrix  stored  in  any sparse storage,
# without rows/cols permutation.
# 
# This function is the most convenient (less parameters to specify), although
# the less efficient, version of sparse Cholesky.
# 
# IMPORTANT: the commercial edition of ALGLIB can parallelize this function.
#            Specific speed-up due  to  parallelism  heavily  depends  on  a
#            sparsity pattern, with the following matrix classes  being  the
#            easiest ones to parallelize:
#            * large matrices with many nearly-independent sets of rows/cols
#            * matrices with large dense blocks on the diagonal
#            See the ALGLIB Reference Manual for more information on how  to
#            activate parallelism support.
# 
# Internally it:
# * calls SparseCholeskyAnalyze()  function  to  perform  symbolic  analysis
#   phase with no permutation being configured.
# * calls SparseCholeskyFactorize() function to perform numerical  phase  of
#   the factorization
# 
# Following alternatives may result in better performance:
# * using SparseCholeskyP(), which selects best  pivoting  available,  which
#   almost always results in improved sparsity and cache locality
# * using  SparseCholeskyAnalyze() and SparseCholeskyFactorize()   functions
#   directly,  which  may  improve  performance of repetitive factorizations
#   with same sparsity patterns.
# 
# The latter also allows one to perform  LDLT  factorization  of  indefinite
# matrix (one with strictly diagonal D, which is known  to  be  stable  only
# in few special cases, like quasi-definite matrices).
# 
# INPUT PARAMETERS:
#     A       -   a square NxN sparse matrix, stored in any storage format.
#     IsUpper -   if IsUpper=True, then factorization is performed on  upper
#                 triangle.  Another triangle is ignored on  input,  dropped
#                 on output. Similarly, if IsUpper=False, the lower triangle
#                 is processed.
# 
# OUTPUT PARAMETERS:
#     A       -   the result of factorization, stored in CRS format:
#                 * if IsUpper=True, then the upper triangle contains matrix
#                   U such  that  A = U^T*U and the lower triangle is empty.
#                 * similarly, if IsUpper=False, then lower triangular L  is
#                   returned and we have A = L*(L^T).
#                 Note that THIS function does not  perform  permutation  of
#                 the rows to reduce fill-in.
# 
# RESULT:
#     If  the  matrix  is  positive-definite,  the  function  returns  True.
#     Otherwise, the function returns False.  Contents  of  A  is  undefined
#     in such case.
# 
# NOTE: for  performance  reasons  this  function  does NOT check that input
#       matrix  includes  only  finite  values. It is your responsibility to
#       make sure that there are no infinite or NAN values in the matrix.
# 
#   -- ALGLIB routine --
#      16.09.2020
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sparsecholesky(a, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_sparsecholeskyanalyze'></a><h3 class=pageheader><code>sparsecholeskyanalyze</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sparse Cholesky/LDLT decomposition: symbolic analysis phase.
# 
# This function is a part of the 'expert' sparse Cholesky API:
# * SparseCholeskyAnalyze(), that performs symbolic analysis phase and loads
#   matrix to be factorized into internal storage
# * SparseCholeskySetModType(), that allows to  use  modified  Cholesky/LDLT
#   with lower bounds on pivot magnitudes and additional overflow safeguards
# * SparseCholeskyFactorize(),  that performs  numeric  factorization  using
#   precomputed symbolic analysis and internally stored matrix - and outputs
#   result
# * SparseCholeskyReload(), that reloads one more matrix with same  sparsity
#   pattern into internal storage so  one  may  reuse  previously  allocated
#   temporaries and previously performed symbolic analysis
# 
# This specific function performs preliminary analysis of the  Cholesky/LDLT
# factorization. It allows to choose  different  permutation  types  and  to
# choose between classic Cholesky and  indefinite  LDLT  factorization  (the
# latter is computed with strictly diagonal D, i.e.  without  Bunch-Kauffman
# pivoting).
# 
# NOTE: L*D*LT family of factorization may be used to  factorize  indefinite
#       matrices. However, numerical stability is guaranteed ONLY for a class
#       of quasi-definite matrices.
# 
# NOTE: all internal processing is performed with lower triangular  matrices
#       stored  in  CRS  format.  Any  other  storage  formats  and/or upper
#       triangular storage means  that  one  format  conversion  and/or  one
#       transposition will be performed  internally  for  the  analysis  and
#       factorization phases. Thus, highest  performance  is  achieved  when
#       input is a lower triangular CRS matrix.
# 
# INPUT PARAMETERS:
#     A           -   sparse square matrix in any sparse storage format.
#     IsUpper     -   whether upper or lower  triangle  is  decomposed  (the
#                     other one is ignored).
#     FactType    -   factorization type:
#                     * 0 for traditional Cholesky of SPD matrix
#                     * 1 for LDLT decomposition with strictly  diagonal  D,
#                         which may have non-positive entries.
#     PermType    -   permutation type:
#                     *-1 for absence of permutation
#                     * 0 for best fill-in reducing  permutation  available,
#                         which is 3 in the current version
#                     * 1 for supernodal ordering (improves locality and
#                       performance, does NOT change fill-in factor)
#                     * 2 for original AMD ordering
#                     * 3 for  improved  AMD  (approximate  minimum  degree)
#                         ordering with better  handling  of  matrices  with
#                         dense rows/columns
# 
# OUTPUT PARAMETERS:
#     Analysis    -   contains:
#                     * symbolic analysis of the matrix structure which will
#                       be used later to guide numerical factorization.
#                     * specific numeric values loaded into internal  memory
#                       waiting for the factorization to be performed
# 
# This function fails if and only if the matrix A is symbolically degenerate
# i.e. has diagonal element which is exactly zero. In  such  case  False  is
# returned, contents of Analysis object is undefined.
# 
#   -- ALGLIB routine --
#      20.09.2020
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, analysis = xalglib.sparsecholeskyanalyze(a, isupper, facttype, permtype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          isupper:    bool
          facttype:   int
          permtype:   int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          analysis:   class xalglib.sparsedecompositionanalysis

</div></pre>
<a name='sub_sparsecholeskyfactorize'></a><h3 class=pageheader><code>sparsecholeskyfactorize</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sparse Cholesky decomposition: numerical analysis phase.
# 
# IMPORTANT: the commercial edition of ALGLIB can parallelize this function.
#            Specific speed-up due  to  parallelism  heavily  depends  on  a
#            sparsity pattern, with the following matrix classes  being  the
#            easiest ones to parallelize:
#            * large matrices with many nearly-independent sets of rows/cols
#            * matrices with large dense blocks on the diagonal
#            See the ALGLIB Reference Manual for more information on how  to
#            activate parallelism support.
# 
# This function is a part of the 'expert' sparse Cholesky API:
# * SparseCholeskyAnalyze(), that performs symbolic analysis phase and loads
#   matrix to be factorized into internal storage
# * SparseCholeskySetModType(), that allows to  use  modified  Cholesky/LDLT
#   with lower bounds on pivot magnitudes and additional overflow safeguards
# * SparseCholeskyFactorize(),  that performs  numeric  factorization  using
#   precomputed symbolic analysis and internally stored matrix - and outputs
#   result
# * SparseCholeskyReload(), that reloads one more matrix with same  sparsity
#   pattern into internal storage so  one  may  reuse  previously  allocated
#   temporaries and previously performed symbolic analysis
# 
# Depending on settings specified during SparseCholeskyAnalyze() call it may
# produce classic Cholesky or L*D*LT  decomposition  (with strictly diagonal
# D), without permutation or with performance-enhancing permutation P.
# 
# NOTE: all internal processing is performed with lower triangular  matrices
#       stored  in  CRS  format.  Any  other  storage  formats  and/or upper
#       triangular storage means  that  one  format  conversion  and/or  one
#       transposition will be performed  internally  for  the  analysis  and
#       factorization phases. Thus, highest  performance  is  achieved  when
#       input is a lower triangular CRS matrix, and lower triangular  output
#       is requested.
# 
# NOTE: L*D*LT family of factorization may be used to  factorize  indefinite
#       matrices. However, numerical stability is guaranteed ONLY for a class
#       of quasi-definite matrices.
# 
# INPUT PARAMETERS:
#     Analysis    -   prior analysis with internally stored matrix which will
#                     be factorized
#     NeedUpper   -   whether upper triangular or lower triangular output is
#                     needed
# 
# OUTPUT PARAMETERS:
#     A           -   Cholesky decomposition of A stored in lower triangular
#                     CRS format, i.e. A=L*L' (or upper triangular CRS, with
#                     A=U'*U, depending on NeedUpper parameter).
#     D           -   array[N], diagonal factor. If no diagonal  factor  was
#                     required during analysis  phase,  still  returned  but
#                     filled with 1's
#     P           -   array[N], pivots. Permutation matrix P is a product of
#                     P(0)*P(1)*...*P(N-1), where P(i) is a  permutation  of
#                     row/col I and P[I] (with P[I]&gt;=I).
#                     If no permutation was requested during analysis phase,
#                     still returned but filled with identity permutation.
# 
# The function returns True  when  factorization  resulted  in nondegenerate
# matrix. False is returned when factorization fails (Cholesky factorization
# of indefinite matrix) or LDLT factorization has exactly zero  elements  at
# the diagonal. In the latter case contents of A, D and P is undefined.
# 
# The analysis object is not changed during  the  factorization.  Subsequent
# calls to SparseCholeskyFactorize() will result in same factorization being
# performed one more time.
# 
#   -- ALGLIB routine --
#      20.09.2020
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, a, d, p = xalglib.sparsecholeskyfactorize(analysis, needupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     analysis:   class xalglib.sparsedecompositionanalysis
          needupper:  bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> analysis
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          a:          class xalglib.sparsematrix
          d:          1D array/list of float
          p:          1D array/list of int

</div></pre>
<a name='sub_sparsecholeskyp'></a><h3 class=pageheader><code>sparsecholeskyp</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sparse Cholesky decomposition for a matrix  stored  in  any sparse storage
# format, with performance-enhancing permutation of rows/cols.
# 
# Present version is configured  to  perform  supernodal  permutation   with
# a sparsity reducing ordering.
# 
# IMPORTANT: the commercial edition of ALGLIB can parallelize this function.
#            Specific speed-up due  to  parallelism  heavily  depends  on  a
#            sparsity pattern, with the following matrix classes  being  the
#            easiest ones to parallelize:
#            * large matrices with many nearly-independent sets of rows/cols
#            * matrices with large dense blocks on the diagonal
#            See the ALGLIB Reference Manual for more information on how  to
#            activate parallelism support.
# 
# This function is a wrapper around generic sparse  decomposition  functions
# that internally:
# * calls SparseCholeskyAnalyze()  function  to  perform  symbolic  analysis
#   phase with best available permutation being configured.
# * calls SparseCholeskyFactorize() function to perform numerical  phase  of
#   the factorization.
# 
# NOTE: using  SparseCholeskyAnalyze() and SparseCholeskyFactorize() directly
#       may improve  performance  of  repetitive  factorizations  with  same
#       sparsity patterns. It also allows one to perform  LDLT factorization
#       of  indefinite  matrix  -  a factorization with strictly diagonal D,
#       which  is  known to be stable only in few special cases, like quasi-
#       definite matrices.
# 
# INPUT PARAMETERS:
#     A       -   a square NxN sparse matrix, stored in any storage format.
#     IsUpper -   if IsUpper=True, then factorization is performed on  upper
#                 triangle.  Another triangle is ignored on  input,  dropped
#                 on output. Similarly, if IsUpper=False, the lower triangle
#                 is processed.
# 
# OUTPUT PARAMETERS:
#     A       -   the result of factorization, stored in CRS format:
#                 * if IsUpper=True, then the upper triangle contains matrix
#                   U such  that  A = U^T*U and the lower triangle is empty.
#                 * similarly, if IsUpper=False, then lower triangular L  is
#                   returned and we have A = L*(L^T).
#     P       -   a row/column permutation, a product of P0*P1*...*Pk, k=N-1,
#                 with Pi being permutation of rows/cols I and P[I]
# 
# RESULT:
#     If  the  matrix  is  positive-definite,  the  function  returns  True.
#     Otherwise, the function returns False.  Contents  of  A  is  undefined
#     in such case.
# 
# NOTE: for  performance  reasons  this  function  does NOT check that input
#       matrix  includes  only  finite  values. It is your responsibility to
#       make sure that there are no infinite or NAN values in the matrix.
# 
#   -- ALGLIB routine --
#      16.09.2020
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, p = xalglib.sparsecholeskyp(a, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          p:          1D array/list of int

</div></pre>
<a name='sub_sparsecholeskyreload'></a><h3 class=pageheader><code>sparsecholeskyreload</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sparse  Cholesky  decomposition:  update  internally  stored  matrix  with
# another one with exactly same sparsity pattern.
# 
# This function is a part of the 'expert' sparse Cholesky API:
# * SparseCholeskyAnalyze(), that performs symbolic analysis phase and loads
#   matrix to be factorized into internal storage
# * SparseCholeskySetModType(), that allows to  use  modified  Cholesky/LDLT
#   with lower bounds on pivot magnitudes and additional overflow safeguards
# * SparseCholeskyFactorize(),  that performs  numeric  factorization  using
#   precomputed symbolic analysis and internally stored matrix - and outputs
#   result
# * SparseCholeskyReload(), that reloads one more matrix with same  sparsity
#   pattern into internal storage so  one  may  reuse  previously  allocated
#   temporaries and previously performed symbolic analysis
# 
# This specific function replaces internally stored  numerical  values  with
# ones from another sparse matrix (but having exactly same sparsity  pattern
# as one that was used for initial SparseCholeskyAnalyze() call).
# 
# NOTE: all internal processing is performed with lower triangular  matrices
#       stored  in  CRS  format.  Any  other  storage  formats  and/or upper
#       triangular storage means  that  one  format  conversion  and/or  one
#       transposition will be performed  internally  for  the  analysis  and
#       factorization phases. Thus, highest  performance  is  achieved  when
#       input is a lower triangular CRS matrix.
# 
# INPUT PARAMETERS:
#     Analysis    -   analysis object
#     A           -   sparse square matrix in any sparse storage format.  It
#                     MUST have exactly same sparsity pattern as that of the
#                     matrix that was passed to SparseCholeskyAnalyze().
#                     Any difference (missing elements or additional elements)
#                     may result in unpredictable and undefined  behavior  -
#                     an algorithm may fail due to memory access violation.
#     IsUpper     -   whether upper or lower  triangle  is  decomposed  (the
#                     other one is ignored).
# 
# OUTPUT PARAMETERS:
#     Analysis    -   contains:
#                     * symbolic analysis of the matrix structure which will
#                       be used later to guide numerical factorization.
#                     * specific numeric values loaded into internal  memory
#                       waiting for the factorization to be performed
# 
#   -- ALGLIB routine --
#      20.09.2020
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.sparsecholeskyreload(analysis, a, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     analysis:   class xalglib.sparsedecompositionanalysis
          a:          class xalglib.sparsematrix
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> analysis
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_sparsecholeskyskyline'></a><h3 class=pageheader><code>sparsecholeskyskyline</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sparse Cholesky decomposition for skyline matrixm using in-place algorithm
# without allocating additional storage.
# 
# The algorithm computes Cholesky decomposition  of  a  symmetric  positive-
# definite sparse matrix. The result of an algorithm is a representation  of
# A as A=U^T*U or A=L*L^T
# 
# This function allows to perform very efficient decomposition of low-profile
# matrices (average bandwidth is ~5-10 elements). For larger matrices it  is
# recommended to use supernodal Cholesky decomposition: SparseCholeskyP() or
# SparseCholeskyAnalyze()/SparseCholeskyFactorize().
# 
# INPUT PARAMETERS:
#     A       -   sparse matrix in skyline storage (SKS) format.
#     N       -   size of matrix A (can be smaller than actual size of A)
#     IsUpper -   if IsUpper=True, then factorization is performed on  upper
#                 triangle. Another triangle is ignored (it may contant some
#                 data, but it is not changed).
# 
# 
# OUTPUT PARAMETERS:
#     A       -   the result of factorization, stored in SKS. If IsUpper=True,
#                 then the upper  triangle  contains  matrix  U,  such  that
#                 A = U^T*U. Lower triangle is not changed.
#                 Similarly, if IsUpper = False. In this case L is returned,
#                 and we have A = L*(L^T).
#                 Note that THIS function does not  perform  permutation  of
#                 rows to reduce bandwidth.
# 
# RESULT:
#     If  the  matrix  is  positive-definite,  the  function  returns  True.
#     Otherwise, the function returns False. Contents of A is not determined
#     in such case.
# 
# NOTE: for  performance  reasons  this  function  does NOT check that input
#       matrix  includes  only  finite  values. It is your responsibility to
#       make sure that there are no infinite or NAN values in the matrix.
# 
#   -- ALGLIB routine --
#      16.01.2014
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.sparsecholeskyskyline(a, n, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          n:          int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_sparselu'></a><h3 class=pageheader><code>sparselu</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sparse LU decomposition with column pivoting for sparsity and row pivoting
# for stability. Input must be square sparse matrix stored in CRS format.
# 
# The algorithm  computes  LU  decomposition  of  a  general  square  matrix
# (rectangular ones are not supported). The result  of  an  algorithm  is  a
# representation of A as A = P*L*U*Q, where:
# * L is lower unitriangular matrix
# * U is upper triangular matrix
# * P = P0*P1*...*PK, K=N-1, Pi - permutation matrix for I and P[I]
# * Q = QK*...*Q1*Q0, K=N-1, Qi - permutation matrix for I and Q[I]
# 
# This function pivots columns for higher sparsity, and then pivots rows for
# stability (larger element at the diagonal).
# 
# INPUT PARAMETERS:
#     A       -   sparse NxN matrix in CRS format. An exception is generated
#                 if matrix is non-CRS or non-square.
#     PivotType-  pivoting strategy:
#                 * 0 for best pivoting available (2 in current version)
#                 * 1 for row-only pivoting (NOT RECOMMENDED)
#                 * 2 for complete pivoting which produces most sparse outputs
# 
# OUTPUT PARAMETERS:
#     A       -   the result of factorization, matrices L and U stored in
#                 compact form using CRS sparse storage format:
#                 * lower unitriangular L is stored strictly under main diagonal
#                 * upper triangilar U is stored ON and ABOVE main diagonal
#     P       -   row permutation matrix in compact form, array[N]
#     Q       -   col permutation matrix in compact form, array[N]
# 
# This function always succeeds, i.e. it ALWAYS returns valid factorization,
# but for your convenience it also returns  boolean  value  which  helps  to
# detect symbolically degenerate matrices:
# * function returns TRUE, if the matrix was factorized AND symbolically
#   non-degenerate
# * function returns FALSE, if the matrix was factorized but U has strictly
#   zero elements at the diagonal (the factorization is returned anyway).
# 
# 
#   -- ALGLIB routine --
#      03.09.2018
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result, p, q = xalglib.sparselu(a, pivottype)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          class xalglib.sparsematrix
          pivottype:  int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool
          p:          1D array/list of int
          q:          1D array/list of int

</div></pre>
<a name='sub_spdmatrixcholesky'></a><h3 class=pageheader><code>spdmatrixcholesky</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Cache-oblivious Cholesky decomposition
# 
# The algorithm computes Cholesky decomposition  of  a  symmetric  positive-
# definite matrix. The result of an algorithm is a representation  of  A  as
# A=U^T*U  or A=L*L^T
# 
# INPUT PARAMETERS:
#     A       -   upper or lower triangle of a factorized matrix.
#                 array with elements [0..N-1, 0..N-1].
#     N       -   size of matrix A.
#     IsUpper -   if IsUpper=True, then A contains an upper triangle of
#                 a symmetric matrix, otherwise A contains a lower one.
# 
# OUTPUT PARAMETERS:
#     A       -   the result of factorization. If IsUpper=True, then
#                 the upper triangle contains matrix U, so that A = U^T*U,
#                 and the elements below the main diagonal are not modified.
#                 Similarly, if IsUpper = False.
# 
# RESULT:
#     If  the  matrix  is  positive-definite,  the  function  returns  True.
#     Otherwise, the function returns False. Contents of A is not determined
#     in such case.
# 
#   ! FREE EDITION OF ALGLIB:
#   !
#   ! Free Edition of ALGLIB supports following important features for  this
#   ! function:
#   ! * C++ version: x64 SIMD support using C++ intrinsics
#   ! * C#  version: x64 SIMD support using NET5/NetCore hardware intrinsics
#   !
#   ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB
#   ! Reference Manual in order  to  find  out  how to activate SIMD support
#   ! in ALGLIB.
# 
#   ! COMMERCIAL EDITION OF ALGLIB:
#   !
#   ! Commercial Edition of ALGLIB includes following important improvements
#   ! of this function:
#   ! * high-performance native backend with same C# interface (C# version)
#   ! * multithreading support (C++ and C# versions)
#   ! * hardware vendor (Intel) implementations of linear algebra primitives
#   !   (C++ and C# versions, x86/x64 platform)
#   !
#   ! We recommend you to read 'Working with commercial version' section  of
#   ! ALGLIB Reference Manual in order to find out how to  use  performance-
#   ! related features provided by commercial edition of ALGLIB.
# 
#   -- ALGLIB routine --
#      15.12.2009
#      Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixcholesky(a, n, isupper)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.spdmatrixcholesky(a, isupper)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     bool

</div></pre>
<a name='sub_spdmatrixcholeskyupdateadd1'></a><h3 class=pageheader><code>spdmatrixcholeskyupdateadd1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Update of Cholesky decomposition: rank-1 update to original A.  &quot;Buffered&quot;
# version which uses preallocated buffer which is saved  between  subsequent
# function calls.
# 
# This function uses internally allocated buffer which is not saved  between
# subsequent  calls.  So,  if  you  perform  a lot  of  subsequent  updates,
# we  recommend   you   to   use   &quot;buffered&quot;   version   of  this function:
# SPDMatrixCholeskyUpdateAdd1Buf().
# 
# INPUT PARAMETERS:
#     A       -   upper or lower Cholesky factor.
#                 array with elements [0..N-1, 0..N-1].
#                 Exception is thrown if array size is too small.
#     N       -   size of matrix A, N&gt;0
#     IsUpper -   if IsUpper=True, then A contains  upper  Cholesky  factor;
#                 otherwise A contains a lower one.
#     U       -   array[N], rank-1 update to A: A_mod = A + u*u'
#                 Exception is thrown if array size is too small.
# 
# OUTPUT PARAMETERS:
#     A       -   updated factorization.  If  IsUpper=True,  then  the  upper
#                 triangle contains matrix U, and the elements below the main
#                 diagonal are not modified. Similarly, if IsUpper = False.
# 
# NOTE: this function always succeeds, so it does not return completion code
# 
# NOTE: this function checks sizes of input arrays, but it does  NOT  checks
#       for presence of infinities or NAN's.
# 
#   -- ALGLIB --
#      03.02.2014
#      Sergey Bochkanov
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spdmatrixcholeskyupdateadd1(a, n, isupper, u)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spdmatrixcholeskyupdateadd1(a, isupper, u)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
          u:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spdmatrixcholeskyupdateadd1buf'></a><h3 class=pageheader><code>spdmatrixcholeskyupdateadd1buf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Update of Cholesky decomposition: rank-1 update to original A.  &quot;Buffered&quot;
# version which uses preallocated buffer which is saved  between  subsequent
# function calls.
# 
# See comments for SPDMatrixCholeskyUpdateAdd1() for more information.
# 
# INPUT PARAMETERS:
#     A       -   upper or lower Cholesky factor.
#                 array with elements [0..N-1, 0..N-1].
#                 Exception is thrown if array size is too small.
#     N       -   size of matrix A, N&gt;0
#     IsUpper -   if IsUpper=True, then A contains  upper  Cholesky  factor;
#                 otherwise A contains a lower one.
#     U       -   array[N], rank-1 update to A: A_mod = A + u*u'
#                 Exception is thrown if array size is too small.
#     BufR    -   possibly preallocated  buffer;  automatically  resized  if
#                 needed. It is recommended to  reuse  this  buffer  if  you
#                 perform a lot of subsequent decompositions.
# 
# OUTPUT PARAMETERS:
#     A       -   updated factorization.  If  IsUpper=True,  then  the  upper
#                 triangle contains matrix U, and the elements below the main
#                 diagonal are not modified. Similarly, if IsUpper = False.
# 
#   -- ALGLIB --
#      03.02.2014
#      Sergey Bochkanov
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   bufr = xalglib.spdmatrixcholeskyupdateadd1buf(a, n, isupper, u, bufr)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
          u:          1D array/list of float
          bufr:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  bufr:       1D array/list of float

</div></pre>
<a name='sub_spdmatrixcholeskyupdatefix'></a><h3 class=pageheader><code>spdmatrixcholeskyupdatefix</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Update of Cholesky decomposition: &quot;fixing&quot; some variables.
# 
# This function uses internally allocated buffer which is not saved  between
# subsequent  calls.  So,  if  you  perform  a lot  of  subsequent  updates,
# we  recommend   you   to   use   &quot;buffered&quot;   version   of  this function:
# SPDMatrixCholeskyUpdateFixBuf().
# 
# &quot;FIXING&quot; EXPLAINED:
# 
#     Suppose we have N*N positive definite matrix A. &quot;Fixing&quot; some variable
#     means filling corresponding row/column of  A  by  zeros,  and  setting
#     diagonal element to 1.
# 
#     For example, if we fix 2nd variable in 4*4 matrix A, it becomes Af:
# 
#         ( A00  A01  A02  A03 )      ( Af00  0   Af02 Af03 )
#         ( A10  A11  A12  A13 )      (  0    1    0    0   )
#         ( A20  A21  A22  A23 )  =&gt;  ( Af20  0   Af22 Af23 )
#         ( A30  A31  A32  A33 )      ( Af30  0   Af32 Af33 )
# 
#     If we have Cholesky decomposition of A, it must be recalculated  after
#     variables were  fixed.  However,  it  is  possible  to  use  efficient
#     algorithm, which needs O(K*N^2)  time  to  &quot;fix&quot;  K  variables,  given
#     Cholesky decomposition of original, &quot;unfixed&quot; A.
# 
# INPUT PARAMETERS:
#     A       -   upper or lower Cholesky factor.
#                 array with elements [0..N-1, 0..N-1].
#                 Exception is thrown if array size is too small.
#     N       -   size of matrix A, N&gt;0
#     IsUpper -   if IsUpper=True, then A contains  upper  Cholesky  factor;
#                 otherwise A contains a lower one.
#     Fix     -   array[N], I-th element is True if I-th  variable  must  be
#                 fixed. Exception is thrown if array size is too small.
#     BufR    -   possibly preallocated  buffer;  automatically  resized  if
#                 needed. It is recommended to  reuse  this  buffer  if  you
#                 perform a lot of subsequent decompositions.
# 
# OUTPUT PARAMETERS:
#     A       -   updated factorization.  If  IsUpper=True,  then  the  upper
#                 triangle contains matrix U, and the elements below the main
#                 diagonal are not modified. Similarly, if IsUpper = False.
# 
# NOTE: this function always succeeds, so it does not return completion code
# 
# NOTE: this function checks sizes of input arrays, but it does  NOT  checks
#       for presence of infinities or NAN's.
# 
# NOTE: this  function  is  efficient  only  for  moderate amount of updated
#       variables - say, 0.1*N or 0.3*N. For larger amount of  variables  it
#       will  still  work,  but  you  may  get   better   performance   with
#       straightforward Cholesky.
# 
#   -- ALGLIB --
#      03.02.2014
#      Sergey Bochkanov
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spdmatrixcholeskyupdatefix(a, n, isupper, fix)
<span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.spdmatrixcholeskyupdatefix(a, isupper, fix)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
          fix:        1D array/list of bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_spdmatrixcholeskyupdatefixbuf'></a><h3 class=pageheader><code>spdmatrixcholeskyupdatefixbuf</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Update of Cholesky  decomposition:  &quot;fixing&quot;  some  variables.  &quot;Buffered&quot;
# version which uses preallocated buffer which is saved  between  subsequent
# function calls.
# 
# See comments for SPDMatrixCholeskyUpdateFix() for more information.
# 
# INPUT PARAMETERS:
#     A       -   upper or lower Cholesky factor.
#                 array with elements [0..N-1, 0..N-1].
#                 Exception is thrown if array size is too small.
#     N       -   size of matrix A, N&gt;0
#     IsUpper -   if IsUpper=True, then A contains  upper  Cholesky  factor;
#                 otherwise A contains a lower one.
#     Fix     -   array[N], I-th element is True if I-th  variable  must  be
#                 fixed. Exception is thrown if array size is too small.
#     BufR    -   possibly preallocated  buffer;  automatically  resized  if
#                 needed. It is recommended to  reuse  this  buffer  if  you
#                 perform a lot of subsequent decompositions.
# 
# OUTPUT PARAMETERS:
#     A       -   updated factorization.  If  IsUpper=True,  then  the  upper
#                 triangle contains matrix U, and the elements below the main
#                 diagonal are not modified. Similarly, if IsUpper = False.
# 
#   -- ALGLIB --
#      03.02.2014
#      Sergey Bochkanov
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   bufr = xalglib.spdmatrixcholeskyupdatefixbuf(a, n, isupper, fix, bufr)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
          n:          int
          isupper:    bool
          fix:        1D array/list of bool
          bufr:       1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  bufr:       1D array/list of float

</div></pre>
<a name=unit_trigintegrals></a><h2 class=pageheader><code>trigintegrals</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_hyperbolicsinecosineintegrals' class=toc>hyperbolicsinecosineintegrals</a><br>
<a href='#sub_sinecosineintegrals' class=toc>sinecosineintegrals</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_hyperbolicsinecosineintegrals'></a><h3 class=pageheader><code>hyperbolicsinecosineintegrals</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Hyperbolic sine and cosine integrals
# 
# Approximates the integrals
# 
#                            x
#                            -
#                           | |   cosh t - 1
#   Chi(x) = eul + ln x +   |    -----------  dt,
#                         | |          t
#                          -
#                          0
# 
#               x
#               -
#              | |  sinh t
#   Shi(x) =   |    ------  dt
#            | |       t
#             -
#             0
# 
# where eul = 0.57721566490153286061 is Euler's constant.
# The integrals are evaluated by power series for x &lt; 8
# and by Chebyshev expansions for x between 8 and 88.
# For large x, both functions approach exp(x)/2x.
# Arguments greater than 88 in magnitude return MAXNUM.
# 
# 
# ACCURACY:
# 
# Test interval 0 to 88.
#                      Relative error:
# arithmetic   function  # trials      peak         rms
#    IEEE         Shi      30000       6.9e-16     1.6e-16
#        Absolute error, except relative when |Chi| &gt; 1:
#    IEEE         Chi      30000       8.4e-16     1.4e-16
# 
# Cephes Math Library Release 2.8:  June, 2000
# Copyright 1984, 1987, 2000 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   shi, chi = xalglib.hyperbolicsinecosineintegrals(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  shi:        float
          chi:        float

</div></pre>
<a name='sub_sinecosineintegrals'></a><h3 class=pageheader><code>sinecosineintegrals</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Sine and cosine integrals
# 
# Evaluates the integrals
# 
#                          x
#                          -
#                         |  cos t - 1
#   Ci(x) = eul + ln x +  |  --------- dt,
#                         |      t
#                        -
#                         0
#             x
#             -
#            |  sin t
#   Si(x) =  |  ----- dt
#            |    t
#           -
#            0
# 
# where eul = 0.57721566490153286061 is Euler's constant.
# The integrals are approximated by rational functions.
# For x &gt; 8 auxiliary functions f(x) and g(x) are employed
# such that
# 
# Ci(x) = f(x) sin(x) - g(x) cos(x)
# Si(x) = pi/2 - f(x) cos(x) - g(x) sin(x)
# 
# 
# ACCURACY:
#    Test interval = [0,50].
# Absolute error, except relative when &gt; 1:
# arithmetic   function   # trials      peak         rms
#    IEEE        Si        30000       4.4e-16     7.3e-17
#    IEEE        Ci        30000       6.9e-16     5.1e-17
# 
# Cephes Math Library Release 2.1:  January, 1989
# Copyright 1984, 1987, 1989 by Stephen L. Moshier
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   si, ci = xalglib.sinecosineintegrals(x)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  si:         float
          ci:         float

</div></pre>
<a name=unit_variancetests></a><h2 class=pageheader><code>variancetests</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_ftest' class=toc>ftest</a><br>
<a href='#sub_onesamplevariancetest' class=toc>onesamplevariancetest</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_ftest'></a><h3 class=pageheader><code>ftest</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Two-sample F-test
# 
# This test checks three hypotheses about dispersions of the given  samples.
# The following tests are performed:
#     * two-tailed test (null hypothesis - the dispersions are equal)
#     * left-tailed test (null hypothesis  -  the  dispersion  of  the first
#       sample is greater than or equal to  the  dispersion  of  the  second
#       sample).
#     * right-tailed test (null hypothesis - the  dispersion  of  the  first
#       sample is less than or equal to the dispersion of the second sample)
# 
# The test is based on the following assumptions:
#     * the given samples have normal distributions
#     * the samples are independent.
# 
# Input parameters:
#     X   -   sample 1. Array whose index goes from 0 to N-1.
#     N   -   sample size.
#     Y   -   sample 2. Array whose index goes from 0 to M-1.
#     M   -   sample size.
# 
# Output parameters:
#     BothTails   -   p-value for two-tailed test.
#                     If BothTails is less than the given significance level
#                     the null hypothesis is rejected.
#     LeftTail    -   p-value for left-tailed test.
#                     If LeftTail is less than the given significance level,
#                     the null hypothesis is rejected.
#     RightTail   -   p-value for right-tailed test.
#                     If RightTail is less than the given significance level
#                     the null hypothesis is rejected.
# 
#   -- ALGLIB --
#      Copyright 19.09.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   bothtails, lefttail, righttail = xalglib.ftest(x, n, y, m)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          y:          1D array/list of float
          m:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  bothtails:  float
          lefttail:   float
          righttail:  float

</div></pre>
<a name='sub_onesamplevariancetest'></a><h3 class=pageheader><code>onesamplevariancetest</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# One-sample chi-square test
# 
# This test checks three hypotheses about the dispersion of the given sample
# The following tests are performed:
#     * two-tailed test (null hypothesis - the dispersion equals  the  given
#       number)
#     * left-tailed test (null hypothesis - the dispersion is  greater  than
#       or equal to the given number)
#     * right-tailed test (null hypothesis  -  dispersion is  less  than  or
#       equal to the given number).
# 
# Test is based on the following assumptions:
#     * the given sample has a normal distribution.
# 
# Input parameters:
#     X           -   sample 1. Array whose index goes from 0 to N-1.
#     N           -   size of the sample.
#     Variance    -   dispersion value to compare with.
# 
# Output parameters:
#     BothTails   -   p-value for two-tailed test.
#                     If BothTails is less than the given significance level
#                     the null hypothesis is rejected.
#     LeftTail    -   p-value for left-tailed test.
#                     If LeftTail is less than the given significance level,
#                     the null hypothesis is rejected.
#     RightTail   -   p-value for right-tailed test.
#                     If RightTail is less than the given significance level
#                     the null hypothesis is rejected.
# 
#   -- ALGLIB --
#      Copyright 19.09.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   bothtails, lefttail, righttail = xalglib.onesamplevariancetest(x, n, variance)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          variance:   float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  bothtails:  float
          lefttail:   float
          righttail:  float

</div></pre>
<a name=unit_wsr></a><h2 class=pageheader><code>wsr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_wilcoxonsignedranktest' class=toc>wilcoxonsignedranktest</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_wilcoxonsignedranktest'></a><h3 class=pageheader><code>wilcoxonsignedranktest</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# Wilcoxon signed-rank test
# 
# This test checks three hypotheses about the median  of  the  given sample.
# The following tests are performed:
#     * two-tailed test (null hypothesis - the median is equal to the  given
#       value)
#     * left-tailed test (null hypothesis - the median is  greater  than  or
#       equal to the given value)
#     * right-tailed test (null hypothesis  -  the  median  is  less than or
#       equal to the given value)
# 
# Requirements:
#     * the scale of measurement should be ordinal, interval or  ratio (i.e.
#       the test could not be applied to nominal variables).
#     * the distribution should be continuous and symmetric relative to  its
#       median.
#     * number of distinct values in the X array should be greater than 4
# 
# The test is non-parametric and doesn't require distribution X to be normal
# 
# Input parameters:
#     X       -   sample. Array whose index goes from 0 to N-1.
#     N       -   size of the sample.
#     Median  -   assumed median value.
# 
# Output parameters:
#     BothTails   -   p-value for two-tailed test.
#                     If BothTails is less than the given significance level
#                     the null hypothesis is rejected.
#     LeftTail    -   p-value for left-tailed test.
#                     If LeftTail is less than the given significance level,
#                     the null hypothesis is rejected.
#     RightTail   -   p-value for right-tailed test.
#                     If RightTail is less than the given significance level
#                     the null hypothesis is rejected.
# 
# To calculate p-values, special approximation is used. This method lets  us
# calculate p-values with two decimal places in interval [0.0001, 1].
# 
# &quot;Two decimal places&quot; does not sound very impressive, but in  practice  the
# relative error of less than 1% is enough to make a decision.
# 
# There is no approximation outside the [0.0001, 1] interval. Therefore,  if
# the significance level outlies this interval, the test returns 0.0001.
# 
#   -- ALGLIB --
#      Copyright 08.09.2006 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   bothtails, lefttail, righttail = xalglib.wilcoxonsignedranktest(x, n, e)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     x:          1D array/list of float
          n:          int
          e:          float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  bothtails:  float
          lefttail:   float
          righttail:  float

</div></pre>
<a name=unit_xdebug></a><h2 class=pageheader><code>xdebug</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_xdebugb1appendcopy' class=toc>xdebugb1appendcopy</a><br>
<a href='#sub_xdebugb1count' class=toc>xdebugb1count</a><br>
<a href='#sub_xdebugb1not' class=toc>xdebugb1not</a><br>
<a href='#sub_xdebugb1outeven' class=toc>xdebugb1outeven</a><br>
<a href='#sub_xdebugb2count' class=toc>xdebugb2count</a><br>
<a href='#sub_xdebugb2not' class=toc>xdebugb2not</a><br>
<a href='#sub_xdebugb2outsin' class=toc>xdebugb2outsin</a><br>
<a href='#sub_xdebugb2transpose' class=toc>xdebugb2transpose</a><br>
<a href='#sub_xdebugc1appendcopy' class=toc>xdebugc1appendcopy</a><br>
<a href='#sub_xdebugc1neg' class=toc>xdebugc1neg</a><br>
<a href='#sub_xdebugc1outeven' class=toc>xdebugc1outeven</a><br>
<a href='#sub_xdebugc1sum' class=toc>xdebugc1sum</a><br>
<a href='#sub_xdebugc2neg' class=toc>xdebugc2neg</a><br>
<a href='#sub_xdebugc2outsincos' class=toc>xdebugc2outsincos</a><br>
<a href='#sub_xdebugc2sum' class=toc>xdebugc2sum</a><br>
<a href='#sub_xdebugc2transpose' class=toc>xdebugc2transpose</a><br>
<a href='#sub_xdebugi1appendcopy' class=toc>xdebugi1appendcopy</a><br>
<a href='#sub_xdebugi1neg' class=toc>xdebugi1neg</a><br>
<a href='#sub_xdebugi1outeven' class=toc>xdebugi1outeven</a><br>
<a href='#sub_xdebugi1sum' class=toc>xdebugi1sum</a><br>
<a href='#sub_xdebugi2neg' class=toc>xdebugi2neg</a><br>
<a href='#sub_xdebugi2outsin' class=toc>xdebugi2outsin</a><br>
<a href='#sub_xdebugi2sum' class=toc>xdebugi2sum</a><br>
<a href='#sub_xdebugi2transpose' class=toc>xdebugi2transpose</a><br>
<a href='#sub_xdebuginitrecord1' class=toc>xdebuginitrecord1</a><br>
<a href='#sub_xdebugmaskedbiasedproductsum' class=toc>xdebugmaskedbiasedproductsum</a><br>
<a href='#sub_xdebugr1appendcopy' class=toc>xdebugr1appendcopy</a><br>
<a href='#sub_xdebugr1internalcopyandsum' class=toc>xdebugr1internalcopyandsum</a><br>
<a href='#sub_xdebugr1neg' class=toc>xdebugr1neg</a><br>
<a href='#sub_xdebugr1outeven' class=toc>xdebugr1outeven</a><br>
<a href='#sub_xdebugr1sum' class=toc>xdebugr1sum</a><br>
<a href='#sub_xdebugr2internalcopyandsum' class=toc>xdebugr2internalcopyandsum</a><br>
<a href='#sub_xdebugr2neg' class=toc>xdebugr2neg</a><br>
<a href='#sub_xdebugr2outsin' class=toc>xdebugr2outsin</a><br>
<a href='#sub_xdebugr2sum' class=toc>xdebugr2sum</a><br>
<a href='#sub_xdebugr2transpose' class=toc>xdebugr2transpose</a><br>
<a href='#sub_xdebugupdaterecord1' class=toc>xdebugupdaterecord1</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_xdebugb1appendcopy'></a><h3 class=pageheader><code>xdebugb1appendcopy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Appends copy of array to itself.
# Array is passed using &quot;var&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.xdebugb1appendcopy(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          1D array/list of bool

</div></pre>
<a name='sub_xdebugb1count'></a><h3 class=pageheader><code>xdebugb1count</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Counts number of True values in the boolean 1D array.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.xdebugb1count(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_xdebugb1not'></a><h3 class=pageheader><code>xdebugb1not</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Replace all values in array by NOT(a[i]).
# Array is passed using &quot;shared&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.xdebugb1not(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_xdebugb1outeven'></a><h3 class=pageheader><code>xdebugb1outeven</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Generate N-element array with even-numbered elements set to True.
# Array is passed using &quot;out&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.xdebugb1outeven(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          1D array/list of bool

</div></pre>
<a name='sub_xdebugb2count'></a><h3 class=pageheader><code>xdebugb2count</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Counts number of True values in the boolean 2D array.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.xdebugb2count(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_xdebugb2not'></a><h3 class=pageheader><code>xdebugb2not</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Replace all values in array by NOT(a[i]).
# Array is passed using &quot;shared&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.xdebugb2not(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of bool
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_xdebugb2outsin'></a><h3 class=pageheader><code>xdebugb2outsin</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Generate MxN matrix with elements set to &quot;Sin(3*I+5*J)&gt;0&quot;
# Array is passed using &quot;out&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.xdebugb2outsin(m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of bool

</div></pre>
<a name='sub_xdebugb2transpose'></a><h3 class=pageheader><code>xdebugb2transpose</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Transposes array.
# Array is passed using &quot;var&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.xdebugb2transpose(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of bool

</div></pre>
<a name='sub_xdebugc1appendcopy'></a><h3 class=pageheader><code>xdebugc1appendcopy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Appends copy of array to itself.
# Array is passed using &quot;var&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.xdebugc1appendcopy(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          1D array/list of complex

</div></pre>
<a name='sub_xdebugc1neg'></a><h3 class=pageheader><code>xdebugc1neg</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Replace all values in array by -A[I]
# Array is passed using &quot;shared&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.xdebugc1neg(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_xdebugc1outeven'></a><h3 class=pageheader><code>xdebugc1outeven</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Generate N-element array with even-numbered A[K] set to (x,y) = (K*0.25, K*0.125)
# and odd-numbered ones are set to 0.
# 
# Array is passed using &quot;out&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.xdebugc1outeven(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          1D array/list of complex

</div></pre>
<a name='sub_xdebugc1sum'></a><h3 class=pageheader><code>xdebugc1sum</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Returns sum of elements in the array.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.xdebugc1sum(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     complex

</div></pre>
<a name='sub_xdebugc2neg'></a><h3 class=pageheader><code>xdebugc2neg</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Replace all values in array by -a[i,j]
# Array is passed using &quot;shared&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.xdebugc2neg(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_xdebugc2outsincos'></a><h3 class=pageheader><code>xdebugc2outsincos</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Generate MxN matrix with elements set to &quot;Sin(3*I+5*J),Cos(3*I+5*J)&quot;
# Array is passed using &quot;out&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.xdebugc2outsincos(m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of complex

</div></pre>
<a name='sub_xdebugc2sum'></a><h3 class=pageheader><code>xdebugc2sum</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Returns sum of elements in the array.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.xdebugc2sum(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     complex

</div></pre>
<a name='sub_xdebugc2transpose'></a><h3 class=pageheader><code>xdebugc2transpose</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Transposes array.
# Array is passed using &quot;var&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.xdebugc2transpose(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of complex
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of complex

</div></pre>
<a name='sub_xdebugi1appendcopy'></a><h3 class=pageheader><code>xdebugi1appendcopy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Appends copy of array to itself.
# Array is passed using &quot;var&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.xdebugi1appendcopy(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          1D array/list of int

</div></pre>
<a name='sub_xdebugi1neg'></a><h3 class=pageheader><code>xdebugi1neg</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Replace all values in array by -A[I]
# Array is passed using &quot;shared&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.xdebugi1neg(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_xdebugi1outeven'></a><h3 class=pageheader><code>xdebugi1outeven</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Generate N-element array with even-numbered A[I] set to I, and odd-numbered
# ones set to 0.
# 
# Array is passed using &quot;out&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.xdebugi1outeven(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          1D array/list of int

</div></pre>
<a name='sub_xdebugi1sum'></a><h3 class=pageheader><code>xdebugi1sum</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Returns sum of elements in the array.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.xdebugi1sum(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_xdebugi2neg'></a><h3 class=pageheader><code>xdebugi2neg</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Replace all values in array by -a[i,j]
# Array is passed using &quot;shared&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.xdebugi2neg(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of int
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_xdebugi2outsin'></a><h3 class=pageheader><code>xdebugi2outsin</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Generate MxN matrix with elements set to &quot;Sign(Sin(3*I+5*J))&quot;
# Array is passed using &quot;out&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.xdebugi2outsin(m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of int

</div></pre>
<a name='sub_xdebugi2sum'></a><h3 class=pageheader><code>xdebugi2sum</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Returns sum of elements in the array.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.xdebugi2sum(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     int

</div></pre>
<a name='sub_xdebugi2transpose'></a><h3 class=pageheader><code>xdebugi2transpose</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Transposes array.
# Array is passed using &quot;var&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.xdebugi2transpose(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of int

</div></pre>
<a name='sub_xdebuginitrecord1'></a><h3 class=pageheader><code>xdebuginitrecord1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Creates and returns XDebugRecord1 structure:
# * integer and complex fields of Rec1 are set to 1 and 1+i correspondingly
# * array field of Rec1 is set to [2,3]
# 
#   -- ALGLIB --
#      Copyright 27.05.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   rec1 = xalglib.xdebuginitrecord1()
<span style='font-weight: bold; color: navy;'>ARGS:</span>     
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  rec1:       class xalglib.xdebugrecord1

</div></pre>
<a name='sub_xdebugmaskedbiasedproductsum'></a><h3 class=pageheader><code>xdebugmaskedbiasedproductsum</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Returns sum of a[i,j]*(1+b[i,j]) such that c[i,j] is True
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.xdebugmaskedbiasedproductsum(m, n, a, b, c)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
          a:          2D array/list of float
          b:          2D array/list of float
          c:          2D array/list of bool
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_xdebugr1appendcopy'></a><h3 class=pageheader><code>xdebugr1appendcopy</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Appends copy of array to itself.
# Array is passed using &quot;var&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.xdebugr1appendcopy(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          1D array/list of float

</div></pre>
<a name='sub_xdebugr1internalcopyandsum'></a><h3 class=pageheader><code>xdebugr1internalcopyandsum</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Returns sum of elements in the array.
# 
# Internally it creates a copy of the array.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.xdebugr1internalcopyandsum(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_xdebugr1neg'></a><h3 class=pageheader><code>xdebugr1neg</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Replace all values in array by -A[I]
# Array is passed using &quot;shared&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.xdebugr1neg(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_xdebugr1outeven'></a><h3 class=pageheader><code>xdebugr1outeven</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Generate N-element array with even-numbered A[I] set to I*0.25,
# and odd-numbered ones are set to 0.
# 
# Array is passed using &quot;out&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.xdebugr1outeven(n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          1D array/list of float

</div></pre>
<a name='sub_xdebugr1sum'></a><h3 class=pageheader><code>xdebugr1sum</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Returns sum of elements in the array.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.xdebugr1sum(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          1D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_xdebugr2internalcopyandsum'></a><h3 class=pageheader><code>xdebugr2internalcopyandsum</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Returns sum of elements in the array.
# 
# Internally it creates a copy of a.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.xdebugr2internalcopyandsum(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_xdebugr2neg'></a><h3 class=pageheader><code>xdebugr2neg</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Replace all values in array by -a[i,j]
# Array is passed using &quot;shared&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.xdebugr2neg(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> a
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>
<a name='sub_xdebugr2outsin'></a><h3 class=pageheader><code>xdebugr2outsin</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Generate MxN matrix with elements set to &quot;Sin(3*I+5*J)&quot;
# Array is passed using &quot;out&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.xdebugr2outsin(m, n)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     m:          int
          n:          int
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of float

</div></pre>
<a name='sub_xdebugr2sum'></a><h3 class=pageheader><code>xdebugr2sum</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Returns sum of elements in the array.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   result = xalglib.xdebugr2sum(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  result:     float

</div></pre>
<a name='sub_xdebugr2transpose'></a><h3 class=pageheader><code>xdebugr2transpose</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Transposes array.
# Array is passed using &quot;var&quot; convention.
# 
#   -- ALGLIB --
#      Copyright 11.10.2013 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   a = xalglib.xdebugr2transpose(a)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     a:          2D array/list of float
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  a:          2D array/list of float

</div></pre>
<a name='sub_xdebugupdaterecord1'></a><h3 class=pageheader><code>xdebugupdaterecord1</code> function</h3>
<pre class=source>
<div style='color: DarkCyan; margin-top: 0; margin-bottom: 0;'>
#
# This is debug function intended for testing ALGLIB interface generator.
# Never use it in any real life project.
# 
# Creates and returns XDebugRecord1 structure:
# * integer and complex fields of Rec1 are set to 1 and 1+i correspondingly
# * array field of Rec1 is set to [2,3]
# 
#   -- ALGLIB --
#      Copyright 27.05.2014 by Bochkanov Sergey
#

</div><div style='margin-top: 0; margin-bottom: 0;'><span style='font-weight: bold; color: black;'>SYNTAX:</span>   xalglib.xdebugupdaterecord1(rec1)
<span style='font-weight: bold; color: navy;'>ARGS:</span>     rec1:       class xalglib.xdebugrecord1
<span style='font-weight: bold; color: navy;'>MODIFIES:</span> rec1
<span style='font-weight: bold; color: navy;'>RETURNS:</span>  None

</div></pre>

</body>
</html>